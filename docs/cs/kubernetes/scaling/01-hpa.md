---
tags:
  - Kubernetes
  - HPA
  - Autoscaling
  - Metrics
  - Performance
---

# HPA ë©”íŠ¸ë¦­ê³¼ ë™ì‘ ì›ë¦¬

## ğŸ¯ ê°œìš”

2019ë…„ ë¸”ë™ í”„ë¼ì´ë°ì´, Targetì˜ ì˜¨ë¼ì¸ ì‡¼í•‘ëª°ì— **í‰ì†Œì˜ 50ë°° íŠ¸ë˜í”½**ì´ ëª°ë ¸ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë†€ëê²Œë„ ì„œë¹„ìŠ¤ëŠ” ì¤‘ë‹¨ ì—†ì´ ì•ˆì •ì ìœ¼ë¡œ ë™ì‘í–ˆìŠµë‹ˆë‹¤. ê·¸ ë¹„ë°€ì€ **Horizontal Pod Autoscaler(HPA)**ì— ìˆì—ˆìŠµë‹ˆë‹¤.

ì˜¤ì „ 9ì‹œ íŠ¸ë˜í”½ì´ ê¸‰ì¦í•˜ê¸° ì‹œì‘í•˜ì, HPAëŠ” CPU ì‚¬ìš©ë¥  80%ë¥¼ ê°ì§€í•˜ê³  **30ì´ˆ ë§Œì— Pod ìˆ˜ë¥¼ 10ê°œì—ì„œ 100ê°œë¡œ ìë™ í™•ì¥**í–ˆìŠµë‹ˆë‹¤. ì˜¤í›„ 6ì‹œ íŠ¸ë˜í”½ì´ ì¤„ì–´ë“¤ì ë‹¤ì‹œ **ì ì§„ì ìœ¼ë¡œ 20ê°œê¹Œì§€ ì¶•ì†Œ**í–ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë“  ê³¼ì •ì—ì„œ **ì¸ê°„ì˜ ê°œì…ì€ ì „í˜€ ì—†ì—ˆìŠµë‹ˆë‹¤.**

ì „í†µì ì¸ í™˜ê²½ì—ì„œëŠ” íŠ¸ë˜í”½ ê¸‰ì¦ì— ëŒ€ë¹„í•´ í•­ìƒ ìµœëŒ€ ìš©ëŸ‰ì˜ ì„œë²„ë¥¼ ìš´ì˜í•´ì•¼ í–ˆì§€ë§Œ, HPAëŠ” **ì‹¤ì‹œê°„ ìˆ˜ìš”ì— ë§ì¶° ë¦¬ì†ŒìŠ¤ë¥¼ ìë™ ì¡°ì ˆ**í•¨ìœ¼ë¡œì¨ ë¹„ìš© íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ë™ì‹œì— ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ğŸ“– HPA ì•„í‚¤í…ì²˜ì™€ ë™ì‘ ì›ë¦¬

### HPA Controller ë‚´ë¶€ ë™ì‘

```mermaid
graph TB
    subgraph "HPA Controller Loop"
        HPA[HPA Controller] --> MC[Metrics Collection]
        MC --> MA[Metrics Analysis]
        MA --> SR[Scaling Decision]
        SR --> UP[Update Deployment]
        UP --> HPA
    end
    
    subgraph "Metrics Sources"
        MS[Metrics Server]
        PM[Prometheus]
        CM[Custom Metrics API]
        EM[External Metrics API]
    end
    
    subgraph "Target Resources"
        D[Deployment]
        RS[ReplicaSet] 
        SS[StatefulSet]
        PODS[Pod Replicas]
    end
    
    MC --> MS
    MC --> PM
    MC --> CM
    MC --> EM
    
    UP --> D
    D --> RS
    RS --> PODS
    
    style HPA fill:#e1f5fe
    style SR fill:#f3e5f5
    style PODS fill:#fff3e0
```

### HPA ì»¨íŠ¸ë¡¤ ë£¨í”„ êµ¬í˜„

```python
class HPAController:
    def __init__(self):
        self.sync_period = 15  # seconds
        self.tolerance = 0.1   # 10% tolerance
        self.stabilization_window = 300  # 5 minutes
        self.scale_up_cooldown = 60     # 1 minute
        self.scale_down_cooldown = 300  # 5 minutes
        
    def reconcile_loop(self, hpa):
        """HPA ì»¨íŠ¸ë¡¤ ë£¨í”„ ë©”ì¸ ë¡œì§"""
        while True:
            try:
                # 1. í˜„ì¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                current_metrics = self.collect_metrics(hpa)
                
                # 2. ëª©í‘œ ë ˆí”Œë¦¬ì¹´ ìˆ˜ ê³„ì‚°
                desired_replicas = self.calculate_desired_replicas(
                    hpa, current_metrics
                )
                
                # 3. ìŠ¤ì¼€ì¼ë§ ê²°ì • ë° ì‹¤í–‰
                if self.should_scale(hpa, desired_replicas):
                    self.execute_scaling(hpa, desired_replicas)
                
                # 4. ìƒíƒœ ì—…ë°ì´íŠ¸
                self.update_hpa_status(hpa, current_metrics, desired_replicas)
                
                time.sleep(self.sync_period)
                
            except Exception as e:
                self.handle_error(hpa, e)
                time.sleep(self.sync_period)
    
    def collect_metrics(self, hpa):
        """ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        metrics = {}
        
        for metric_spec in hpa.spec.metrics:
            if metric_spec.type == "Resource":
                # CPU, Memory ë“± ë¦¬ì†ŒìŠ¤ ë©”íŠ¸ë¦­
                metrics[metric_spec.resource.name] = self.get_resource_metrics(
                    hpa.spec.scaleTargetRef, 
                    metric_spec.resource.name
                )
            elif metric_spec.type == "Pods":
                # Podë³„ ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­
                metrics[metric_spec.pods.metric.name] = self.get_pods_metrics(
                    hpa.spec.scaleTargetRef,
                    metric_spec.pods.metric
                )
            elif metric_spec.type == "Object":
                # ì˜¤ë¸Œì íŠ¸ ë©”íŠ¸ë¦­ (Service, Ingress ë“±)
                metrics[metric_spec.object.metric.name] = self.get_object_metrics(
                    metric_spec.object.describedObject,
                    metric_spec.object.metric
                )
            elif metric_spec.type == "External":
                # ì™¸ë¶€ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
                metrics[metric_spec.external.metric.name] = self.get_external_metrics(
                    metric_spec.external.metric
                )
        
        return metrics
    
    def calculate_desired_replicas(self, hpa, current_metrics):
        """ëª©í‘œ ë ˆí”Œë¦¬ì¹´ ìˆ˜ ê³„ì‚°"""
        current_replicas = self.get_current_replicas(hpa.spec.scaleTargetRef)
        proposals = []
        
        for metric_name, metric_data in current_metrics.items():
            metric_spec = self.get_metric_spec(hpa, metric_name)
            
            if metric_spec.type == "Resource":
                # ë¦¬ì†ŒìŠ¤ ë©”íŠ¸ë¦­ ê¸°ë°˜ ê³„ì‚°
                target_utilization = metric_spec.resource.target.averageUtilization
                current_utilization = metric_data['utilization']
                
                desired = math.ceil(
                    current_replicas * (current_utilization / target_utilization)
                )
                
            elif metric_spec.type == "Pods":
                # Pod ë©”íŠ¸ë¦­ ê¸°ë°˜ ê³„ì‚°
                target_value = metric_spec.pods.target.averageValue
                current_value = metric_data['averageValue']
                
                desired = math.ceil(
                    current_replicas * (current_value / target_value)
                )
            
            proposals.append({
                'metric': metric_name,
                'current_replicas': current_replicas,
                'desired_replicas': desired,
                'reason': f"based on {metric_name}"
            })
        
        # ê°€ì¥ í° ìŠ¤ì¼€ì¼ë§ ìš”êµ¬ì‚¬í•­ ì„ íƒ
        return max(proposals, key=lambda x: x['desired_replicas'])
    
    def should_scale(self, hpa, desired_replicas_info):
        """ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰ ì—¬ë¶€ ê²°ì •"""
        current_replicas = self.get_current_replicas(hpa.spec.scaleTargetRef)
        desired_replicas = desired_replicas_info['desired_replicas']
        
        # ìµœì†Œ/ìµœëŒ€ ì œì•½ ì ìš©
        min_replicas = hpa.spec.minReplicas or 1
        max_replicas = hpa.spec.maxReplicas
        
        desired_replicas = max(min_replicas, min(max_replicas, desired_replicas))
        
        # í—ˆìš© ì˜¤ì°¨ ë‚´ ë³€í™”ëŠ” ë¬´ì‹œ
        change_ratio = abs(desired_replicas - current_replicas) / current_replicas
        if change_ratio < self.tolerance:
            return False
        
        # ì¿¨ë‹¤ìš´ ê¸°ê°„ ì²´í¬
        last_scale_time = self.get_last_scale_time(hpa)
        now = time.time()
        
        if desired_replicas > current_replicas:
            # Scale up
            if now - last_scale_time < self.scale_up_cooldown:
                return False
        else:
            # Scale down
            if now - last_scale_time < self.scale_down_cooldown:
                return False
        
        return True
    
    def execute_scaling(self, hpa, desired_replicas_info):
        """ì‹¤ì œ ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰"""
        target_ref = hpa.spec.scaleTargetRef
        desired_replicas = desired_replicas_info['desired_replicas']
        
        # Scale subresource ì—…ë°ì´íŠ¸
        scale = self.get_scale_subresource(target_ref)
        scale.spec.replicas = desired_replicas
        
        self.update_scale_subresource(target_ref, scale)
        
        # ì´ë²¤íŠ¸ ê¸°ë¡
        self.record_event(hpa, {
            'type': 'Normal',
            'reason': 'SuccessfulRescale',
            'message': f"New size: {desired_replicas}; reason: {desired_replicas_info['reason']}"
        })
        
        # ë§ˆì§€ë§‰ ìŠ¤ì¼€ì¼ë§ ì‹œê°„ ê¸°ë¡
        self.update_last_scale_time(hpa, time.time())
```

## ğŸ“Š ë©”íŠ¸ë¦­ íƒ€ì…ê³¼ ìˆ˜ì§‘

### Resource ë©”íŠ¸ë¦­ (CPU/Memory)

```python
class ResourceMetricsCollector:
    def __init__(self):
        self.metrics_server_client = MetricsServerClient()
        
    def collect_cpu_metrics(self, deployment):
        """CPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¶„ì„"""
        pods = self.get_deployment_pods(deployment)
        cpu_data = []
        
        for pod in pods:
            # Pod ë©”íŠ¸ë¦­ ì¡°íšŒ
            pod_metrics = self.metrics_server_client.get_pod_metrics(
                pod.metadata.name, 
                pod.metadata.namespace
            )
            
            if pod_metrics and pod.status.phase == "Running":
                # CPU ì‚¬ìš©ëŸ‰ (millicores)
                cpu_usage = sum(
                    container.usage['cpu'] 
                    for container in pod_metrics.containers
                )
                
                # CPU ìš”ì²­ëŸ‰ (millicores)
                cpu_requests = sum(
                    container.resources.requests.get('cpu', 0)
                    for container in pod.spec.containers
                )
                
                if cpu_requests > 0:
                    utilization = (cpu_usage / cpu_requests) * 100
                    cpu_data.append({
                        'pod': pod.metadata.name,
                        'usage': cpu_usage,
                        'requests': cpu_requests,
                        'utilization': utilization
                    })
        
        if not cpu_data:
            return None
            
        return {
            'averageUtilization': sum(d['utilization'] for d in cpu_data) / len(cpu_data),
            'currentAverageValue': sum(d['usage'] for d in cpu_data) / len(cpu_data),
            'pods_count': len(cpu_data),
            'individual_metrics': cpu_data
        }
    
    def collect_memory_metrics(self, deployment):
        """Memory ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¶„ì„"""
        pods = self.get_deployment_pods(deployment)
        memory_data = []
        
        for pod in pods:
            pod_metrics = self.metrics_server_client.get_pod_metrics(
                pod.metadata.name,
                pod.metadata.namespace  
            )
            
            if pod_metrics and pod.status.phase == "Running":
                # Memory ì‚¬ìš©ëŸ‰ (bytes)
                memory_usage = sum(
                    self.parse_memory_value(container.usage['memory'])
                    for container in pod_metrics.containers
                )
                
                # Memory ìš”ì²­ëŸ‰ (bytes)
                memory_requests = sum(
                    self.parse_memory_value(
                        container.resources.requests.get('memory', '0')
                    )
                    for container in pod.spec.containers
                )
                
                if memory_requests > 0:
                    utilization = (memory_usage / memory_requests) * 100
                    memory_data.append({
                        'pod': pod.metadata.name,
                        'usage': memory_usage,
                        'requests': memory_requests,
                        'utilization': utilization
                    })
        
        if not memory_data:
            return None
            
        return {
            'averageUtilization': sum(d['utilization'] for d in memory_data) / len(memory_data),
            'currentAverageValue': sum(d['usage'] for d in memory_data) / len(memory_data),
            'pods_count': len(memory_data)
        }
    
    def parse_memory_value(self, memory_str):
        """Memory ê°’ íŒŒì‹± (Ki, Mi, Gi ë“±)"""
        units = {
            'Ki': 1024,
            'Mi': 1024**2, 
            'Gi': 1024**3,
            'Ti': 1024**4,
            'k': 1000,
            'm': 1000**2,
            'g': 1000**3,
            't': 1000**4
        }
        
        if memory_str.isdigit():
            return int(memory_str)
        
        for unit, multiplier in units.items():
            if memory_str.endswith(unit):
                value = float(memory_str[:-len(unit)])
                return int(value * multiplier)
        
        return int(memory_str)
```

### Custom ë©”íŠ¸ë¦­ (Prometheus ì—°ë™)

```python
class CustomMetricsCollector:
    def __init__(self):
        self.prometheus_client = PrometheusClient()
        
    def collect_http_requests_per_second(self, deployment):
        """HTTP RPS ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        # Prometheus ì¿¼ë¦¬
        query = f'''
            sum(rate(http_requests_total{{
                deployment="{deployment.metadata.name}",
                namespace="{deployment.metadata.namespace}"
            }}[2m])) by (pod)
        '''
        
        result = self.prometheus_client.query(query)
        
        if not result:
            return None
        
        pod_metrics = []
        total_rps = 0
        
        for metric in result:
            pod_name = metric['metric']['pod']
            rps_value = float(metric['value'][1])
            
            pod_metrics.append({
                'pod': pod_name,
                'requests_per_second': rps_value
            })
            total_rps += rps_value
        
        return {
            'currentAverageValue': total_rps / len(pod_metrics) if pod_metrics else 0,
            'pods_count': len(pod_metrics),
            'total_rps': total_rps,
            'individual_metrics': pod_metrics
        }
    
    def collect_queue_length(self, queue_name):
        """í ê¸¸ì´ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        query = f'queue_length{{queue="{queue_name}"}}'
        result = self.prometheus_client.query(query)
        
        if result and len(result) > 0:
            return {
                'currentValue': float(result[0]['value'][1]),
                'timestamp': result[0]['value'][0]
            }
        
        return None
    
    def collect_application_lag(self, app_selector):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì§€ì—° ì‹œê°„ ë©”íŠ¸ë¦­"""
        query = f'''
            histogram_quantile(0.95,
                rate(http_request_duration_seconds_bucket{{
                    {app_selector}
                }}[5m])
            )
        '''
        
        result = self.prometheus_client.query(query)
        
        if result and len(result) > 0:
            return {
                'p95_latency_seconds': float(result[0]['value'][1]),
                'timestamp': result[0]['value'][0]
            }
        
        return None
```

### External ë©”íŠ¸ë¦­ (AWS CloudWatch)

```python
class ExternalMetricsCollector:
    def __init__(self):
        self.cloudwatch_client = boto3.client('cloudwatch')
        
    def collect_sqs_queue_length(self, queue_url):
        """SQS í ê¸¸ì´ ë©”íŠ¸ë¦­"""
        try:
            response = self.cloudwatch_client.get_metric_statistics(
                Namespace='AWS/SQS',
                MetricName='ApproximateNumberOfMessages',
                Dimensions=[
                    {
                        'Name': 'QueueName',
                        'Value': queue_url.split('/')[-1]
                    }
                ],
                StartTime=datetime.utcnow() - timedelta(minutes=5),
                EndTime=datetime.utcnow(),
                Period=300,  # 5 minutes
                Statistics=['Average']
            )
            
            if response['Datapoints']:
                latest = max(response['Datapoints'], key=lambda x: x['Timestamp'])
                return {
                    'currentValue': int(latest['Average']),
                    'timestamp': latest['Timestamp']
                }
                
        except Exception as e:
            print(f"Error collecting SQS metrics: {e}")
            
        return None
    
    def collect_alb_request_count(self, load_balancer_name):
        """ALB ìš”ì²­ ìˆ˜ ë©”íŠ¸ë¦­"""
        try:
            response = self.cloudwatch_client.get_metric_statistics(
                Namespace='AWS/ApplicationELB',
                MetricName='RequestCount',
                Dimensions=[
                    {
                        'Name': 'LoadBalancer',
                        'Value': load_balancer_name
                    }
                ],
                StartTime=datetime.utcnow() - timedelta(minutes=10),
                EndTime=datetime.utcnow(),
                Period=300,
                Statistics=['Sum']
            )
            
            if response['Datapoints']:
                # ë¶„ë‹¹ ìš”ì²­ ìˆ˜ ê³„ì‚°
                total_requests = sum(dp['Sum'] for dp in response['Datapoints'])
                duration_minutes = len(response['Datapoints']) * 5
                requests_per_minute = total_requests / duration_minutes if duration_minutes > 0 else 0
                
                return {
                    'currentValue': requests_per_minute,
                    'totalRequests': total_requests
                }
                
        except Exception as e:
            print(f"Error collecting ALB metrics: {e}")
            
        return None
```

## ğŸ›ï¸ ê³ ê¸‰ HPA ì„¤ì •

### Behavior ì„¤ì • (ìŠ¤ì¼€ì¼ë§ ì •ì±…)

```python
class HPABehaviorConfig:
    def __init__(self):
        self.scaling_policies = {}
        
    def create_aggressive_scale_up_config(self):
        """ê³µê²©ì  ìŠ¤ì¼€ì¼ ì—… ì„¤ì •"""
        return {
            "apiVersion": "autoscaling/v2",
            "kind": "HorizontalPodAutoscaler", 
            "metadata": {"name": "aggressive-hpa"},
            "spec": {
                "scaleTargetRef": {
                    "apiVersion": "apps/v1",
                    "kind": "Deployment", 
                    "name": "web-app"
                },
                "minReplicas": 2,
                "maxReplicas": 100,
                "metrics": [
                    {
                        "type": "Resource",
                        "resource": {
                            "name": "cpu",
                            "target": {
                                "type": "Utilization",
                                "averageUtilization": 70
                            }
                        }
                    }
                ],
                "behavior": {
                    "scaleUp": {
                        "stabilizationWindowSeconds": 60,  # 1ë¶„ ì•ˆì •í™”
                        "policies": [
                            {
                                "type": "Percent",
                                "value": 100,     # 100% ì¦ê°€
                                "periodSeconds": 60
                            },
                            {
                                "type": "Pods", 
                                "value": 10,      # ìµœëŒ€ 10ê°œ Pod ì¶”ê°€
                                "periodSeconds": 60
                            }
                        ],
                        "selectPolicy": "Max"  # ë” í° ê°’ ì„ íƒ
                    },
                    "scaleDown": {
                        "stabilizationWindowSeconds": 300,  # 5ë¶„ ì•ˆì •í™”
                        "policies": [
                            {
                                "type": "Percent",
                                "value": 10,      # 10%ë§Œ ê°ì†Œ
                                "periodSeconds": 60
                            }
                        ]
                    }
                }
            }
        }
    
    def create_conservative_scaling_config(self):
        """ë³´ìˆ˜ì  ìŠ¤ì¼€ì¼ë§ ì„¤ì •"""
        return {
            "behavior": {
                "scaleUp": {
                    "stabilizationWindowSeconds": 300,  # 5ë¶„ ì•ˆì •í™”
                    "policies": [
                        {
                            "type": "Percent",
                            "value": 25,      # 25% ì¦ê°€
                            "periodSeconds": 120
                        },
                        {
                            "type": "Pods",
                            "value": 2,       # ìµœëŒ€ 2ê°œ Pod ì¶”ê°€
                            "periodSeconds": 120
                        }
                    ],
                    "selectPolicy": "Min"  # ë” ì‘ì€ ê°’ ì„ íƒ
                },
                "scaleDown": {
                    "stabilizationWindowSeconds": 600,  # 10ë¶„ ì•ˆì •í™”
                    "policies": [
                        {
                            "type": "Percent", 
                            "value": 5,       # 5%ë§Œ ê°ì†Œ
                            "periodSeconds": 300
                        }
                    ]
                }
            }
        }
    
    def create_time_based_scaling_config(self):
        """ì‹œê°„ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§ ì •ì±…"""
        return {
            "business_hours_policy": {
                "time_range": "09:00-18:00 KST",
                "behavior": {
                    "scaleUp": {
                        "stabilizationWindowSeconds": 30,
                        "policies": [
                            {
                                "type": "Percent",
                                "value": 50,
                                "periodSeconds": 30
                            }
                        ]
                    }
                }
            },
            "off_hours_policy": {
                "time_range": "18:01-08:59 KST",
                "behavior": {
                    "scaleUp": {
                        "stabilizationWindowSeconds": 120,
                        "policies": [
                            {
                                "type": "Percent",
                                "value": 20,
                                "periodSeconds": 120
                            }
                        ]
                    }
                }
            }
        }
```

### ë‹¤ì¤‘ ë©”íŠ¸ë¦­ HPA

```python
class MultiMetricHPA:
    def __init__(self):
        self.metric_combinations = []
        
    def create_comprehensive_hpa(self):
        """í¬ê´„ì  ë©”íŠ¸ë¦­ ê¸°ë°˜ HPA"""
        return {
            "apiVersion": "autoscaling/v2",
            "kind": "HorizontalPodAutoscaler",
            "metadata": {"name": "comprehensive-hpa"},
            "spec": {
                "scaleTargetRef": {
                    "apiVersion": "apps/v1",
                    "kind": "Deployment",
                    "name": "api-server"
                },
                "minReplicas": 3,
                "maxReplicas": 50,
                "metrics": [
                    {
                        "type": "Resource",
                        "resource": {
                            "name": "cpu",
                            "target": {
                                "type": "Utilization", 
                                "averageUtilization": 70
                            }
                        }
                    },
                    {
                        "type": "Resource",
                        "resource": {
                            "name": "memory",
                            "target": {
                                "type": "Utilization",
                                "averageUtilization": 80
                            }
                        }
                    },
                    {
                        "type": "Pods",
                        "pods": {
                            "metric": {
                                "name": "http_requests_per_second"
                            },
                            "target": {
                                "type": "AverageValue",
                                "averageValue": "100"
                            }
                        }
                    },
                    {
                        "type": "Object",
                        "object": {
                            "metric": {
                                "name": "ingress_requests_per_second"
                            },
                            "describedObject": {
                                "apiVersion": "networking.k8s.io/v1",
                                "kind": "Ingress",
                                "name": "api-ingress"
                            },
                            "target": {
                                "type": "Value",
                                "value": "1000"
                            }
                        }
                    },
                    {
                        "type": "External",
                        "external": {
                            "metric": {
                                "name": "sqs_queue_length",
                                "selector": {
                                    "matchLabels": {
                                        "queue": "api-processing-queue"
                                    }
                                }
                            },
                            "target": {
                                "type": "Value", 
                                "value": "50"
                            }
                        }
                    }
                ]
            }
        }
    
    def explain_metric_priority(self):
        """ë©”íŠ¸ë¦­ ìš°ì„ ìˆœìœ„ ì„¤ëª…"""
        return {
            "selection_algorithm": "Maximum scaling requirement wins",
            "example_scenario": {
                "cpu_suggests": 5, 
                "memory_suggests": 8,
                "rps_suggests": 12,
                "queue_suggests": 7,
                "final_decision": 12,
                "reasoning": "RPS ë©”íŠ¸ë¦­ì´ ê°€ì¥ í° ìŠ¤ì¼€ì¼ë§ì„ ìš”êµ¬í•¨"
            },
            "considerations": [
                "ê° ë©”íŠ¸ë¦­ì´ ë…ë¦½ì ìœ¼ë¡œ ê³„ì‚°ë¨",
                "ê°€ì¥ í° ê°’ì´ ì„ íƒë¨",
                "min/max ì œì•½ì€ ë‚˜ì¤‘ì— ì ìš©ë¨",
                "ìŠ¤ì¼€ì¼ë§ ì •ì±…ì€ ìµœì¢… ê²°ì •ì— ì ìš©ë¨"
            ]
        }
```

## ğŸ› ï¸ HPA ìµœì í™” ì „ëµ

### ë©”íŠ¸ë¦­ ì„œë²„ ìµœì í™”

```python
class MetricsServerOptimizer:
    def __init__(self):
        self.optimization_configs = {}
        
    def optimize_metrics_collection(self):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ìµœì í™”"""
        return {
            "kubelet_optimization": {
                "summary_api_cache": {
                    "cache_duration": "10s",
                    "purpose": "ë©”íŠ¸ë¦­ ì¡°íšŒ ì„±ëŠ¥ í–¥ìƒ"
                },
                "metrics_resolution": {
                    "cpu_cfs_period": "ë” ì •í™•í•œ CPU ë©”íŠ¸ë¦­",
                    "memory_working_set": "ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ì¤€"
                }
            },
            "metrics_server_tuning": {
                "collection_interval": "15s",  # ê¸°ë³¸ê°’ 60sì—ì„œ ë‹¨ì¶•
                "resolution": "10s",           # ë©”íŠ¸ë¦­ í•´ìƒë„
                "retention": "2m",             # ë©”íŠ¸ë¦­ ë³´ì¡´ ê¸°ê°„
                "aggregation_window": "30s"    # ì§‘ê³„ ìœˆë„ìš°
            },
            "deployment_config": '''
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-server
  namespace: kube-system
spec:
  template:
    spec:
      containers:
      - name: metrics-server
        image: k8s.gcr.io/metrics-server/metrics-server:v0.6.2
        args:
        - --cert-dir=/tmp
        - --secure-port=4443
        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        - --kubelet-use-node-status-port
        - --metric-resolution=15s
        - --kubelet-insecure-tls
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
          limits:
            cpu: 500m
            memory: 500Mi
'''
        }
    
    def setup_custom_metrics_api(self):
        """ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ API ì„¤ì •"""
        return {
            "prometheus_adapter": '''
apiVersion: v1
kind: ConfigMap
metadata:
  name: adapter-config
  namespace: monitoring
data:
  config.yaml: |
    rules:
    # HTTP ìš”ì²­ë¥  ë©”íŠ¸ë¦­
    - seriesQuery: 'http_requests_total{namespace!="",pod!=""}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "^http_requests_total"
        as: "http_requests_per_second"
      metricsQuery: |
        sum(rate(<<.Series>>{<<.LabelMatchers>>}[2m])) by (<<.GroupBy>>)
    
    # í ê¸¸ì´ ë©”íŠ¸ë¦­  
    - seriesQuery: 'queue_length{queue!=""}'
      name:
        matches: "^queue_length"
        as: "queue_depth"
      metricsQuery: |
        max(<<.Series>>{<<.LabelMatchers>>}) by (<<.GroupBy>>)
    
    # ì‘ë‹µ ì§€ì—°ì‹œê°„ ë©”íŠ¸ë¦­
    - seriesQuery: 'http_request_duration_seconds_bucket{namespace!="",pod!=""}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "^http_request_duration_seconds_bucket"
        as: "http_request_latency"
      metricsQuery: |
        histogram_quantile(0.95, 
          sum(rate(<<.Series>>{<<.LabelMatchers>>}[5m])) by (<<.GroupBy>>, le)
        )
''',
            "external_metrics": {
                "aws_cloudwatch": "CloudWatch ë©”íŠ¸ë¦­ì„ External APIë¡œ ë…¸ì¶œ",
                "datadog": "Datadog ë©”íŠ¸ë¦­ í†µí•©",
                "newrelic": "New Relic APM ë©”íŠ¸ë¦­"
            }
        }
```

### ìŠ¤ì¼€ì¼ë§ ì„±ëŠ¥ íŠœë‹

```python
class HPAPerformanceTuning:
    def __init__(self):
        self.tuning_parameters = {}
        
    def optimize_scaling_responsiveness(self):
        """ìŠ¤ì¼€ì¼ë§ ì‘ë‹µì„± ìµœì í™”"""
        return {
            "fast_scale_up_scenario": {
                "use_case": "íŠ¸ë˜í”½ ê¸‰ì¦ ëŒ€ì‘ (Black Friday, ë§ˆì¼€íŒ… ìº í˜ì¸)",
                "configuration": {
                    "horizontal_pod_autoscaler_sync_period": "10s",  # ê¸°ë³¸ 15s
                    "horizontal_pod_autoscaler_upscale_delay": "30s", # ê¸°ë³¸ 3m
                    "horizontal_pod_autoscaler_downscale_delay": "5m", # ê¸°ë³¸ 5m
                    "horizontal_pod_autoscaler_downscale_stabilization": "5m"
                },
                "behavior_policy": {
                    "scaleUp": {
                        "stabilizationWindowSeconds": 30,
                        "policies": [
                            {
                                "type": "Percent",
                                "value": 100,
                                "periodSeconds": 15
                            },
                            {
                                "type": "Pods",
                                "value": 20,
                                "periodSeconds": 15  
                            }
                        ]
                    }
                }
            },
            "cost_optimized_scenario": {
                "use_case": "ë¹„ìš© ìµœì í™” ìš°ì„  (ê°œë°œ/í…ŒìŠ¤íŠ¸ í™˜ê²½)",
                "configuration": {
                    "horizontal_pod_autoscaler_sync_period": "30s",
                    "horizontal_pod_autoscaler_downscale_stabilization": "10m"
                },
                "behavior_policy": {
                    "scaleUp": {
                        "stabilizationWindowSeconds": 300,
                        "policies": [
                            {
                                "type": "Percent", 
                                "value": 50,
                                "periodSeconds": 120
                            }
                        ]
                    },
                    "scaleDown": {
                        "stabilizationWindowSeconds": 600,
                        "policies": [
                            {
                                "type": "Pods",
                                "value": 1,
                                "periodSeconds": 300
                            }
                        ]
                    }
                }
            }
        }
    
    def anti_flapping_strategies(self):
        """í”Œë˜í•‘ ë°©ì§€ ì „ëµ"""
        return {
            "stabilization_window": {
                "purpose": "ìµœê·¼ ë©”íŠ¸ë¦­ ê°’ë“¤ì˜ ì•ˆì •ì„± í™•ì¸",
                "scale_up": "ì§§ì€ ìœˆë„ìš° (30-60s) - ë¹ ë¥¸ ë°˜ì‘",
                "scale_down": "ê¸´ ìœˆë„ìš° (300-600s) - ì‹ ì¤‘í•œ ì¶•ì†Œ"
            },
            "tolerance_threshold": {
                "default": "10%",
                "aggressive": "5%",
                "conservative": "20%",
                "calculation": "(desired - current) / current > tolerance"
            },
            "metric_smoothing": {
                "moving_average": "ë©”íŠ¸ë¦­ ê°’ì˜ ì´ë™í‰ê·  ì‚¬ìš©",
                "outlier_filtering": "ê·¹ê°’ ì œê±°",
                "weighted_average": "ìµœê·¼ ê°’ì— ë” í° ê°€ì¤‘ì¹˜"
            }
        }
```

## ğŸ¯ ì‹¤ì „ í™œìš© íŒ¨í„´

### ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ HPA

```python
class WebApplicationHPA:
    def __init__(self):
        self.patterns = {}
        
    def ecommerce_hpa_pattern(self):
        """ì „ììƒê±°ë˜ HPA íŒ¨í„´"""
        return {
            "scenario": "ì˜¨ë¼ì¸ ì‡¼í•‘ëª° - íŠ¸ë˜í”½ ë³€ë™ì´ í° í™˜ê²½",
            "hpa_config": '''
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ecommerce-frontend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ecommerce-frontend
  minReplicas: 5      # ê¸°ë³¸ íŠ¸ë˜í”½ ì²˜ë¦¬
  maxReplicas: 200    # ë¸”ë™í”„ë¼ì´ë°ì´ ëŒ€ë¹„
  metrics:
  # CPU ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
  
  # RPS ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§ (ë” ë¯¼ê°í•œ ë°˜ì‘)
  - type: Pods
    pods:
      metric:
        name: nginx_ingress_controller_requests
      target:
        type: AverageValue
        averageValue: "50"
  
  # ì‘ë‹µ ì‹œê°„ ê¸°ë°˜
  - type: Pods
    pods:
      metric:
        name: http_request_duration_95percentile
      target:
        type: AverageValue
        averageValue: "500m"  # 500ms
  
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 30
      policies:
      - type: Percent
        value: 50
        periodSeconds: 30
      - type: Pods
        value: 10
        periodSeconds: 30
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
''',
            "monitoring_alerts": '''
# HPA ìŠ¤ì¼€ì¼ë§ ì´ë²¤íŠ¸ ëª¨ë‹ˆí„°ë§
- alert: HPAScalingEvent
  expr: |
    increase(kube_hpa_status_current_replicas[5m]) > 10
  for: 0m
  annotations:
    summary: "HPA scaled up significantly"
    description: "{{ $labels.hpa }} scaled up by {{ $value }} replicas"

# HPA ìµœëŒ€ì¹˜ ë„ë‹¬ ì•Œë¦¼
- alert: HPAMaxReplicasReached  
  expr: |
    kube_hpa_status_current_replicas == kube_hpa_spec_max_replicas
  for: 5m
  annotations:
    summary: "HPA reached maximum replicas"
    description: "{{ $labels.hpa }} is at maximum capacity"
'''
        }
    
    def api_service_hpa_pattern(self):
        """API ì„œë¹„ìŠ¤ HPA íŒ¨í„´"""
        return {
            "scenario": "RESTful API ì„œë²„ - ì•ˆì •ì  ì„±ëŠ¥ ì¤‘ì‹¬",
            "multiple_hpa_strategy": {
                "read_api_hpa": '''
# ì½ê¸° ì „ìš© API (ìºì‹œ í™œìš©ë„ ë†’ìŒ)
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: read-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: read-api
  minReplicas: 3
  maxReplicas: 30
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70    # ë†’ì€ CPU í—ˆìš©
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "200"       # ë†’ì€ RPS ì²˜ë¦¬
''',
                "write_api_hpa": '''
# ì“°ê¸° API (ë°ì´í„°ë² ì´ìŠ¤ ë¶€í•˜ ê³ ë ¤)
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: write-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: write-api
  minReplicas: 2
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50    # ë³´ìˆ˜ì  CPU ê¸°ì¤€
  - type: External
    external:
      metric:
        name: database_connection_pool_usage
      target:
        type: Value
        value: "80"               # DB ì—°ê²° í’€ ê³ ë ¤
'''
            }
        }
```

### ë°°ì¹˜ ì²˜ë¦¬ HPA

```python
class BatchProcessingHPA:
    def __init__(self):
        self.queue_based_patterns = {}
        
    def message_queue_hpa_pattern(self):
        """ë©”ì‹œì§€ í ê¸°ë°˜ HPA"""
        return {
            "scenario": "ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬ - í ê¸¸ì´ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§",
            "hpa_config": '''
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: worker-queue-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: background-worker
  minReplicas: 1
  maxReplicas: 100
  metrics:
  # SQS í ê¸¸ì´ ê¸°ë°˜
  - type: External
    external:
      metric:
        name: sqs_queue_length
        selector:
          matchLabels:
            queue_name: "image-processing-queue"
      target:
        type: AverageValue
        averageValue: "5"         # Podë‹¹ 5ê°œ ë©”ì‹œì§€ ì²˜ë¦¬
  
  # Redis í ê¸¸ì´ ê¸°ë°˜
  - type: External
    external:
      metric:
        name: redis_list_length
        selector:
          matchLabels:
            queue_key: "tasks:pending"
      target:
        type: AverageValue
        averageValue: "10"
  
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 200              # ë¹ ë¥¸ í™•ì¥ (3ë°°ê¹Œì§€)
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 600   # íê°€ ë¹„ì–´ë„ 10ë¶„ ëŒ€ê¸°
      policies:
      - type: Percent
        value: 25               # ì²œì²œíˆ ì¶•ì†Œ
        periodSeconds: 300
''',
            "custom_metrics_setup": '''
# Prometheus ë©”íŠ¸ë¦­ ë…¸ì¶œ
apiVersion: v1
kind: Service
metadata:
  name: queue-metrics-exporter
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
spec:
  ports:
  - port: 8080
    targetPort: 8080
  selector:
    app: queue-metrics-exporter
---
# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì„¤ì •
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: queue-metrics
spec:
  selector:
    matchLabels:
      app: queue-metrics-exporter
  endpoints:
  - port: http-metrics
    interval: 15s
    path: /metrics
'''
        }
```

## ğŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ HPA ë¬¸ì œë“¤

```python
class HPATroubleshooting:
    def __init__(self):
        self.common_issues = {}
        
    def scaling_not_working_issues(self):
        """ìŠ¤ì¼€ì¼ë§ì´ ì‘ë™í•˜ì§€ ì•ŠëŠ” ë¬¸ì œë“¤"""
        return {
            "no_metrics_available": {
                "symptoms": [
                    "HPA statusì— 'unknown' í‘œì‹œ",
                    "ë©”íŠ¸ë¦­ì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ëŠ” ì˜¤ë¥˜"
                ],
                "causes": [
                    "Metrics Serverê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ",
                    "Custom Metrics API ì„¤ì • ì˜¤ë¥˜",
                    "Podì— ë¦¬ì†ŒìŠ¤ requestsê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ"
                ],
                "solutions": [
                    "kubectl get apiservice | grep metrics",
                    "kubectl top nodes && kubectl top pods",
                    "Pod specì— resources.requests ì¶”ê°€"
                ],
                "debug_commands": [
                    "kubectl describe hpa <hpa-name>",
                    "kubectl get --raw '/apis/metrics.k8s.io/v1beta1/pods'",
                    "kubectl logs -n kube-system deployment/metrics-server"
                ]
            },
            "permissions_issues": {
                "symptoms": ["HPA controller ì˜¤ë¥˜", "ë©”íŠ¸ë¦­ ì ‘ê·¼ ì‹¤íŒ¨"],
                "solutions": '''
# HPAë¥¼ ìœ„í•œ RBAC ì„¤ì •
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: system:hpa-controller
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list", "patch", "update"]
- apiGroups: ["metrics.k8s.io"]
  resources: ["*"]
  verbs: ["get", "list"]
'''
            }
        }
    
    def performance_issues(self):
        """ì„±ëŠ¥ ê´€ë ¨ ë¬¸ì œë“¤"""
        return {
            "slow_scaling": {
                "symptoms": ["ìŠ¤ì¼€ì¼ë§ ë°˜ì‘ì´ ëŠë¦¼", "ì§€ì—°ëœ Pod ìƒì„±"],
                "analysis": '''
# HPA ì´ë²¤íŠ¸ í™•ì¸
kubectl describe hpa <hpa-name>

# ìµœê·¼ ìŠ¤ì¼€ì¼ë§ ì´ë²¤íŠ¸
kubectl get events --field-selector involvedObject.name=<hpa-name>

# í˜„ì¬ ë©”íŠ¸ë¦­ ê°’ í™•ì¸
kubectl get hpa <hpa-name> -o yaml
''',
                "optimizations": [
                    "ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì£¼ê¸° ë‹¨ì¶• (sync-period)",
                    "ì•ˆì •í™” ìœˆë„ìš° ì¡°ì •",
                    "ë” ë¯¼ê°í•œ ì„ê³„ê°’ ì„¤ì •",
                    "Pod ì‹œì‘ ì‹œê°„ ìµœì í™” (ì´ë¯¸ì§€ ìºì‹±)"
                ]
            },
            "flapping_behavior": {
                "symptoms": ["ë¹ˆë²ˆí•œ ìŠ¤ì¼€ì¼ ì—…/ë‹¤ìš´", "ë¶ˆì•ˆì •í•œ ë ˆí”Œë¦¬ì¹´ ìˆ˜"],
                "root_causes": [
                    "ë©”íŠ¸ë¦­ ë³€ë™ì„±ì´ í¼",
                    "ì•ˆì •í™” ìœˆë„ìš°ê°€ ë„ˆë¬´ ì§§ìŒ", 
                    "ì„ê³„ê°’ì´ ë„ˆë¬´ ë¯¼ê°í•¨"
                ],
                "solutions": {
                    "increase_stabilization": "ì•ˆì •í™” ìœˆë„ìš° ì¦ê°€ (300s â†’ 600s)",
                    "adjust_tolerance": "í—ˆìš© ì˜¤ì°¨ ì¦ê°€ (10% â†’ 20%)",
                    "smooth_metrics": "ë©”íŠ¸ë¦­ í‰í™œí™” (ì´ë™í‰ê·  ì‚¬ìš©)"
                }
            }
        }
    
    def monitoring_and_debugging_tools(self):
        """ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹… ë„êµ¬"""
        return {
            "hpa_status_check": '''
#!/bin/bash
echo "=== HPA Status Check ==="

# ëª¨ë“  HPA ìƒíƒœ í™•ì¸
kubectl get hpa -A

# íŠ¹ì • HPA ìƒì„¸ ì •ë³´
HPA_NAME="web-app-hpa"
kubectl describe hpa $HPA_NAME

# HPA ë©”íŠ¸ë¦­ í™•ì¸
kubectl get hpa $HPA_NAME -o jsonpath='{.status.currentMetrics}'

# ìµœê·¼ ìŠ¤ì¼€ì¼ë§ ì´ë²¤íŠ¸
kubectl get events --field-selector involvedObject.name=$HPA_NAME --sort-by='.lastTimestamp'

# ëŒ€ìƒ Deployment ìƒíƒœ
TARGET_DEPLOYMENT=$(kubectl get hpa $HPA_NAME -o jsonpath='{.spec.scaleTargetRef.name}')
kubectl get deployment $TARGET_DEPLOYMENT -o wide

# Pod ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
kubectl top pods -l app=$TARGET_DEPLOYMENT
''',
            "metrics_debugging": '''
# ë©”íŠ¸ë¦­ API ì ‘ê·¼ í…ŒìŠ¤íŠ¸
kubectl get --raw "/apis/metrics.k8s.io/v1beta1/nodes"
kubectl get --raw "/apis/metrics.k8s.io/v1beta1/pods"

# ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ API í…ŒìŠ¤íŠ¸  
kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1"

# ì™¸ë¶€ ë©”íŠ¸ë¦­ API í…ŒìŠ¤íŠ¸
kubectl get --raw "/apis/external.metrics.k8s.io/v1beta1"

# Prometheus ì–´ëŒ‘í„° ë¡œê·¸
kubectl logs -n monitoring deployment/prometheus-adapter
''',
            "performance_monitoring": '''
# HPA ì„±ëŠ¥ ë©”íŠ¸ë¦­
- name: hpa_scaling_duration
  query: |
    time() - on(hpa) kube_hpa_status_last_scale_time

- name: hpa_scaling_frequency  
  query: |
    rate(kube_hpa_status_last_scale_time[1h])

- name: hpa_metrics_lag
  query: |
    time() - on(hpa) kube_hpa_status_observed_generation
'''
        }
```

## ğŸ› ï¸ ì‹¤ìŠµ ë° ê²€ì¦

### HPA í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash

echo "=== HPA Testing Suite ==="

# 1. HPA ê¸°ë³¸ ì„¤ì • í…ŒìŠ¤íŠ¸
test_basic_hpa() {
    echo "Testing basic HPA setup..."
    
    # í…ŒìŠ¤íŠ¸ìš© ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
    cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hpa-test-app
  labels:
    app: hpa-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hpa-test
  template:
    metadata:
      labels:
        app: hpa-test
    spec:
      containers:
      - name: test-app
        image: k8s.gcr.io/hpa-example
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: 500m
            memory: 128Mi
---
apiVersion: v1
kind: Service
metadata:
  name: hpa-test-service
spec:
  selector:
    app: hpa-test
  ports:
  - port: 80
    targetPort: 80
EOF

    # HPA ìƒì„±
    cat <<EOF | kubectl apply -f -
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-test
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: hpa-test-app
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
EOF

    # ë°°í¬ ì™„ë£Œ ëŒ€ê¸°
    kubectl wait --for=condition=available deployment/hpa-test-app --timeout=120s
    
    # HPA ìƒíƒœ í™•ì¸
    kubectl get hpa hpa-test
    kubectl describe hpa hpa-test
}

# 2. ë¶€í•˜ í…ŒìŠ¤íŠ¸ ë° ìŠ¤ì¼€ì¼ë§ í™•ì¸
test_load_scaling() {
    echo "Testing HPA scaling under load..."
    
    # ë¶€í•˜ ìƒì„± Pod ìƒì„±
    kubectl run load-generator --rm -i --tty --image=busybox /bin/sh <<EOF
echo "Generating load on hpa-test-service..."
while true; do
  wget -q -O- http://hpa-test-service.default.svc.cluster.local/
done
EOF &
    
    LOAD_PID=$!
    
    echo "Load generation started. Monitoring HPA scaling..."
    
    # 5ë¶„ ë™ì•ˆ HPA ìƒíƒœ ëª¨ë‹ˆí„°ë§
    for i in {1..30}; do
        echo "=== Minute $((i/2)) ==="
        kubectl get hpa hpa-test
        kubectl get pods -l app=hpa-test
        sleep 10
    done
    
    # ë¶€í•˜ ìƒì„± ì¤‘ë‹¨
    kill $LOAD_PID 2>/dev/null
    
    echo "Load test completed. Monitoring scale down..."
    
    # ìŠ¤ì¼€ì¼ ë‹¤ìš´ ëª¨ë‹ˆí„°ë§
    for i in {1..20}; do
        echo "=== Scale down check $i ==="
        kubectl get hpa hpa-test
        sleep 30
    done
}

# 3. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
test_metrics_collection() {
    echo "Testing metrics collection..."
    
    # Metrics Server ìƒíƒœ í™•ì¸
    echo "=== Metrics Server Status ==="
    kubectl get pods -n kube-system | grep metrics-server
    
    # ë…¸ë“œ ë©”íŠ¸ë¦­ í™•ì¸
    echo "=== Node Metrics ==="
    kubectl top nodes
    
    # Pod ë©”íŠ¸ë¦­ í™•ì¸
    echo "=== Pod Metrics ==="
    kubectl top pods -l app=hpa-test
    
    # ë©”íŠ¸ë¦­ API ì§ì ‘ í˜¸ì¶œ
    echo "=== Direct Metrics API Call ==="
    kubectl get --raw "/apis/metrics.k8s.io/v1beta1/namespaces/default/pods" | jq '.items[] | select(.metadata.labels.app=="hpa-test") | {name: .metadata.name, cpu: .containers[].usage.cpu, memory: .containers[].usage.memory}'
}

# 4. HPA ì´ë²¤íŠ¸ ë° ë¡œê·¸ ë¶„ì„
analyze_hpa_events() {
    echo "Analyzing HPA events and behavior..."
    
    # HPA ìƒì„¸ ì •ë³´
    echo "=== HPA Detailed Status ==="
    kubectl describe hpa hpa-test
    
    # HPA ê´€ë ¨ ì´ë²¤íŠ¸
    echo "=== HPA Events ==="
    kubectl get events --field-selector involvedObject.name=hpa-test --sort-by='.lastTimestamp'
    
    # Deployment ì´ë²¤íŠ¸
    echo "=== Deployment Events ==="
    kubectl get events --field-selector involvedObject.name=hpa-test-app --sort-by='.lastTimestamp'
    
    # HPA Controller ë¡œê·¸
    echo "=== HPA Controller Logs ==="
    kubectl logs -n kube-system -l component=controller-manager --tail=50 | grep -i hpa
}

# 5. ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ HPA í…ŒìŠ¤íŠ¸ (Prometheus í•„ìš”)
test_custom_metrics_hpa() {
    echo "Testing custom metrics HPA..."
    
    # Prometheusì™€ ì–´ëŒ‘í„°ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if ! kubectl get pods -n monitoring | grep prometheus-adapter >/dev/null 2>&1; then
        echo "Prometheus adapter not found. Skipping custom metrics test."
        return
    fi
    
    # ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ê¸°ë°˜ HPA ìƒì„±
    cat <<EOF | kubectl apply -f -
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-custom-test
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: hpa-test-app
  minReplicas: 1
  maxReplicas: 5
  metrics:
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "10"
EOF

    # ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ API í™•ì¸
    echo "=== Custom Metrics API ==="
    kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1" | jq '.'
    
    # HPA ìƒíƒœ í™•ì¸
    kubectl describe hpa hpa-custom-test
}

# ì •ë¦¬ í•¨ìˆ˜
cleanup_hpa_test() {
    echo "Cleaning up HPA test resources..."
    kubectl delete hpa hpa-test hpa-custom-test --ignore-not-found
    kubectl delete deployment hpa-test-app --ignore-not-found
    kubectl delete service hpa-test-service --ignore-not-found
    kubectl delete pod load-generator --ignore-not-found
    
    echo "HPA test cleanup completed"
}

# ë©”ë‰´ ì„ íƒ
case "$1" in
    basic)
        test_basic_hpa
        ;;
    load)
        test_load_scaling
        ;;
    metrics)
        test_metrics_collection
        ;;
    events)
        analyze_hpa_events
        ;;
    custom)
        test_custom_metrics_hpa
        ;;
    all)
        test_basic_hpa
        echo "===================="
        test_metrics_collection
        echo "===================="
        test_load_scaling
        echo "===================="
        analyze_hpa_events
        ;;
    cleanup)
        cleanup_hpa_test
        ;;
    *)
        echo "Usage: $0 {basic|load|metrics|events|custom|all|cleanup}"
        echo ""
        echo "Commands:"
        echo "  basic   - Test basic HPA setup"
        echo "  load    - Test HPA scaling under load"
        echo "  metrics - Test metrics collection"
        echo "  events  - Analyze HPA events"
        echo "  custom  - Test custom metrics HPA"
        echo "  all     - Run all tests"
        echo "  cleanup - Clean up test resources"
        exit 1
        ;;
esac
```

ì´ì²˜ëŸ¼ HPAëŠ” **ì‹¤ì‹œê°„ ì›Œí¬ë¡œë“œ ë³€í™”ì— ë”°ë¥¸ ìë™ ìŠ¤ì¼€ì¼ë§**ì„ í†µí•´ ì„±ëŠ¥ê³¼ ë¹„ìš© íš¨ìœ¨ì„±ì„ ë™ì‹œì— ë‹¬ì„±í•˜ëŠ” í•µì‹¬ ê¸°ëŠ¥ì…ë‹ˆë‹¤. CPU, ë©”ëª¨ë¦¬ ê°™ì€ ê¸°ë³¸ ë©”íŠ¸ë¦­ë¶€í„° ë¹„ì¦ˆë‹ˆìŠ¤ íŠ¹í™” ë©”íŠ¸ë¦­ê¹Œì§€ ë‹¤ì–‘í•œ ì§€í‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì§€ëŠ¥ì ì¸ ìŠ¤ì¼€ì¼ë§ ê²°ì •**ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¤ìŒ ë¬¸ì„œì—ì„œëŠ” **VPA(Vertical Pod Autoscaler)ì˜ ì¶”ì²œ ì—”ì§„**ê³¼ ë¦¬ì†ŒìŠ¤ ìµœì í™” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.
