---
tags:
  - Kubernetes
  - Service
  - LoadBalancer
  - Ingress
---

# Kubernetes Service íƒ€ì…ë³„ ë™ì‘ ì›ë¦¬

## ğŸ¯ ê°œìš”

2020ë…„, ì „ ì„¸ê³„ê°€ ì§‘ì— ë¨¸ë¬¼ë©° Netflixë¥¼ ì‹œì²­í•  ë•Œ, Netflixì˜ ë°±ì—”ë“œì—ì„œëŠ” ìˆ˜ì²œ ê°œì˜ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ê°€ ì´ˆë‹¹ ìˆ˜ë°±ë§Œ ê±´ì˜ ìš”ì²­ì„ ì²˜ë¦¬í•˜ê³  ìˆì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ê° ì„œë¹„ìŠ¤ëŠ” ë™ì ìœ¼ë¡œ ìƒì„±ë˜ê³  ì‚­ì œë˜ëŠ” Podë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ì„œ, **Podì˜ IPê°€ ê³„ì† ë°”ë€ŒëŠ” ìƒí™©**ì´ì—ˆìŠµë‹ˆë‹¤.

ë§Œì•½ ì „í†µì ì¸ ë°©ì‹ì´ë¼ë©´ ë¡œë“œë°¸ëŸ°ì„œ ì„¤ì •ì„ ëŠì„ì—†ì´ ì—…ë°ì´íŠ¸í•´ì•¼ í–ˆê² ì§€ë§Œ, Kubernetes ServiceëŠ” ì´ ëª¨ë“  ê²ƒì„ **ìë™ìœ¼ë¡œ ì¶”ìƒí™”**í–ˆìŠµë‹ˆë‹¤. ë‹¨ í•˜ë‚˜ì˜ ì•ˆì •ì ì¸ IPì™€ DNS ì´ë¦„ìœ¼ë¡œ, ë’¤ì—ì„œ ë³€í™”í•˜ëŠ” ìˆ˜ë°± ê°œì˜ Pod ì¸ìŠ¤í„´ìŠ¤ë¥¼ íˆ¬ëª…í•˜ê²Œ ê´€ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤.

ì´ê²ƒì´ ë°”ë¡œ Kubernetes Serviceì˜ í•µì‹¬ ê°€ì¹˜ì…ë‹ˆë‹¤. **ë³€í™”í•˜ëŠ” ì¸í”„ë¼ ìœ„ì—ì„œ ë³€í•˜ì§€ ì•ŠëŠ” ì ‘ì ì„ ì œê³µí•˜ëŠ” ê²ƒ.**

## ğŸ“– Service ê°œë…ê³¼ í•„ìš”ì„±

### ì „í†µì ì¸ ë°©ì‹ì˜ í•œê³„

```python
# ì „í†µì ì¸ ë¡œë“œë°¸ëŸ°ì‹±ì˜ ë¬¸ì œì 
class TraditionalLoadBalancer:
    def __init__(self):
        self.backend_servers = []
        self.health_check_failures = 0
    
    def add_server(self, ip, port):
        # ìˆ˜ë™ìœ¼ë¡œ ì„œë²„ ì¶”ê°€
        self.backend_servers.append(f"{ip}:{port}")
        self.update_config_file()  # ì„¤ì • íŒŒì¼ ìˆ˜ì •
        self.reload_config()       # ì„œë¹„ìŠ¤ ì¬ì‹œì‘
    
    def remove_server(self, ip, port):
        # ì„œë²„ ì œê±° ì‹œì—ë„ ìˆ˜ë™ ì‘ì—…
        server = f"{ip}:{port}"
        if server in self.backend_servers:
            self.backend_servers.remove(server)
            self.update_config_file()
            self.reload_config()
    
    def handle_pod_crash(self):
        # Podê°€ ì£½ìœ¼ë©´ ìˆ˜ë™ìœ¼ë¡œ IP ì œê±°í•´ì•¼ í•¨
        print("Manual intervention required!")
        print("Update load balancer configuration")
        print("Remove failed instances")
```

### Kubernetes Serviceì˜ ìë™í™”

```python
# Kubernetes Serviceì˜ ë™ì  ê´€ë¦¬
class KubernetesService:
    def __init__(self, service_name, selector):
        self.name = service_name
        self.selector = selector  # app=nginx ê°™ì€ ë¼ë²¨ ì…€ë ‰í„°
        self.cluster_ip = self.allocate_cluster_ip()
        self.endpoints = []
        self.iptables_rules = []
    
    def watch_pods(self):
        """Pod ë³€í™”ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ì—”ë“œí¬ì¸íŠ¸ ì—…ë°ì´íŠ¸"""
        while True:
            matching_pods = self.get_pods_by_selector(self.selector)
            new_endpoints = []
            
            for pod in matching_pods:
                if self.is_pod_ready(pod):
                    new_endpoints.append({
                        "ip": pod.status.podIP,
                        "port": 80,
                        "node": pod.spec.nodeName
                    })
            
            if new_endpoints != self.endpoints:
                self.endpoints = new_endpoints
                self.update_iptables_rules()
                print(f"Service {self.name} updated: {len(self.endpoints)} endpoints")
    
    def allocate_cluster_ip(self):
        """Service CIDRì—ì„œ ê³ ìœ  IP í• ë‹¹"""
        return "10.96.1.100"  # kube-apiserverê°€ ìë™ í• ë‹¹
    
    def update_iptables_rules(self):
        """iptables ê·œì¹™ì„ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸"""
        self.cleanup_old_rules()
        
        for i, endpoint in enumerate(self.endpoints):
            probability = f"1/{len(self.endpoints) - i}"
            rule = (
                f"iptables -t nat -A KUBE-SERVICES "
                f"-d {self.cluster_ip}/32 -p tcp --dport 80 "
                f"-m statistic --mode random --probability {probability} "
                f"-j DNAT --to-destination {endpoint['ip']}:{endpoint['port']}"
            )
            self.iptables_rules.append(rule)
```

## ğŸŒ Service íƒ€ì… ìƒì„¸ ë¶„ì„

### 1. ClusterIP Service

**ê°€ì¥ ê¸°ë³¸ì ì¸ Service íƒ€ì…**ìœ¼ë¡œ, í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ì—ì„œë§Œ ì ‘ê·¼ ê°€ëŠ¥í•œ ê°€ìƒ IPë¥¼ ì œê³µí•©ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "ClusterIP Service ë™ì‘"
        C[Client Pod] -->|1. Request to 10.96.1.100:80| S[Service ClusterIP]
        S -->|2. iptables DNAT| K[kube-proxy]
        K -->|3. Load Balance| P1[Pod 1, 10.244.1.5]
        K --> P2[Pod 2, 10.244.2.8]
        K --> P3[Pod 3, 10.244.3.12]
    end
    
    style S fill:#e1f5fe
    style K fill:#f3e5f5
```

**êµ¬í˜„ ì›ë¦¬:**

```python
class ClusterIPService:
    def __init__(self, name, selector, port):
        self.name = name
        self.selector = selector
        self.cluster_ip = self.get_cluster_ip()
        self.port = port
        self.endpoints_controller = EndpointsController(self)
    
    def get_cluster_ip(self):
        """Service CIDR ë²”ìœ„ì—ì„œ IP í• ë‹¹"""
        # ê¸°ë³¸ì ìœ¼ë¡œ 10.96.0.0/12 ë²”ìœ„ì—ì„œ í• ë‹¹
        # kube-apiserverê°€ ì¤‘ë³µ ë°©ì§€í•˜ë©° í• ë‹¹
        return "10.96.1.100"
    
    def create_iptables_rules(self):
        """iptables ê¸°ë°˜ ë¡œë“œë°¸ëŸ°ì‹± ê·œì¹™ ìƒì„±"""
        endpoints = self.endpoints_controller.get_ready_endpoints()
        
        if not endpoints:
            return []
        
        rules = []
        # ì²« ë²ˆì§¸ ê·œì¹™: Service IPë¡œì˜ ì ‘ê·¼ì„ ê°ì§€
        rules.append(
            f"iptables -A KUBE-SERVICES "
            f"-d {self.cluster_ip}/32 -p tcp --dport {self.port} "
            f"-j KUBE-SVC-{self.name}"
        )
        
        # ê° ì—”ë“œí¬ì¸íŠ¸ë¡œì˜ ë¶„ì‚° ê·œì¹™
        for i, endpoint in enumerate(endpoints):
            probability = f"1/{len(endpoints) - i}"
            rules.append(
                f"iptables -A KUBE-SVC-{self.name} "
                f"-m statistic --mode random --probability {probability} "
                f"-j KUBE-SEP-{endpoint['name']}"
            )
            
            rules.append(
                f"iptables -A KUBE-SEP-{endpoint['name']} "
                f"-p tcp -j DNAT --to-destination {endpoint['ip']}:{endpoint['port']}"
            )
        
        return rules
```

**ì„¸ì…˜ ì–´í”¼ë‹ˆí‹° (Session Affinity):**

```python
class SessionAffinityHandler:
    def __init__(self, service):
        self.service = service
        self.session_timeout = 10800  # 3ì‹œê°„
    
    def enable_client_ip_affinity(self):
        """í´ë¼ì´ì–¸íŠ¸ IP ê¸°ë°˜ ì„¸ì…˜ ê³ ì •"""
        return {
            "sessionAffinity": "ClientIP",
            "sessionAffinityConfig": {
                "clientIP": {
                    "timeoutSeconds": self.session_timeout
                }
            }
        }
    
    def create_affinity_rules(self):
        """ì„¸ì…˜ ì–´í”¼ë‹ˆí‹°ë¥¼ ìœ„í•œ iptables ê·œì¹™"""
        return [
            # í´ë¼ì´ì–¸íŠ¸ IPë¥¼ í•´ì‹œí•˜ì—¬ ì¼ê´€ëœ ì—”ë“œí¬ì¸íŠ¸ë¡œ ë¼ìš°íŒ…
            f"iptables -A KUBE-SVC-{self.service.name} "
            f"-m statistic --mode random --probability 0.33 "
            f"-m recent --name {self.service.name} --set "
            f"-j KUBE-SEP-ENDPOINT1",
            
            # ê¸°ì¡´ ì—°ê²°ì€ ê°™ì€ ì—”ë“œí¬ì¸íŠ¸ë¡œ ìœ ì§€
            f"iptables -A KUBE-SVC-{self.service.name} "
            f"-m recent --name {self.service.name} --rcheck --seconds {self.session_timeout} "
            f"-j KUBE-SEP-ENDPOINT1"
        ]
```

### 2. NodePort Service

**ëª¨ë“  ë…¸ë“œì˜ íŠ¹ì • í¬íŠ¸**ë¥¼ í†µí•´ Serviceì— ì™¸ë¶€ ì ‘ê·¼ì„ í—ˆìš©í•©ë‹ˆë‹¤.

```mermaid
sequenceDiagram
    participant E as External Client
    participant N as Node (192.168.1.10)
    participant K as kube-proxy
    participant P as Pod (10.244.1.5)
    
    E->>N: HTTP Request :32080
    N->>K: Forward to NodePort
    K->>K: iptables DNAT
    K->>P: Forward to Pod :80
    P->>K: HTTP Response
    K->>N: Response
    N->>E: Response
```

**êµ¬í˜„ ì„¸ë¶€ì‚¬í•­:**

```python
class NodePortService:
    def __init__(self, name, selector, port, node_port=None):
        self.cluster_ip_service = ClusterIPService(name, selector, port)
        self.node_port = node_port or self.allocate_node_port()
        self.external_traffic_policy = "Cluster"  # or "Local"
    
    def allocate_node_port(self):
        """30000-32767 ë²”ìœ„ì—ì„œ í¬íŠ¸ í• ë‹¹"""
        import random
        allocated_ports = self.get_allocated_node_ports()
        
        while True:
            port = random.randint(30000, 32767)
            if port not in allocated_ports:
                return port
    
    def create_nodeport_rules(self):
        """ëª¨ë“  ë…¸ë“œì— NodePort ê·œì¹™ ì ìš©"""
        rules = []
        
        # ëª¨ë“  ë…¸ë“œ IPì—ì„œ NodePort ìˆ˜ì‹ 
        for node_ip in self.get_node_ips():
            rules.append(
                f"iptables -A KUBE-NODEPORTS "
                f"-p tcp --dport {self.node_port} "
                f"-j KUBE-SVC-{self.cluster_ip_service.name}"
            )
        
        # ì™¸ë¶€ íŠ¸ë˜í”½ì„ ClusterIPë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        rules.append(
            f"iptables -A KUBE-SVC-{self.cluster_ip_service.name} "
            f"-j DNAT --to-destination {self.cluster_ip_service.cluster_ip}:80"
        )
        
        return rules
    
    def handle_external_traffic_policy(self):
        """ì™¸ë¶€ íŠ¸ë˜í”½ ì •ì±…ì— ë”°ë¥¸ ë¼ìš°íŒ…"""
        if self.external_traffic_policy == "Local":
            # ë¡œì»¬ ë…¸ë“œì˜ Podë§Œ ì‚¬ìš© (ì†ŒìŠ¤ IP ë³´ì¡´)
            return self.get_local_endpoints()
        else:
            # í´ëŸ¬ìŠ¤í„° ì „ì²´ Pod ì‚¬ìš© (SNAT ì ìš©)
            return self.cluster_ip_service.endpoints_controller.get_ready_endpoints()
```

**ì†ŒìŠ¤ IP ë³´ì¡´:**

```python
class SourceIPPreservation:
    def __init__(self, service):
        self.service = service
    
    def configure_local_traffic_policy(self):
        """Local íŠ¸ë˜í”½ ì •ì±…ìœ¼ë¡œ ì†ŒìŠ¤ IP ë³´ì¡´"""
        return {
            "externalTrafficPolicy": "Local",
            "healthCheckNodePort": 32123,  # í—¬ìŠ¤ì²´í¬ìš© í¬íŠ¸
            "advantages": [
                "Client IP is preserved",
                "No extra network hops",
                "Better performance"
            ],
            "disadvantages": [
                "Potential load imbalance",
                "Health check complexity"
            ]
        }
    
    def setup_health_check_endpoint(self, node_port):
        """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •"""
        return {
            "path": "/healthz",
            "port": node_port,
            "response": "200 OK if local endpoints exist",
            "purpose": "External LB health checking"
        }
```

### 3. LoadBalancer Service

**í´ë¼ìš°ë“œ í”„ë¡œë°”ì´ë”ì˜ ë¡œë“œë°¸ëŸ°ì„œ**ì™€ í†µí•©í•˜ì—¬ ì™¸ë¶€ ì ‘ê·¼ì„ ì œê³µí•©ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "Cloud Provider"
        LB[Cloud LoadBalancer, 203.0.113.1]
    end
    
    subgraph "Kubernetes Cluster"
        N1[Node 1, NodePort :32080]
        N2[Node 2, NodePort :32080] 
        N3[Node 3, NodePort :32080]
        
        subgraph "Pods"
            P1[Pod 1]
            P2[Pod 2]
            P3[Pod 3]
        end
    end
    
    Internet --> LB
    LB --> N1
    LB --> N2
    LB --> N3
    
    N1 --> P1
    N2 --> P2  
    N3 --> P3
```

**êµ¬í˜„ ì˜ˆì‹œ (AWS ELB):**

```python
class AWSLoadBalancerService:
    def __init__(self, service_spec):
        self.service = service_spec
        self.elb_client = boto3.client('elbv2')
        self.node_port = None
        self.target_group_arn = None
    
    def provision_load_balancer(self):
        """AWS ALB/NLB í”„ë¡œë¹„ì €ë‹"""
        # 1. NodePort Service ìƒì„± (ë°±ì—”ë“œìš©)
        node_port_service = NodePortService(
            name=self.service.name,
            selector=self.service.selector,
            port=self.service.port
        )
        self.node_port = node_port_service.node_port
        
        # 2. Target Group ìƒì„±
        self.target_group_arn = self.create_target_group()
        
        # 3. Load Balancer ìƒì„±
        lb_arn = self.create_load_balancer()
        
        # 4. Listener ì„¤ì •
        self.create_listener(lb_arn, self.target_group_arn)
        
        # 5. Health Check ì„¤ì •
        self.configure_health_checks()
        
        return self.get_load_balancer_dns(lb_arn)
    
    def create_target_group(self):
        """Target Group ìƒì„± ë° ë…¸ë“œ ë“±ë¡"""
        response = self.elb_client.create_target_group(
            Name=f"{self.service.name}-tg",
            Protocol='HTTP',
            Port=self.node_port,
            VpcId=self.get_vpc_id(),
            TargetType='instance',
            HealthCheckProtocol='HTTP',
            HealthCheckPath='/',
            HealthCheckPort=str(self.node_port)
        )
        
        tg_arn = response['TargetGroups'][0]['TargetGroupArn']
        
        # ëª¨ë“  ì›Œì»¤ ë…¸ë“œë¥¼ íƒ€ê²Ÿìœ¼ë¡œ ë“±ë¡
        targets = []
        for node in self.get_worker_nodes():
            targets.append({
                'Id': node.instance_id,
                'Port': self.node_port
            })
        
        self.elb_client.register_targets(
            TargetGroupArn=tg_arn,
            Targets=targets
        )
        
        return tg_arn
    
    def handle_node_changes(self, event):
        """ë…¸ë“œ ì¶”ê°€/ì œê±° ì‹œ Target Group ì—…ë°ì´íŠ¸"""
        if event.type == "ADDED":
            self.elb_client.register_targets(
                TargetGroupArn=self.target_group_arn,
                Targets=[{
                    'Id': event.node.instance_id,
                    'Port': self.node_port
                }]
            )
        elif event.type == "DELETED":
            self.elb_client.deregister_targets(
                TargetGroupArn=self.target_group_arn,
                Targets=[{
                    'Id': event.node.instance_id,
                    'Port': self.node_port
                }]
            )
```

**GCP Load Balancer í†µí•©:**

```python
class GCPLoadBalancerService:
    def __init__(self, service_spec):
        self.service = service_spec
        self.compute = googleapiclient.discovery.build('compute', 'v1')
    
    def create_gce_load_balancer(self):
        """GCE Load Balancer ìƒì„±"""
        components = {
            # 1. Instance Group ìƒì„±
            "instance_group": self.create_instance_group(),
            
            # 2. Backend Service ìƒì„±  
            "backend_service": self.create_backend_service(),
            
            # 3. URL Map ìƒì„±
            "url_map": self.create_url_map(),
            
            # 4. HTTP(S) Proxy ìƒì„±
            "proxy": self.create_proxy(),
            
            # 5. Forwarding Rule ìƒì„±
            "forwarding_rule": self.create_forwarding_rule()
        }
        
        return components
    
    def create_backend_service(self):
        """Backend Service ì„¤ì •"""
        return {
            "name": f"{self.service.name}-backend",
            "protocol": "HTTP",
            "port": self.node_port,
            "timeoutSec": 30,
            "connectionDraining": {
                "drainingTimeoutSec": 300
            },
            "healthChecks": [self.create_health_check()],
            "backends": [
                {
                    "group": instance_group_url,
                    "balancingMode": "UTILIZATION",
                    "maxUtilization": 0.8
                }
                for instance_group_url in self.get_instance_groups()
            ]
        }
```

### 4. ExternalName Service

**ì™¸ë¶€ ì„œë¹„ìŠ¤ì— ëŒ€í•œ DNS CNAME**ì„ ì œê³µí•˜ì—¬ ë‚´ë¶€ ì„œë¹„ìŠ¤ì²˜ëŸ¼ ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

```python
class ExternalNameService:
    def __init__(self, name, external_name):
        self.name = name
        self.external_name = external_name  # ì˜ˆ: database.example.com
        # ClusterIPê°€ í• ë‹¹ë˜ì§€ ì•ŠìŒ
        self.cluster_ip = None
    
    def create_dns_record(self):
        """CoreDNSì— CNAME ë ˆì½”ë“œ ìƒì„±"""
        return {
            "record_type": "CNAME",
            "name": f"{self.name}.default.svc.cluster.local",
            "target": self.external_name,
            "ttl": 30
        }
    
    def resolve_service(self, query):
        """Service ì´ë¦„ì„ ì™¸ë¶€ FQDNìœ¼ë¡œ í•´ì„"""
        if query == f"{self.name}.default.svc.cluster.local":
            return {
                "type": "CNAME",
                "target": self.external_name,
                "additional_records": self.resolve_external_name()
            }
    
    def resolve_external_name(self):
        """ì™¸ë¶€ ë„ë©”ì¸ì˜ ì‹¤ì œ IP ì£¼ì†Œ ì¡°íšŒ"""
        import socket
        try:
            return socket.gethostbyname_ex(self.external_name)
        except socket.gaierror:
            return None
```

**ì‚¬ìš© ì˜ˆì‹œ:**

```yaml
# ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤ë¥¼ ë‚´ë¶€ ì„œë¹„ìŠ¤ì²˜ëŸ¼ ì‚¬ìš©
apiVersion: v1
kind: Service
metadata:
  name: postgres-external
spec:
  type: ExternalName
  externalName: postgres.rds.amazonaws.com
  ports:
  - port: 5432
---
# ì´ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ postgres-external:5432ë¡œ ì ‘ê·¼ ê°€ëŠ¥
```

## ğŸ”„ Endpoints Controllerì™€ ë™ì  ì—…ë°ì´íŠ¸

### Endpoints ìë™ ê´€ë¦¬

```python
class EndpointsController:
    def __init__(self, service):
        self.service = service
        self.current_endpoints = []
        self.watch_handle = None
    
    def start_watching(self):
        """Pod ë³€í™”ë¥¼ ê°ì‹œí•˜ê³  Endpoints ì—…ë°ì´íŠ¸"""
        self.watch_handle = self.kubernetes_client.watch_pods(
            namespace=self.service.namespace,
            label_selector=self.service.selector,
            callback=self.handle_pod_event
        )
    
    def handle_pod_event(self, event):
        """Pod ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        pod = event.object
        event_type = event.type
        
        if event_type == "ADDED" and self.is_pod_ready(pod):
            self.add_endpoint(pod)
        elif event_type == "MODIFIED":
            self.update_endpoint(pod)
        elif event_type == "DELETED":
            self.remove_endpoint(pod)
    
    def is_pod_ready(self, pod):
        """Pod Ready ìƒíƒœ í™•ì¸"""
        if pod.status.phase != "Running":
            return False
            
        for condition in pod.status.conditions:
            if condition.type == "Ready" and condition.status == "True":
                return True
        
        return False
    
    def add_endpoint(self, pod):
        """ìƒˆ Endpoint ì¶”ê°€"""
        endpoint = {
            "name": pod.metadata.name,
            "ip": pod.status.podIP,
            "port": self.get_container_port(pod),
            "node": pod.spec.nodeName,
            "ready": True
        }
        
        self.current_endpoints.append(endpoint)
        self.update_service_rules()
        
        print(f"Added endpoint: {endpoint['ip']}:{endpoint['port']}")
    
    def update_service_rules(self):
        """Serviceì˜ iptables ê·œì¹™ ì—…ë°ì´íŠ¸"""
        # ê¸°ì¡´ ê·œì¹™ ì œê±°
        self.cleanup_old_rules()
        
        # ìƒˆ ê·œì¹™ ì ìš©
        new_rules = self.service.create_iptables_rules()
        for rule in new_rules:
            self.execute_iptables_command(rule)
```

### í—¬ìŠ¤ì²´í¬ì™€ Ready ìƒíƒœ

```python
class HealthChecker:
    def __init__(self, pod_spec):
        self.readiness_probe = pod_spec.containers[0].readiness_probe
        self.liveness_probe = pod_spec.containers[0].liveness_probe
    
    def check_readiness(self, pod_ip):
        """Readiness Probe ì‹¤í–‰"""
        if not self.readiness_probe:
            return True  # Probe ì—†ìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ Ready
        
        probe_config = self.readiness_probe
        
        if probe_config.http_get:
            return self.http_health_check(pod_ip, probe_config.http_get)
        elif probe_config.tcp_socket:
            return self.tcp_health_check(pod_ip, probe_config.tcp_socket)
        elif probe_config.exec:
            return self.exec_health_check(pod_ip, probe_config.exec)
    
    def http_health_check(self, pod_ip, http_config):
        """HTTP í—¬ìŠ¤ì²´í¬"""
        import requests
        try:
            url = f"http://{pod_ip}:{http_config.port}{http_config.path}"
            response = requests.get(
                url,
                timeout=http_config.timeout_seconds,
                headers=http_config.http_headers
            )
            return 200 <= response.status_code < 400
        except requests.RequestException:
            return False
    
    def tcp_health_check(self, pod_ip, tcp_config):
        """TCP í¬íŠ¸ ì²´í¬"""
        import socket
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(tcp_config.timeout_seconds)
            result = sock.connect_ex((pod_ip, tcp_config.port))
            sock.close()
            return result == 0
        except socket.error:
            return False
```

## ğŸ® kube-proxy êµ¬í˜„ ë°©ì‹

### iptables vs IPVS ëª¨ë“œ

```python
class KubeProxyManager:
    def __init__(self, mode="iptables"):
        self.mode = mode
        self.services = {}
    
    def setup_iptables_mode(self):
        """iptables ëª¨ë“œ ì„¤ì •"""
        advantages = [
            "Mature and stable",
            "Wide compatibility", 
            "Simple debugging"
        ]
        
        disadvantages = [
            "Linear rule processing O(n)",
            "No real load balancing algorithms",
            "Performance degrades with many services"
        ]
        
        return {
            "mode": "iptables",
            "advantages": advantages,
            "disadvantages": disadvantages,
            "best_for": "Small to medium clusters (< 1000 services)"
        }
    
    def setup_ipvs_mode(self):
        """IPVS ëª¨ë“œ ì„¤ì •"""
        algorithms = [
            "round-robin", "least-conn", "dest-hash",
            "source-hash", "shortest-expected-delay"
        ]
        
        return {
            "mode": "ipvs",
            "load_balancing_algorithms": algorithms,
            "performance": "O(1) lookup time",
            "advantages": [
                "Better performance",
                "Real load balancing algorithms",
                "Connection tracking"
            ],
            "requirements": ["IPVS kernel modules"],
            "best_for": "Large clusters (> 1000 services)"
        }
    
    def create_ipvs_service(self, service):
        """IPVS ì„œë¹„ìŠ¤ ìƒì„±"""
        commands = [
            # IPVS ê°€ìƒ ì„œë¹„ìŠ¤ ìƒì„±
            f"ipvsadm -A -t {service.cluster_ip}:{service.port} -s rr",
            
            # ê° ì—”ë“œí¬ì¸íŠ¸ë¥¼ real serverë¡œ ì¶”ê°€
            *[
                f"ipvsadm -a -t {service.cluster_ip}:{service.port} "
                f"-r {endpoint['ip']}:{endpoint['port']} -m"
                for endpoint in service.endpoints
            ]
        ]
        
        return commands
```

## ğŸ” Service Discovery ë©”ì»¤ë‹ˆì¦˜

### DNS ê¸°ë°˜ ë””ìŠ¤ì»¤ë²„ë¦¬

```python
class ServiceDiscovery:
    def __init__(self, cluster_domain="cluster.local"):
        self.cluster_domain = cluster_domain
        self.dns_cache = {}
    
    def resolve_service_dns(self, service_name, namespace="default"):
        """Service DNS ì´ë¦„ í•´ì„"""
        fqdn_patterns = {
            "short_name": f"{service_name}",
            "namespace_qualified": f"{service_name}.{namespace}",
            "service_qualified": f"{service_name}.{namespace}.svc",
            "fully_qualified": f"{service_name}.{namespace}.svc.{self.cluster_domain}"
        }
        
        return {
            "patterns": fqdn_patterns,
            "resolution": f"{service_name}.{namespace}.svc.{self.cluster_domain}",
            "record_type": "A",
            "ip": "10.96.1.100"  # Service ClusterIP
        }
    
    def create_srv_records(self, service):
        """SRV ë ˆì½”ë“œ ìƒì„± (í¬íŠ¸ ì •ë³´ í¬í•¨)"""
        srv_records = []
        
        for port in service.spec.ports:
            srv_name = f"_{port.name}._{port.protocol.lower()}.{service.name}.{service.namespace}.svc.{self.cluster_domain}"
            srv_records.append({
                "name": srv_name,
                "type": "SRV",
                "priority": 0,
                "weight": 100,
                "port": port.port,
                "target": f"{service.name}.{service.namespace}.svc.{self.cluster_domain}"
            })
        
        return srv_records
```

### í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ë””ìŠ¤ì»¤ë²„ë¦¬

```python
class EnvironmentVariableDiscovery:
    def __init__(self):
        self.services = {}
    
    def generate_service_env_vars(self, pod_namespace):
        """Podì´ ì‹œì‘ë  ë•Œ Service í™˜ê²½ ë³€ìˆ˜ ìƒì„±"""
        env_vars = {}
        
        # ê°™ì€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ëª¨ë“  Service ì¡°íšŒ
        services = self.get_services_in_namespace(pod_namespace)
        
        for service in services:
            service_name_upper = service.name.upper().replace('-', '_')
            
            # Service IPì™€ í¬íŠ¸ í™˜ê²½ ë³€ìˆ˜
            env_vars[f"{service_name_upper}_SERVICE_HOST"] = service.cluster_ip
            
            for port in service.ports:
                port_name = port.name.upper().replace('-', '_') if port.name else 'PORT'
                env_vars[f"{service_name_upper}_SERVICE_PORT_{port_name}"] = str(port.port)
                
                # ì²« ë²ˆì§¸ í¬íŠ¸ëŠ” ê¸°ë³¸ í¬íŠ¸ë¡œ ì„¤ì •
                if not env_vars.get(f"{service_name_upper}_SERVICE_PORT"):
                    env_vars[f"{service_name_upper}_SERVICE_PORT"] = str(port.port)
        
        return env_vars
    
    def example_env_vars(self):
        """í™˜ê²½ ë³€ìˆ˜ ì˜ˆì‹œ"""
        return {
            "REDIS_SERVICE_HOST": "10.96.2.100",
            "REDIS_SERVICE_PORT": "6379",
            "POSTGRES_SERVICE_HOST": "10.96.3.200", 
            "POSTGRES_SERVICE_PORT": "5432",
            "POSTGRES_SERVICE_PORT_POSTGRESQL": "5432"
        }
```

## ğŸ› ï¸ ì‹¤ì „ í™œìš© ì‚¬ë¡€

### 1. ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°„ í†µì‹ 

```python
class MicroservicesCommunication:
    def __init__(self):
        self.services = {}
    
    def setup_service_mesh(self):
        """ì„œë¹„ìŠ¤ ë©”ì‹œ í†µì‹  êµ¬ì„±"""
        services_config = {
            "frontend": {
                "type": "LoadBalancer",
                "ports": [80, 443],
                "downstream": ["api-gateway"]
            },
            "api-gateway": {
                "type": "ClusterIP", 
                "ports": [8080],
                "downstream": ["user-service", "order-service", "product-service"]
            },
            "user-service": {
                "type": "ClusterIP",
                "ports": [8080],
                "downstream": ["database"]
            },
            "database": {
                "type": "ClusterIP",
                "ports": [5432],
                "downstream": []
            }
        }
        
        return services_config
    
    def create_service_chain(self, service_name):
        """ì„œë¹„ìŠ¤ ì²´ì¸ ìƒì„±"""
        service_yaml = f"""
apiVersion: v1
kind: Service
metadata:
  name: {service_name}
  labels:
    app: {service_name}
    tier: backend
spec:
  selector:
    app: {service_name}
  ports:
  - name: http
    port: 80
    targetPort: 8080
    protocol: TCP
  type: ClusterIP
"""
        return service_yaml
```

### 2. Blue/Green ë°°í¬ì™€ ì¹´ë‚˜ë¦¬ ë°°í¬

```python
class AdvancedDeploymentStrategies:
    def __init__(self):
        self.deployments = {}
    
    def blue_green_deployment(self, app_name, new_version):
        """Blue/Green ë°°í¬ë¥¼ ìœ„í•œ Service ì „í™˜"""
        blue_service = f"{app_name}-blue"
        green_service = f"{app_name}-green" 
        main_service = app_name
        
        # 1. Green í™˜ê²½ì— ìƒˆ ë²„ì „ ë°°í¬
        self.deploy_version(green_service, new_version)
        
        # 2. í—¬ìŠ¤ì²´í¬ í™•ì¸
        if self.health_check_passed(green_service):
            # 3. ë©”ì¸ Serviceë¥¼ Greenìœ¼ë¡œ ì „í™˜
            self.switch_service_selector(main_service, "version", new_version)
            
            # 4. Blue í™˜ê²½ ì •ë¦¬ (ì„ íƒì )
            # self.cleanup_blue_environment(blue_service)
        
        return {
            "status": "switched",
            "active_environment": "green",
            "version": new_version
        }
    
    def canary_deployment(self, app_name, new_version, traffic_percentage=10):
        """ì¹´ë‚˜ë¦¬ ë°°í¬ë¥¼ ìœ„í•œ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë¼ìš°íŒ…"""
        stable_replicas = 90
        canary_replicas = 10
        
        # Stable ì„œë¹„ìŠ¤ (ê¸°ì¡´ ë²„ì „)
        stable_service = {
            "name": f"{app_name}-stable",
            "selector": {"app": app_name, "version": "stable"},
            "weight": 100 - traffic_percentage
        }
        
        # Canary ì„œë¹„ìŠ¤ (ìƒˆ ë²„ì „)  
        canary_service = {
            "name": f"{app_name}-canary",
            "selector": {"app": app_name, "version": new_version},
            "weight": traffic_percentage
        }
        
        return {
            "strategy": "canary",
            "stable_traffic": f"{100 - traffic_percentage}%",
            "canary_traffic": f"{traffic_percentage}%",
            "services": [stable_service, canary_service]
        }
```

### 3. ë©€í‹° í´ëŸ¬ìŠ¤í„° Service ì—°ë™

```python
class MultiClusterServices:
    def __init__(self):
        self.clusters = {}
    
    def setup_cross_cluster_service(self, service_name):
        """í´ëŸ¬ìŠ¤í„° ê°„ Service ì—°ë™"""
        return {
            "primary_cluster": {
                "service": service_name,
                "cluster_ip": "10.96.1.100",
                "endpoints": ["10.244.1.5", "10.244.2.8"]
            },
            "secondary_cluster": {
                "service": f"{service_name}-external",
                "type": "ExternalName",
                "external_name": f"{service_name}.primary-cluster.example.com"
            },
            "service_mesh_integration": {
                "istio": {
                    "virtual_service": True,
                    "destination_rule": True,
                    "gateway": "istio-system/main-gateway"
                }
            }
        }
    
    def create_headless_service(self, service_name):
        """Headless Serviceë¡œ ì§ì ‘ Pod ì ‘ê·¼"""
        return {
            "apiVersion": "v1",
            "kind": "Service",
            "metadata": {"name": service_name},
            "spec": {
                "clusterIP": "None",  # Headless ì„¤ì •
                "selector": {"app": service_name},
                "ports": [{"port": 80, "targetPort": 8080}]
            },
            "benefits": [
                "Direct pod IP resolution",
                "Service discovery for StatefulSets",
                "Custom load balancing logic"
            ]
        }
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### Service ì„±ëŠ¥ íŠœë‹

```python
class ServicePerformanceOptimizer:
    def __init__(self):
        self.metrics = {}
    
    def optimize_large_scale_services(self, service_count):
        """ëŒ€ê·œëª¨ Service í™˜ê²½ ìµœì í™”"""
        if service_count > 1000:
            return {
                "proxy_mode": "ipvs",  # iptables ëŒ€ì‹  IPVS
                "ipvs_scheduler": "lc",  # Least Connection
                "connection_tracking": {
                    "enabled": True,
                    "timeout": 900
                },
                "performance_gain": "10x faster rule lookup"
            }
        else:
            return {
                "proxy_mode": "iptables",
                "optimization": "default_settings_sufficient"
            }
    
    def optimize_dns_performance(self):
        """DNS ì„±ëŠ¥ ìµœì í™”"""
        return {
            "nodelocal_dns": {
                "enabled": True,
                "cache_size": 1000,
                "negative_ttl": 30
            },
            "coredns_optimization": {
                "cache_ttl": 30,
                "reload_period": "10s",
                "max_concurrent": 1000
            },
            "pod_dns_config": {
                "ndots": 2,
                "search_domains": ["default.svc.cluster.local"],
                "timeout": 2
            }
        }
    
    def monitor_service_performance(self, service_name):
        """Service ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
        return {
            "metrics_to_track": [
                "service_request_duration_seconds",
                "service_request_total",
                "endpoint_ready_count",
                "service_dns_resolution_duration"
            ],
            "alerts": [
                "endpoint_ready_count < expected_replicas",
                "service_request_duration_seconds > 1s",
                "service_dns_resolution_duration > 100ms"
            ]
        }
```

## ğŸ”’ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### Service ë³´ì•ˆ ê°•í™”

```python
class ServiceSecurity:
    def __init__(self):
        self.security_policies = {}
    
    def implement_zero_trust_services(self):
        """ì œë¡œ íŠ¸ëŸ¬ìŠ¤íŠ¸ Service ë³´ì•ˆ"""
        return {
            "network_policies": {
                "default_deny": True,
                "explicit_allow": "Required for each service communication"
            },
            "service_mesh_security": {
                "mutual_tls": True,
                "certificate_rotation": "Automatic",
                "identity_based_routing": True
            },
            "pod_security": {
                "service_account": "Dedicated per service",
                "rbac": "Minimal required permissions",
                "secrets_management": "External secret store"
            }
        }
    
    def secure_external_services(self):
        """ì™¸ë¶€ Service ë…¸ì¶œ ì‹œ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­"""
        return {
            "load_balancer_security": {
                "source_ranges": ["10.0.0.0/8"],  # ë‚´ë¶€ IPë§Œ í—ˆìš©
                "ssl_termination": "At load balancer",
                "waf_protection": True
            },
            "nodeport_limitations": {
                "firewall_rules": "Restrict source IPs",
                "port_range": "30000-32767 only",
                "monitoring": "Track unusual traffic patterns"
            }
        }
```

ì´ì²˜ëŸ¼ Kubernetes ServiceëŠ” **ë‹¨ìˆœí•œ ë¡œë“œë°¸ëŸ°ì„œê°€ ì•„ë‹Œ, ë™ì ì¸ ì¸í”„ë¼ ìœ„ì—ì„œ ì•ˆì •ì ì¸ ë„¤íŠ¸ì›Œí¬ ì¶”ìƒí™”ë¥¼ ì œê³µí•˜ëŠ” í•µì‹¬ ì»´í¬ë„ŒíŠ¸**ì…ë‹ˆë‹¤. Podê°€ ì–¸ì œë“  ìƒì„±ë˜ê³  ì‚­ì œë  ìˆ˜ ìˆëŠ” í™˜ê²½ì—ì„œ, ServiceëŠ” ë³€í•˜ì§€ ì•ŠëŠ” ì ‘ì ì„ ì œê³µí•˜ì—¬ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ì˜ ê¸°ë°˜ì´ ë©ë‹ˆë‹¤.

ë‹¤ìŒ ë¬¸ì„œì—ì„œëŠ” **Ingressì™€ Ingress Controller**ë¥¼ í†µí•´ ì–´ë–»ê²Œ HTTP/HTTPS íŠ¸ë˜í”½ì„ ë”ìš± ì •êµí•˜ê²Œ ë¼ìš°íŒ…í•˜ëŠ”ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.
