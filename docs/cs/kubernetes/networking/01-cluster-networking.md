---
tags:
  - Kubernetes
  - Networking
  - CNI
  - CoreDNS
---

# Kubernetes í´ëŸ¬ìŠ¤í„° ë„¤íŠ¸ì›Œí‚¹ ëª¨ë¸

## ğŸ¯ ê°œìš”

2019ë…„ ë¸”ë™ í”„ë¼ì´ë°ì´, Shopifyì˜ íŠ¸ë˜í”½ì´ í‰ì†Œì˜ 10ë°°ë¡œ ê¸‰ì¦í–ˆìŠµë‹ˆë‹¤. ìˆ˜ì²œ ê°œì˜ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ê°€ ë™ì‹œì— í†µì‹ í•˜ë©° ì£¼ë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ìƒí™©ì—ì„œ, í•œ ê°€ì§€ ë†€ë¼ìš´ ì‚¬ì‹¤ì´ ìˆì—ˆìŠµë‹ˆë‹¤. **ëª¨ë“  PodëŠ” ì„œë¡œë¥¼ ì§ì ‘ ì°¾ì•„ í†µì‹ í•  ìˆ˜ ìˆì—ˆê³ , ë³µì¡í•œ NATë‚˜ í¬íŠ¸ ë§¤í•‘ ì—†ì´ë„ ì•ˆì •ì ìœ¼ë¡œ ë™ì‘í–ˆìŠµë‹ˆë‹¤.**

ì´ê²ƒì´ ë°”ë¡œ Kubernetesì˜ í˜ì‹ ì ì¸ ë„¤íŠ¸ì›Œí‚¹ ëª¨ë¸ì˜ í˜ì…ë‹ˆë‹¤. ì „í†µì ì¸ ê°€ìƒ ë¨¸ì‹  í™˜ê²½ì—ì„œëŠ” ë³µì¡í•œ í¬íŠ¸ í¬ì›Œë”©ê³¼ í”„ë¡ì‹œ ì„¤ì •ì´ í•„ìš”í–ˆì§€ë§Œ, KubernetesëŠ” **"ëª¨ë“  Podê°€ ê³ ìœ í•œ IPë¥¼ ê°–ê³  ì„œë¡œ ì§ì ‘ í†µì‹ í•œë‹¤"**ëŠ” ë‹¨ìˆœí•˜ë©´ì„œë„ ê°•ë ¥í•œ ì›ì¹™ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤.

## ğŸ“– Kubernetes ë„¤íŠ¸ì›Œí‚¹ ì›ì¹™

### í•µì‹¬ ì›ì¹™ 3ê°€ì§€

Kubernetes ë„¤íŠ¸ì›Œí‚¹ì€ ì„¸ ê°€ì§€ í•µì‹¬ ì›ì¹™ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤:

```mermaid
graph TB
    P1["ğŸ”— ì›ì¹™ 1: Pod ê°„ NAT ì—†ëŠ” í†µì‹ "] --> P2["ğŸŒ ì›ì¹™ 2: Nodeì™€ Pod ê°„ NAT ì—†ëŠ” í†µì‹ "]
    P2 --> P3["ğŸ¯ ì›ì¹™ 3: Podê°€ ë³´ëŠ” ìì‹ ì˜ IP = ì™¸ë¶€ì—ì„œ ë³´ëŠ” IP"]
    
    P1 --> E1["ì˜ˆ: Pod A (10.244.1.5) â†’ Pod B (10.244.2.8)"]
    P2 --> E2["ì˜ˆ: Node (192.168.1.100) â†’ Pod (10.244.1.5)"]
    P3 --> E3["ì˜ˆ: Pod ë‚´ë¶€ì—ì„œ hostname -i = ì™¸ë¶€ì—ì„œ kubectl get pod -o wide"]
    
    style P1 fill:#e1f5fe
    style P2 fill:#f3e5f5
    style P3 fill:#fff3e0
```

### 1. Pod ê°„ NAT ì—†ëŠ” í†µì‹ 

**ì „í†µì ì¸ ë°©ì‹ì˜ ë¬¸ì œì :**

```python
# ì „í†µì ì¸ ì»¨í…Œì´ë„ˆ ë„¤íŠ¸ì›Œí‚¹ (Docker ê¸°ë³¸ ëª¨ë“œ)
class DockerNetworking:
    def __init__(self):
        self.bridge = "docker0"  # 172.17.0.1
        self.containers = {}
    
    def communicate(self, container_a, container_b):
        # ë³µì¡í•œ í¬íŠ¸ ë§¤í•‘ê³¼ NAT í•„ìš”
        port_mapping = {
            "container_a": {"internal": 8080, "external": 32001},
            "container_b": {"internal": 8080, "external": 32002}
        }
        
        # ì™¸ë¶€ í¬íŠ¸ë¡œë§Œ í†µì‹  ê°€ëŠ¥
        return f"http://host:{port_mapping['container_b']['external']}"
```

**Kubernetes ë°©ì‹ì˜ ì¥ì :**

```python
# Kubernetes Pod ë„¤íŠ¸ì›Œí‚¹
class KubernetesPodNetworking:
    def __init__(self):
        self.pod_cidr = "10.244.0.0/16"
        self.pods = {
            "frontend-pod": "10.244.1.5",
            "backend-pod": "10.244.2.8",
            "database-pod": "10.244.3.12"
        }
    
    def communicate(self, source_pod, target_pod):
        # ì§ì ‘ IP í†µì‹  - NAT ë¶ˆí•„ìš”!
        source_ip = self.pods[source_pod]
        target_ip = self.pods[target_pod]
        
        return f"Direct communication: {source_ip} â†’ {target_ip}:8080"
    
    def service_discovery(self, service_name):
        # DNS ê¸°ë°˜ ì„œë¹„ìŠ¤ ë°œê²¬
        return f"{service_name}.default.svc.cluster.local"
```

### 2. í´ëŸ¬ìŠ¤í„° IP ê³µê°„ ì„¤ê³„

**IP ì£¼ì†Œ ê³µê°„ ë¶„í• :**

```mermaid
graph TD
    subgraph "í´ëŸ¬ìŠ¤í„° IP ê³µê°„"
        N["Node CIDR, 192.168.1.0/24"] 
        P["Pod CIDR, 10.244.0.0/16"]
        S["Service CIDR, 10.96.0.0/12"]
    end
    
    N --> N1["Node 1: 192.168.1.10"]
    N --> N2["Node 2: 192.168.1.11"] 
    N --> N3["Node 3: 192.168.1.12"]
    
    P --> P1["Node 1 Pods: 10.244.1.0/24"]
    P --> P2["Node 2 Pods: 10.244.2.0/24"]
    P --> P3["Node 3 Pods: 10.244.3.0/24"]
    
    S --> S1["kube-dns: 10.96.0.10"]
    S --> S2["frontend-svc: 10.96.1.100"]
    S --> S3["backend-svc: 10.96.2.200"]
```

```python
class ClusterNetworkManager:
    def __init__(self):
        self.network_config = {
            "cluster_cidr": "10.244.0.0/16",      # Pod ì „ìš©
            "service_cidr": "10.96.0.0/12",       # Service ì „ìš©
            "node_cidr": "192.168.1.0/24"         # Node ì „ìš©
        }
        self.node_pod_cidrs = {}
    
    def allocate_pod_cidr(self, node_name):
        """ê° ë…¸ë“œì— Pod CIDR ë¸”ë¡ í• ë‹¹"""
        node_count = len(self.node_pod_cidrs)
        pod_subnet = f"10.244.{node_count + 1}.0/24"  # ê° ë…¸ë“œë‹¹ 254ê°œ Pod IP
        
        self.node_pod_cidrs[node_name] = {
            "cidr": pod_subnet,
            "available_ips": list(range(2, 255)),  # .1ì€ ê²Œì´íŠ¸ì›¨ì´ìš©
            "allocated_pods": {}
        }
        
        return pod_subnet
    
    def assign_pod_ip(self, node_name, pod_name):
        """Podì— IP ì£¼ì†Œ í• ë‹¹"""
        node_info = self.node_pod_cidrs[node_name]
        if not node_info["available_ips"]:
            raise Exception("No more IPs available on this node")
        
        ip_suffix = node_info["available_ips"].pop(0)
        node_subnet = node_info["cidr"].split('/')[0].rsplit('.', 1)[0]
        pod_ip = f"{node_subnet}.{ip_suffix}"
        
        node_info["allocated_pods"][pod_name] = pod_ip
        return pod_ip
```

## ğŸŒ ë„¤íŠ¸ì›Œí¬ êµ¬í˜„ ì•„í‚¤í…ì²˜

### Container Network Interface (CNI) ê°œìš”

```mermaid
sequenceDiagram
    participant K as kubelet
    participant C as CNI Plugin
    participant N as Network Provider
    participant P as Pod
    
    K->>C: ADD network to container
    C->>N: Configure network interface
    N->>N: Create veth pair
    N->>N: Assign IP from IPAM
    N->>N: Configure routes
    C->>K: Return network configuration
    K->>P: Start container with network
    
    Note over K,P: PodëŠ” ì´ì œ í´ëŸ¬ìŠ¤í„° ë„¤íŠ¸ì›Œí¬ì—ì„œ í†µì‹  ê°€ëŠ¥
```

### ë„¤íŠ¸ì›Œí¬ êµ¬í˜„ ë°©ì‹

#### 1. Overlay ë„¤íŠ¸ì›Œí¬ (VXLAN)

**Flannel VXLAN ëª¨ë“œ ì˜ˆì‹œ:**

```python
class FlannelVXLAN:
    def __init__(self):
        self.vxlan_config = {
            "network": "10.244.0.0/16",
            "backend_type": "vxlan",
            "vni": 1,  # VXLAN Network Identifier
            "port": 8472
        }
        self.node_mappings = {}
    
    def setup_vxlan_interface(self, node_ip, pod_subnet):
        """VXLAN í„°ë„ ì¸í„°í˜ì´ìŠ¤ ì„¤ì •"""
        commands = [
            # VXLAN ì¸í„°í˜ì´ìŠ¤ ìƒì„±
            f"ip link add flannel.1 type vxlan id 1 dev eth0 dstport 8472",
            
            # IP ì£¼ì†Œ í• ë‹¹
            f"ip addr add {pod_subnet} dev flannel.1",
            
            # ì¸í„°í˜ì´ìŠ¤ í™œì„±í™”
            f"ip link set flannel.1 up",
            
            # ë¼ìš°íŒ… ê·œì¹™ ì¶”ê°€
            f"ip route add 10.244.0.0/16 dev flannel.1"
        ]
        
        return commands
    
    def create_tunnel_route(self, dest_subnet, dest_node_ip):
        """ë‹¤ë¥¸ ë…¸ë“œë¡œì˜ í„°ë„ ë¼ìš°íŒ… ìƒì„±"""
        return [
            f"ip route add {dest_subnet} via {dest_node_ip} dev flannel.1",
            f"bridge fdb append 00:00:00:00:00:00 dev flannel.1 dst {dest_node_ip}"
        ]
```

#### 2. ë¼ìš°íŒ… ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬

**Calico BGP ëª¨ë“œ ì˜ˆì‹œ:**

```python
class CalicoBGP:
    def __init__(self):
        self.bgp_config = {
            "as_number": 64512,
            "router_id": "auto",
            "network": "10.244.0.0/16"
        }
        self.bird_config = {}
    
    def generate_bird_config(self, node_ip, neighbors):
        """BIRD BGP ë¼ìš°í„° ì„¤ì • ìƒì„±"""
        config = f"""
# BIRD ë¼ìš°í„° ì„¤ì •
router id {node_ip};

# BGP í”„ë¡œí† ì½œ ì •ì˜
protocol bgp kubernetes {{
    description "Kubernetes BGP";
    local as {self.bgp_config['as_number']};
    
    # ì´ì›ƒ ë…¸ë“œë“¤ê³¼ BGP í”¼ì–´ë§
"""
        
        for neighbor_ip in neighbors:
            config += f"""
    neighbor {neighbor_ip} as {self.bgp_config['as_number']};
"""
        
        config += """
    # Pod CIDR ê²½ë¡œ ê´‘ê³ 
    export filter {
        if net ~ 10.244.0.0/16 then accept;
        reject;
    };
}
"""
        
        return config
    
    def advertise_pod_routes(self, node_subnet):
        """Pod ì„œë¸Œë„·ì„ BGPë¡œ ê´‘ê³ """
        return f"ip route add {node_subnet} dev cali+ proto bird"
```

#### 3. í´ë¼ìš°ë“œ í”„ë¡œë°”ì´ë” í†µí•©

**AWS VPC CNI ì˜ˆì‹œ:**

```python
class AWSVPCCNI:
    def __init__(self, instance_type="m5.large"):
        self.instance_limits = {
            "m5.large": {"max_enis": 3, "ips_per_eni": 10},
            "m5.xlarge": {"max_enis": 4, "ips_per_eni": 15},
            "m5.2xlarge": {"max_enis": 4, "ips_per_eni": 15}
        }
        self.instance_type = instance_type
    
    def calculate_max_pods(self):
        """ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…ë³„ ìµœëŒ€ Pod ìˆ˜ ê³„ì‚°"""
        limits = self.instance_limits[self.instance_type]
        
        # ì²« ë²ˆì§¸ ENIëŠ” Primary IP ì‚¬ìš©
        primary_eni_pods = limits["ips_per_eni"] - 1
        
        # ë‚˜ë¨¸ì§€ ENIëŠ” ëª¨ë“  IP ì‚¬ìš© ê°€ëŠ¥
        secondary_eni_pods = (limits["max_enis"] - 1) * limits["ips_per_eni"]
        
        return primary_eni_pods + secondary_eni_pods
    
    def assign_pod_ip(self, pod_name):
        """AWS ENIì—ì„œ Secondary IPë¥¼ Podì— í• ë‹¹"""
        return {
            "method": "ENI Secondary IP",
            "pod_ip": "192.168.1.100",  # VPC CIDR ë²”ìœ„ ë‚´
            "subnet": "subnet-abc123",
            "security_groups": ["sg-pod-default"],
            "direct_vpc_routing": True
        }
```

## ğŸ¯ Pod ë„¤íŠ¸ì›Œí‚¹ êµ¬í˜„

### Pod ë„¤íŠ¸ì›Œí¬ ì„¤ì • ê³¼ì •

```mermaid
graph TB
    subgraph "Pod ë„¤íŠ¸ì›Œí¬ ì„¤ì •"
        A["1. kubeletì´ Pod ìƒì„± ìš”ì²­ ë°›ìŒ"] --> B["2. CNI í”ŒëŸ¬ê·¸ì¸ í˜¸ì¶œ"]
        B --> C["3. veth pair ìƒì„±"]
        C --> D["4. Pod ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— veth ì´ë™"]
        D --> E["5. IP ì£¼ì†Œ í• ë‹¹ (IPAM)"]
        E --> F["6. ê¸°ë³¸ ê²½ë¡œ ì„¤ì •"]
        F --> G["7. Pod ì‹œì‘"]
    end
    
    subgraph "ë„¤íŠ¸ì›Œí¬ ì»´í¬ë„ŒíŠ¸"
        H["Host Network Namespace"]
        I["Pod Network Namespace"]
        J["Bridge (cbr0/cni0)"]
        K["iptables Rules"]
    end
    
    C --> H
    D --> I
    E --> J
    F --> K
```

### veth pair êµ¬í˜„

```python
class VethPairManager:
    def __init__(self):
        self.bridge_name = "cni0"
        self.pods = {}
    
    def create_veth_pair(self, pod_name, pod_ip, netns_path):
        """veth pair ìƒì„± ë° ì„¤ì •"""
        host_veth = f"veth{pod_name[:8]}"
        pod_veth = "eth0"
        
        commands = [
            # veth pair ìƒì„±
            f"ip link add {host_veth} type veth peer name {pod_veth}",
            
            # Pod vethë¥¼ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ ì´ë™
            f"ip link set {pod_veth} netns {netns_path}",
            
            # Host vethë¥¼ ë¸Œë¦¬ì§€ì— ì—°ê²°
            f"ip link set {host_veth} master {self.bridge_name}",
            f"ip link set {host_veth} up",
            
            # Pod ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
            f"ip netns exec {netns_path} ip addr add {pod_ip}/24 dev {pod_veth}",
            f"ip netns exec {netns_path} ip link set {pod_veth} up",
            f"ip netns exec {netns_path} ip route add default via 169.254.1.1 dev {pod_veth}"
        ]
        
        self.pods[pod_name] = {
            "host_veth": host_veth,
            "pod_veth": pod_veth,
            "ip": pod_ip,
            "netns": netns_path
        }
        
        return commands
    
    def setup_bridge(self):
        """CNI ë¸Œë¦¬ì§€ ì„¤ì •"""
        return [
            f"ip link add {self.bridge_name} type bridge",
            f"ip link set {self.bridge_name} up",
            f"ip addr add 10.244.1.1/24 dev {self.bridge_name}"
        ]
```

### iptables ê·œì¹™ ê´€ë¦¬

```python
class IptablesManager:
    def __init__(self):
        self.cluster_cidr = "10.244.0.0/16"
        self.service_cidr = "10.96.0.0/12"
    
    def setup_pod_networking_rules(self):
        """Pod ë„¤íŠ¸ì›Œí‚¹ì„ ìœ„í•œ iptables ê·œì¹™"""
        rules = [
            # Pod ê°„ í†µì‹  í—ˆìš©
            f"iptables -A FORWARD -s {self.cluster_cidr} -j ACCEPT",
            f"iptables -A FORWARD -d {self.cluster_cidr} -j ACCEPT",
            
            # NAT ê·œì¹™ (ì™¸ë¶€ í†µì‹ ìš©)
            f"iptables -t nat -A POSTROUTING -s {self.cluster_cidr} ! -d {self.cluster_cidr} -j MASQUERADE",
            
            # ì„œë¹„ìŠ¤ íŠ¸ë˜í”½ í—ˆìš©
            f"iptables -A FORWARD -s {self.service_cidr} -j ACCEPT",
            f"iptables -A FORWARD -d {self.service_cidr} -j ACCEPT"
        ]
        
        return rules
    
    def setup_service_rules(self, service_ip, service_port, endpoints):
        """Serviceì— ëŒ€í•œ ë¡œë“œë°¸ëŸ°ì‹± ê·œì¹™"""
        rules = []
        
        # ê° ì—”ë“œí¬ì¸íŠ¸ì— ëŒ€í•œ DNAT ê·œì¹™
        for i, endpoint in enumerate(endpoints):
            endpoint_ip, endpoint_port = endpoint.split(':')
            probability = f"1/{len(endpoints) - i}"
            
            rules.append(
                f"iptables -t nat -A KUBE-SERVICES "
                f"-d {service_ip}/32 -p tcp --dport {service_port} "
                f"-m statistic --mode random --probability {probability} "
                f"-j DNAT --to-destination {endpoint_ip}:{endpoint_port}"
            )
        
        return rules
```

## ğŸ” í´ëŸ¬ìŠ¤í„° DNS (CoreDNS)

### DNS ê¸°ë°˜ ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬

Kubernetesì˜ DNS ì‹œìŠ¤í…œì€ Serviceì™€ Podì— ëŒ€í•œ ìë™ ì´ë¦„ í•´ì„ì„ ì œê³µí•©ë‹ˆë‹¤:

```mermaid
graph TB
    subgraph "DNS ê³„ì¸µ êµ¬ì¡°"
        A["Pod: my-app-pod"] --> B["Service: frontend.default.svc.cluster.local"]
        B --> C["Namespace: default.svc.cluster.local"]
        C --> D["Cluster: svc.cluster.local"]
        D --> E["Root: cluster.local"]
    end
    
    subgraph "DNS ë ˆì½”ë“œ íƒ€ì…"
        F["A ë ˆì½”ë“œ: Service ClusterIP"]
        G["SRV ë ˆì½”ë“œ: Port ì •ë³´"]
        H["PTR ë ˆì½”ë“œ: ì—­ë°©í–¥ ì¡°íšŒ"]
    end
    
    B --> F
    B --> G
    B --> H
```

### CoreDNS ì„¤ì •

```python
class CoreDNSManager:
    def __init__(self):
        self.cluster_domain = "cluster.local"
        self.cluster_dns_ip = "10.96.0.10"
        self.upstream_servers = ["8.8.8.8", "8.8.4.4"]
    
    def generate_corefile(self):
        """CoreDNS Corefile ì„¤ì • ìƒì„±"""
        return f"""
# Kubernetes DNS ì²˜ë¦¬
{self.cluster_domain}:53 {{
    errors
    health {{
        lameduck 5s
    }}
    ready
    kubernetes {self.cluster_domain} in-addr.arpa ip6.arpa {{
        pods insecure
        fallthrough in-addr.arpa ip6.arpa
        ttl 30
    }}
    prometheus :9153
    forward . /etc/resolv.conf {{
        max_concurrent 1000
    }}
    cache 30
    loop
    reload
    loadbalance
}}

# ì™¸ë¶€ DNS ì²˜ë¦¬
.:53 {{
    errors
    health
    ready
    kubernetes {self.cluster_domain} in-addr.arpa ip6.arpa {{
        pods insecure
        fallthrough in-addr.arpa ip6.arpa
    }}
    forward . {' '.join(self.upstream_servers)}
    cache 30
    loop
    reload
    loadbalance
}}
"""
    
    def resolve_service(self, service_name, namespace="default"):
        """ì„œë¹„ìŠ¤ ì´ë¦„ì„ IPë¡œ í•´ì„"""
        fqdn = f"{service_name}.{namespace}.svc.{self.cluster_domain}"
        
        return {
            "fqdn": fqdn,
            "type": "A",
            "ttl": 30,
            "records": ["10.96.1.100"]  # Service ClusterIP
        }
    
    def resolve_pod(self, pod_ip):
        """Pod IPë¥¼ DNS ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
        # Pod IP 10.244.1.5 â†’ 1-5.10-244-1.default.pod.cluster.local
        ip_parts = pod_ip.split('.')
        pod_dns = f"{ip_parts[2]}-{ip_parts[3]}.{ip_parts[0]}-{ip_parts[1]}.default.pod.{self.cluster_domain}"
        
        return {
            "fqdn": pod_dns,
            "type": "A", 
            "ttl": 30,
            "records": [pod_ip]
        }
```

### DNS ì •ì±…ê³¼ ì„±ëŠ¥ ìµœì í™”

```python
class DNSOptimizer:
    def __init__(self):
        self.dns_policies = {
            "Default": "Use node DNS settings",
            "ClusterFirst": "Use cluster DNS first, then node DNS",
            "ClusterFirstWithHostNet": "For hostNetwork pods",
            "None": "Custom DNS configuration required"
        }
    
    def optimize_dns_config(self, workload_type):
        """ì›Œí¬ë¡œë“œ íƒ€ì…ë³„ DNS ìµœì í™”"""
        configs = {
            "web_service": {
                "policy": "ClusterFirst",
                "ndots": 2,  # ì§§ì€ ì´ë¦„ë„ í—ˆìš©
                "searches": ["default.svc.cluster.local", "svc.cluster.local"],
                "nameservers": ["10.96.0.10"],
                "options": [
                    {"name": "timeout", "value": "2"},
                    {"name": "attempts", "value": "2"}
                ]
            },
            "batch_job": {
                "policy": "ClusterFirst", 
                "ndots": 1,  # ì™¸ë¶€ ë„ë©”ì¸ ì¡°íšŒ ìµœì í™”
                "searches": ["default.svc.cluster.local"],
                "nameservers": ["10.96.0.10", "8.8.8.8"],
                "options": [
                    {"name": "single-request-reopen", "value": None}
                ]
            }
        }
        
        return configs.get(workload_type, configs["web_service"])
    
    def setup_dns_caching(self):
        """ë…¸ë“œ ë ˆë²¨ DNS ìºì‹± ì„¤ì •"""
        return {
            "nodelocal_dns": {
                "enabled": True,
                "local_dns": "169.254.20.10",
                "cache_size": 1000,
                "negative_cache_ttl": 30
            },
            "pod_dns_config": {
                "nameservers": ["169.254.20.10"],  # NodeLocal DNS
                "searches": ["default.svc.cluster.local"],
                "options": [
                    {"name": "ndots", "value": "2"},
                    {"name": "edns0", "value": None}
                ]
            }
        }
```

## ğŸ› ï¸ ì‹¤ì „ í™œìš©

### 1. ë„¤íŠ¸ì›Œí¬ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

**ì—°ê²° ë¬¸ì œ ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸:**

```python
class NetworkTroubleshooter:
    def __init__(self):
        self.diagnostic_tools = ["ping", "nslookup", "traceroute", "netstat", "ss"]
    
    def diagnose_pod_connectivity(self, source_pod, target_pod):
        """Pod ê°„ ì—°ê²° ë¬¸ì œ ì§„ë‹¨"""
        checks = {
            "basic_connectivity": [
                f"kubectl exec {source_pod} -- ping -c 3 {target_pod}",
                f"kubectl exec {source_pod} -- nc -zv {target_pod} 8080"
            ],
            "dns_resolution": [
                f"kubectl exec {source_pod} -- nslookup kubernetes.default",
                f"kubectl exec {source_pod} -- nslookup {target_pod}"
            ],
            "routing_check": [
                f"kubectl exec {source_pod} -- ip route",
                f"kubectl exec {source_pod} -- arp -a"
            ],
            "firewall_check": [
                "iptables -L -n | grep -E 'DROP|REJECT'",
                "kubectl get networkpolicies"
            ]
        }
        
        return checks
    
    def check_cni_status(self, node_name):
        """CNI í”ŒëŸ¬ê·¸ì¸ ìƒíƒœ í™•ì¸"""
        return {
            "cni_config": "/etc/cni/net.d/",
            "cni_bin": "/opt/cni/bin/",
            "pod_cidrs": f"kubectl get node {node_name} -o jsonpath='{{.spec.podCIDR}}'",
            "network_interfaces": f"kubectl debug node/{node_name} -- ip link show"
        }
```

### 2. ë„¤íŠ¸ì›Œí¬ ì •ì±… ì„¤ê³„

```python
class NetworkPolicyDesigner:
    def __init__(self):
        self.default_policies = {}
    
    def create_default_deny_policy(self, namespace):
        """ê¸°ë³¸ ê±°ë¶€ ì •ì±… ìƒì„±"""
        return {
            "apiVersion": "networking.k8s.io/v1",
            "kind": "NetworkPolicy",
            "metadata": {
                "name": "default-deny-all",
                "namespace": namespace
            },
            "spec": {
                "podSelector": {},  # ëª¨ë“  Podì— ì ìš©
                "policyTypes": ["Ingress", "Egress"]
            }
        }
    
    def create_microservice_policy(self, service_name, allowed_services):
        """ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ë³„ ë„¤íŠ¸ì›Œí¬ ì •ì±…"""
        return {
            "apiVersion": "networking.k8s.io/v1",
            "kind": "NetworkPolicy", 
            "metadata": {
                "name": f"{service_name}-netpol"
            },
            "spec": {
                "podSelector": {
                    "matchLabels": {"app": service_name}
                },
                "policyTypes": ["Ingress", "Egress"],
                "ingress": [
                    {
                        "from": [
                            {
                                "podSelector": {
                                    "matchLabels": {"app": svc}
                                }
                            }
                            for svc in allowed_services
                        ],
                        "ports": [
                            {"protocol": "TCP", "port": 8080}
                        ]
                    }
                ],
                "egress": [
                    {
                        "to": [
                            {
                                "podSelector": {
                                    "matchLabels": {"app": "database"}
                                }
                            }
                        ],
                        "ports": [
                            {"protocol": "TCP", "port": 5432}
                        ]
                    }
                ]
            }
        }
```

### 3. ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
class NetworkMonitor:
    def __init__(self):
        self.metrics_endpoints = {
            "prometheus": "http://prometheus.monitoring:9090",
            "grafana": "http://grafana.monitoring:3000"
        }
    
    def collect_network_metrics(self):
        """ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        return {
            "bandwidth_metrics": [
                "container_network_receive_bytes_total",
                "container_network_transmit_bytes_total"
            ],
            "latency_metrics": [
                "coredns_dns_request_duration_seconds",
                "rest_client_request_duration_seconds"
            ],
            "error_metrics": [
                "container_network_receive_errors_total",
                "coredns_dns_responses_total{rcode!='NOERROR'}"
            ]
        }
    
    def setup_network_dashboard(self):
        """ë„¤íŠ¸ì›Œí¬ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì„¤ì •"""
        return {
            "panels": [
                {
                    "title": "Pod ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½",
                    "query": "rate(container_network_receive_bytes_total[5m])"
                },
                {
                    "title": "DNS í•´ì„ ì§€ì—°ì‹œê°„", 
                    "query": "histogram_quantile(0.95, coredns_dns_request_duration_seconds_bucket)"
                },
                {
                    "title": "CNI í”ŒëŸ¬ê·¸ì¸ ì„±ëŠ¥",
                    "query": "cni_operations_duration_seconds"
                }
            ]
        }
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### DNS ì„±ëŠ¥ ìµœì í™”

```python
class DNSPerformanceOptimizer:
    def __init__(self):
        self.optimization_strategies = {}
    
    def optimize_ndots(self, workload_profile):
        """ndots ìµœì í™”ë¡œ DNS ì¡°íšŒ íšŸìˆ˜ ê°ì†Œ"""
        profiles = {
            "internal_services": {
                "ndots": 2,  # cluster.local ë„ë©”ì¸ ìš°ì„ 
                "expected_queries": 1
            },
            "external_apis": {
                "ndots": 1,  # ì™¸ë¶€ FQDN ìš°ì„ 
                "expected_queries": 1
            },
            "mixed_workload": {
                "ndots": 2,
                "search_domains": ["default.svc.cluster.local"],
                "expected_queries": 1.5
            }
        }
        
        return profiles[workload_profile]
    
    def setup_nodelocal_dns(self):
        """NodeLocal DNSCache ì„¤ì •"""
        return {
            "daemonset_config": {
                "cache_size": 1000,
                "negative_cache_ttl": 30,
                "local_dns_ip": "169.254.20.10",
                "prometheus_metrics": True
            },
            "performance_gain": {
                "latency_reduction": "85%",
                "dns_queries_per_second": "10x improvement",
                "cache_hit_rate": "95%"
            }
        }
```

### ëŒ€ì—­í­ ìµœì í™”

```python
class BandwidthOptimizer:
    def __init__(self):
        self.node_capacity = {}
    
    def calculate_network_limits(self, instance_type):
        """ì¸ìŠ¤í„´ìŠ¤ë³„ ë„¤íŠ¸ì›Œí¬ í•œê³„ ê³„ì‚°"""
        network_limits = {
            "m5.large": {"bandwidth_mbps": 750, "pps": 300000},
            "m5.xlarge": {"bandwidth_mbps": 1250, "pps": 500000},
            "c5n.xlarge": {"bandwidth_mbps": 25000, "pps": 1000000}
        }
        
        return network_limits.get(instance_type, {"bandwidth_mbps": 1000, "pps": 400000})
    
    def optimize_pod_placement(self, network_intensive_pods):
        """ë„¤íŠ¸ì›Œí¬ ì§‘ì•½ì  Pod ë°°ì¹˜ ìµœì í™”"""
        placement_strategy = {
            "anti_affinity": "Spread across nodes to avoid bandwidth contention",
            "node_selector": {
                "node.kubernetes.io/instance-type": "c5n.large"  # Enhanced networking
            },
            "topology_spread": {
                "max_skew": 1,
                "topology_key": "kubernetes.io/hostname"
            }
        }
        
        return placement_strategy
```

## ğŸ”’ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬ ì „ëµ

```python
class NetworkSecurityManager:
    def __init__(self):
        self.security_zones = {}
    
    def create_zero_trust_network(self):
        """ì œë¡œ íŠ¸ëŸ¬ìŠ¤íŠ¸ ë„¤íŠ¸ì›Œí¬ êµ¬í˜„"""
        return {
            "default_policy": "DENY_ALL",
            "explicit_allows": {
                "frontend": ["backend"],
                "backend": ["database"],
                "monitoring": ["all"]  # ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œë§Œ ì˜ˆì™¸
            },
            "encryption": {
                "service_mesh": "istio/linkerd",
                "mutual_tls": True,
                "certificates": "cert-manager"
            }
        }
    
    def implement_network_segmentation(self, environment):
        """í™˜ê²½ë³„ ë„¤íŠ¸ì›Œí¬ ë¶„í• """
        segmentation = {
            "production": {
                "namespaces": ["prod-frontend", "prod-backend", "prod-data"],
                "policies": "strict",
                "cross_namespace": False
            },
            "staging": {
                "namespaces": ["staging"],
                "policies": "permissive",
                "cross_namespace": True
            },
            "development": {
                "namespaces": ["dev-*"],
                "policies": "open",
                "cross_namespace": True
            }
        }
        
        return segmentation[environment]
```

## ğŸ¯ ì‹¤ìŠµ ë° ê²€ì¦

### ë„¤íŠ¸ì›Œí¬ ì„¤ì • ê²€ì¦

```bash
#!/bin/bash

# 1. Pod ê°„ ì—°ê²° í…ŒìŠ¤íŠ¸
echo "Testing pod-to-pod connectivity..."
kubectl run test-pod --image=busybox --rm -it -- ping -c 3 10.244.2.5

# 2. ì„œë¹„ìŠ¤ DNS í•´ì„ í…ŒìŠ¤íŠ¸  
echo "Testing DNS resolution..."
kubectl run dns-test --image=busybox --rm -it -- nslookup kubernetes.default

# 3. ì™¸ë¶€ ì—°ê²° í…ŒìŠ¤íŠ¸
echo "Testing external connectivity..."
kubectl run external-test --image=busybox --rm -it -- ping -c 3 8.8.8.8

# 4. CNI í”ŒëŸ¬ê·¸ì¸ ìƒíƒœ í™•ì¸
echo "Checking CNI status..."
kubectl get pods -n kube-system | grep -E "(flannel|calico|weave)"
```

ì´ì²˜ëŸ¼ Kubernetesì˜ í´ëŸ¬ìŠ¤í„° ë„¤íŠ¸ì›Œí‚¹ì€ ë³µì¡í•´ ë³´ì´ì§€ë§Œ, **ë‹¨ìˆœí•œ ì›ì¹™**ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë“  Podê°€ ê³ ìœ í•œ IPë¥¼ ê°–ê³ , NAT ì—†ì´ ì„œë¡œ í†µì‹ í•  ìˆ˜ ìˆë‹¤ëŠ” ê¸°ë³¸ ì›ì¹™ë§Œ ì´í•´í•˜ë©´, ë‚˜ë¨¸ì§€ëŠ” CNI í”ŒëŸ¬ê·¸ì¸ê³¼ CoreDNSê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•´ì¤ë‹ˆë‹¤.

ë‹¤ìŒ ë¬¸ì„œì—ì„œëŠ” ì´ëŸ¬í•œ ë„¤íŠ¸ì›Œí¬ ìœ„ì—ì„œ ë™ì‘í•˜ëŠ” **Serviceì˜ íƒ€ì…ë³„ ë™ì‘ ì›ë¦¬**ë¥¼ ìì„¸íˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.
