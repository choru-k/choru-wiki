---
tags:
  - AWS
  - ElastiCache
  - Redis
  - Memcached
  - Cache
---

# ElastiCacheì˜ ì¸ë©”ëª¨ë¦¬ ë§ˆë²•: ë§ˆì´í¬ë¡œì´ˆì˜ ì„¸ê³„

## ğŸ¯ Twitterì˜ íƒ€ì„ë¼ì¸ ì„œë¹™ ë„ì „

### 2022ë…„ ì¼ë¡  ë¨¸ìŠ¤í¬ ì¸ìˆ˜ í›„ ìµœì í™”

```text
ğŸ“… 2022ë…„ 11ì›”, Twitter ì¬í¸
ğŸ¦ ì¼ì¼ í™œì„± ì‚¬ìš©ì: 3ì–µ ëª…
ğŸ“ ì´ˆë‹¹ íŠ¸ìœ—: 6,000ê°œ
ğŸ”„ íƒ€ì„ë¼ì¸ ìƒˆë¡œê³ ì¹¨: ì´ˆë‹¹ 100ë§Œ íšŒ
âš¡ ìš”êµ¬ ë ˆì´í„´ì‹œ: < 50ms
```

Twitterì˜ ì¸í”„ë¼ íŒ€ì€ ê·¹í•œì˜ ìµœì í™” ì••ë°•ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ë§Œìœ¼ë¡œëŠ” ë¶ˆê°€ëŠ¥í–ˆì£ :

- **íƒ€ì„ë¼ì¸ ìƒì„±**: íŒ”ë¡œì›Œë³„ ì¿¼ë¦¬ 500ms
- **íŠ¸ë Œë”© ê³„ì‚°**: ì‹¤ì‹œê°„ ì§‘ê³„ 2ì´ˆ
- **ì‚¬ìš©ì ì„¸ì…˜**: 3ì–µ ê°œ ë™ì‹œ ê´€ë¦¬
- **API ë ˆì´íŠ¸ ë¦¬ë°‹**: ì´ˆë‹¹ 1000ë§Œ ì²´í¬

**"ìºì‹œê°€ ì—†ìœ¼ë©´ Twitterê°€ ì—†ë‹¤. ëª¨ë“  ê²ƒì€ ë©”ëª¨ë¦¬ì—ì„œ ì¼ì–´ë‚˜ì•¼ í•œë‹¤!"**

## ğŸš€ ElastiCache ì•„í‚¤í…ì²˜: Redis vs Memcached

### Redis Cluster Mode

```mermaid
graph TB
    subgraph "Application Layer"
        APP1[API Server 1]
        APP2[API Server 2]
        APP3[API Server 3]
    end

    subgraph "ElastiCache Redis Cluster"
        subgraph "Shard 1"
            M1[Master 1, Slots: 0-5460]
            R1[Replica 1-1]
            R2[Replica 1-2]
        end

        subgraph "Shard 2"
            M2[Master 2, Slots: 5461-10922]
            R3[Replica 2-1]
            R4[Replica 2-2]
        end

        subgraph "Shard 3"
            M3[Master 3, Slots: 10923-16383]
            R5[Replica 3-1]
            R6[Replica 3-2]
        end

        CM[Configuration Endpoint]
    end

    APP1 --> CM
    APP2 --> CM
    APP3 --> CM

    CM --> M1
    CM --> M2
    CM --> M3

    M1 -.->|Async Replication| R1
    M1 -.->|Async Replication| R2

    style M1 fill:#90EE90
    style M2 fill:#90EE90
    style M3 fill:#90EE90
```

### Redis Data Structures í™œìš©

```python
class TwitterCacheStrategy:
    def __init__(self):
        self.redis = redis.RedisCluster(
            startup_nodes=[{"host": "twitter-cache.abc.cache.amazonaws.com", "port": 6379}]
        )

    def cache_timeline(self, user_id):
        """
        ì‚¬ìš©ì íƒ€ì„ë¼ì¸ ìºì‹± ì „ëµ
        """
        # 1. Sorted Setìœ¼ë¡œ íƒ€ì„ë¼ì¸ ì €ì¥
        timeline_key = f"timeline:{user_id}"

        # íŠ¸ìœ—ì„ ì‹œê°„ìˆœìœ¼ë¡œ ì €ì¥
        tweets = self.get_latest_tweets(user_id)
        for tweet in tweets:
            self.redis.zadd(
                timeline_key,
                {tweet['id']: tweet['timestamp']}
            )

        # ìµœê·¼ 1000ê°œë§Œ ìœ ì§€
        self.redis.zremrangebyrank(timeline_key, 0, -1001)

        # TTL ì„¤ì • (1ì‹œê°„)
        self.redis.expire(timeline_key, 3600)

        return {
            "structure": "Sorted Set",
            "operations": {
                "add_tweet": "O(log N)",
                "get_timeline": "O(log N + M)",
                "remove_old": "O(log N + M)"
            },
            "memory": "~100KB per user"
        }

    def cache_trending(self):
        """
        íŠ¸ë Œë”© í† í”½ ì‹¤ì‹œê°„ ê³„ì‚°
        """
        # HyperLogLogìœ¼ë¡œ unique ì‚¬ìš©ì ì¶”ì 
        for hashtag in self.extract_hashtags(tweet):
            self.redis.pfadd(f"trending:{hashtag}:users", user_id)

        # ì¹´ìš´í„° ì¦ê°€
        self.redis.hincrby("trending:counts", hashtag, 1)

        # Top 10 íŠ¸ë Œë”© ê³„ì‚°
        trending = self.redis.zrevrange("trending:scores", 0, 9, withscores=True)

        return {
            "hyperloglog_accuracy": "0.81% ì˜¤ì°¨",
            "memory_usage": "12KB per hashtag",
            "calculation_time": "< 1ms"
        }
```

## ğŸ­ Auto Discoveryì™€ Failover

### ìë™ í˜ì¼ì˜¤ë²„ ë©”ì»¤ë‹ˆì¦˜

```mermaid
sequenceDiagram
    participant App as Application
    participant CE as Config Endpoint
    participant M as Master
    participant R1 as Replica 1
    participant R2 as Replica 2
    participant S as Sentinel

    Note over M: === ì •ìƒ ìš´ì˜ ===
    App->>CE: Get Cluster Topology
    CE-->>App: Master: M, Replicas: R1, R2
    App->>M: SET key value
    M-->>App: OK
    M->>R1: Async Replication
    M->>R2: Async Replication

    Note over M: === ì¥ì•  ê°ì§€ ===
    S->>M: PING
    M--xS: No Response
    S->>M: PING (Retry)
    M--xS: No Response
    S->>S: Master Down Confirmed

    Note over R1: === ìë™ í˜ì¼ì˜¤ë²„ ===
    S->>R1: Promote to Master
    R1->>R1: Accept Writes
    S->>R2: Replicate from R1
    S->>CE: Update Topology

    App->>CE: Get Cluster Topology
    CE-->>App: Master: R1, Replica: R2
    App->>R1: SET key value

    Note over S: Total Failover: 15-30ì´ˆ
```

### Multi-AZ êµ¬ì„±

```python
class ElastiCacheMultiAZ:
    def __init__(self):
        self.configuration = {
            "mode": "Multi-AZ with Auto-Failover",
            "replication_group": {
                "primary_endpoint": "twitter-cache.abc.cache.amazonaws.com",
                "reader_endpoint": "twitter-cache-ro.abc.cache.amazonaws.com"
            }
        }

    def setup_multi_az(self):
        """
        Multi-AZ ì„¤ì • ë° ì¥ì•  ì²˜ë¦¬
        """
        return {
            "architecture": {
                "primary": "us-west-2a",
                "replica1": "us-west-2b",
                "replica2": "us-west-2c"
            },

            "failover_behavior": {
                "detection_time": "3-15 seconds",
                "promotion_time": "15-30 seconds",
                "dns_propagation": "1-2 seconds",
                "total_downtime": "< 60 seconds"
            },

            "data_persistence": {
                "aof": "Append Only File",
                "rdb": "Point-in-time snapshots",
                "backup_retention": "35 days"
            },

            "split_brain_prevention": {
                "min_replicas_to_write": 1,
                "min_replicas_max_lag": 10
            }
        }
```

## ğŸ”¥ ìºì‹± íŒ¨í„´ê³¼ ì „ëµ

### Cache-Aside Pattern

```python
class CacheAsidePattern:
    def __init__(self):
        self.cache = ElastiCacheClient()
        self.db = RDSClient()

    def get_user_profile(self, user_id):
        """
        Lazy Loading: ìºì‹œ ë¯¸ìŠ¤ ì‹œì—ë§Œ ë¡œë“œ
        """
        # 1. ìºì‹œ í™•ì¸
        cache_key = f"user:{user_id}"
        cached = self.cache.get(cache_key)

        if cached:
            # ìºì‹œ íˆíŠ¸
            return {
                "data": json.loads(cached),
                "source": "cache",
                "latency": "< 1ms"
            }

        # 2. ìºì‹œ ë¯¸ìŠ¤ - DB ì¡°íšŒ
        user = self.db.query(f"SELECT * FROM users WHERE id = {user_id}")

        # 3. ìºì‹œì— ì €ì¥
        self.cache.setex(
            cache_key,
            3600,  # TTL: 1ì‹œê°„
            json.dumps(user)
        )

        return {
            "data": user,
            "source": "database",
            "latency": "50ms"
        }
```

### Write-Through Pattern

```python
class WriteThroughPattern:
    def update_user_profile(self, user_id, data):
        """
        Write-Through: DBì™€ ìºì‹œ ë™ì‹œ ì—…ë°ì´íŠ¸
        """
        # 1. ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
        self.db.execute(
            f"UPDATE users SET profile = %s WHERE id = %s",
            (json.dumps(data), user_id)
        )

        # 2. ìºì‹œ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
        cache_key = f"user:{user_id}"
        self.cache.setex(cache_key, 3600, json.dumps(data))

        # 3. ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”
        self.invalidate_related_caches(user_id)

        return {
            "consistency": "ê°•í•œ ì¼ê´€ì„±",
            "write_penalty": "2x (DB + Cache)",
            "benefit": "ìºì‹œ í•­ìƒ ìµœì‹ "
        }
```

### Cache Stampede ë°©ì§€

```python
class CacheStampedePrevention:
    def __init__(self):
        self.locks = {}

    def get_with_lock(self, key, fetch_function):
        """
        Cache Stampede ë°©ì§€ íŒ¨í„´
        """
        # 1. ìºì‹œ í™•ì¸
        cached = self.cache.get(key)
        if cached:
            return cached

        # 2. ë½ íšë“ ì‹œë„
        lock_key = f"lock:{key}"
        lock_acquired = self.cache.set(
            lock_key, "1",
            nx=True,  # Only if not exists
            ex=30     # 30ì´ˆ í›„ ìë™ í•´ì œ
        )

        if lock_acquired:
            try:
                # 3. ë°ì´í„° fetch (í•œ ë²ˆë§Œ ì‹¤í–‰)
                data = fetch_function()

                # 4. ìºì‹œ ì €ì¥
                self.cache.setex(key, 3600, data)

                return data
            finally:
                # 5. ë½ í•´ì œ
                self.cache.delete(lock_key)
        else:
            # ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ fetch ì¤‘ - ëŒ€ê¸° í›„ ì¬ì‹œë„
            time.sleep(0.1)
            return self.get_with_lock(key, fetch_function)
```

## ğŸ¨ Advanced Redis Features

### Redis Streams for ì‹¤ì‹œê°„ ë°ì´í„°

```python
class TwitterRealtimeStream:
    def __init__(self):
        self.stream_key = "tweets:stream"

    def publish_tweet(self, tweet):
        """
        Redis Streamsë¡œ ì‹¤ì‹œê°„ íŠ¸ìœ— ìŠ¤íŠ¸ë¦¬ë°
        """
        # ìŠ¤íŠ¸ë¦¼ì— ì¶”ê°€
        message_id = self.redis.xadd(
            self.stream_key,
            {
                "user_id": tweet["user_id"],
                "content": tweet["content"],
                "timestamp": tweet["timestamp"],
                "hashtags": json.dumps(tweet["hashtags"])
            },
            maxlen=100000  # ìµœëŒ€ 10ë§Œ ê°œ ìœ ì§€
        )

        return message_id

    def consume_stream(self, consumer_group, consumer_name):
        """
        Consumer Groupìœ¼ë¡œ ìŠ¤íŠ¸ë¦¼ ì†Œë¹„
        """
        # Consumer Group ìƒì„±
        try:
            self.redis.xgroup_create(self.stream_key, consumer_group, id='0')
        except:
            pass  # ì´ë¯¸ ì¡´ì¬

        # ë©”ì‹œì§€ ì½ê¸°
        messages = self.redis.xreadgroup(
            consumer_group,
            consumer_name,
            {self.stream_key: '>'},  # ìƒˆ ë©”ì‹œì§€ë§Œ
            count=100,
            block=1000  # 1ì´ˆ ëŒ€ê¸°
        )

        # ë©”ì‹œì§€ ì²˜ë¦¬ ë° ACK
        for message in messages:
            self.process_tweet(message)
            self.redis.xack(self.stream_key, consumer_group, message['id'])

        return len(messages)
```

### Redis Modules í™œìš©

```python
def redis_modules_usage():
    """
    Redis ëª¨ë“ˆì„ í™œìš©í•œ ê³ ê¸‰ ê¸°ëŠ¥
    """
    modules = {
        "RedisJSON": {
            "usage": "JSON ë¬¸ì„œ ì €ì¥ ë° ì¡°ì‘",
            "example": """
                JSON.SET user:123 . '{"name":"John","tweets":[]}'
                JSON.ARRAPPEND user:123 .tweets '"New tweet"'
            """,
            "benefit": "ë³µì¡í•œ ë°ì´í„° êµ¬ì¡° ë„¤ì´í‹°ë¸Œ ì§€ì›"
        },

        "RedisSearch": {
            "usage": "ì „ë¬¸ ê²€ìƒ‰",
            "example": """
                FT.CREATE tweets_idx ON JSON
                    PREFIX 1 tweet:
                    SCHEMA $.content TEXT $.user TAG

                FT.SEARCH tweets_idx "@content:elasticsearch"
            """,
            "benefit": "ë°€ë¦¬ì´ˆ ë‹¨ìœ„ ì „ë¬¸ ê²€ìƒ‰"
        },

        "RedisTimeSeries": {
            "usage": "ì‹œê³„ì—´ ë°ì´í„°",
            "example": """
                TS.ADD temperature:sensor1 * 25.3
                TS.RANGE temperature:sensor1 - + AGGREGATION avg 60
            """,
            "benefit": "íš¨ìœ¨ì ì¸ ì‹œê³„ì—´ ì €ì¥ ë° ì§‘ê³„"
        },

        "RedisBloom": {
            "usage": "í™•ë¥ ì  ë°ì´í„° êµ¬ì¡°",
            "example": """
                BF.ADD spam_filter "spam@example.com"
                BF.EXISTS spam_filter "user@example.com"
            """,
            "benefit": "ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì¤‘ë³µ ì²´í¬"
        }
    }

    return modules
```

## ğŸ’° ë¹„ìš© ìµœì í™” ì „ëµ

### Twitterì˜ ElastiCache ìµœì í™”

```python
class CostOptimization:
    def __init__(self):
        self.before = {
            "setup": "Self-managed Redis on EC2",
            "nodes": 100,  # r5.12xlarge
            "memory": "384GB per node",
            "monthly_cost": 200000,
            "ops_hours": 500
        }

        self.after = {
            "setup": "ElastiCache Redis",
            "nodes": 50,  # cache.r6g.8xlarge
            "memory": "203GB per node",
            "monthly_cost": 75000,
            "ops_hours": 50
        }

    def optimization_techniques(self):
        return {
            "1_data_tiering": {
                "strategy": "Hot data in memory, warm in SSD",
                "config": "cache.r6gd nodes with NVMe",
                "savings": "60% for warm data"
            },

            "2_compression": {
                "method": "LZF compression",
                "config": "activedefrag yes",
                "savings": "40% memory reduction"
            },

            "3_reserved_nodes": {
                "term": "3-year",
                "savings": "55% discount"
            },

            "4_right_sizing": {
                "monitoring": "CloudWatch metrics",
                "adjustment": "Scale down during off-peak",
                "savings": "30% from auto-scaling"
            }
        }
```

### Data Tiering ì „ëµ

```python
class DataTieringStrategy:
    def implement_tiering(self):
        """
        ë©”ëª¨ë¦¬ì™€ SSDë¥¼ í™œìš©í•œ ê³„ì¸µí™”
        """
        return {
            "hot_tier": {
                "storage": "Memory (DRAM)",
                "capacity": "200GB",
                "latency": "< 1ms",
                "data": "ìµœê·¼ 1ì‹œê°„ ë°ì´í„°"
            },

            "warm_tier": {
                "storage": "NVMe SSD",
                "capacity": "1TB",
                "latency": "< 5ms",
                "data": "1ì‹œê°„ ~ 24ì‹œê°„ ë°ì´í„°"
            },

            "automatic_tiering": {
                "algorithm": "LFU (Least Frequently Used)",
                "promotion": "SSD â†’ Memory on access",
                "demotion": "Memory â†’ SSD when cold"
            },

            "cost_benefit": {
                "memory_only": "$10,000/month",
                "with_tiering": "$4,000/month",
                "savings": "60%"
            }
        }
```

## ğŸš¨ ì‹¤ì „ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Case 1: ë©”ëª¨ë¦¬ ë¶€ì¡± (OOM)

```python
def troubleshoot_oom():
    """
    Out of Memory ë¬¸ì œ í•´ê²°
    """
    diagnosis = {
        "check_memory": "INFO memory",
        "check_eviction": "INFO stats | grep evicted_keys",
        "check_policy": "CONFIG GET maxmemory-policy"
    }

    solutions = {
        "1_eviction_policy": {
            "volatile-lru": "TTL ìˆëŠ” í‚¤ ì¤‘ LRU",
            "allkeys-lru": "ëª¨ë“  í‚¤ ì¤‘ LRU",
            "volatile-lfu": "TTL ìˆëŠ” í‚¤ ì¤‘ LFU",
            "allkeys-lfu": "ëª¨ë“  í‚¤ ì¤‘ LFU (ì¶”ì²œ)"
        },

        "2_memory_optimization": {
            "compression": "ì••ì¶• í™œì„±í™”",
            "data_structure": "ì ì ˆí•œ ìë£Œêµ¬ì¡° ì„ íƒ",
            "ttl": "ì ê·¹ì ì¸ TTL ì„¤ì •"
        },

        "3_scaling": {
            "vertical": "ë” í° ë…¸ë“œë¡œ ì—…ê·¸ë ˆì´ë“œ",
            "horizontal": "ìƒ¤ë“œ ì¶”ê°€"
        }
    }

    return solutions
```

### Case 2: ë†’ì€ ë ˆì´í„´ì‹œ

```python
class LatencyTroubleshooting:
    def diagnose_latency(self):
        """
        ë ˆì´í„´ì‹œ ë¬¸ì œ ì§„ë‹¨
        """
        commands = {
            "slowlog": "SLOWLOG GET 10",
            "latency_monitor": "LATENCY LATEST",
            "client_list": "CLIENT LIST",
            "command_stats": "INFO commandstats"
        }

        common_causes = {
            "slow_commands": {
                "issue": "KEYS, FLUSHDB ê°™ì€ O(N) ëª…ë ¹ì–´",
                "solution": "SCAN ì‚¬ìš©, ë°°ì¹˜ ì²˜ë¦¬"
            },

            "large_values": {
                "issue": "í° ê°’ ì²˜ë¦¬ (> 1MB)",
                "solution": "ê°’ ë¶„í• , ì••ì¶•"
            },

            "network": {
                "issue": "Cross-AZ í†µì‹ ",
                "solution": "ê°™ì€ AZì— ë°°ì¹˜"
            },

            "persistence": {
                "issue": "RDB ì €ì¥ ì¤‘ í¬í¬",
                "solution": "AOF ì‚¬ìš©, ë³µì œë³¸ì—ì„œ ë°±ì—…"
            }
        }

        return common_causes
```

### Case 3: ë³µì œ ì§€ì—°

```python
def handle_replication_lag():
    """
    ë³µì œ ì§€ì—° í•´ê²°
    """
    monitoring = {
        "check_lag": "INFO replication",
        "check_buffer": "CONFIG GET repl-backlog-size",
        "check_network": "PING replica"
    }

    solutions = {
        "increase_buffer": {
            "command": "CONFIG SET repl-backlog-size 256mb",
            "benefit": "ë„¤íŠ¸ì›Œí¬ ë‹¨ì ˆ ì‹œ ë³µêµ¬"
        },

        "reduce_write_load": {
            "strategy": "ì“°ê¸° ë¶€í•˜ ë¶„ì‚°",
            "implementation": "ì—¬ëŸ¬ ìƒ¤ë“œë¡œ ë¶„í• "
        },

        "optimize_network": {
            "placement": "ê°™ì€ placement group",
            "instance": "ë„¤íŠ¸ì›Œí¬ ìµœì í™” ì¸ìŠ¤í„´ìŠ¤"
        }
    }

    return solutions
```

## ğŸ¯ ElastiCache vs Self-Managed ì„ íƒ

```python
def elasticache_decision():
    """
    ê´€ë¦¬í˜• vs ìì²´ ê´€ë¦¬ ê²°ì •
    """
    comparison = {
        "ElastiCache": {
            "pros": [
                "ìë™ í˜ì¼ì˜¤ë²„",
                "ìë™ ë°±ì—…/ë³µêµ¬",
                "CloudWatch í†µí•©",
                "íŒŒë¼ë¯¸í„° ê·¸ë£¹ ê´€ë¦¬",
                "ë³´ì•ˆ íŒ¨ì¹˜ ìë™í™”"
            ],
            "cons": [
                "ì»¤ìŠ¤í…€ ëª¨ë“ˆ ì œí•œ",
                "íŠ¹ì • Redis ë²„ì „ë§Œ ì§€ì›",
                "15% ë¹„ìš© í”„ë¦¬ë¯¸ì—„"
            ],
            "best_for": "99% ì‚¬ìš© ì‚¬ë¡€"
        },

        "Self-Managed": {
            "pros": [
                "ì™„ì „í•œ ì œì–´",
                "ìµœì‹  ë²„ì „ ì¦‰ì‹œ ì‚¬ìš©",
                "ì»¤ìŠ¤í…€ ëª¨ë“ˆ ì„¤ì¹˜"
            ],
            "cons": [
                "ìš´ì˜ ë¶€ë‹´",
                "í˜ì¼ì˜¤ë²„ êµ¬í˜„ í•„ìš”",
                "ëª¨ë‹ˆí„°ë§ êµ¬ì¶• í•„ìš”"
            ],
            "best_for": "íŠ¹ìˆ˜ ìš”êµ¬ì‚¬í•­"
        }
    }

    return comparison
```

## ğŸ¬ ë§ˆë¬´ë¦¬: Twitterì˜ ElastiCache ì„±ê³µ

2024ë…„ í˜„ì¬, TwitterëŠ” ElastiCacheë¡œ:

- **ì‘ë‹µ ì‹œê°„**: 500ms â†’ 5ms (100x ê°œì„ )
- **ì²˜ë¦¬ëŸ‰**: ì´ˆë‹¹ 1000ë§Œ ìš”ì²­ ì²˜ë¦¬
- **ê°€ìš©ì„±**: 99.99% ë‹¬ì„±
- **ë¹„ìš©**: 70% ì ˆê°
- **ìš´ì˜**: 90% ìë™í™”

**"ElastiCacheëŠ” ìš°ë¦¬ê°€ ë§ˆì´í¬ë¡œì´ˆì˜ ì„¸ê³„ì—ì„œ ê²½ìŸí•  ìˆ˜ ìˆê²Œ í•´ì£¼ì—ˆë‹¤."**

---

## ğŸ¯ AWS Database ì„œë¹„ìŠ¤ ìµœì¢… ì„ íƒ ê°€ì´ë“œ

```python
def choose_aws_database():
    """
    ìµœì¢… ë°ì´í„°ë² ì´ìŠ¤ ì„ íƒ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬
    """
    decision_tree = {
        "ê´€ê³„í˜•_ë°ì´í„°": {
            "ë³µì¡í•œ_ì¿¼ë¦¬": {
                "ëŒ€ìš©ëŸ‰": "Aurora",
                "ì¤‘ì†Œê·œëª¨": "RDS"
            },
            "ë‹¨ìˆœ_CRUD": "DynamoDB"
        },

        "NoSQL_ë°ì´í„°": {
            "Key-Value": "DynamoDB",
            "Document": "DocumentDB",
            "Graph": "Neptune",
            "Time-Series": "Timestream"
        },

        "ìºì‹±": {
            "ë‹¨ìˆœ_ìºì‹±": "ElastiCache Memcached",
            "ë³µì¡í•œ_ìë£Œêµ¬ì¡°": "ElastiCache Redis",
            "ì‹¤ì‹œê°„_ìŠ¤íŠ¸ë¦¼": "ElastiCache Redis + Streams"
        },

        "ë¶„ì„": {
            "ì‹¤ì‹œê°„": "Kinesis + DynamoDB",
            "ë°°ì¹˜": "Aurora + Redshift",
            "ê²€ìƒ‰": "OpenSearch"
        }
    }

    return decision_tree
```

AWS Database ì„œë¹„ìŠ¤ì˜ ì—¬ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!

ì´ì œ AWSì˜ í•µì‹¬ ì„œë¹„ìŠ¤ë“¤(Networking, Compute, Database)ì˜ ë‚´ë¶€ êµ¬ì¡°ì™€ ì‹¤ì „ í™œìš©ë²•ì„ ëª¨ë‘ ë§ˆìŠ¤í„°í–ˆìŠµë‹ˆë‹¤!
