---
tags:
  - AWS
  - LoadBalancing
  - Algorithm
  - Mathematics
  - Performance
---

# ë¡œë“œë°¸ëŸ°ì‹± ì•Œê³ ë¦¬ì¦˜: Instagramì´ 10ì–µ ì‚¬ìš©ìì—ê²Œ ì‚¬ì§„ì„ ê³µì •í•˜ê²Œ ë¶„ë°°í•˜ëŠ” ë¹„ë²• ğŸ“Š

## ì´ ë¬¸ì„œë¥¼ ì½ê³  ë‚˜ë©´ ë‹µí•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ë“¤

- Instagramì€ ì–´ë–»ê²Œ 10ì–µ ì¥ì˜ ì‚¬ì§„ ì—…ë¡œë“œë¥¼ ê· ë“±í•˜ê²Œ ë¶„ì‚°í•˜ëŠ”ê°€?
- ì™œ Round Robinìœ¼ë¡œëŠ” ì„œë²„ í•˜ë‚˜ê°€ ì£½ì„ ë•Œê¹Œì§€ ëª°ë¼ì°¨ë¦¬ëŠ”ê°€?
- Googleì˜ MaglevëŠ” ì–´ë–»ê²Œ 99.99% ê· ë“± ë¶„ì‚°ì„ ë‹¬ì„±í•˜ëŠ”ê°€?
- NetflixëŠ” ì™œ P2C(Power of Two Choices)ë¥¼ ì„ íƒí–ˆëŠ”ê°€?
- Consistent Hashingì€ ì–´ë–»ê²Œ ì„œë²„ ì¶”ê°€/ì œê±° ì‹œ í˜¼ë€ì„ ìµœì†Œí™”í•˜ëŠ”ê°€?

## ì‹œì‘í•˜ë©°: 2018ë…„ Instagram ì›”ë“œì»µ ì‚¬ì§„ ëŒ€ë€ âš½

### 10ì–µ ì¥ì˜ ì‚¬ì§„ì´ ë™ì‹œì— ì—…ë¡œë“œë˜ë˜ ë‚ 

2018ë…„ 7ì›” 15ì¼, FIFA ì›”ë“œì»µ ê²°ìŠ¹ì „ - í”„ë‘ìŠ¤ ìš°ìŠ¹ ìˆœê°„:

```python
# ì›”ë“œì»µ ê²°ìŠ¹ - Instagram ì„œë²„ì˜ ì•…ëª½
world_cup_final = {
    "date": "2018-07-15 18:00 UTC",
    "event": "í”„ë‘ìŠ¤ ìš°ìŠ¹ ìˆœê°„",
    "impact": {
        "photo_uploads_per_second": "1,200,000",  # ì´ˆë‹¹ 120ë§Œ ì¥
        "stories_per_second": "800,000",
        "live_viewers": "50,000,000",
        "total_requests": "10,000,000,000"  # 100ì–µ ìš”ì²­
    }
}

# Round Robinìœ¼ë¡œ ë¶„ì‚°í–ˆë‹¤ë©´?
round_robin_disaster = {
    "server_1": "CPU 100% â†’ ğŸ’€ ë‹¤ìš´",
    "server_2": "ë©”ëª¨ë¦¬ ë¶€ì¡± â†’ ğŸ’€ ë‹¤ìš´", 
    "server_3": "ë””ìŠ¤í¬ í’€ â†’ ğŸ’€ ë‹¤ìš´",
    "server_4-1000": "ìœ íœ´ ìƒíƒœ... ğŸ˜´"
}

# Instagramì˜ ì‹¤ì œ í•´ê²°ì±…
instagram_solution = {
    "algorithm": "Bounded Load Consistent Hashing",
    "result": "ëª¨ë“  ì„œë²„ 60-70% ê· ë“± ë¶€í•˜",
    "downtime": "0ì´ˆ",
    "user_impact": "ì—†ìŒ"
}

print("êµí›ˆ: ì•Œê³ ë¦¬ì¦˜ì´ 10ì–µ ì‚¬ìš©ìì˜ ê²½í—˜ì„ ê²°ì •í•œë‹¤")
```

ì–´ë–»ê²Œ Instagramì€ ì´ëŸ° ëŒ€ê·œëª¨ íŠ¸ë˜í”½ì„ ì™„ë²½í•˜ê²Œ ë¶„ì‚°í–ˆì„ê¹Œìš”?

## Part 1: Round Robinì˜ í•¨ì • - ê³µì •í•¨ì˜ ì—­ì„¤ ğŸ²

### ìŠ¤íƒ€ë²…ìŠ¤ ì¤„ì„œê¸°ì˜ êµí›ˆ

```python
class StarbucksQueueProblem:
    """
    ìŠ¤íƒ€ë²…ìŠ¤ì—ì„œ Round Robinì´ ì‹¤íŒ¨í•˜ëŠ” ì´ìœ 
    """
    
    def simulate_coffee_orders(self):
        """
        3ëª…ì˜ ë°”ë¦¬ìŠ¤íƒ€, ë‹¤ì–‘í•œ ì£¼ë¬¸
        """
        baristas = {
            "Alice": {"skill": "Expert", "speed": 30},  # 30ì´ˆ/ìŒë£Œ
            "Bob": {"skill": "Intermediate", "speed": 45},  # 45ì´ˆ/ìŒë£Œ
            "Charlie": {"skill": "Beginner", "speed": 90}  # 90ì´ˆ/ìŒë£Œ
        }
        
        orders = [
            {"customer": "1", "drink": "Americano", "complexity": 1},
            {"customer": "2", "drink": "Caramel Macchiato", "complexity": 3},
            {"customer": "3", "drink": "Espresso", "complexity": 0.5},
            {"customer": "4", "drink": "Frappuccino", "complexity": 4},
            # ... 100ëª…ì˜ ê³ ê°
        ]
        
        # Round Robin ë¶„ë°°
        round_robin_result = self.round_robin_distribute(orders, baristas)
        
        print("â° Round Robin ê²°ê³¼:")
        print(f"Alice: {round_robin_result['Alice']['total_time']}ì´ˆ")
        print(f"Bob: {round_robin_result['Bob']['total_time']}ì´ˆ")  
        print(f"Charlie: {round_robin_result['Charlie']['total_time']}ì´ˆ")
        print(f"ğŸ˜± CharlieëŠ” ì—¬ì „íˆ ì¼í•˜ëŠ” ì¤‘... ë‚˜ë¨¸ì§€ëŠ” ë†€ê³  ìˆìŒ")
        
        # ì‹¤ì œ ìµœì  ë¶„ë°°
        optimal_result = self.optimal_distribute(orders, baristas)
        
        print(", âœ¨ ìµœì  ë¶„ë°° ê²°ê³¼:")
        print(f"ëª¨ë“  ë°”ë¦¬ìŠ¤íƒ€ê°€ ë™ì‹œì— ëë‚¨: {optimal_result['finish_time']}ì´ˆ")
        
        return {
            "round_robin_inefficiency": "40%",
            "optimal_efficiency": "95%"
        }
    
    def visualize_problem(self):
        """
        Round Robinì˜ ë¬¸ì œ ì‹œê°í™”
        """
        print("""
        Round Robin (ë‹¨ìˆœ ìˆœí™˜):
        Customer 1 â†’ Alice   âœ“ (30s)
        Customer 2 â†’ Bob     âœ“ (45s)
        Customer 3 â†’ Charlie âœ“ (90s)
        Customer 4 â†’ Alice   âœ“ (30s)
        Customer 5 â†’ Bob     âœ“ (45s)
        Customer 6 â†’ Charlie ... (ì•„ì§ë„ Customer 3 ì²˜ë¦¬ ì¤‘) âŒ
        
        ê²°ê³¼: Charlie ì•ì— ê¸´ ì¤„, AliceëŠ” ë†€ê³  ìˆìŒ
        
        ìµœì  ì•Œê³ ë¦¬ì¦˜ (Least Outstanding Work):
        Customer 1 â†’ Alice   âœ“ (30s)
        Customer 2 â†’ Alice   âœ“ (ì´ë¯¸ ëë‚¨, ë°”ë¡œ ì‹œì‘)
        Customer 3 â†’ Bob     âœ“ (45s)
        Customer 4 â†’ Alice   âœ“ 
        Customer 5 â†’ Bob     âœ“
        Customer 6 â†’ Alice   âœ“ (CharlieëŠ” ë³µì¡í•œ ì£¼ë¬¸ë§Œ)
        
        ê²°ê³¼: ëª¨ë“  ë°”ë¦¬ìŠ¤íƒ€ê°€ íš¨ìœ¨ì ìœ¼ë¡œ ì¼í•¨
        """)
```

### ì‹¤ì œ Round Robin êµ¬í˜„ê³¼ ê°œì„ 

```python
class ImprovedRoundRobin:
    """
    Instagramì´ ì‚¬ìš©í•˜ëŠ” ê°œì„ ëœ Round Robin
    """
    
    def __init__(self):
        self.servers = []
        self.current_index = 0
        self.request_counter = {}
        
    def weighted_smooth_round_robin(self):
        """
        Nginxê°€ ì‚¬ìš©í•˜ëŠ” Smooth Weighted Round Robin
        ì‹¤ì œë¡œ Instagram ì´ˆê¸°ì— ì‚¬ìš©í–ˆë˜ ì•Œê³ ë¦¬ì¦˜
        """
        servers = [
            {"id": "server1", "weight": 5, "current_weight": 0},
            {"id": "server2", "weight": 3, "current_weight": 0},
            {"id": "server3", "weight": 2, "current_weight": 0}
        ]
        
        total_weight = sum(s["weight"] for s in servers)
        
        # 100ê°œ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜
        distribution = []
        
        for request in range(100):
            # ê° ì„œë²„ì˜ current_weight ì¦ê°€
            for server in servers:
                server["current_weight"] += server["weight"]
            
            # ê°€ì¥ ë†’ì€ current_weight ì„œë²„ ì„ íƒ
            selected = max(servers, key=lambda x: x["current_weight"])
            selected["current_weight"] -= total_weight
            
            distribution.append(selected["id"])
        
        # ë¶„í¬ ë¶„ì„
        from collections import Counter
        result = Counter(distribution)
        
        print("ğŸ“Š Smooth Weighted Round Robin ë¶„í¬:")
        print(f"Server1 (weight=5): {result['server1']}% (ì˜ˆìƒ: 50%)")
        print(f"Server2 (weight=3): {result['server2']}% (ì˜ˆìƒ: 30%)")
        print(f"Server3 (weight=2): {result['server3']}% (ì˜ˆìƒ: 20%)")
        
        # ë¶„ì‚°ì˜ "smoothness" ì¸¡ì •
        self.measure_smoothness(distribution)
        
        return distribution
    
    def measure_smoothness(self, distribution):
        """
        ë¶„ì‚°ì˜ ê· ë“±ì„± ì¸¡ì • (Instagram ë©”íŠ¸ë¦­)
        """
        # ì—°ì†ëœ ê°™ì€ ì„œë²„ ì„ íƒ ì°¾ê¸°
        max_consecutive = 1
        current_consecutive = 1
        
        for i in range(1, len(distribution)):
            if distribution[i] == distribution[i-1]:
                current_consecutive += 1
                max_consecutive = max(max_consecutive, current_consecutive)
            else:
                current_consecutive = 1
        
        print(f", ğŸ¯ Smoothness ì ìˆ˜:")
        print(f"ìµœëŒ€ ì—°ì† ì„ íƒ: {max_consecutive}")
        print(f"ì´ìƒì : 1, ì‹¤ì œ: {max_consecutive}")
        print(f"í’ˆì§ˆ: {'â­' * (6 - min(max_consecutive, 5))}")
```

## Part 2: Consistent Hashing - Instagramì˜ ë¹„ë°€ ë¬´ê¸° ğŸ¯

### 2012ë…„ Instagramì˜ ìœ„ê¸°ì™€ í•´ê²°

```python
class InstagramConsistentHashing:
    """
    Instagramì´ Facebookì— ì¸ìˆ˜ë˜ë©° ê²ªì€ ìŠ¤ì¼€ì¼ë§ ë¬¸ì œ í•´ê²°
    """
    
    def __init__(self):
        self.year = 2012
        self.users = "100 million"
        self.servers = 100
        
    def the_scaling_crisis(self):
        """
        2012ë…„ 4ì›” - ì„œë²„ ì¶”ê°€ì˜ ì•…ëª½
        """
        crisis = {
            "date": "2012-04-09",
            "event": "Facebookì´ Instagram ì¸ìˆ˜ ë°œí‘œ",
            "user_surge": "30% ì¦ê°€ in 24 hours",
            "problem": "ì„œë²„ ì¶”ê°€ ì‹œ ëª¨ë“  ì‚¬ì§„ì´ ì¬ë°°ì¹˜ë¨"
        }
        
        # ê¸°ì¡´ í•´ì‹±ì˜ ë¬¸ì œ
        print("âŒ ê¸°ì¡´ ëª¨ë“ˆë¡œ í•´ì‹±ì˜ ì¬ì•™:")
        self.demonstrate_modulo_hashing_problem()
        
        # Consistent Hashing ë„ì…
        print(", âœ… Consistent Hashingì˜ êµ¬ì›:")
        self.demonstrate_consistent_hashing_solution()
        
        return crisis
    
    def demonstrate_modulo_hashing_problem(self):
        """
        ëª¨ë“ˆë¡œ í•´ì‹±ì˜ ë¬¸ì œì  ì‹œì—°
        """
        # 3ê°œ ì„œë²„ì—ì„œ ì‹œì‘
        servers = 3
        photos = {
            "photo1.jpg": hash("photo1.jpg") % servers,  # ì„œë²„ 0
            "photo2.jpg": hash("photo2.jpg") % servers,  # ì„œë²„ 1
            "photo3.jpg": hash("photo3.jpg") % servers,  # ì„œë²„ 2
            "photo4.jpg": hash("photo4.jpg") % servers,  # ì„œë²„ 0
            "photo5.jpg": hash("photo5.jpg") % servers,  # ì„œë²„ 1
        }
        
        print("ì´ˆê¸° ìƒíƒœ (3ê°œ ì„œë²„):")
        for photo, server in photos.items():
            print(f"  {photo} â†’ Server {server}")
        
        # ì„œë²„ 1ê°œ ì¶”ê°€
        servers = 4
        new_photos = {
            photo: hash(photo) % servers for photo in photos.keys()
        }
        
        print(", ì„œë²„ ì¶”ê°€ í›„ (4ê°œ ì„œë²„):")
        moved = 0
        for photo in photos.keys():
            old_server = photos[photo]
            new_server = new_photos[photo]
            if old_server != new_server:
                print(f"  {photo}: Server {old_server} â†’ Server {new_server} ğŸš¨ ì´ë™!")
                moved += 1
            else:
                print(f"  {photo}: Server {new_server} (ìœ ì§€)")
        
        print(f", ğŸ˜± {moved}/{len(photos)} ì‚¬ì§„ì´ ì´ë™í•´ì•¼ í•¨ ({moved*100//len(photos)}%)")
        print("ğŸ’€ ìºì‹œ ì „ì²´ ë¬´íš¨í™”, ì„œë¹„ìŠ¤ ë‹¤ìš´ ìœ„í—˜!")
    
    def demonstrate_consistent_hashing_solution(self):
        """
        Consistent Hashingìœ¼ë¡œ í•´ê²°
        """
        import hashlib
        
        class ConsistentHash:
            def __init__(self, nodes=None, virtual_nodes=150):
                self.virtual_nodes = virtual_nodes
                self.ring = {}
                self.sorted_keys = []
                self.nodes = nodes or []
                
                for node in self.nodes:
                    self.add_node(node)
            
            def _hash(self, key):
                return int(hashlib.md5(key.encode()).hexdigest(), 16)
            
            def add_node(self, node):
                """ë…¸ë“œ ì¶”ê°€"""
                for i in range(self.virtual_nodes):
                    virtual_key = f"{node}:{i}"
                    hash_value = self._hash(virtual_key)
                    self.ring[hash_value] = node
                    self.sorted_keys.append(hash_value)
                self.sorted_keys.sort()
            
            def get_node(self, key):
                """í‚¤ì— ëŒ€í•œ ë…¸ë“œ ì°¾ê¸°"""
                if not self.ring:
                    return None
                
                hash_value = self._hash(key)
                
                # ì´ì§„ íƒìƒ‰ìœ¼ë¡œ ë‹¤ìŒ ë…¸ë“œ ì°¾ê¸°
                import bisect
                index = bisect.bisect_right(self.sorted_keys, hash_value)
                if index == len(self.sorted_keys):
                    index = 0
                
                return self.ring[self.sorted_keys[index]]
        
        # ì‹œì—°
        ch = ConsistentHash(["server1", "server2", "server3"])
        
        photos = ["photo1.jpg", "photo2.jpg", "photo3.jpg", "photo4.jpg", "photo5.jpg"]
        original_mapping = {photo: ch.get_node(photo) for photo in photos}
        
        print("ì´ˆê¸° ìƒíƒœ (3ê°œ ì„œë²„):")
        for photo, server in original_mapping.items():
            print(f"  {photo} â†’ {server}")
        
        # ì„œë²„ ì¶”ê°€
        ch.add_node("server4")
        new_mapping = {photo: ch.get_node(photo) for photo in photos}
        
        print(", ì„œë²„ ì¶”ê°€ í›„ (4ê°œ ì„œë²„):")
        moved = 0
        for photo in photos:
            old = original_mapping[photo]
            new = new_mapping[photo]
            if old != new:
                print(f"  {photo}: {old} â†’ {new} ğŸ”„ ì´ë™")
                moved += 1
            else:
                print(f"  {photo}: {new} âœ… ìœ ì§€")
        
        print(f", ğŸ˜Š {moved}/{len(photos)} ì‚¬ì§„ë§Œ ì´ë™ ({moved*100//len(photos)}%)")
        print("âœ¨ ëŒ€ë¶€ë¶„ì˜ ìºì‹œ ìœ ì§€, ì„œë¹„ìŠ¤ ì•ˆì •!")
        
        # ê°€ìƒ ë…¸ë“œì˜ íš¨ê³¼
        self.visualize_virtual_nodes()
    
    def visualize_virtual_nodes(self):
        """
        ê°€ìƒ ë…¸ë“œì˜ ë¶„ì‚° íš¨ê³¼ ì‹œê°í™”
        """
        print(", ğŸ¯ ê°€ìƒ ë…¸ë“œì˜ ë§ˆë²•:")
        print("""
        ë¬¼ë¦¬ ì„œë²„ 1ê°œ â†’ 150ê°œ ê°€ìƒ ë…¸ë“œ
        
        í•´ì‹œ ë§ (0 ~ 2^32):
        |--v1.1--v2.1--v3.1--v1.2--v2.2--v1.3--v3.2--|
        
        Server1ì˜ ê°€ìƒ ë…¸ë“œ: v1.1, v1.2, v1.3, ... (150ê°œ)
        Server2ì˜ ê°€ìƒ ë…¸ë“œ: v2.1, v2.2, v2.3, ... (150ê°œ)
        Server3ì˜ ê°€ìƒ ë…¸ë“œ: v3.1, v3.2, v3.3, ... (150ê°œ)
        
        íš¨ê³¼:
        1. ê· ë“± ë¶„ì‚°: ê° ì„œë²„ê°€ ë§ì˜ ì—¬ëŸ¬ ë¶€ë¶„ ë‹´ë‹¹
        2. ë¶€ë“œëŸ¬ìš´ ì¶”ê°€/ì œê±°: ì˜í–¥ ìµœì†Œí™”
        3. í•«ìŠ¤íŒŸ ë°©ì§€: ë‹¨ì¼ ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€
        """)
```

## Part 3: Google Maglev - ìˆ˜í•™ì˜ ì˜ˆìˆ  ğŸ¨

### Googleì˜ 99.999% ê°€ìš©ì„± ë¹„ë°€

```python
class GoogleMaglevAlgorithm:
    """
    Googleì´ ì „ ì„¸ê³„ íŠ¸ë˜í”½ì„ ì²˜ë¦¬í•˜ëŠ” Maglev ì•Œê³ ë¦¬ì¦˜
    """
    
    def __init__(self):
        self.name = "Maglev"
        self.paper = "SIGCOMM 2016"
        self.use_cases = ["Google Load Balancer", "YouTube", "Gmail"]
        
    def the_maglev_story(self):
        """
        2008ë…„ YouTube ìŠ¤íŠ¸ë¦¬ë° ìœ„ê¸°ì™€ Maglev íƒ„ìƒ
        """
        story = {
            "year": 2008,
            "problem": "YouTube ë™ì˜ìƒ ë²„í¼ë§ ì§€ì˜¥",
            "cause": "ì¼ê´€ë˜ì§€ ì•Šì€ ì„œë²„ ì„ íƒ",
            "user_impact": "ê°™ì€ ë™ì˜ìƒì´ ë§¤ë²ˆ ë‹¤ë¥¸ ì„œë²„ì—ì„œ ë¡œë“œ",
            "solution": "Maglev - ì¼ê´€ë˜ê³  ê· ë“±í•œ í•´ì‹±"
        }
        
        print("ğŸ“º YouTubeì˜ ë¬¸ì œ:")
        print("User â†’ CDN Server A (ë¹„ë””ì˜¤ ì²­í¬ 1-10)")
        print("User â†’ CDN Server B (ë¹„ë””ì˜¤ ì²­í¬ 11-20) âŒ ìºì‹œ ë¯¸ìŠ¤!")
        print("User â†’ CDN Server C (ë¹„ë””ì˜¤ ì²­í¬ 21-30) âŒ ë˜ ìºì‹œ ë¯¸ìŠ¤!")
        print("ê²°ê³¼: ëŠê¹€, ë²„í¼ë§, ì‚¬ìš©ì ì´íƒˆ")
        
        print(", âœ¨ Maglevì˜ í•´ê²°:")
        print("User + VideoID â†’ í•­ìƒ ê°™ì€ ì„œë²„")
        print("ìºì‹œ íˆíŠ¸ìœ¨: 45% â†’ 97%")
        
        return story
    
    def maglev_implementation(self):
        """
        ì‹¤ì œ Maglev êµ¬í˜„ (Google ë…¼ë¬¸ ê¸°ë°˜)
        """
        import hashlib
        
        class Maglev:
            def __init__(self, backends, table_size=65537):
                """
                backends: ë°±ì—”ë“œ ì„œë²„ ë¦¬ìŠ¤íŠ¸
                table_size: ë£©ì—… í…Œì´ë¸” í¬ê¸° (ì†Œìˆ˜ì—¬ì•¼ í•¨)
                """
                self.backends = backends
                self.m = table_size  # 65537ì€ ì‹¤ì œ Googleì´ ì‚¬ìš©í•˜ëŠ” í¬ê¸°
                self.lookup_table = self._build_table()
                
            def _hash1(self, name):
                """offset ê³„ì‚°ìš© í•´ì‹œ"""
                h = hashlib.md5(name.encode()).digest()
                return int.from_bytes(h[:8], 'big')
            
            def _hash2(self, name):
                """skip ê³„ì‚°ìš© í•´ì‹œ"""
                h = hashlib.sha1(name.encode()).digest()
                return int.from_bytes(h[:8], 'big')
            
            def _build_table(self):
                """
                Maglev ë£©ì—… í…Œì´ë¸” êµ¬ì¶•
                ì‹œê°„ ë³µì¡ë„: O(M * N) where M = table_size, N = num_backends
                """
                n = len(self.backends)
                m = self.m
                
                # ê° ë°±ì—”ë“œì˜ preference list ìƒì„±
                preferences = []
                for backend in self.backends:
                    offset = self._hash1(backend) % m
                    skip = (self._hash2(backend) % (m - 1)) + 1
                    
                    # ì´ ë°±ì—”ë“œê°€ ì„ í˜¸í•˜ëŠ” ìŠ¬ë¡¯ ìˆœì„œ
                    pref = []
                    for j in range(m):
                        pref.append((offset + j * skip) % m)
                    preferences.append(pref)
                
                # ë£©ì—… í…Œì´ë¸” ì±„ìš°ê¸°
                lookup = [-1] * m
                next_index = [0] * n
                
                for _ in range(m):
                    for i in range(n):
                        # ë°±ì—”ë“œ iì˜ ë‹¤ìŒ ì„ í˜¸ ìŠ¬ë¡¯
                        while next_index[i] < m:
                            slot = preferences[i][next_index[i]]
                            next_index[i] += 1
                            
                            if lookup[slot] == -1:
                                lookup[slot] = i
                                break
                
                return lookup
            
            def get_backend(self, key):
                """
                í‚¤ì— ëŒ€í•œ ë°±ì—”ë“œ ì„ íƒ
                ì‹œê°„ ë³µì¡ë„: O(1)
                """
                hash_value = self._hash1(key) % self.m
                backend_index = self.lookup_table[hash_value]
                return self.backends[backend_index]
        
        # ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ
        maglev = Maglev(["server1", "server2", "server3"])
        
        # ë™ì¼í•œ ë¹„ë””ì˜¤ëŠ” í•­ìƒ ê°™ì€ ì„œë²„ë¡œ
        video_id = "dQw4w9WgXcQ"  # Never Gonna Give You Up
        server = maglev.get_backend(video_id)
        print(f"Video {video_id} â†’ {server}")
        
        # ë¶„ì‚° ê· ë“±ì„± í…ŒìŠ¤íŠ¸
        self.test_distribution_uniformity(maglev)
        
        return maglev
    
    def test_distribution_uniformity(self, maglev):
        """
        Maglevì˜ ê· ë“± ë¶„ì‚° í…ŒìŠ¤íŠ¸
        """
        from collections import Counter
        
        # 100ë§Œ ê°œ í‚¤ í…ŒìŠ¤íŠ¸
        distribution = Counter()
        for i in range(1000000):
            key = f"key_{i}"
            backend = maglev.get_backend(key)
            distribution[backend] += 1
        
        print(", ğŸ“Š Maglev ë¶„ì‚° ê· ë“±ì„± (100ë§Œ í‚¤):")
        total = sum(distribution.values())
        for backend, count in distribution.items():
            percentage = (count / total) * 100
            ideal = 100 / len(distribution)
            deviation = abs(percentage - ideal)
            print(f"{backend}: {percentage:.2f}% (ì´ìƒ: {ideal:.2f}%, í¸ì°¨: {deviation:.2f}%)")
        
        # Jain's Fairness Index ê³„ì‚°
        values = list(distribution.values())
        n = len(values)
        fairness = (sum(values) ** 2) / (n * sum(v ** 2 for v in values))
        print(f", ğŸ¯ Jain's Fairness Index: {fairness:.4f} (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê· ë“±)")
        print(f"Google ê¸°ì¤€: > 0.99 âœ…" if fairness > 0.99 else "ê°œì„  í•„ìš” âŒ")
```

## Part 4: Netflixì˜ P2C - ë‹¨ìˆœí•¨ì˜ ë¯¸í•™ ğŸ¬

### Power of Two Choicesì˜ ë†€ë¼ìš´ íš¨ê³¼

```python
class NetflixP2CAlgorithm:
    """
    Netflixê°€ ì„ íƒí•œ P2C (Power of Two Random Choices)
    """
    
    def __init__(self):
        self.name = "P2C"
        self.simplicity = "ë§¤ìš° ê°„ë‹¨"
        self.effectiveness = "ë†€ëê²Œ íš¨ê³¼ì "
        
    def netflix_streaming_challenge(self):
        """
        2020ë…„ íŒ¬ë°ë¯¹ - Netflix íŠ¸ë˜í”½ í­ì¦
        """
        pandemic_impact = {
            "date": "2020-03-15",
            "event": "ì „ ì„¸ê³„ ë¡ë‹¤ìš´ ì‹œì‘",
            "traffic_increase": "300%",
            "concurrent_streams": "200,000,000",
            "problem": "ì„œë²„ ë¶€í•˜ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥"
        }
        
        print("ğŸ¬ Netflixì˜ ë”œë ˆë§ˆ:")
        print("- Least Connections: ìƒíƒœ ì¶”ì  ì˜¤ë²„í—¤ë“œ í¼")
        print("- Consistent Hashing: ìŠ¤íŠ¸ë¦¬ë°ì—” ê³¼ë„í•¨")
        print("- Round Robin: ë„ˆë¬´ ë‹¨ìˆœí•¨")
        print(", ğŸ’¡ í•´ê²°ì±…: P2C - 2ê°œë§Œ ë³´ê³  ë” ë‚˜ì€ ê²ƒ ì„ íƒ!")
        
        self.demonstrate_p2c_magic()
        
        return pandemic_impact
    
    def demonstrate_p2c_magic(self):
        """
        P2Cì˜ ë§ˆë²• ê°™ì€ íš¨ê³¼ ì‹œì—°
        """
        import random
        import numpy as np
        
        class P2CBalancer:
            def __init__(self, num_servers=100):
                self.servers = {
                    f"server_{i}": {
                        "load": 0,
                        "capacity": random.randint(100, 200)
                    } for i in range(num_servers)
                }
            
            def select_server_random(self):
                """ìˆœìˆ˜ ëœë¤ ì„ íƒ"""
                return random.choice(list(self.servers.keys()))
            
            def select_server_p2c(self):
                """P2C: 2ê°œ ì¤‘ ë” ë‚˜ì€ ê²ƒ"""
                # ëœë¤í•˜ê²Œ 2ê°œ ì„ íƒ
                candidates = random.sample(list(self.servers.items()), 2)
                
                # ë¶€í•˜ê°€ ì ì€ ì„œë²„ ì„ íƒ
                server1, data1 = candidates[0]
                server2, data2 = candidates[1]
                
                load1 = data1["load"] / data1["capacity"]
                load2 = data2["load"] / data2["capacity"]
                
                return server1 if load1 < load2 else server2
            
            def simulate(self, num_requests=100000, algorithm="p2c"):
                """ì‹œë®¬ë ˆì´ì…˜"""
                # ì´ˆê¸°í™”
                for server in self.servers.values():
                    server["load"] = 0
                
                # ìš”ì²­ ë¶„ë°°
                for _ in range(num_requests):
                    if algorithm == "random":
                        selected = self.select_server_random()
                    else:  # p2c
                        selected = self.select_server_p2c()
                    
                    self.servers[selected]["load"] += 1
                
                # ê²°ê³¼ ë¶„ì„
                loads = [s["load"] / s["capacity"] for s in self.servers.values()]
                return {
                    "max_load": max(loads),
                    "avg_load": np.mean(loads),
                    "std_dev": np.std(loads),
                    "overloaded": sum(1 for l in loads if l > 1.0)
                }
        
        # ë¹„êµ í…ŒìŠ¤íŠ¸
        balancer = P2CBalancer(100)
        
        print(", ğŸ² ìˆœìˆ˜ ëœë¤ vs P2C ë¹„êµ (100ê°œ ì„œë²„, 10ë§Œ ìš”ì²­):")
        
        # ëœë¤
        random_result = balancer.simulate(100000, "random")
        print(f", ëœë¤ ì„ íƒ:")
        print(f"  ìµœëŒ€ ë¶€í•˜: {random_result['max_load']:.2f}")
        print(f"  í‘œì¤€í¸ì°¨: {random_result['std_dev']:.2f}")
        print(f"  ê³¼ë¶€í•˜ ì„œë²„: {random_result['overloaded']}ê°œ")
        
        # P2C
        p2c_result = balancer.simulate(100000, "p2c")
        print(f", P2C (2ê°œ ì¤‘ ì„ íƒ):")
        print(f"  ìµœëŒ€ ë¶€í•˜: {p2c_result['max_load']:.2f}")
        print(f"  í‘œì¤€í¸ì°¨: {p2c_result['std_dev']:.2f}")
        print(f"  ê³¼ë¶€í•˜ ì„œë²„: {p2c_result['overloaded']}ê°œ")
        
        improvement = (random_result['max_load'] - p2c_result['max_load']) / random_result['max_load'] * 100
        print(f", âœ¨ P2C ê°œì„  íš¨ê³¼: {improvement:.1f}% ìµœëŒ€ ë¶€í•˜ ê°ì†Œ!")
        
        # ìˆ˜í•™ì  ì¦ëª…
        self.mathematical_proof()
    
    def mathematical_proof(self):
        """
        P2Cì˜ ìˆ˜í•™ì  ìš°ìˆ˜ì„±
        """
        print(", ğŸ“ P2Cì˜ ìˆ˜í•™ì  ì¦ëª…:")
        print("""
        ìµœëŒ€ ë¶€í•˜ì˜ ê¸°ëŒ“ê°’:
        
        1. ëœë¤: O(log n / log log n)
        2. P2C:  O(log log n)
        
        n=1000 ì„œë²„ì¼ ë•Œ:
        - ëœë¤: ~3.0
        - P2C:  ~1.7
        
        ê±°ì˜ 2ë°° ê°œì„ ! ë‹¨ì§€ 2ê°œë§Œ ë´¤ì„ ë¿ì¸ë°!
        
        ì™œ íš¨ê³¼ì ì¸ê°€?
        - ì²« ë²ˆì§¸ ì„ íƒ: í‰ê· ì ì¸ ì„œë²„
        - ë‘ ë²ˆì§¸ ì„ íƒ: ë˜ ë‹¤ë¥¸ í‰ê· ì ì¸ ì„œë²„
        - ë‘˜ ì¤‘ í•˜ë‚˜ëŠ” í‰ê· ë³´ë‹¤ ë‚˜ì„ í™•ë¥ : 75%!
        """)
```

## Part 5: ì‹¤ì „ ìµœì í™” - Instagramì˜ êµí›ˆ ğŸ’¡

### ì•Œê³ ë¦¬ì¦˜ ì„ íƒ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬

```python
class AlgorithmSelectionGuide:
    """
    Instagram ì—”ì§€ë‹ˆì–´ë§ íŒ€ì˜ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ ê°€ì´ë“œ
    """
    
    def decision_tree(self, requirements):
        """
        ìš”êµ¬ì‚¬í•­ì— ë”°ë¥¸ ìµœì  ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
        """
        print("ğŸŒ³ ë¡œë“œë°¸ëŸ°ì‹± ì•Œê³ ë¦¬ì¦˜ ì„ íƒ íŠ¸ë¦¬:, ")
        
        # ì„¸ì…˜ ìœ ì§€ í•„ìš”?
        if requirements.get("session_affinity"):
            print("âœ“ ì„¸ì…˜ ìœ ì§€ í•„ìš” â†’ Consistent Hashing")
            return self.consistent_hashing_tuning()
        
        # ì„œë²„ ì„±ëŠ¥ ì°¨ì´ê°€ í°ê°€?
        if requirements.get("heterogeneous_servers"):
            print("âœ“ ì„œë²„ ì„±ëŠ¥ ì°¨ì´ í¼ â†’ Weighted Least Connections")
            return self.weighted_least_connections_tuning()
        
        # ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì´ ì¼ì •í•œê°€?
        if requirements.get("uniform_request_time"):
            print("âœ“ ì²˜ë¦¬ ì‹œê°„ ì¼ì • â†’ Round Robin")
            return self.round_robin_tuning()
        
        # ì´ˆê³ ì† ì²˜ë¦¬ í•„ìš”?
        if requirements.get("ultra_low_latency"):
            print("âœ“ ì´ˆì €ì§€ì—° í•„ìš” â†’ P2C")
            return self.p2c_tuning()
        
        # ê¸°ë³¸ê°’
        print("âœ“ ì¼ë°˜ì ì¸ ê²½ìš° â†’ Least Outstanding Requests")
        return self.least_outstanding_requests_tuning()
    
    def real_world_examples(self):
        """
        ì‹¤ì œ íšŒì‚¬ë“¤ì˜ ì„ íƒ
        """
        examples = {
            "Instagram": {
                "algorithm": "Bounded Load Consistent Hashing",
                "reason": "ì‚¬ì§„ ìºì‹± + ê· ë“± ë¶„ì‚°",
                "scale": "10ì–µ ì‚¬ìš©ì"
            },
            "Netflix": {
                "algorithm": "P2C with subsetting",
                "reason": "ë‹¨ìˆœí•¨ + íš¨ê³¼ì„±",
                "scale": "2ì–µ êµ¬ë…ì"
            },
            "Google": {
                "algorithm": "Maglev",
                "reason": "ì™„ë²½í•œ ê· ë“±ì„±",
                "scale": "ì „ ì„¸ê³„ íŠ¸ë˜í”½"
            },
            "Uber": {
                "algorithm": "Least Outstanding Requests",
                "reason": "ì‹¤ì‹œê°„ ë§¤ì¹­",
                "scale": "ì´ˆë‹¹ 100ë§Œ ìš”ì²­"
            },
            "Spotify": {
                "algorithm": "Rendezvous Hashing",
                "reason": "ìŒì•… ìŠ¤íŠ¸ë¦¬ë° ìºì‹±",
                "scale": "4ì–µ ì‚¬ìš©ì"
            }
        }
        
        print(", ğŸ¢ ì‹¤ì œ ê¸°ì—…ë“¤ì˜ ì„ íƒ:")
        for company, details in examples.items():
            print(f", {company}:")
            print(f"  ì•Œê³ ë¦¬ì¦˜: {details['algorithm']}")
            print(f"  ì´ìœ : {details['reason']}")
            print(f"  ê·œëª¨: {details['scale']}")
        
        return examples
    
    def performance_comparison(self):
        """
        ì•Œê³ ë¦¬ì¦˜ë³„ ì„±ëŠ¥ ë¹„êµ
        """
        print(", ğŸ“Š ì„±ëŠ¥ ë¹„êµí‘œ:, ")
        print("ì•Œê³ ë¦¬ì¦˜         | ì‹œê°„ë³µì¡ë„ | ê³µê°„ë³µì¡ë„ | ê· ë“±ì„± | ìƒíƒœìœ ì§€")
        print("----------------|-----------|-----------|-------|--------")
        print("Round Robin     | O(1)      | O(1)      | ë†’ìŒ   | ë¶ˆí•„ìš”")
        print("Least Conn      | O(log n)  | O(n)      | ìµœê³    | í•„ìš”")
        print("Consistent Hash | O(log n)  | O(n)      | ë†’ìŒ   | ë¶ˆí•„ìš”")
        print("Maglev          | O(1)      | O(M)      | ìµœê³    | ë¶ˆí•„ìš”")
        print("P2C             | O(1)      | O(n)      | ë†’ìŒ   | ì„ íƒì ")
        
        print(", ğŸ’¡ Instagramì˜ êµí›ˆ:")
        print("1. ì™„ë²½í•œ ì•Œê³ ë¦¬ì¦˜ì€ ì—†ë‹¤")
        print("2. íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ì´í•´í•˜ë¼")
        print("3. ì‹¤ì œ ì›Œí¬ë¡œë“œë¡œ í…ŒìŠ¤íŠ¸í•˜ë¼")
        print("4. ëª¨ë‹ˆí„°ë§ì´ í•µì‹¬ì´ë‹¤")
        print("5. í•„ìš”ì‹œ ì»¤ìŠ¤í…€ ì•Œê³ ë¦¬ì¦˜ì„ ë§Œë“¤ì–´ë¼")
```

## ë§ˆì¹˜ë©°: ì•Œê³ ë¦¬ì¦˜ì˜ ì˜ˆìˆ ê³¼ ê³¼í•™ ğŸ¨

### í•µì‹¬ êµí›ˆ ì •ë¦¬

```python
def load_balancing_mastery():
    """
    ë¡œë“œë°¸ëŸ°ì‹± ì•Œê³ ë¦¬ì¦˜ ë§ˆìŠ¤í„°ì˜ ê¸¸
    """
    golden_rules = {
        "1ï¸âƒ£": "Round Robinì€ ì‹œì‘ì ì¼ ë¿ì´ë‹¤",
        "2ï¸âƒ£": "Consistent Hashingì€ ìºì‹±ì˜ ì¹œêµ¬ë‹¤",
        "3ï¸âƒ£": "P2CëŠ” ë‹¨ìˆœí•¨ì˜ ê·¹ì¹˜ë‹¤",
        "4ï¸âƒ£": "MaglevëŠ” ì™„ë²½ì£¼ì˜ìë¥¼ ìœ„í•œ ê²ƒì´ë‹¤",
        "5ï¸âƒ£": "ì‹¤ì œ ì›Œí¬ë¡œë“œê°€ ë‹µì„ ì•Œë ¤ì¤€ë‹¤"
    }
    
    mastery_levels = {
        "ğŸ¥‰ Bronze": "Round Robin êµ¬í˜„, ê¸°ë³¸ ì´í•´",
        "ğŸ¥ˆ Silver": "Consistent Hashing êµ¬í˜„, ê°€ìƒ ë…¸ë“œ ì´í•´",
        "ğŸ¥‡ Gold": "P2C, Maglev ì´í•´, íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„",
        "ğŸ’ Diamond": "ì»¤ìŠ¤í…€ ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„, 10ì–µ ê·œëª¨ ì²˜ë¦¬"
    }
    
    final_wisdom = """
    ğŸ’¡ Remember:
    
    "Instagramì´ 10ì–µ ì‚¬ìš©ìë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ê²ƒì€
     ë‹¨ìˆœí•œ Round Robinì´ ì•„ë‹Œ,
     Bounded Load Consistent Hashing ë•ë¶„ì…ë‹ˆë‹¤.
     
     ì•Œê³ ë¦¬ì¦˜ í•˜ë‚˜ê°€ ì„œë¹„ìŠ¤ì˜ ì„±íŒ¨ë¥¼ ê°€ë¥¸ë‹¤."
    
    - Instagram Infrastructure Team
    """
    
    return golden_rules, mastery_levels, final_wisdom

# ì²´í¬ë¦¬ìŠ¤íŠ¸
print("ğŸ¯ Load Balancing Algorithm Mastery Check:")
print("â–¡ Round Robinì˜ í•œê³„ ê²½í—˜")
print("â–¡ Consistent Hashing êµ¬í˜„")
print("â–¡ P2C íš¨ê³¼ ì²´í—˜")
print("â–¡ Maglev ì´í•´")
print("â–¡ ì‹¤ì œ ëŒ€ê·œëª¨ ì‹œìŠ¤í…œ ì ìš©")
```

---

*"ìµœê³ ì˜ ì•Œê³ ë¦¬ì¦˜ì€ ê°€ì¥ ë³µì¡í•œ ê²ƒì´ ì•„ë‹ˆë¼, ë¬¸ì œì— ê°€ì¥ ì í•©í•œ ê²ƒì´ë‹¤"* - Instagram Engineering

ë‹¤ìŒì€ Kubernetes ë¬¸ì„œë¥¼ ìŠ¤í† ë¦¬í…”ë§ìœ¼ë¡œ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤! ğŸš€
