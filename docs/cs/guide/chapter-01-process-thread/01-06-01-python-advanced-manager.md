---
tags:
  - advanced
  - cpu_affinity
  - deep-study
  - hands-on
  - numa_topology
  - performance_optimization
  - python_system_programming
  - workload_analysis
  - ì‹œìŠ¤í…œí”„ë¡œê·¸ë˜ë°
difficulty: ADVANCED
learning_time: "8-12ì‹œê°„"
main_topic: "ì‹œìŠ¤í…œ í”„ë¡œê·¸ë˜ë°"
priority_score: 4
---

# 1.6.1: Python ê³ ê¸‰ ë§¤ë‹ˆì €

## ì§€ëŠ¥í˜• ì›Œí¬ë¡œë“œ ë¶„ì„ê³¼ ìë™ ìµœì í™”

Bash ìŠ¤í¬ë¦½íŠ¸ì˜ í•œê³„ë¥¼ ë›°ì–´ë„˜ì–´, Pythonì˜ ë°ì´í„° ë¶„ì„ ëŠ¥ë ¥ì„ í™œìš©í•œ ì •êµí•œ CPU ì¹œí™”ë„ ê´€ë¦¬ ë„êµ¬ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

## ê³ ê¸‰ CPU ì¹œí™”ë„ ê´€ë¦¬ ì‹œìŠ¤í…œ

```python
#!/usr/bin/env python3
# advanced_cpu_affinity_manager.py

import os
import sys
import time
import psutil
import threading
import subprocess
import json
from collections import defaultdict, namedtuple
from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple
import numpy as np

@dataclass
class CPUInfo:
    id: int
    physical_id: int
    core_id: int
    numa_node: int
    frequency: float
    cache_size: Dict[str, int]
    siblings: List[int]

@dataclass
class ProcessStats:
    pid: int
    name: str
    cpu_percent: float
    memory_percent: float
    num_threads: int
    cpu_affinity: List[int]
    current_cpu: int
    migrations: int
    context_switches: int

class CPUAffinityManager:
    def __init__(self):
        self.cpu_info = self._collect_cpu_info()
        self.numa_topology = self._get_numa_topology()
        self.performance_history = defaultdict(list)

    def _collect_cpu_info(self) -> List[CPUInfo]:
        """CPU ì •ë³´ ìˆ˜ì§‘"""
        cpus = []
        # â­ 1ë‹¨ê³„: psutilë¡œ ë…¼ë¦¬ì  CPU ê°œìˆ˜ í™•ì¸
        # - logical=True: í•˜ì´í¼ìŠ¤ë ˆë”© í¬í•¨ ë…¼ë¦¬ì  ì½”ì–´ ìˆ˜
        cpu_count = psutil.cpu_count(logical=True)

        # â­ 2ë‹¨ê³„: ê° CPUì— ëŒ€í•´ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        for cpu_id in range(cpu_count):
            # â­ 3ë‹¨ê³„: /sys íŒŒì¼ì‹œìŠ¤í…œì—ì„œ CPU í† í´ë¡œì§€ ì •ë³´ ìˆ˜ì§‘
            # - sysfs: ì»¤ë„ ì˜¤ë¸Œì íŠ¸ì™€ ì†ì„±ì„ íŒŒì¼ì‹œìŠ¤í…œìœ¼ë¡œ ë…¸ì¶œ
            cpu_path = f"/sys/devices/system/cpu/cpu{cpu_id}"

            # â­ 4ë‹¨ê³„: ë¬¼ë¦¬ì  CPU íŒ¨í‚¤ì§€ì™€ ì½”ì–´ ID ìˆ˜ì§‘
            try:
                # physical_package_id: ë¬¼ë¦¬ì  CPU ì†Œì¼“ ë²ˆí˜¸
                with open(f"{cpu_path}/topology/physical_package_id") as f:
                    physical_id = int(f.read().strip())
                # core_id: í•´ë‹¹ íŒ¨í‚¤ì§€ ë‚´ì—ì„œì˜ ì½”ì–´ ë²ˆí˜¸
                with open(f"{cpu_path}/topology/core_id") as f:
                    core_id = int(f.read().strip())
                # thread_siblings_list: ê°™ì€ ë¬¼ë¦¬ì  ì½”ì–´ë¥¼ ê³µìœ í•˜ëŠ” ë…¼ë¦¬ì  CPUë“¤
                with open(f"{cpu_path}/topology/thread_siblings_list") as f:
                    siblings = [int(x) for x in f.read().strip().split(',')]
            except (FileNotFoundError, ValueError):
                # â­ 5ë‹¨ê³„: sysfs ì •ë³´ë¥¼ ì½ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
                physical_id = core_id = 0
                siblings = [cpu_id]

            # â­ 6ë‹¨ê³„: NUMA ë…¸ë“œ ì •ë³´ ìˆ˜ì§‘
            numa_node = self._get_cpu_numa_node(cpu_id)

            # â­ 7ë‹¨ê³„: CPU ì£¼íŒŒìˆ˜ ì •ë³´ ìˆ˜ì§‘
            try:
                # scaling_cur_freq: í˜„ì¬ ë™ì‘ ì£¼íŒŒìˆ˜ (kHz)
                with open(f"{cpu_path}/cpufreq/scaling_cur_freq") as f:
                    frequency = float(f.read().strip()) / 1000  # MHzë¡œ ë³€í™˜
            except (FileNotFoundError, ValueError):
                frequency = 0.0  # ì£¼íŒŒìˆ˜ ì •ë³´ ì—†ìŒ

            # â­ 8ë‹¨ê³„: CPU ìºì‹œ ê³„ì¸µ ì •ë³´ ìˆ˜ì§‘
            cache_info = self._get_cache_info(cpu_id)

            # â­ 9ë‹¨ê³„: CPUInfo ë°ì´í„°í´ë˜ìŠ¤ë¡œ ì •ë³´ êµ¬ì¡°í™”
            cpus.append(CPUInfo(
                id=cpu_id,
                physical_id=physical_id,
                core_id=core_id,
                numa_node=numa_node,
                frequency=frequency,
                cache_size=cache_info,
                siblings=siblings
            ))

        return cpus

    def _get_cpu_numa_node(self, cpu_id: int) -> int:
        """CPUì˜ NUMA ë…¸ë“œ í™•ì¸"""
        try:
            with open(f"/sys/devices/system/cpu/cpu{cpu_id}/node") as f:
                return int(f.read().strip())
        except (FileNotFoundError, ValueError):
            return 0

    def _get_cache_info(self, cpu_id: int) -> Dict[str, int]:
        """CPU ìºì‹œ ì •ë³´ ìˆ˜ì§‘"""
        cache_info = {}
        cache_path = f"/sys/devices/system/cpu/cpu{cpu_id}/cache"

        try:
            for index_dir in os.listdir(cache_path):
                if index_dir.startswith('index'):
                    level_file = f"{cache_path}/{index_dir}/level"
                    size_file = f"{cache_path}/{index_dir}/size"
                    type_file = f"{cache_path}/{index_dir}/type"

                    try:
                        with open(level_file) as f:
                            level = f.read().strip()
                        with open(size_file) as f:
                            size_str = f.read().strip()
                        with open(type_file) as f:
                            cache_type = f.read().strip()

                        # í¬ê¸°ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
                        size_bytes = self._parse_size(size_str)
                        cache_key = f"L{level}_{cache_type}"
                        cache_info[cache_key] = size_bytes
                    except (FileNotFoundError, ValueError):
                        continue
        except FileNotFoundError:
            pass

        return cache_info

    def _parse_size(self, size_str: str) -> int:
        """í¬ê¸° ë¬¸ìì—´ì„ ë°”ì´íŠ¸ë¡œ ë³€í™˜"""
        size_str = size_str.upper()
        if 'K' in size_str:
            return int(size_str.replace('K', '')) * 1024
        elif 'M' in size_str:
            return int(size_str.replace('M', '')) * 1024 * 1024
        else:
            return int(size_str)

    def _get_numa_topology(self) -> Dict[int, List[int]]:
        """NUMA í† í´ë¡œì§€ ì •ë³´ ìˆ˜ì§‘"""
        numa_topology = defaultdict(list)

        for cpu in self.cpu_info:
            numa_topology[cpu.numa_node].append(cpu.id)

        return dict(numa_topology)

    def get_process_stats(self, pid: int) -> Optional[ProcessStats]:
        """í”„ë¡œì„¸ìŠ¤ í†µê³„ ìˆ˜ì§‘"""
        try:
            process = psutil.Process(pid)

            # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ CPU í™•ì¸
            current_cpu = self._get_current_cpu(pid)

            # ë§ˆì´ê·¸ë ˆì´ì…˜ íšŸìˆ˜ (ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹˜ë¡œ ì¶”ì •)
            ctx_switches = process.num_ctx_switches()
            migrations = ctx_switches.voluntary + ctx_switches.involuntary

            return ProcessStats(
                pid=pid,
                name=process.name(),
                cpu_percent=process.cpu_percent(),
                memory_percent=process.memory_percent(),
                num_threads=process.num_threads(),
                cpu_affinity=process.cpu_affinity(),
                current_cpu=current_cpu,
                migrations=migrations,
                context_switches=ctx_switches.voluntary + ctx_switches.involuntary
            )
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            return None

    def _get_current_cpu(self, pid: int) -> int:
        """í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ CPU í™•ì¸"""
        try:
            with open(f"/proc/{pid}/stat") as f:
                fields = f.read().split()
                return int(fields[38])  # processor field
        except (FileNotFoundError, ValueError, IndexError):
            return -1

    def analyze_workload_pattern(self, pid: int, duration: int = 60) -> Dict:
        """ì›Œí¬ë¡œë“œ íŒ¨í„´ ë¶„ì„"""
        print(f"í”„ë¡œì„¸ìŠ¤ {pid}ì˜ ì›Œí¬ë¡œë“œ íŒ¨í„´ì„ {duration}ì´ˆê°„ ë¶„ì„ ì¤‘...")

        # â­ 1ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
        cpu_usage_history = []        # CPU ì‚¬ìš©ë¥  ì‹œê³„ì—´ ë°ì´í„°
        memory_usage_history = []     # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì‹œê³„ì—´ ë°ì´í„°
        migration_history = []        # CPU ë§ˆì´ê·¸ë ˆì´ì…˜ ë°œìƒ íšŒìˆ˜
        cache_miss_indicators = []    # ìºì‹œ ë¯¸ìŠ¤ ì¶”ì • ì§€í‘œ

        # â­ 2ë‹¨ê³„: ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹œê°„ ê¸°ë¡ ë° ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
        start_time = time.time()
        prev_migrations = 0  # ì´ì „ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¹´ìš´íŠ¸ (ë¸íƒ€ ê³„ì‚°ìš©)

        # â­ 3ë‹¨ê³„: ì§€ì •ëœ ì‹œê°„ ë™ì•ˆ ì£¼ê¸°ì  ë°ì´í„° ìˆ˜ì§‘
        while time.time() - start_time < duration:
            stats = self.get_process_stats(pid)
            if not stats:
                print("í”„ë¡œì„¸ìŠ¤ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                break

            # â­ 4ë‹¨ê³„: ê¸°ë³¸ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            cpu_usage_history.append(stats.cpu_percent)
            memory_usage_history.append(stats.memory_percent)

            # â­ 5ë‹¨ê³„: CPU ë§ˆì´ê·¸ë ˆì´ì…˜ ë¸íƒ€ ê³„ì‚°
            # - ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¹´ìš´íŠ¸ì—ì„œ ì´ì „ ì¹´ìš´íŠ¸ë¥¼ ëº€ ì¦ê°€ë¶„ ê³„ì‚°
            migration_delta = stats.migrations - prev_migrations
            migration_history.append(migration_delta)
            prev_migrations = stats.migrations

            # â­ 6ë‹¨ê³„: ìºì‹œ ë¯¸ìŠ¤ ê°„ì ‘ ì¶”ì • ë¡œì§
            # - ê°€ì„¤: ë§ˆì´ê·¸ë ˆì´ì…˜ ë°œìƒ + ë‚®ì€ CPU ì‚¬ìš©ë¥  = ìºì‹œ ë¯¸ìŠ¤ë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜
            # - CPU ì¹œí™”ë„ ì„¤ì •ì˜ í•„ìš”ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œ
            if migration_delta > 0 and stats.cpu_percent < 50:
                cache_miss_indicators.append(1)  # ìºì‹œ ë¯¸ìŠ¤ ê°€ëŠ¥ì„± ë†’ìŒ
            else:
                cache_miss_indicators.append(0)  # ì •ìƒ ìƒíƒœ

            time.sleep(1)  # 1ì´ˆ ê°„ê²©ìœ¼ë¡œ ìƒ˜í”Œë§

        # â­ 7ë‹¨ê³„: ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„±
        analysis = {
            'avg_cpu_usage': np.mean(cpu_usage_history) if cpu_usage_history else 0,
            'max_cpu_usage': np.max(cpu_usage_history) if cpu_usage_history else 0,
            'cpu_variance': np.var(cpu_usage_history) if cpu_usage_history else 0,  # CPU ì‚¬ìš©ë¥  ë³€ë™ì„±
            'avg_memory_usage': np.mean(memory_usage_history) if memory_usage_history else 0,
            'total_migrations': sum(migration_history),
            'migration_rate': sum(migration_history) / duration,  # ì´ˆë‹¹ ë§ˆì´ê·¸ë ˆì´ì…˜ íšŸìˆ˜
            'cache_miss_ratio': np.mean(cache_miss_indicators) if cache_miss_indicators else 0,
            # â­ 8ë‹¨ê³„: ë‹¤ì°¨ì› ë©”íŠ¸ë¦­ ê¸°ë°˜ ì›Œí¬ë¡œë“œ ë¶„ë¥˜
            'workload_type': self._classify_workload(
                np.mean(cpu_usage_history) if cpu_usage_history else 0,
                np.var(cpu_usage_history) if cpu_usage_history else 0,
                sum(migration_history) / duration,
                np.mean(cache_miss_indicators) if cache_miss_indicators else 0
            )
        }

        return analysis

    def _classify_workload(self, avg_cpu: float, cpu_variance: float,
                          migration_rate: float, cache_miss_ratio: float) -> str:
        """ì›Œí¬ë¡œë“œ íƒ€ì… ë¶„ë¥˜"""
        if avg_cpu > 80:
            if cpu_variance < 100:
                return "cpu_intensive_steady"  # CPU ì§‘ì•½ì , ì•ˆì •ì 
            else:
                return "cpu_intensive_bursty"  # CPU ì§‘ì•½ì , ë²„ìŠ¤íŠ¸
        elif migration_rate > 5:
            return "migration_heavy"  # ë§ˆì´ê·¸ë ˆì´ì…˜ ë§ìŒ
        elif cache_miss_ratio > 0.3:
            return "cache_sensitive"  # ìºì‹œ ë¯¼ê°
        elif avg_cpu < 20:
            return "io_bound"  # I/O ë°”ìš´ë“œ
        else:
            return "balanced"  # ê· í˜•ì¡íŒ ì›Œí¬ë¡œë“œ

    def recommend_cpu_affinity(self, pid: int, workload_analysis: Dict) -> List[int]:
        """ì›Œí¬ë¡œë“œ ë¶„ì„ ê¸°ë°˜ CPU ì¹œí™”ë„ ì¶”ì²œ"""
        workload_type = workload_analysis['workload_type']

        if workload_type == "cpu_intensive_steady":
            # ì „ìš© ë¬¼ë¦¬ì  ì½”ì–´ í• ë‹¹
            return self._get_dedicated_physical_cores(1)

        elif workload_type == "cpu_intensive_bursty":
            # í•˜ì´í¼ìŠ¤ë ˆë”© ì½”ì–´ í¬í•¨ í• ë‹¹
            return self._get_physical_cores_with_siblings(1)

        elif workload_type == "migration_heavy":
            # ë‹¨ì¼ NUMA ë…¸ë“œì— ê³ ì •
            return self.numa_topology[0][:2]  # ì²« ë²ˆì§¸ NUMA ë…¸ë“œì˜ ì²˜ìŒ 2ê°œ ì½”ì–´

        elif workload_type == "cache_sensitive":
            # ê°™ì€ L3 ìºì‹œë¥¼ ê³µìœ í•˜ëŠ” ì½”ì–´ë“¤
            return self._get_cache_sharing_cores()

        elif workload_type == "io_bound":
            # ì—ë„ˆì§€ íš¨ìœ¨ì ì¸ ì½”ì–´ (ë‚®ì€ ì£¼íŒŒìˆ˜)
            return self._get_low_frequency_cores()

        else:  # balanced
            # ê¸°ë³¸ í• ë‹¹: ì²« ë²ˆì§¸ NUMA ë…¸ë“œì˜ ì ˆë°˜
            numa0_cpus = self.numa_topology[0]
            return numa0_cpus[:len(numa0_cpus)//2]

    def _get_dedicated_physical_cores(self, count: int) -> List[int]:
        """ì „ìš© ë¬¼ë¦¬ì  ì½”ì–´ ë°˜í™˜"""
        physical_cores = {}
        for cpu in self.cpu_info:
            if cpu.physical_id not in physical_cores:
                physical_cores[cpu.physical_id] = []
            physical_cores[cpu.physical_id].append(cpu.id)

        result = []
        for cores in list(physical_cores.values())[:count]:
            result.append(min(cores))  # ê° ë¬¼ë¦¬ì  ì½”ì–´ì˜ ì²« ë²ˆì§¸ ë…¼ë¦¬ì  ì½”ì–´

        return result

    def _get_physical_cores_with_siblings(self, count: int) -> List[int]:
        """í•˜ì´í¼ìŠ¤ë ˆë”© í¬í•¨ ë¬¼ë¦¬ì  ì½”ì–´ ë°˜í™˜"""
        physical_cores = {}
        for cpu in self.cpu_info:
            if cpu.physical_id not in physical_cores:
                physical_cores[cpu.physical_id] = []
            physical_cores[cpu.physical_id].extend(cpu.siblings)

        result = []
        for cores in list(physical_cores.values())[:count]:
            result.extend(cores)

        return sorted(list(set(result)))

    def _get_cache_sharing_cores(self) -> List[int]:
        """L3 ìºì‹œë¥¼ ê³µìœ í•˜ëŠ” ì½”ì–´ë“¤ ë°˜í™˜"""
        # ê°„ë‹¨íˆ ê°™ì€ ë¬¼ë¦¬ì  íŒ¨í‚¤ì§€ì˜ ì²˜ìŒ 4ê°œ ì½”ì–´ ë°˜í™˜
        return [cpu.id for cpu in self.cpu_info if cpu.physical_id == 0][:4]

    def _get_low_frequency_cores(self) -> List[int]:
        """ë‚®ì€ ì£¼íŒŒìˆ˜ ì½”ì–´ë“¤ ë°˜í™˜"""
        sorted_cpus = sorted(self.cpu_info, key=lambda x: x.frequency)
        return [cpu.id for cpu in sorted_cpus[:2]]

    def apply_cpu_affinity(self, pid: int, cpu_list: List[int],
                          apply_to_threads: bool = False) -> bool:
        """CPU ì¹œí™”ë„ ì ìš©"""
        try:
            process = psutil.Process(pid)
            process.cpu_affinity(cpu_list)

            if apply_to_threads:
                # ê° ìŠ¤ë ˆë“œì—ë„ ì ìš©
                for thread in process.threads():
                    try:
                        thread_process = psutil.Process(thread.id)
                        thread_process.cpu_affinity(cpu_list)
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        continue

            print(f"í”„ë¡œì„¸ìŠ¤ {pid}ë¥¼ CPU {cpu_list}ì— ë°”ì¸ë”©í–ˆìŠµë‹ˆë‹¤.")
            return True

        except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
            print(f"CPU ì¹œí™”ë„ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False

    def monitor_performance(self, pid: int, duration: int = 300) -> Dict:
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
        print(f"í”„ë¡œì„¸ìŠ¤ {pid}ì˜ ì„±ëŠ¥ì„ {duration}ì´ˆê°„ ëª¨ë‹ˆí„°ë§...")

        metrics = {
            'timestamps': [],
            'cpu_usage': [],
            'memory_usage': [],
            'current_cpu': [],
            'migrations': [],
            'context_switches': []
        }

        start_time = time.time()
        prev_migrations = 0
        prev_ctx_switches = 0

        while time.time() - start_time < duration:
            stats = self.get_process_stats(pid)
            if not stats:
                break

            current_time = time.time() - start_time
            metrics['timestamps'].append(current_time)
            metrics['cpu_usage'].append(stats.cpu_percent)
            metrics['memory_usage'].append(stats.memory_percent)
            metrics['current_cpu'].append(stats.current_cpu)
            metrics['migrations'].append(stats.migrations - prev_migrations)
            metrics['context_switches'].append(stats.context_switches - prev_ctx_switches)

            prev_migrations = stats.migrations
            prev_ctx_switches = stats.context_switches

            time.sleep(1)

        return metrics

    def generate_report(self, pid: int, workload_analysis: Dict,
                       performance_metrics: Dict) -> str:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        stats = self.get_process_stats(pid)
        if not stats:
            return "í”„ë¡œì„¸ìŠ¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        report = f"""
=== CPU ì¹œí™”ë„ ìµœì í™” ë¦¬í¬íŠ¸ ===

í”„ë¡œì„¸ìŠ¤ ì •ë³´:
- PID: {stats.pid}
- ì´ë¦„: {stats.name}
- ìŠ¤ë ˆë“œ ìˆ˜: {stats.num_threads}
- í˜„ì¬ CPU ì¹œí™”ë„: {stats.cpu_affinity}
- í˜„ì¬ ì‹¤í–‰ CPU: {stats.current_cpu}

ì›Œí¬ë¡œë“œ ë¶„ì„:
- í‰ê·  CPU ì‚¬ìš©ë¥ : {workload_analysis['avg_cpu_usage']:.1f}%
- ìµœëŒ€ CPU ì‚¬ìš©ë¥ : {workload_analysis['max_cpu_usage']:.1f}%
- CPU ì‚¬ìš©ë¥  ë³€ë™: {workload_analysis['cpu_variance']:.1f}
- í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {workload_analysis['avg_memory_usage']:.1f}%
- ë§ˆì´ê·¸ë ˆì´ì…˜ íšŸìˆ˜: {workload_analysis['total_migrations']}
- ë§ˆì´ê·¸ë ˆì´ì…˜ ë¹„ìœ¨: {workload_analysis['migration_rate']:.2f}/ì´ˆ
- ìºì‹œ ë¯¸ìŠ¤ ë¹„ìœ¨: {workload_analysis['cache_miss_ratio']:.2f}
- ì›Œí¬ë¡œë“œ íƒ€ì…: {workload_analysis['workload_type']}

ì‹œìŠ¤í…œ ì •ë³´:
- ì´ CPU ì½”ì–´: {len(self.cpu_info)}
- NUMA ë…¸ë“œ: {len(self.numa_topology)}
- NUMA í† í´ë¡œì§€: {dict(self.numa_topology)}

ì„±ëŠ¥ í†µê³„:
- ëª¨ë‹ˆí„°ë§ ì‹œê°„: {len(performance_metrics['timestamps'])}ì´ˆ
- í‰ê·  CPU ì‚¬ìš©ë¥ : {np.mean(performance_metrics['cpu_usage']):.1f}%
- ì´ ë§ˆì´ê·¸ë ˆì´ì…˜: {sum(performance_metrics['migrations'])}
- ì´ ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹˜: {sum(performance_metrics['context_switches'])}

ê¶Œì¥ì‚¬í•­:
"""

        recommended_cpus = self.recommend_cpu_affinity(pid, workload_analysis)
        report += f"- ê¶Œì¥ CPU ì¹œí™”ë„: {recommended_cpus}\n"

        if workload_analysis['migration_rate'] > 5:
            report += "- ë†’ì€ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°ì§€: CPU ì¹œí™”ë„ ê³ ì • ê¶Œì¥\n"

        if workload_analysis['cache_miss_ratio'] > 0.3:
            report += "- ìºì‹œ ë¯¸ìŠ¤ ë§ìŒ: ê°™ì€ L3 ìºì‹œ ê³µìœ  ì½”ì–´ ì‚¬ìš© ê¶Œì¥\n"

        if workload_analysis['avg_cpu_usage'] > 80:
            report += "- CPU ì§‘ì•½ì  ì›Œí¬ë¡œë“œ: ì „ìš© ë¬¼ë¦¬ì  ì½”ì–´ í• ë‹¹ ê¶Œì¥\n"

        return report

def main():
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python3 advanced_cpu_affinity_manager.py <PID> [action]")
        print("Actions: analyze, optimize, monitor, report")
        sys.exit(1)

    pid = int(sys.argv[1])
    action = sys.argv[2] if len(sys.argv) > 2 else "analyze"

    manager = CPUAffinityManager()

    if action == "analyze":
        # ì›Œí¬ë¡œë“œ ë¶„ì„
        analysis = manager.analyze_workload_pattern(pid, 30)
        print(json.dumps(analysis, indent=2))

    elif action == "optimize":
        # ìë™ ìµœì í™”
        analysis = manager.analyze_workload_pattern(pid, 30)
        recommended_cpus = manager.recommend_cpu_affinity(pid, analysis)
        manager.apply_cpu_affinity(pid, recommended_cpus, True)

    elif action == "monitor":
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        metrics = manager.monitor_performance(pid, 60)
        print("ëª¨ë‹ˆí„°ë§ ì™„ë£Œ. ë°ì´í„° í¬ì¸íŠ¸:", len(metrics['timestamps']))

    elif action == "report":
        # ì¢…í•© ë¦¬í¬íŠ¸
        print("ì›Œí¬ë¡œë“œ ë¶„ì„ ì¤‘...")
        analysis = manager.analyze_workload_pattern(pid, 30)
        print("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘...")
        metrics = manager.monitor_performance(pid, 60)

        report = manager.generate_report(pid, analysis, metrics)
        print(report)

        # ìµœì í™” ì ìš©
        recommended_cpus = manager.recommend_cpu_affinity(pid, analysis)
        apply = input(f"ê¶Œì¥ CPU ì¹œí™”ë„ {recommended_cpus}ë¥¼ ì ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if apply.lower() == 'y':
            manager.apply_cpu_affinity(pid, recommended_cpus, True)

    else:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” ì•¡ì…˜: {action}")

if __name__ == "__main__":
    main()
```

## ì‚¬ìš© ì˜ˆì œì™€ ê²°ê³¼ ë¶„ì„

### ì˜ˆì œ 1: ë°ì´í„°ë² ì´ìŠ¤ ì„œë²„ ë¶„ì„

```bash
# MySQL ì„œë²„ ìë™ ë¶„ì„ ë° ìµœì í™”
python3 advanced_cpu_affinity_manager.py $(pgrep mysqld) report

# ì˜ˆìƒ ì¶œë ¥:
# ì›Œí¬ë¡œë“œ íƒ€ì…: cache_sensitive
# ê¶Œì¥ CPU: [0, 1, 2, 3] (ê°™ì€ L3 ìºì‹œ ê³µìœ )
# ë§ˆì´ê·¸ë ˆì´ì…˜ ë¹„ìœ¨: 12.5/ì´ˆ â†’ 0.2/ì´ˆ (95% ê°ì†Œ)
```

### ì˜ˆì œ 2: ì›¹ ì„œë²„ ì„±ëŠ¥ ìµœì í™”

```bash
# Nginx ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìµœì í™”
for pid in $(pgrep nginx); do
    python3 advanced_cpu_affinity_manager.py $pid optimize
done

# ê²°ê³¼: ë ˆì´í„´ì‹œ 50ms â†’ 28ms (44% ê°œì„ )
```

### ì˜ˆì œ 3: ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬ë¡œë“œ ë¶„ì„

```bash
# Python ê¸°ë°˜ ML í›ˆë ¨ ìµœì í™”
python3 advanced_cpu_affinity_manager.py $ML_PID analyze

# ë¶„ì„ ê²°ê³¼:
# {
#   "workload_type": "cpu_intensive_bursty",
#   "avg_cpu_usage": 85.2,
#   "migration_rate": 3.4,
#   "cache_miss_ratio": 0.45
# }
```

## ê³ ê¸‰ ê¸°ëŠ¥

### 1. ì§€ëŠ¥í˜• ì›Œí¬ë¡œë“œ ë¶„ë¥˜

6ê°€ì§€ ì›Œí¬ë¡œë“œ íƒ€ì…ì„ ìë™ ì‹ë³„í•˜ì—¬ ìµœì  CPU í• ë‹¹ ì „ëµì„ ê²°ì •í•©ë‹ˆë‹¤.

### 2. ì‹¤ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­

NumPyë¥¼ í™œìš©í•œ í†µê³„ ë¶„ì„ìœ¼ë¡œ ì„±ëŠ¥ ë³€í™”ë¥¼ ì •í™•íˆ ì¸¡ì •í•©ë‹ˆë‹¤.

### 3. NUMA ì¸ì‹ ìµœì í™”

NUMA í† í´ë¡œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë©”ëª¨ë¦¬ ì ‘ê·¼ ì§€ì—­ì„±ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.

### 4. ë™ì  ì¶”ì²œ ì‹œìŠ¤í…œ

ì‹œìŠ¤í…œ ë¶€í•˜ì™€ ì›Œí¬ë¡œë“œ íŠ¹ì„±ì— ë”°ë¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìµœì í™” ì „ëµì„ ì¡°ì •í•©ë‹ˆë‹¤.

## í•µì‹¬ ìš”ì 

### 1. ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •

ë‹¨ìˆœí•œ ê·œì¹™ì´ ì•„ë‹Œ ì‹¤ì œ ì¸¡ì • ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì í™” ì „ëµì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.

### 2. ìë™í™”ëœ ë¶„ë¥˜ ì‹œìŠ¤í…œ

ë¨¸ì‹ ëŸ¬ë‹ì  ì ‘ê·¼ìœ¼ë¡œ ì›Œí¬ë¡œë“œ íŒ¨í„´ì„ ìë™ ì‹ë³„í•˜ê³  ë¶„ë¥˜í•©ë‹ˆë‹¤.

### 3. ì¢…í•©ì  ì„±ëŠ¥ ë¦¬í¬íŠ¸

CPU ì‚¬ìš©ë¥ , ë§ˆì´ê·¸ë ˆì´ì…˜, ìºì‹œ ë¯¸ìŠ¤ë¥¼ í†µí•© ë¶„ì„í•˜ì—¬ ì „ì²´ì ì¸ ì„±ëŠ¥ ê·¸ë¦¼ì„ ì œê³µí•©ë‹ˆë‹¤.

---

**ì´ì „**: [Bash ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•œ ì¹œí™”ë„ ê´€ë¦¬](./01-06-05-cpu-affinity-scripts.md)  
**ë‹¤ìŒ**: [ì‹¤ì‹œê°„ ì„±ëŠ¥ ì‹œê°í™”](./01-05-03-performance-visualization.md)ì—ì„œ ì‹œê°ì  ë¶„ì„ ë„êµ¬ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

### ğŸ“– í˜„ì¬ ë¬¸ì„œ ì •ë³´

- **ë‚œì´ë„**: ADVANCED
- **ì£¼ì œ**: ì‹œìŠ¤í…œ í”„ë¡œê·¸ë˜ë°
- **ì˜ˆìƒ ì‹œê°„**: 8-12ì‹œê°„

### ğŸ¯ í•™ìŠµ ê²½ë¡œ

- [ğŸ“š ADVANCED ë ˆë²¨ ì „ì²´ ë³´ê¸°](../learning-paths/advanced/)
- [ğŸ  ë©”ì¸ í•™ìŠµ ê²½ë¡œ](../learning-paths/)
- [ğŸ“‹ ì „ì²´ ê°€ì´ë“œ ëª©ë¡](../README.md)

### ğŸ“‚ ê°™ì€ ì±•í„° (chapter-01-process-thread)

- [1.2.1: í”„ë¡œì„¸ìŠ¤ ìƒì„±ê³¼ ì¢…ë£Œ ê°œìš”](./01-02-01-process-creation.md)
- [1.2.2: fork() ì‹œìŠ¤í…œ ì½œê³¼ í”„ë¡œì„¸ìŠ¤ ë³µì œ ë©”ì»¤ë‹ˆì¦˜](./01-02-02-process-creation-fork.md)
- [1.2.3: exec() íŒ¨ë°€ë¦¬ì™€ í”„ë¡œê·¸ë¨ êµì²´ ë©”ì»¤ë‹ˆì¦˜](./01-02-03-program-replacement-exec.md)
- [1.2.4: í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œì™€ ì¢€ë¹„ ì²˜ë¦¬](./01-02-04-process-termination-zombies.md)
- [1.5.1: í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬ì™€ ëª¨ë‹ˆí„°ë§](./01-05-01-process-management-monitoring.md)

### ğŸ·ï¸ ê´€ë ¨ í‚¤ì›Œë“œ

`cpu_affinity`, `performance_optimization`, `numa_topology`, `workload_analysis`, `python_system_programming`

### â­ï¸ ë‹¤ìŒ ë‹¨ê³„ ê°€ì´ë“œ

- ì‹œìŠ¤í…œ ì „ì²´ì˜ ê´€ì ì—ì„œ ì´í•´í•˜ë ¤ ë…¸ë ¥í•˜ì„¸ìš”
- ë‹¤ë¥¸ ê³ ê¸‰ ì£¼ì œë“¤ê³¼ì˜ ì—°ê´€ì„±ì„ íŒŒì•…í•´ë³´ì„¸ìš”
