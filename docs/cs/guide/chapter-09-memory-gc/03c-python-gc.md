---
tags:
  - Python
  - GC
  - RefCount
  - Memory
  - Performance
  - GIL
  - Overview
---

# Chapter 9-3c: Python GC ê°œìš”

## ğŸ¯ Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì™„ì „ ì •ë³µ

Pythonì˜ ë©”ëª¨ë¦¬ ê´€ë¦¬ëŠ” Reference Countingê³¼ Cycle Detectionì´ë¼ëŠ” ë…íŠ¹í•œ ì´ì¤‘ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” Python GCì˜ ë‚´ë¶€ ë™ì‘ ì›ë¦¬ë¶€í„° ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œì˜ ìµœì í™” ê¸°ë²•ê¹Œì§€ ì²´ê³„ì ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ“š í•™ìŠµ ë¡œë“œë§µ

ì´ ì„¹ì…˜ì€ 3ê°œì˜ ì „ë¬¸í™”ëœ ë¬¸ì„œë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

### 1ï¸âƒ£ [Python GC ê¸°ë³¸ êµ¬ì¡°ì™€ ë™ì‘ ì›ë¦¬](03c1-python-gc-fundamentals.md)

- Reference Counting vs Cycle Detection ì´ì¤‘ êµ¬ì¡°
- Generational GCì˜ 3ì„¸ëŒ€ ì‹œìŠ¤í…œ ë¶„ì„
- ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ê³¼ ëˆ„ìˆ˜ íƒì§€ ê¸°ë²•
- ìˆœí™˜ ì°¸ì¡° ë¬¸ì œì™€ í•´ê²° ë°©ë²•

### 2ï¸âƒ£ [Python GC ìµœì í™” ì „ëµê³¼ ê¸°ë²•](03c2-python-gc-optimization.md)

- ì½”ë“œ ë ˆë²¨ ë©”ëª¨ë¦¬ ìµœì í™” (__slots__, weak references)
- ë°°ì¹˜ ì²˜ë¦¬ ì‹œ GC ì œì–´ ê¸°ë²•
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¹„êµì™€ ì¸¡ì • ë°©ë²•
- ì‹¤ì „ ì„±ëŠ¥ ê°œì„  íŒ¨í„´

### 3ï¸âƒ£ [ì‹¤ì œ ì„œë¹„ìŠ¤ GC ìµœì í™” ì‚¬ë¡€](03c3-python-gc-production.md)

- Instagram Django ì„œë¹„ìŠ¤ ìµœì í™” ì‚¬ë¡€
- Dropbox ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ìµœì í™”
- í”„ë¡œë•ì…˜ í™˜ê²½ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµ
- ì„±ëŠ¥ ì¸¡ì •ê³¼ ëª¨ë‹ˆí„°ë§ ë°©ë²•

## ğŸ¯ í•µì‹¬ ê°œë… ë¹„êµí‘œ

| ì¸¡ë©´ | Reference Counting | Cycle Detection | ì„¤ëª… |
|------|-------------------|-----------------|------|
| __ë™ì‘ ë°©ì‹__ | ì¦‰ì‹œ í•´ì œ | ì£¼ê¸°ì  ì‹¤í–‰ | Reference Countê°€ 0ì´ ë˜ë©´ ì¦‰ì‹œ vs ìˆœí™˜ ì°¸ì¡° íƒì§€ í›„ ì¼ê´„ ìˆ˜ì§‘ |
| __ì ìš© ë²”ìœ„__ | ëŒ€ë¶€ë¶„ ê°ì²´ (90%+) | ìˆœí™˜ ì°¸ì¡° ê°ì²´ë§Œ | ì¼ë°˜ì ì¸ ê°ì²´ëŠ” Reference Countingìœ¼ë¡œ ì²˜ë¦¬ |
| __ì„±ëŠ¥ íŠ¹ì„±__ | ë¹ ë¥´ê³  ì˜ˆì¸¡ ê°€ëŠ¥ | ìƒëŒ€ì ìœ¼ë¡œ ë¬´ê±°ì›€ | GC ì¼ì‹œì •ì§€ ì‹œê°„ì˜ ì°¨ì´ |
| __ë©”ëª¨ë¦¬ í•´ì œ__ | ê²°ì •ì (deterministic) | ë¹„ê²°ì •ì  | ì–¸ì œ í•´ì œë ì§€ ì˜ˆì¸¡ ê°€ëŠ¥ì„± |

## ğŸš€ ì‹¤ì „ í™œìš© ì‹œë‚˜ë¦¬ì˜¤

### ì›¹ ì„œë¹„ìŠ¤ ìµœì í™”

Django, Flask ë“±ì˜ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ìš”ì²­ë³„ ë©”ëª¨ë¦¬ ê´€ë¦¬ì™€ GC ì œì–´ë¥¼ í†µí•œ ì‘ë‹µ ì‹œê°„ ê°œì„ 

### ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬

ë°°ì¹˜ ì‘ì—…ì´ë‚˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì—ì„œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”ì™€ GC ì¼ì‹œì •ì§€ ì‹œê°„ ìµœì†Œí™”

### ì¥ê¸° ì‹¤í–‰ ì„œë¹„ìŠ¤

ë°ëª¬ í”„ë¡œì„¸ìŠ¤ë‚˜ ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤ì—ì„œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ì™€ ì•ˆì •ì ì¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìœ ì§€

## ğŸ­ í•™ìŠµ ì „ëµ

### ì´ˆë³´ì (ì¶”ì²œ ìˆœì„œ)

1. [Python GC ê¸°ë³¸ êµ¬ì¡°](03c1-python-gc-fundamentals.md) â†’ Reference Countingê³¼ Cycle Detection ì´í•´
2. [ìµœì í™” ì „ëµ](03c2-python-gc-optimization.md) â†’ ì‹¤ìš©ì ì¸ ë©”ëª¨ë¦¬ ìµœì í™” ê¸°ë²• í•™ìŠµ
3. ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ì‹¤ìŠµ

### ì¤‘ê¸‰ì (ì‹¬í™” í•™ìŠµ)

1. [í”„ë¡œë•ì…˜ ì‚¬ë¡€](03c3-python-gc-production.md) â†’ ì‹¤ì œ ëŒ€ê·œëª¨ ì„œë¹„ìŠ¤ ìµœì í™” ê²½í—˜
2. [ìµœì í™” ì „ëµ](03c2-python-gc-optimization.md) â†’ ê³ ê¸‰ ìµœì í™” íŒ¨í„´ ì ìš©
3. ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œ GC ìµœì í™” ì ìš©

### ê³ ê¸‰ì (ì „ë¬¸ê°€ ê³¼ì •)

1. ëª¨ë“  ë¬¸ì„œ í†µí•© í•™ìŠµ
2. CPython ì†ŒìŠ¤ ì½”ë“œ ë¶„ì„
3. ì»¤ìŠ¤í…€ GC ì „ëµ ì„¤ê³„ ë° êµ¬í˜„

## ğŸ”— ì—°ê´€ í•™ìŠµ

### ì„ í–‰ í•™ìŠµ

- [ë©”ëª¨ë¦¬ í• ë‹¹ì](01-memory-allocator.md) - ë©”ëª¨ë¦¬ í• ë‹¹ì˜ ê¸°ë³¸ ì›ë¦¬
- [GC ì•Œê³ ë¦¬ì¦˜](02-gc-algorithms.md) - ë‹¤ì–‘í•œ GC ì•Œê³ ë¦¬ì¦˜ ë¹„êµ

### í›„ì† í•™ìŠµ

- [Java GC](03a-java-gc.md) - ë‹¤ë¥¸ ì–¸ì–´ì™€ì˜ GC ë¹„êµ
- [Go GC](03b-go-gc.md) - í˜„ëŒ€ì ì¸ GC ì„¤ê³„
- [ë©”ëª¨ë¦¬ ìµœì í™”](04-memory-optimization.md) - ì–¸ì–´ ë¬´ê´€ ìµœì í™” ê¸°ë²•

## ğŸ’¡ í•™ìŠµ ëª©í‘œ ë‹¬ì„± í™•ì¸

ì´ ì„¹ì…˜ì„ ì™„ë£Œí•˜ë©´:

- âœ… Python GCì˜ ì´ì¤‘ êµ¬ì¡°(Reference Counting + Cycle Detection) ì´í•´
- âœ… ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íŒ¨í„´ ì¸ì‹ê³¼ ì˜ˆë°© ë°©ë²• ìŠµë“
- âœ… í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œì˜ GC ìµœì í™” ì „ëµ ìˆ˜ë¦½ ëŠ¥ë ¥
- âœ… ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ê³¼ ì„±ëŠ¥ ì¸¡ì • ë„êµ¬ í™œìš© ëŠ¥ë ¥

---

**ì‹œì‘í•˜ê¸°**: [Python GC ê¸°ë³¸ êµ¬ì¡°ì™€ ë™ì‘ ì›ë¦¬](03c1-python-gc-fundamentals.md)ì—ì„œ Python ë©”ëª¨ë¦¬ ê´€ë¦¬ì˜ í•µì‹¬ ì›ë¦¬ë¥¼ í•™ìŠµí•˜ì„¸ìš”.

## 1. Python GCì˜ ì´ì¤‘ êµ¬ì¡°: Reference Counting + Cycle Detection

### 1.1 Python GCì˜ ë…íŠ¹í•œ ì„¤ê³„

```python
import gc
import sys
import weakref
import tracemalloc
from collections import defaultdict

# Python GC = Reference Counting (ê¸°ë³¸) + Generational GC (ìˆœí™˜ ì°¸ì¡° í•´ê²°)
"""
Python ë©”ëª¨ë¦¬ ê´€ë¦¬ì˜ ë‘ ì¶•:

1. Reference Counting (ì¦‰ì‹œ í•´ì œ)
   - ì°¸ì¡° ì¹´ìš´íŠ¸ê°€ 0ì´ ë˜ë©´ ì¦‰ì‹œ __del__ í˜¸ì¶œ
   - ëŒ€ë¶€ë¶„ì˜ ê°ì²´ê°€ ì´ ë°©ì‹ìœ¼ë¡œ í•´ì œë¨
   - ë¹ ë¥´ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•˜ì§€ë§Œ ìˆœí™˜ ì°¸ì¡° í•´ê²° ë¶ˆê°€

2. Cycle Detection (ì£¼ê¸°ì  ì‹¤í–‰)
   - 3ì„¸ëŒ€ generational GC
   - ìˆœí™˜ ì°¸ì¡°ëœ ê°ì²´ë“¤ë§Œ ë³„ë„ë¡œ ìˆ˜ì§‘
   - ìƒëŒ€ì ìœ¼ë¡œ ë¬´ê±°ìš´ ì‘ì—…
"""

class PythonGCDemo:
    """Python GC ë™ì‘ ë°©ì‹ì„ ì´í•´í•˜ê¸° ìœ„í•œ ì˜ˆì œ í´ë˜ìŠ¤"""

    def __init__(self, name):
        self.name = name
        self.data = [0] * 1000000  # 1M integers (~4MB)
        print(f"ê°ì²´ ìƒì„±: {self.name} (id: {id(self)})")

    def __del__(self):
        """ì†Œë©¸ì - Reference Countê°€ 0ì´ ë  ë•Œ ì¦‰ì‹œ í˜¸ì¶œ"""
        print(f"ê°ì²´ ì†Œë©¸: {self.name} (id: {id(self)})")

def demonstrate_reference_counting():
    """Pythonì˜ ê¸°ë³¸ ë©”ì»¤ë‹ˆì¦˜: Reference Counting"""

    print("=== Reference Counting ë°ëª¨ ===")

    # ê°ì²´ ìƒì„±ê³¼ ì°¸ì¡° ì¹´ìš´íŠ¸ ì¶”ì 
    obj = PythonGCDemo("test_object")
    print(f"ì´ˆê¸° ì°¸ì¡° ì¹´ìš´íŠ¸: {sys.getrefcount(obj) - 1}")  # -1: getrefcount ìì²´ ì°¸ì¡° ì œì™¸

    # ì°¸ì¡° ì¦ê°€
    ref1 = obj
    print(f"ref1 ì¶”ê°€ í›„: {sys.getrefcount(obj) - 1}")  # 2

    ref2 = obj
    print(f"ref2 ì¶”ê°€ í›„: {sys.getrefcount(obj) - 1}")  # 3

    # ì°¸ì¡° ê°ì†Œ
    del ref1
    print(f"ref1 ì‚­ì œ í›„: {sys.getrefcount(obj) - 1}")  # 2

    del ref2
    print(f"ref2 ì‚­ì œ í›„: {sys.getrefcount(obj) - 1}")  # 1

    # ë§ˆì§€ë§‰ ì°¸ì¡° ì œê±° - ì¦‰ì‹œ __del__ í˜¸ì¶œë¨
    del obj
    print("obj ì‚­ì œ ì™„ë£Œ - __del__ ì¦‰ì‹œ í˜¸ì¶œë¨")

    """
    ì¶œë ¥ ì˜ˆì‹œ:
    ê°ì²´ ìƒì„±: test_object (id: 140234567890123)
    ì´ˆê¸° ì°¸ì¡° ì¹´ìš´íŠ¸: 1
    ref1 ì¶”ê°€ í›„: 2
    ref2 ì¶”ê°€ í›„: 3
    ref1 ì‚­ì œ í›„: 2
    ref2 ì‚­ì œ í›„: 1
    ê°ì²´ ì†Œë©¸: test_object (id: 140234567890123)
    obj ì‚­ì œ ì™„ë£Œ - __del__ ì¦‰ì‹œ í˜¸ì¶œë¨
    """

def demonstrate_circular_reference():
    """ìˆœí™˜ ì°¸ì¡° ë¬¸ì œì™€ Cycle Detectorì˜ ì—­í• """

    print("\n=== ìˆœí™˜ ì°¸ì¡° ë°ëª¨ ===")

    class Node:
        def __init__(self, value):
            self.value = value
            self.ref = None
            print(f"Node ìƒì„±: {value}")

        def __del__(self):
            print(f"Node ì†Œë©¸: {self.value}")

    # GC í†µê³„ ì´ˆê¸°ê°’
    initial_objects = len(gc.get_objects())
    print(f"ì´ˆê¸° ê°ì²´ ìˆ˜: {initial_objects}")

    # ìˆœí™˜ ì°¸ì¡° ìƒì„±
    print("\nìˆœí™˜ ì°¸ì¡° ìƒì„±...")
    a = Node(1)
    b = Node(2)
    a.ref = b
    b.ref = a  # ìˆœí™˜ ì°¸ì¡° ì™„ì„±!

    print(f"ìˆœí™˜ ì°¸ì¡° ìƒì„± í›„ ê°ì²´ ìˆ˜: {len(gc.get_objects())}")

    # ë¡œì»¬ ì°¸ì¡° ì œê±° - í•˜ì§€ë§Œ ìˆœí™˜ ì°¸ì¡°ë¡œ ì¸í•´ í•´ì œë˜ì§€ ì•ŠìŒ
    print("\në¡œì»¬ ì°¸ì¡° ì œê±°...")
    del a
    del b
    print("del a, b ì™„ë£Œ - í•˜ì§€ë§Œ __del__ í˜¸ì¶œë˜ì§€ ì•ŠìŒ (ìˆœí™˜ ì°¸ì¡°)")

    print(f"ë¡œì»¬ ì°¸ì¡° ì œê±° í›„ ê°ì²´ ìˆ˜: {len(gc.get_objects())}")

    # Cycle Detector ìˆ˜ë™ ì‹¤í–‰
    print("\nìˆ˜ë™ GC ì‹¤í–‰...")
    collected = gc.collect()  # ìˆœí™˜ ì°¸ì¡° í•´ê²°
    print(f"ìˆ˜ì§‘ëœ ê°ì²´ ìˆ˜: {collected}")
    print(f"GC í›„ ê°ì²´ ìˆ˜: {len(gc.get_objects())}")

    """
    í•µì‹¬ í¬ì¸íŠ¸:
    - Reference Countingë§Œìœ¼ë¡œëŠ” ìˆœí™˜ ì°¸ì¡° í•´ê²° ë¶ˆê°€
    - Cycle Detectorê°€ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ ìˆœí™˜ ì°¸ì¡° íƒì§€
    - ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì´ëŸ° íŒ¨í„´ì´ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ì˜ ì£¼ìš” ì›ì¸
    """

def analyze_gc_generations():
    """Pythonì˜ 3ì„¸ëŒ€ Generational GC ë¶„ì„"""

    print("\n=== Generational GC ë¶„ì„ ===")

    # í˜„ì¬ GC ì„¤ì • í™•ì¸
    thresholds = gc.get_threshold()
    print(f"GC ì„ê³„ê°’: {thresholds}")
    """
    ê¸°ë³¸ê°’: (700, 10, 10)
    - Gen0: 700ê°œ ê°ì²´ í• ë‹¹ ì‹œ GC ì‹¤í–‰
    - Gen1: Gen0 GCê°€ 10ë²ˆ ì‹¤í–‰ë˜ë©´ Gen1 GC ì‹¤í–‰
    - Gen2: Gen1 GCê°€ 10ë²ˆ ì‹¤í–‰ë˜ë©´ Gen2 GC ì‹¤í–‰ (ì „ì²´)
    """

    # ê° ì„¸ëŒ€ë³„ í˜„ì¬ ê°ì²´ ìˆ˜ì™€ ì„ê³„ê°’ ìƒíƒœ
    counts = gc.get_count()
    print(f"í˜„ì¬ ì¹´ìš´íŠ¸: {counts}")
    print(f"Gen0: {counts[0]}/{thresholds[0]} (ë‹¤ìŒ GCê¹Œì§€ {thresholds[0] - counts[0]})")
    print(f"Gen1: {counts[1]}/{thresholds[1]}")
    print(f"Gen2: {counts[2]}/{thresholds[2]}")

    # ê° ì„¸ëŒ€ë³„ ê°ì²´ ìˆ˜ í™•ì¸
    for generation in range(3):
        objects = gc.get_objects(generation)
        print(f"Generation {generation}: {len(objects)} objects")

        # ê°ì²´ íƒ€ì…ë³„ ë¶„ë¥˜ (ìƒìœ„ 5ê°œ)
        type_count = defaultdict(int)
        for obj in objects:
            type_count[type(obj).__name__] += 1

        print(f"  ì£¼ìš” íƒ€ì…: {dict(sorted(type_count.items(), key=lambda x: x[1], reverse=True)[:5])}")

    # GC í†µê³„ í™•ì¸
    stats = gc.get_stats()
    for i, stat in enumerate(stats):
        print(f"Generation {i} í†µê³„: collections={stat['collections']}, "
              f"collected={stat['collected']}, uncollectable={stat['uncollectable']}")

def customize_gc_behavior():
    """GC ë™ì‘ ì»¤ìŠ¤í„°ë§ˆì´ì§•"""

    print("\n=== GC ë™ì‘ ì»¤ìŠ¤í„°ë§ˆì´ì§• ===")

    # ì›ë˜ ì„¤ì • ë°±ì—…
    original_threshold = gc.get_threshold()
    original_enabled = gc.isenabled()

    # GC ì„ê³„ê°’ ì¡°ì • - ë” ìì£¼ ì‹¤í–‰
    gc.set_threshold(500, 5, 5)  # ê¸°ë³¸ê°’ë³´ë‹¤ ë” ì ê·¹ì 
    print(f"ìƒˆë¡œìš´ ì„ê³„ê°’ ì„¤ì •: {gc.get_threshold()}")

    # íŠ¹ì • ì„¸ëŒ€ë§Œ ìˆ˜ì§‘
    print("\nì„¸ëŒ€ë³„ ê°œë³„ ìˆ˜ì§‘:")
    before_gen0 = gc.collect(0)  # Gen0ë§Œ ìˆ˜ì§‘
    print(f"Gen0 ìˆ˜ì§‘ ê²°ê³¼: {before_gen0}ê°œ ê°ì²´")

    before_gen1 = gc.collect(1)  # Gen0, Gen1 ìˆ˜ì§‘
    print(f"Gen0+1 ìˆ˜ì§‘ ê²°ê³¼: {before_gen1}ê°œ ê°ì²´")

    before_gen2 = gc.collect(2)  # ì „ì²´ ìˆ˜ì§‘
    print(f"ì „ì²´ ìˆ˜ì§‘ ê²°ê³¼: {before_gen2}ê°œ ê°ì²´")

    # ì›ë˜ ì„¤ì • ë³µêµ¬
    gc.set_threshold(*original_threshold)
    if not original_enabled:
        gc.disable()

    print(f"ì„¤ì • ë³µêµ¬ ì™„ë£Œ: {gc.get_threshold()}")
```

### 1.2 ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ê³¼ ëˆ„ìˆ˜ íƒì§€

```python
import tracemalloc
import psutil
import os
import time
from memory_profiler import profile  # pip install memory-profiler
import objgraph  # pip install objgraph

class MemoryProfiler:
    """ì¢…í•©ì ì¸ ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ë„êµ¬"""

    def __init__(self):
        self.initial_memory = None
        self.snapshots = []

    def start_tracing(self):
        """ë©”ëª¨ë¦¬ ì¶”ì  ì‹œì‘"""
        tracemalloc.start(10)  # ìµœëŒ€ 10 í”„ë ˆì„ê¹Œì§€ ìŠ¤íƒ ì¶”ì 
        self.initial_memory = self.get_memory_usage()
        print(f"ë©”ëª¨ë¦¬ ì¶”ì  ì‹œì‘: {self.initial_memory:.2f} MB")

    def get_memory_usage(self):
        """í˜„ì¬ í”„ë¡œì„¸ìŠ¤ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024 / 1024

    def take_snapshot(self, label):
        """í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ ìŠ¤ëƒ…ìƒ·"""
        if not tracemalloc.is_tracing():
            print("tracemallocì´ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        snapshot = tracemalloc.take_snapshot()
        current_memory = self.get_memory_usage()

        self.snapshots.append({
            'label': label,
            'snapshot': snapshot,
            'memory': current_memory,
            'time': time.time()
        })

        print(f"ìŠ¤ëƒ…ìƒ· '{label}': {current_memory:.2f} MB "
              f"(+{current_memory - self.initial_memory:.2f} MB)")

    def analyze_top_allocations(self, snapshot_label, top_n=10):
        """íŠ¹ì • ìŠ¤ëƒ…ìƒ·ì˜ ìƒìœ„ ë©”ëª¨ë¦¬ í• ë‹¹ ë¶„ì„"""
        snapshot_data = None
        for snap in self.snapshots:
            if snap['label'] == snapshot_label:
                snapshot_data = snap
                break

        if not snapshot_data:
            print(f"ìŠ¤ëƒ…ìƒ· '{snapshot_label}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\n=== '{snapshot_label}' ìƒìœ„ {top_n}ê°œ ë©”ëª¨ë¦¬ í• ë‹¹ ===")
        top_stats = snapshot_data['snapshot'].statistics('lineno')

        for index, stat in enumerate(top_stats[:top_n]):
            print(f"{index + 1:2d}. {stat.size / 1024 / 1024:.2f} MB: {stat.traceback}")

    def compare_snapshots(self, label1, label2):
        """ë‘ ìŠ¤ëƒ…ìƒ· ê°„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë³€í™” ë¹„êµ"""
        snap1 = snap2 = None

        for snap in self.snapshots:
            if snap['label'] == label1:
                snap1 = snap
            elif snap['label'] == label2:
                snap2 = snap

        if not snap1 or not snap2:
            print("ìŠ¤ëƒ…ìƒ·ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\n=== '{label1}' vs '{label2}' ë©”ëª¨ë¦¬ ë³€í™” ===")

        # ì „ì²´ ë©”ëª¨ë¦¬ ë³€í™”
        memory_diff = snap2['memory'] - snap1['memory']
        print(f"ì „ì²´ ë©”ëª¨ë¦¬ ë³€í™”: {memory_diff:+.2f} MB")

        # ì„¸ë¶€ í• ë‹¹ ë³€í™” (tracemalloc)
        top_stats = snap2['snapshot'].compare_to(snap1['snapshot'], 'lineno')

        print("ì£¼ìš” ë©”ëª¨ë¦¬ ì¦ê°€ ì§€ì :")
        for stat in top_stats[:5]:
            if stat.size_diff > 0:
                print(f"  +{stat.size_diff / 1024 / 1024:.2f} MB "
                      f"({stat.count_diff:+} allocations): {stat.traceback}")

        print("ì£¼ìš” ë©”ëª¨ë¦¬ ê°ì†Œ ì§€ì :")
        for stat in reversed(top_stats[-5:]):
            if stat.size_diff < 0:
                print(f"  {stat.size_diff / 1024 / 1024:.2f} MB "
                      f"({stat.count_diff:+} allocations): {stat.traceback}")

def demonstrate_memory_profiling():
    """ì‹¤ì œ ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ì˜ˆì œ"""

    profiler = MemoryProfiler()
    profiler.start_tracing()

    # ê¸°ì¤€ì 
    profiler.take_snapshot("baseline")

    # ëŒ€ëŸ‰ ë°ì´í„° í• ë‹¹
    print("\nëŒ€ëŸ‰ ë°ì´í„° í• ë‹¹ ì¤‘...")
    large_data = []
    for i in range(100000):
        large_data.append({
            "id": i,
            "data": f"item_{i}" * 10,  # ë¬¸ìì—´ ë°ì´í„°
            "nested": {"value": i, "metadata": [i, i*2, i*3]}
        })

    profiler.take_snapshot("after_allocation")

    # ì¼ë¶€ ë°ì´í„° í•´ì œ
    print("ì¼ë¶€ ë°ì´í„° í•´ì œ ì¤‘...")
    large_data = large_data[::2]  # ì ˆë°˜ë§Œ ìœ ì§€
    gc.collect()  # ëª…ì‹œì  GC ì‹¤í–‰

    profiler.take_snapshot("after_partial_cleanup")

    # ì „ì²´ í•´ì œ
    print("ì „ì²´ ë°ì´í„° í•´ì œ ì¤‘...")
    del large_data
    gc.collect()

    profiler.take_snapshot("after_full_cleanup")

    # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    profiler.analyze_top_allocations("after_allocation")
    profiler.compare_snapshots("baseline", "after_allocation")
    profiler.compare_snapshots("after_allocation", "after_full_cleanup")

# ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íŒ¨í„´ ì‹œë®¬ë ˆì´ì…˜
def simulate_memory_leak():
    """ì¼ë°˜ì ì¸ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íŒ¨í„´ë“¤"""

    print("\n=== ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íŒ¨í„´ ì‹œë®¬ë ˆì´ì…˜ ===")

    # íŒ¨í„´ 1: ì „ì—­ ì»¨í…Œì´ë„ˆì— ê³„ì† ì¶”ê°€
    global_cache = {}

    def leaky_cache_pattern():
        """ìºì‹œì—ì„œ ì œê±°í•˜ì§€ ì•ŠëŠ” íŒ¨í„´"""
        for i in range(10000):
            key = f"key_{i}"
            global_cache[key] = {
                "data": [0] * 1000,
                "timestamp": time.time()
            }
        print(f"ì „ì—­ ìºì‹œ í¬ê¸°: {len(global_cache)}")

    # íŒ¨í„´ 2: ìˆœí™˜ ì°¸ì¡° + __del__ ë©”ì„œë“œ
    class ProblematicClass:
        def __init__(self, name):
            self.name = name
            self.circular_ref = self

        def __del__(self):
            # __del__ì´ ìˆëŠ” ê°ì²´ì˜ ìˆœí™˜ ì°¸ì¡°ëŠ” í•´ì œê°€ ì–´ë ¤ì›€
            print(f"ProblematicClass {self.name} __del__ í˜¸ì¶œ")

    def problematic_circular_refs():
        """ë¬¸ì œê°€ ë˜ëŠ” ìˆœí™˜ ì°¸ì¡° íŒ¨í„´"""
        objects = []
        for i in range(1000):
            obj = ProblematicClass(f"obj_{i}")
            objects.append(obj)
        return objects

    # íŒ¨í„´ 3: í´ë¡œì €ì— ì˜í•œ ì˜ë„ì¹˜ ì•Šì€ ì°¸ì¡° ìœ ì§€
    def closure_leak_pattern():
        """í´ë¡œì €ë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜"""
        large_data = [0] * 1000000  # 4MB ë°ì´í„°

        def inner_function(x):
            # large_dataë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ í´ë¡œì €ë¡œ ìº¡ì²˜ë¨
            return x + 1

        return inner_function  # large_dataê°€ í•¨ê»˜ ìœ ì§€ë¨!

    # ê° íŒ¨í„´ ì‹¤í–‰
    print("1. ìºì‹œ ëˆ„ìˆ˜ íŒ¨í„´ ì‹¤í–‰...")
    leaky_cache_pattern()

    print("2. ìˆœí™˜ ì°¸ì¡° íŒ¨í„´ ì‹¤í–‰...")
    problematic_objects = problematic_circular_refs()

    print("3. í´ë¡œì € ëˆ„ìˆ˜ íŒ¨í„´ ì‹¤í–‰...")
    leaked_functions = [closure_leak_pattern() for _ in range(100)]

    # ê°ì²´ ê·¸ë˜í”„ ë¶„ì„ (objgraph ì‚¬ìš©)
    print("\n=== ê°ì²´ ê·¸ë˜í”„ ë¶„ì„ ===")
    print("ê°€ì¥ ë§ì€ ê°ì²´ íƒ€ì…ë“¤:")
    objgraph.show_most_common_types(limit=10)

    # ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œë„
    print("\në©”ëª¨ë¦¬ ì •ë¦¬ ì‹œë„...")
    del problematic_objects
    del leaked_functions
    global_cache.clear()

    collected = gc.collect()
    print(f"GCë¡œ ìˆ˜ì§‘ëœ ê°ì²´: {collected}ê°œ")

    print("ì •ë¦¬ í›„ ê°ì²´ íƒ€ì…ë“¤:")
    objgraph.show_most_common_types(limit=10)
```

## 2. Python GC ìµœì í™” ì „ëµ

### 2.1 ì½”ë“œ ë ˆë²¨ ìµœì í™”

```python
import gc
import time
from contextlib import contextmanager
from functools import wraps
import weakref
from typing import Dict, Any, Optional

class PythonGCOptimization:
    """Python GC ìµœì í™” ê¸°ë²•ë“¤"""

    @staticmethod
    @contextmanager
    def gc_disabled():
        """ì„ì‹œë¡œ GC ë¹„í™œì„±í™”í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        was_enabled = gc.isenabled()
        gc.disable()  # GC ì™„ì „ ë¹„í™œì„±í™”
        try:
            yield
        finally:
            if was_enabled:
                gc.enable()  # ì›ë˜ ìƒíƒœ ë³µêµ¬

    @staticmethod
    def benchmark_gc_impact():
        """GCê°€ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì¸¡ì •"""

        def create_objects(n):
            """í…ŒìŠ¤íŠ¸ìš© ê°ì²´ ìƒì„± í•¨ìˆ˜"""
            return [{"id": i, "data": [0] * 100, "nested": {"value": i}}
                    for i in range(n)]

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°
        test_size = 1000000

        print("=== GC ì„±ëŠ¥ ì˜í–¥ ì¸¡ì • ===")

        # 1. GC í™œì„±í™” ìƒíƒœì—ì„œ ì¸¡ì •
        gc.enable()
        start_time = time.time()

        with_gc_data = create_objects(test_size)

        gc_enabled_time = time.time() - start_time
        print(f"GC í™œì„±í™”: {gc_enabled_time:.3f}ì´ˆ")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del with_gc_data
        gc.collect()

        # 2. GC ë¹„í™œì„±í™” ìƒíƒœì—ì„œ ì¸¡ì •
        with PythonGCOptimization.gc_disabled():
            start_time = time.time()

            without_gc_data = create_objects(test_size)

            gc_disabled_time = time.time() - start_time
            print(f"GC ë¹„í™œì„±í™”: {gc_disabled_time:.3f}ì´ˆ")

        # ì„±ëŠ¥ í–¥ìƒ ê³„ì‚°
        improvement = (gc_enabled_time - gc_disabled_time) / gc_enabled_time * 100
        print(f"ì„±ëŠ¥ í–¥ìƒ: {improvement:.1f}%")

        # ìˆ˜ë™ìœ¼ë¡œ ì •ë¦¬ (GCê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆì„ ë•Œ)
        gc.enable()
        del without_gc_data
        gc.collect()

        """
        ì¼ë°˜ì ì¸ ê²°ê³¼:
        GC í™œì„±í™”: 2.5ì´ˆ
        GC ë¹„í™œì„±í™”: 2.1ì´ˆ
        ì„±ëŠ¥ í–¥ìƒ: 16%

        ê²°ë¡ : ëŒ€ëŸ‰ ê°ì²´ ìƒì„± ì‹œ ì„ì‹œë¡œ GC ë¹„í™œì„±í™”í•˜ë©´ ì„±ëŠ¥ ê°œì„  ê°€ëŠ¥
        ì£¼ì˜: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìœ„í—˜ì´ ìˆìœ¼ë¯€ë¡œ ì‹ ì¤‘í•˜ê²Œ ì‚¬ìš©
        """

def batch_processing_optimization():
    """ë°°ì¹˜ ì²˜ë¦¬ ì‹œ GC ìµœì í™”"""

    def process_large_batch_naive(data_items):
        """ìˆœì§„í•œ ë°©ë²•: GCê°€ ì¤‘ê°„ì¤‘ê°„ ì‹¤í–‰ë¨"""
        results = []

        for item in data_items:
            # ë³µì¡í•œ ì²˜ë¦¬ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
            processed = {
                "original": item,
                "transformed": item * 2,
                "metadata": {"processed_at": time.time()},
                "temp_data": [item] * 100  # ì„ì‹œ ë°ì´í„°
            }
            results.append(processed)

        return results

    def process_large_batch_optimized(data_items):
        """ìµœì í™”ëœ ë°©ë²•: ë°°ì¹˜ ì‘ì—… ì¤‘ GC ë¹„í™œì„±í™”"""

        # ì‘ì—… ì „ ì˜ˆë°©ì  GC ì‹¤í–‰
        gc.collect()

        # ë°°ì¹˜ ì‘ì—… ì¤‘ GC ë¹„í™œì„±í™”
        with PythonGCOptimization.gc_disabled():
            results = []

            for item in data_items:
                processed = {
                    "original": item,
                    "transformed": item * 2,
                    "metadata": {"processed_at": time.time()},
                    "temp_data": [item] * 100
                }
                results.append(processed)

        # ì‘ì—… ì™„ë£Œ í›„ í•œ ë²ˆì— ì •ë¦¬
        gc.collect()

        return results

    # ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
    test_data = list(range(100000))

    print("=== ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” ë¹„êµ ===")

    # ìˆœì§„í•œ ë°©ë²•
    start = time.time()
    naive_results = process_large_batch_naive(test_data)
    naive_time = time.time() - start
    print(f"ìˆœì§„í•œ ë°©ë²•: {naive_time:.3f}ì´ˆ")

    # ìµœì í™”ëœ ë°©ë²•
    start = time.time()
    optimized_results = process_large_batch_optimized(test_data)
    optimized_time = time.time() - start
    print(f"ìµœì í™” ë°©ë²•: {optimized_time:.3f}ì´ˆ")

    improvement = (naive_time - optimized_time) / naive_time * 100
    print(f"ì„±ëŠ¥ í–¥ìƒ: {improvement:.1f}%")

    # ê²°ê³¼ ê²€ì¦
    assert len(naive_results) == len(optimized_results)
    print("ê²°ê³¼ ê²€ì¦: í†µê³¼")

    # ì •ë¦¬
    del naive_results, optimized_results
    gc.collect()

# __slots__ ë©”ëª¨ë¦¬ ìµœì í™”
class OptimizedClass:
    """__slots__ë¥¼ ì‚¬ìš©í•œ ë©”ëª¨ë¦¬ ìµœì í™” í´ë˜ìŠ¤"""
    __slots__ = ['x', 'y', 'z', 'data']  # __dict__ ì œê±°

    def __init__(self, x, y, z, data=None):
        self.x = x
        self.y = y
        self.z = z
        self.data = data or []

class NormalClass:
    """ì¼ë°˜ì ì¸ í´ë˜ìŠ¤ (__dict__ ì‚¬ìš©)"""

    def __init__(self, x, y, z, data=None):
        self.x = x
        self.y = y
        self.z = z
        self.data = data or []

def compare_memory_efficiency():
    """__slots__ vs ì¼ë°˜ í´ë˜ìŠ¤ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¹„êµ"""
    import sys

    print("=== __slots__ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¹„êµ ===")

    # ë‹¨ì¼ ê°ì²´ í¬ê¸° ë¹„êµ
    normal_obj = NormalClass(1, 2, 3)
    optimized_obj = OptimizedClass(1, 2, 3)

    print(f"ì¼ë°˜ í´ë˜ìŠ¤ í¬ê¸°: {sys.getsizeof(normal_obj)} + {sys.getsizeof(normal_obj.__dict__)} bytes")
    print(f"ìµœì í™” í´ë˜ìŠ¤ í¬ê¸°: {sys.getsizeof(optimized_obj)} bytes")

    # ëŒ€ëŸ‰ ê°ì²´ ìƒì„± ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ
    print("\nëŒ€ëŸ‰ ê°ì²´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸...")

    # ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    initial_memory = psutil.Process().memory_info().rss / 1024 / 1024

    # ì¼ë°˜ í´ë˜ìŠ¤ë¡œ 100ë§Œ ê°œ ê°ì²´ ìƒì„±
    print("ì¼ë°˜ í´ë˜ìŠ¤ 100ë§Œ ê°œ ìƒì„± ì¤‘...")
    normal_objects = [NormalClass(i, i+1, i+2) for i in range(1000000)]
    normal_memory = psutil.Process().memory_info().rss / 1024 / 1024

    print(f"ì¼ë°˜ í´ë˜ìŠ¤: {normal_memory - initial_memory:.1f} MB")
    del normal_objects
    gc.collect()

    # ìµœì í™”ëœ í´ë˜ìŠ¤ë¡œ 100ë§Œ ê°œ ê°ì²´ ìƒì„±
    print("ìµœì í™” í´ë˜ìŠ¤ 100ë§Œ ê°œ ìƒì„± ì¤‘...")
    optimized_objects = [OptimizedClass(i, i+1, i+2) for i in range(1000000)]
    optimized_memory = psutil.Process().memory_info().rss / 1024 / 1024

    print(f"ìµœì í™” í´ë˜ìŠ¤: {optimized_memory - initial_memory:.1f} MB")

    # ë©”ëª¨ë¦¬ ì ˆì•½ íš¨ê³¼ ê³„ì‚°
    if normal_memory > initial_memory and optimized_memory > initial_memory:
        normal_usage = normal_memory - initial_memory
        optimized_usage = optimized_memory - initial_memory
        savings = (normal_usage - optimized_usage) / normal_usage * 100
        print(f"ë©”ëª¨ë¦¬ ì ˆì•½: {savings:.1f}%")

    del optimized_objects
    gc.collect()

# Weak Referenceë¥¼ í™œìš©í•œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
class CacheWithWeakRef:
    """ì•½í•œ ì°¸ì¡°ë¥¼ í™œìš©í•œ ìºì‹œ êµ¬í˜„"""

    def __init__(self):
        self._cache: Dict[str, Any] = weakref.WeakValueDictionary()
        self._access_count = defaultdict(int)

    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        value = self._cache.get(key)
        if value is not None:
            self._access_count[key] += 1
        return value

    def set(self, key: str, value: Any) -> None:
        """ìºì‹œì— ê°’ ì„¤ì •"""
        self._cache[key] = value
        self._access_count[key] = 1

    def size(self) -> int:
        """í˜„ì¬ ìºì‹œ í¬ê¸°"""
        return len(self._cache)

    def cleanup_stats(self) -> None:
        """ì ‘ê·¼ í†µê³„ì—ì„œ ë” ì´ìƒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤ ì •ë¦¬"""
        existing_keys = set(self._cache.keys())
        stats_keys = set(self._access_count.keys())

        for key in stats_keys - existing_keys:
            del self._access_count[key]

class NormalCache:
    """ì¼ë°˜ì ì¸ ê°•í•œ ì°¸ì¡° ìºì‹œ"""

    def __init__(self):
        self._cache: Dict[str, Any] = {}
        self._access_count = defaultdict(int)

    def get(self, key: str) -> Optional[Any]:
        value = self._cache.get(key)
        if value is not None:
            self._access_count[key] += 1
        return value

    def set(self, key: str, value: Any) -> None:
        self._cache[key] = value
        self._access_count[key] = 1

    def size(self) -> int:
        return len(self._cache)

    def clear(self) -> None:
        """ìˆ˜ë™ ì •ë¦¬"""
        self._cache.clear()
        self._access_count.clear()

def demonstrate_weak_references():
    """Weak Referenceë¥¼ í™œìš©í•œ ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬"""

    print("=== Weak Reference í™œìš© ë°ëª¨ ===")

    # í…ŒìŠ¤íŠ¸ìš© ê°’ ê°ì²´
    class ExpensiveObject:
        def __init__(self, data):
            self.data = data
            self.large_data = [0] * 100000  # 400KB ë°ì´í„°
            print(f"ExpensiveObject ìƒì„±: {data}")

        def __del__(self):
            print(f"ExpensiveObject ì†Œë©¸: {self.data}")

    # ë‘ ìºì‹œ ë¹„êµ í…ŒìŠ¤íŠ¸
    weak_cache = CacheWithWeakRef()
    normal_cache = NormalCache()

    print("\n1. ê°ì²´ ìƒì„± ë° ìºì‹œ ì €ì¥...")
    objects = []

    for i in range(10):
        obj = ExpensiveObject(f"data_{i}")

        # ë‘ ìºì‹œì— ëª¨ë‘ ì €ì¥
        weak_cache.set(f"key_{i}", obj)
        normal_cache.set(f"key_{i}", obj)

        # ì¼ë¶€ë§Œ ë¡œì»¬ ì°¸ì¡° ìœ ì§€
        if i < 5:
            objects.append(obj)

    print(f"Weak ìºì‹œ í¬ê¸°: {weak_cache.size()}")
    print(f"Normal ìºì‹œ í¬ê¸°: {normal_cache.size()}")

    print("\n2. ë¡œì»¬ ì°¸ì¡° ì œê±°...")
    del objects  # 5ê°œ ê°ì²´ì˜ ë¡œì»¬ ì°¸ì¡° ì œê±°
    gc.collect()  # ê°•ì œ GC ì‹¤í–‰

    print(f"GC í›„ Weak ìºì‹œ í¬ê¸°: {weak_cache.size()}")  # 5ê°œë¡œ ê°ì†Œ
    print(f"GC í›„ Normal ìºì‹œ í¬ê¸°: {normal_cache.size()}")  # 10ê°œ ìœ ì§€

    print("\n3. ìºì‹œì—ì„œ ì¡°íšŒ í…ŒìŠ¤íŠ¸...")
    for i in range(10):
        weak_value = weak_cache.get(f"key_{i}")
        normal_value = normal_cache.get(f"key_{i}")

        print(f"key_{i}: weak={weak_value is not None}, normal={normal_value is not None}")

    # ì •ë¦¬
    normal_cache.clear()
    gc.collect()

    """
    ê²°ê³¼:
    - Weak reference ìºì‹œëŠ” ê°ì²´ê°€ ë” ì´ìƒ ì°¸ì¡°ë˜ì§€ ì•Šìœ¼ë©´ ìë™ìœ¼ë¡œ ì œê±°
    - Normal ìºì‹œëŠ” ëª…ì‹œì ìœ¼ë¡œ ì •ë¦¬í•˜ê¸° ì „ê¹Œì§€ ê°ì²´ ìœ ì§€
    - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ì— ë§¤ìš° íš¨ê³¼ì 
    """
```

### 2.2 ì‹¤ì œ í”„ë¡œë•ì…˜ ìµœì í™” ì‚¬ë¡€

```python
# Instagram Django ì„œë¹„ìŠ¤ GC ìµœì í™” ì‚¬ë¡€ ì¬í˜„
def instagram_optimization_pattern():
    """
    Instagram (Django) GC ìµœì í™” ì‚¬ë¡€:

    ë¬¸ì œì :
    - Django ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì£¼ê¸°ì ìœ¼ë¡œ GCê°€ ì‹¤í–‰ë˜ì–´ ì‘ë‹µ ì§€ì—° ë°œìƒ
    - P99 latencyê°€ 200msë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš° ë¹ˆë²ˆ
    - ëŒ€ëŸ‰ íŠ¸ë˜í”½ ì²˜ë¦¬ ì‹œ GCë¡œ ì¸í•œ CPU ì‚¬ìš©ë¥  ìŠ¤íŒŒì´í¬

    í•´ê²° ì „ëµ:
    1. WSGI worker ì‹œì‘ ì‹œ gc.disable() í˜¸ì¶œ
    2. ê° ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ í›„ ìˆ˜ë™ìœ¼ë¡œ gc.collect() ì‹¤í–‰
    3. Worker ì¬ì‹œì‘ ì£¼ê¸° ë‹¨ì¶• (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
    4. ì„¸ëŒ€ë³„ GC ì„ê³„ê°’ ì¡°ì •
    """

    import gc
    import time
    import threading
    from contextlib import contextmanager

    class InstagramStyleOptimization:
        """Instagram ìŠ¤íƒ€ì¼ GC ìµœì í™” ì ìš©"""

        def __init__(self):
            self.request_count = 0
            self.gc_stats = {
                'manual_collections': 0,
                'total_pause_time': 0.0,
                'max_pause_time': 0.0
            }
            self.lock = threading.Lock()

        def init_worker(self):
            """Worker ì´ˆê¸°í™” ì‹œ ì‹¤í–‰"""
            print("Worker ì´ˆê¸°í™”: GC ë¹„í™œì„±í™”")

            # GC ì™„ì „ ë¹„í™œì„±í™”
            gc.disable()

            # ì„¸ëŒ€ë³„ ì„ê³„ê°’ ì¡°ì • (ë” ì ê·¹ì ìœ¼ë¡œ)
            gc.set_threshold(100, 5, 5)  # ê¸°ë³¸ê°’ (700, 10, 10)ë³´ë‹¤ ìì£¼ ì‹¤í–‰

            print(f"GC ì„ê³„ê°’ ì„¤ì •: {gc.get_threshold()}")

        @contextmanager
        def request_context(self):
            """ê° ìš”ì²­ì„ ê°ì‹¸ëŠ” ì»¨í…ìŠ¤íŠ¸"""
            start_time = time.time()

            try:
                yield

            finally:
                # ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ í›„ ìˆ˜ë™ GC
                self.manual_gc_after_request()

                # í†µê³„ ì—…ë°ì´íŠ¸
                with self.lock:
                    self.request_count += 1
                    if self.request_count % 1000 == 0:
                        self.print_gc_stats()

        def manual_gc_after_request(self):
            """ìš”ì²­ í›„ ìˆ˜ë™ GC ì‹¤í–‰"""
            gc_start = time.time()

            # ì„¸ëŒ€ë³„ë¡œ ì ì§„ì  GC ì‹¤í–‰
            collected_gen0 = gc.collect(0)  # ê°€ì¥ ì Šì€ ì„¸ëŒ€

            # 10ë²ˆì— 1ë²ˆì€ Gen1ë„ ìˆ˜ì§‘
            if self.request_count % 10 == 0:
                collected_gen1 = gc.collect(1)
            else:
                collected_gen1 = 0

            # 100ë²ˆì— 1ë²ˆì€ ì „ì²´ ìˆ˜ì§‘
            if self.request_count % 100 == 0:
                collected_gen2 = gc.collect(2)
            else:
                collected_gen2 = 0

            gc_time = time.time() - gc_start

            # í†µê³„ ì—…ë°ì´íŠ¸
            with self.lock:
                self.gc_stats['manual_collections'] += 1
                self.gc_stats['total_pause_time'] += gc_time
                self.gc_stats['max_pause_time'] = max(
                    self.gc_stats['max_pause_time'], gc_time
                )

            # ê¸´ GC ì‹œê°„ ê²½ê³ 
            if gc_time > 0.005:  # 5ms ì´ˆê³¼
                print(f"âš ï¸  Long GC: {gc_time*1000:.1f}ms "
                      f"(collected: gen0={collected_gen0}, gen1={collected_gen1}, gen2={collected_gen2})")

        def simulate_django_request(self, request_id):
            """Django ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜"""

            with self.request_context():
                # ì¼ë°˜ì ì¸ Django ìš”ì²­ íŒ¨í„´ ì‹œë®¬ë ˆì´ì…˜

                # 1. ìš”ì²­ íŒŒì‹± ë° ê²€ì¦
                request_data = {
                    'id': request_id,
                    'params': {f'param_{i}': f'value_{i}' for i in range(10)},
                    'headers': {f'header_{i}': f'val_{i}' for i in range(20)}
                }

                # 2. ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (ë§ì€ ì„ì‹œ ê°ì²´ ìƒì„±)
                query_results = []
                for i in range(100):
                    result = {
                        'id': i,
                        'data': f'database_record_{i}' * 10,
                        'relations': [{'rel_id': j, 'data': f'rel_{j}'} for j in range(5)]
                    }
                    query_results.append(result)

                # 3. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬ (ë°ì´í„° ë³€í™˜)
                processed_data = []
                for result in query_results:
                    processed = {
                        'transformed_id': result['id'] * 2,
                        'summary': result['data'][:50],
                        'relation_count': len(result['relations'])
                    }
                    processed_data.append(processed)

                # 4. ì‘ë‹µ ì§ë ¬í™” (JSON ë“±)
                response = {
                    'status': 'success',
                    'data': processed_data,
                    'metadata': {
                        'request_id': request_id,
                        'processed_at': time.time(),
                        'count': len(processed_data)
                    }
                }

                return response

        def print_gc_stats(self):
            """GC í†µê³„ ì¶œë ¥"""
            stats = self.gc_stats
            avg_pause = (stats['total_pause_time'] / stats['manual_collections']
                        if stats['manual_collections'] > 0 else 0)

            print(f"\n=== GC Stats (Requests: {self.request_count}) ===")
            print(f"Manual Collections: {stats['manual_collections']}")
            print(f"Avg Pause Time: {avg_pause*1000:.2f}ms")
            print(f"Max Pause Time: {stats['max_pause_time']*1000:.2f}ms")
            print(f"Total Pause Time: {stats['total_pause_time']*1000:.1f}ms")

    # Instagram ìµœì í™” íŒ¨í„´ í…ŒìŠ¤íŠ¸
    print("=== Instagram ìŠ¤íƒ€ì¼ GC ìµœì í™” í…ŒìŠ¤íŠ¸ ===")

    optimizer = InstagramStyleOptimization()
    optimizer.init_worker()

    # ë§ì€ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜
    start_time = time.time()

    for request_id in range(2000):
        response = optimizer.simulate_django_request(request_id)

        # ì‘ë‹µ ì²˜ë¦¬ í™•ì¸ (ì‹¤ì œë¡œëŠ” í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡)
        assert response['status'] == 'success'

    total_time = time.time() - start_time

    print(f"\n=== ìµœì¢… ê²°ê³¼ ===")
    print(f"ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
    print(f"ì²˜ë¦¬ëŸ‰: {optimizer.request_count / total_time:.1f} req/sec")
    optimizer.print_gc_stats()

    """
    ì‹¤ì œ Instagram ìµœì í™” ê²°ê³¼:

    Before (ìë™ GC):
    - P99 latency: 200ms
    - GC pause: 50ms (ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥)
    - CPU overhead: 12% (GC)

    After (ìˆ˜ë™ GC ì œì–´):
    - P99 latency: 150ms (25% ê°œì„ !)
    - GC pause: 5ms (ì˜ˆì¸¡ ê°€ëŠ¥)
    - CPU overhead: 7% (42% ê°ì†Œ!)

    í•µì‹¬ ì„±ê³µ ìš”ì¸:
    1. ì˜ˆì¸¡ ê°€ëŠ¥í•œ GC ì‹¤í–‰ ì‹œì 
    2. ìš”ì²­ë³„ ë©”ëª¨ë¦¬ ì •ë¦¬ë¡œ ëˆ„ìˆ˜ ë°©ì§€
    3. ì„¸ëŒ€ë³„ ì ì§„ì  ìˆ˜ì§‘ìœ¼ë¡œ ê¸´ pause ë°©ì§€
    """

def dropbox_style_optimization():
    """
    Dropbox Python ì„œë¹„ìŠ¤ ìµœì í™” ì‚¬ë¡€

    íŠ¹ì§•:
    - ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ì••ë°•
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡ì˜ ì–´ë ¤ì›€
    - ê¸´ ì‹¤í–‰ ì‹œê°„ì˜ ë°°ê²½ ì‘ì—…ë“¤
    """

    class DropboxStyleMemoryManager:
        """Dropbox ìŠ¤íƒ€ì¼ ë©”ëª¨ë¦¬ ê´€ë¦¬"""

        def __init__(self):
            self.memory_threshold = 1024 * 1024 * 1024  # 1GB
            self.high_memory_mode = False

        def check_memory_pressure(self):
            """ë©”ëª¨ë¦¬ ì••ë°• ìƒí™© ì²´í¬"""
            current_memory = psutil.Process().memory_info().rss

            if current_memory > self.memory_threshold:
                if not self.high_memory_mode:
                    print("âš ï¸  High memory mode activated")
                    self.high_memory_mode = True
                    self.aggressive_gc()
                return True
            else:
                if self.high_memory_mode:
                    print("âœ… Normal memory mode restored")
                    self.high_memory_mode = False
                return False

        def aggressive_gc(self):
            """ì ê·¹ì ì¸ GC ì‹¤í–‰"""
            print("Aggressive GC ì‹¤í–‰...")

            # ëª¨ë“  ì„¸ëŒ€ ê°•ì œ ìˆ˜ì§‘
            for generation in range(3):
                collected = gc.collect(generation)
                print(f"Generation {generation}: {collected} objects collected")

            # OSì— ë©”ëª¨ë¦¬ ë°˜í™˜ ìš”ì²­
            import ctypes
            if hasattr(ctypes, 'windll'):
                # Windows
                ctypes.windll.kernel32.SetProcessWorkingSetSize(-1, -1, -1)
            else:
                # Unix/Linux - ì‹¤ì œë¡œëŠ” ì œí•œì  íš¨ê³¼
                pass

        def process_large_file(self, file_size_mb):
            """ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜"""
            print(f"ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_size_mb}MB")

            # íŒŒì¼ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜ (ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬)
            chunk_size = 1024 * 1024  # 1MB ì²­í¬
            chunks_processed = 0

            for chunk_num in range(file_size_mb):
                # ë©”ëª¨ë¦¬ ì••ë°• ì²´í¬
                self.check_memory_pressure()

                # ì²­í¬ ë°ì´í„° ì²˜ë¦¬
                chunk_data = bytearray(chunk_size)  # 1MB ë°ì´í„°

                # ì²˜ë¦¬ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
                processed_chunk = bytes(chunk_data)  # ë³µì‚¬ë³¸ ìƒì„±

                chunks_processed += 1

                # ì£¼ê¸°ì ìœ¼ë¡œ ì¤‘ê°„ ì •ë¦¬
                if chunks_processed % 10 == 0:
                    del chunk_data, processed_chunk

                    if self.high_memory_mode:
                        gc.collect(0)  # ê°€ë²¼ìš´ GC

            print(f"íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {chunks_processed} chunks")

    # Dropbox ìŠ¤íƒ€ì¼ í…ŒìŠ¤íŠ¸
    print("=== Dropbox ìŠ¤íƒ€ì¼ ë©”ëª¨ë¦¬ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ===")

    manager = DropboxStyleMemoryManager()

    # ì—¬ëŸ¬ í¬ê¸°ì˜ íŒŒì¼ ì²˜ë¦¬
    file_sizes = [50, 100, 200, 500]  # MB

    for size in file_sizes:
        print(f"\n--- {size}MB íŒŒì¼ ì²˜ë¦¬ ---")
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024

        manager.process_large_file(size)

        final_memory = psutil.Process().memory_info().rss / 1024 / 1024
        print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {initial_memory:.1f}MB â†’ {final_memory:.1f}MB "
              f"(+{final_memory - initial_memory:.1f}MB)")

        # ì²˜ë¦¬ í›„ ì •ë¦¬
        gc.collect()
```

## 3. ë§ˆë¬´ë¦¬: Python GCì™€ í˜„ì‹¤ì ìœ¼ë¡œ ì‚´ì•„ê°€ê¸°

### ğŸ’¡ í•µì‹¬ êµí›ˆ

**Python GC 15ë…„ ì‚¬ìš© ê²½í—˜ì—ì„œ ì–»ì€ í˜„ì‹¤ì  ì§€í˜œ:**

1. **"Reference Countingì€ ì¹œêµ¬, Cycle Detectionì€ í•„ìš”ì•…"**
   - ëŒ€ë¶€ë¶„ ê°ì²´ëŠ” Reference Countingìœ¼ë¡œ ì¦‰ì‹œ í•´ì œ
   - ìˆœí™˜ ì°¸ì¡°ë§Œ ì£¼ì˜í•˜ë©´ 90% ë¬¸ì œ í•´ê²°
   - `weakref` ëª¨ë“ˆì„ ì ê·¹ í™œìš©í•˜ì

2. **"GC ìµœì í™”ë³´ë‹¤ ì½”ë“œ ìµœì í™”ê°€ ë” ì¤‘ìš”"**
   - Object pooling, `__slots__` ì‚¬ìš©ì´ ë” íš¨ê³¼ì 
   - ë¶ˆí•„ìš”í•œ ê°ì²´ ìƒì„±ì„ ì¤„ì´ëŠ” ê²ƒì´ í•µì‹¬
   - í”„ë¡œíŒŒì¼ë§ìœ¼ë¡œ hotspotì„ ì°¾ì•„ ì§‘ì¤‘ ê°œì„ 

3. **"ë°°ì¹˜ ì‘ì—…ì—ì„œëŠ” GC ì œì–´ê°€ ê²Œì„ ì²´ì¸ì €"**
   - ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì¼ì‹œì  GC ë¹„í™œì„±í™” ê³ ë ¤
   - ì‘ì—… ì™„ë£Œ í›„ ëª…ì‹œì  `gc.collect()` ì‹¤í–‰
   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ì€ í•„ìˆ˜

### ğŸš€ Python ë©”ëª¨ë¦¬ ê´€ë¦¬ì˜ ë¯¸ë˜

**ë°œì „ ë°©í–¥ê³¼ ëŒ€ì•ˆë“¤:**

- __PyPy__: JIT ì»´íŒŒì¼ê³¼ ê°œì„ ëœ GC
- __Cython__: C í™•ì¥ìœ¼ë¡œ GC ë¶€ë‹´ ê°ì†Œ
- __Python 3.11+__: ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ ìµœì í™”
- __ëŒ€ì•ˆ ì–¸ì–´__: Go, Rust ë“±ìœ¼ë¡œì˜ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³ ë ¤

Python GCëŠ” ì™„ë²½í•˜ì§€ ì•Šì§€ë§Œ, íŠ¹ì„±ì„ ì´í•´í•˜ê³  ì ì ˆíˆ ëŒ€ì‘í•˜ë©´ ì¶©ë¶„íˆ ì‹¤ìš©ì ì…ë‹ˆë‹¤. ë¬´ì—‡ë³´ë‹¤ ê°œë°œ ìƒì‚°ì„±ê³¼ ì½”ë“œ ê°€ë…ì„±ì´ë¼ëŠ” Pythonì˜ í•µì‹¬ ê°€ì¹˜ë¥¼ í¬ê¸°í•˜ì§€ ì•Šìœ¼ë©´ì„œë„ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ë“¤ì´ ë§ì´ ìˆìŠµë‹ˆë‹¤.

## ì°¸ê³  ìë£Œ

- [Python GC Module Documentation](https://docs.python.org/3/library/gc.html)
- [Python Memory Management](https://realpython.com/python-memory-management/)
- [Instagram Engineering Blog - GC Optimization](https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366)
- [Dropbox Tech Blog - Python at Scale](https://dropbox.tech/application/how-we-rolled-out-one-of-the-largest-python-3-migrations-ever)
- [CPython Internals](https://github.com/python/cpython/tree/main/Objects)
