---
tags:
  - advanced
  - cost-management
  - deep-study
  - distributed-tracing
  - hands-on
  - opentelemetry
  - performance-tuning
  - sampling-optimization
  - ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜
difficulty: ADVANCED
learning_time: "8-12ì‹œê°„"
main_topic: "ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜"
priority_score: 5
---

# 12.4.1: ìƒ˜í”Œë§ ìµœì í™”

## ğŸ¯ ë¶„ì‚° ì¶”ì  ìµœì í™” ì „ëµ

### ğŸ“Š ìƒ˜í”Œë§ ì „ëµ

```python
from opentelemetry.sdk.trace.sampling import (
    StaticSampler, 
    TraceIdRatioBasedSampler,
    ParentBased
)
import random
import time
import threading
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import hashlib
import json

class AdaptiveSampler:
    """ì ì‘í˜• ìƒ˜í”Œë§"""
    
    def __init__(self, base_rate: float = 0.1):
        self.base_rate = base_rate
        self.error_rate = 1.0  # ì—ëŸ¬ ë°œìƒ ì‹œ 100% ìƒ˜í”Œë§
        self.high_latency_threshold = 2.0
        self.high_latency_rate = 0.5
        self.recent_errors = []  # ìµœê·¼ ì—ëŸ¬ ì¶”ì 
        self.lock = threading.Lock()
        
    def should_sample(self, trace_context: Dict[str, Any]) -> bool:
        """ìƒ˜í”Œë§ ì—¬ë¶€ ê²°ì •"""
        # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ í•­ìƒ ìƒ˜í”Œë§
        if trace_context.get("has_error", False):
            self._record_error()
            return True
        
        # ë†’ì€ ì§€ì—°ì‹œê°„ì´ë©´ ë†’ì€ í™•ë¥ ë¡œ ìƒ˜í”Œë§
        duration = trace_context.get("duration", 0)
        if duration > self.high_latency_threshold:
            return random.random() < self.high_latency_rate
        
        # ë™ì  ìƒ˜í”Œë§ë¥  ì¡°ì •
        current_rate = self._calculate_dynamic_rate()
        return random.random() < current_rate
    
    def _record_error(self):
        """ì—ëŸ¬ ê¸°ë¡"""
        with self.lock:
            now = datetime.now()
            self.recent_errors.append(now)
            
            # 5ë¶„ ì´ì „ ì—ëŸ¬ ì œê±°
            cutoff = now - timedelta(minutes=5)
            self.recent_errors = [err for err in self.recent_errors if err > cutoff]
    
    def _calculate_dynamic_rate(self) -> float:
        """ë™ì  ìƒ˜í”Œë§ë¥  ê³„ì‚°"""
        with self.lock:
            # ìµœê·¼ 5ë¶„ê°„ ì—ëŸ¬ ë¹ˆë„ì— ë”°ë¼ ìƒ˜í”Œë§ë¥  ì¡°ì •
            error_count = len(self.recent_errors)
            
            if error_count > 10:  # ì—ëŸ¬ê°€ ë§ìœ¼ë©´ ìƒ˜í”Œë§ë¥  ì¦ê°€
                return min(1.0, self.base_rate * 3)
            elif error_count > 5:
                return min(1.0, self.base_rate * 2)
            else:
                return self.base_rate

class IntelligentSampler:
    """ì§€ëŠ¥í˜• ìƒ˜í”Œë§ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê¸°ë°˜)"""
    
    def __init__(self):
        self.sampling_rules = {
            # ì¤‘ìš”í•œ ì—”ë“œí¬ì¸íŠ¸ëŠ” ë†’ì€ ìƒ˜í”Œë§ë¥ 
            "/api/payment": 0.5,
            "/api/order": 0.3,
            "/api/user/login": 0.2,
            
            # ì¼ë°˜ì ì¸ ì—”ë“œí¬ì¸íŠ¸ëŠ” ë‚®ì€ ìƒ˜í”Œë§ë¥ 
            "/api/health": 0.01,
            "/api/metrics": 0.01,
            
            # ê¸°ë³¸ê°’
            "default": 0.1
        }
        
        self.user_tier_sampling = {
            "premium": 0.3,  # í”„ë¦¬ë¯¸ì—„ ì‚¬ìš©ìëŠ” ë†’ì€ ìƒ˜í”Œë§
            "standard": 0.1,
            "free": 0.05
        }
        
        # ì‹œê°„ëŒ€ë³„ ìƒ˜í”Œë§ (íŠ¸ë˜í”½ í”¼í¬ ì‹œê°„ì— ì¦ê°€)
        self.time_based_multiplier = {
            "peak": 1.5,    # 09:00-18:00
            "normal": 1.0,  # 18:00-23:00
            "low": 0.5      # 23:00-09:00
        }
    
    def get_sampling_rate(self, endpoint: str, user_tier: str = "standard", 
                         current_hour: int = None) -> float:
        """ì—”ë“œí¬ì¸íŠ¸ì™€ ì‚¬ìš©ì ë“±ê¸‰ì— ë”°ë¥¸ ìƒ˜í”Œë§ë¥ """
        base_rate = self.sampling_rules.get(endpoint, self.sampling_rules["default"])
        
        # ì‚¬ìš©ì ë“±ê¸‰ ì¡°ì •
        user_multiplier = {
            "premium": 1.5,
            "standard": 1.0,
            "free": 0.5
        }.get(user_tier, 1.0)
        
        # ì‹œê°„ëŒ€ ì¡°ì •
        if current_hour is not None:
            if 9 <= current_hour < 18:
                time_multiplier = self.time_based_multiplier["peak"]
            elif 18 <= current_hour < 23:
                time_multiplier = self.time_based_multiplier["normal"]
            else:
                time_multiplier = self.time_based_multiplier["low"]
        else:
            time_multiplier = 1.0
        
        final_rate = base_rate * user_multiplier * time_multiplier
        return min(1.0, final_rate)
    
    def should_force_sample(self, trace_context: Dict[str, Any]) -> bool:
        """ê°•ì œ ìƒ˜í”Œë§ ì—¬ë¶€ ê²°ì •"""
        # ì¤‘ìš”í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë²¤íŠ¸ëŠ” ë‹¹ì„¸ ê°•ì œ ìƒ˜í”Œë§
        force_sample_conditions = [
            trace_context.get("is_payment", False),
            trace_context.get("is_order_creation", False),
            trace_context.get("is_user_registration", False),
            trace_context.get("has_security_event", False),
            trace_context.get("amount", 0) > 1000,  # ê³ ì•¡ ê±°ë˜
        ]
        
        return any(force_sample_conditions)

class CostAwareSampler:
    """ë¹„ìš© ì¸ì§€ ìƒ˜í”Œë§"""
    
    def __init__(self, monthly_budget: float, cost_per_span: float = 0.001):
        self.monthly_budget = monthly_budget
        self.cost_per_span = cost_per_span
        self.monthly_span_limit = int(monthly_budget / cost_per_span)
        self.current_span_count = 0
        self.month_start = datetime.now().replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        self.lock = threading.Lock()
        
        print(f"ğŸ’° Monthly budget: ${monthly_budget}, Span limit: {self.monthly_span_limit:,}")
    
    def should_sample(self) -> bool:
        """ì˜ˆì‚° ê¸°ë°˜ ìƒ˜í”Œë§ ê²°ì •"""
        with self.lock:
            # ì›”ì´ ë°”ë€ìœ¼ë©´ ì¹´ìš´í„° ë¦¬ì…‹
            now = datetime.now()
            current_month_start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
            
            if current_month_start > self.month_start:
                self.month_start = current_month_start
                self.current_span_count = 0
                print(f"ğŸ“… New month started, resetting span count")
            
            # ì˜ˆì‚° ë‚´ì—ì„œ ìƒ˜í”Œë§ ê°€ëŠ¥í•œì§€ í™•ì¸
            if self.current_span_count >= self.monthly_span_limit:
                return False
            
            # ë‚¨ì€ ì˜ˆì‚°ì— ë”°ë¥¸ ë™ì  ìƒ˜í”Œë§ë¥  ê³„ì‚°
            days_in_month = (current_month_start.replace(month=current_month_start.month + 1) - current_month_start).days
            days_passed = (now - current_month_start).days + 1
            days_remaining = days_in_month - days_passed
            
            expected_usage = (days_passed / days_in_month) * self.monthly_span_limit
            usage_ratio = self.current_span_count / max(expected_usage, 1)
            
            # ì˜ˆì‚°ì„ ë„ˆë¬´ ë¹ ë¥´ê²Œ ì†Œë¹„í•˜ê³  ìˆìœ¼ë©´ ìƒ˜í”Œë§ë¥  ê°ì†Œ
            if usage_ratio > 1.2:
                return random.random() < 0.3  # 30% ìƒ˜í”Œë§
            elif usage_ratio > 1.0:
                return random.random() < 0.7  # 70% ìƒ˜í”Œë§
            else:
                return True  # ì •ìƒ ìƒ˜í”Œë§
    
    def record_span(self):
        """ìƒ˜í”Œë§ëœ Span ê¸°ë¡"""
        with self.lock:
            self.current_span_count += 1
    
    def get_budget_status(self) -> Dict[str, Any]:
        """ì˜ˆì‚° ì‚¬ìš© í˜„í™©"""
        with self.lock:
            used_budget = self.current_span_count * self.cost_per_span
            remaining_budget = self.monthly_budget - used_budget
            usage_percentage = (used_budget / self.monthly_budget) * 100
            
            return {
                "monthly_budget": self.monthly_budget,
                "used_budget": used_budget,
                "remaining_budget": remaining_budget,
                "usage_percentage": usage_percentage,
                "spans_used": self.current_span_count,
                "spans_remaining": self.monthly_span_limit - self.current_span_count
            }

# ì„±ëŠ¥ ìµœì í™”ëœ ì¶”ì ê¸°
class OptimizedTracer:
    """ì„±ëŠ¥ ìµœì í™”ëœ ì¶”ì ê¸°"""
    
    def __init__(self, service_name: str, monthly_budget: float = 100.0):
        self.service_name = service_name
        self.tracer = setup_tracing(service_name)  # ì´ì „ ì„¹ì…˜ì—ì„œ ì •ì˜ëœ í•¨ìˆ˜
        self.intelligent_sampler = IntelligentSampler()
        self.adaptive_sampler = AdaptiveSampler()
        self.cost_sampler = CostAwareSampler(monthly_budget)
        self.span_buffer = []
        self.buffer_size = 100
        self.flush_interval = 10  # 10ì´ˆë§ˆë‹¤ í”ŒëŸ¬ì‹œ
        self.metrics = {
            "spans_created": 0,
            "spans_sampled": 0,
            "spans_dropped": 0
        }
        
        # ë¹„ë™ê¸° í”ŒëŸ¬ì‹œ ìŠ¤ë ˆë“œ ì‹œì‘
        self._start_async_flush()
        
        # ë§¤ë¶„ ë§¤íŠ¸ë¦­ ì¶œë ¥
        self._start_metrics_reporter()
    
    def start_span_with_sampling(self, operation_name: str, endpoint: str = None, 
                                user_tier: str = "standard", trace_context: Dict[str, Any] = None,
                              **attributes):
        """ìƒ˜í”Œë§ì„ ê³ ë ¤í•œ Span ì‹œì‘"""
        self.metrics["spans_created"] += 1
        
        # ë‹¤ë‹¨ê³„ ìƒ˜í”Œë§ ê²°ì •
        should_sample = self._should_sample(
            operation_name, endpoint, user_tier, trace_context or {}
        )
        
        if not should_sample:
            self.metrics["spans_dropped"] += 1
            return NoOpSpan()
        
        # ë¹„ìš© ê¸°ë°˜ ìƒ˜í”Œë§ ì¶”ê°€ ê²€ì‚¬
        if not self.cost_sampler.should_sample():
            self.metrics["spans_dropped"] += 1
            return NoOpSpan()
        
        # ì‹¤ì œ Span ìƒì„±
        span = self.tracer.start_span(operation_name)
        self.metrics["spans_sampled"] += 1
        self.cost_sampler.record_span()
        
        # ìƒ˜í”Œë§ ì •ë³´ ê¸°ë¡
        sampling_rate = self.intelligent_sampler.get_sampling_rate(
            endpoint or operation_name, user_tier, datetime.now().hour
        )
        span.set_attribute("sampling_rate", sampling_rate)
        span.set_attribute("sampled", True)
        span.set_attribute("service.name", self.service_name)
        
        # ê¸°ë³¸ ì†ì„± ì„¤ì •
        for key, value in attributes.items():
            span.set_attribute(key, str(value))
        
        return span
    
    def _should_sample(self, operation_name: str, endpoint: str, 
                      user_tier: str, trace_context: Dict[str, Any]) -> bool:
        """ë‹¤ë‹¨ê³„ ìƒ˜í”Œë§ ë¡œì§"""
        # 1. ê°•ì œ ìƒ˜í”Œë§ ê²€ì‚¬
        if self.intelligent_sampler.should_force_sample(trace_context):
            return True
        
        # 2. ì ì‘í˜• ìƒ˜í”Œë§ (ì—ëŸ¬/ì§€ì—° ê¸°ë°˜)
        if self.adaptive_sampler.should_sample(trace_context):
            return True
        
        # 3. ì§€ëŠ¥í˜• ìƒ˜í”Œë§ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê¸°ë°˜)
        sampling_rate = self.intelligent_sampler.get_sampling_rate(
            endpoint or operation_name, user_tier, datetime.now().hour
        )
        
        return random.random() < sampling_rate
    
    def add_span_to_buffer(self, span_data: Dict[str, Any]):
        """ë¹„ë™ê¸° Span ë°ì´í„° ë²„í¼ë§"""
        # Span ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë²„í¼ë§
        span_hash = hashlib.md5(json.dumps(span_data, sort_keys=True).encode()).hexdigest()
        
        buffered_span = {
            "data": span_data,
            "hash": span_hash,
            "timestamp": datetime.now(),
            "retry_count": 0
        }
        
        self.span_buffer.append(buffered_span)
        
        if len(self.span_buffer) >= self.buffer_size:
            self._flush_buffer()
    
    def _flush_buffer(self):
        """ë²„í¼ í”ŒëŸ¬ì‹œ ì‚¬ ì¤‘ë³µ ì œê±° ë° ì¬ì‹œë„"""
        if not self.span_buffer:
            return
            
        print(f"ğŸš€ Flushing {len(self.span_buffer)} spans to backend...")
        
        # ì¤‘ë³µ Span ì œê±° (í•´ì‹œ ê¸°ë°˜)
        unique_spans = {}
        for span in self.span_buffer:
            span_hash = span["hash"]
            if span_hash not in unique_spans:
                unique_spans[span_hash] = span
        
        success_count = 0
        failed_spans = []
        
        for span_hash, span in unique_spans.items():
            try:
                # ì‹¤ì œë¡œëŠ” Jaeger/OTLP ì—”ë“œí¬ì¸íŠ¸ë¡œ ì „ì†¡
                # self._send_to_backend(span["data"])
                success_count += 1
                
            except Exception as e:
                print(f"âš ï¸ Failed to send span {span_hash[:8]}: {e}")
                
                # ì¬ì‹œë„ ì¹´ìš´íŠ¸ ì¦ê°€
                span["retry_count"] += 1
                
                # 3ë²ˆ ì‹œë„ í›„ ì‹¤íŒ¨í•˜ë©´ ë“œë¡­
                if span["retry_count"] < 3:
                    failed_spans.append(span)
                else:
                    print(f"âŒ Dropping span {span_hash[:8]} after 3 retries")
        
        print(f"âœ… Successfully sent {success_count} spans, {len(failed_spans)} failed")
        
        # ì‹¤íŒ¨í•œ Spanë“¤ë§Œ ë²„í¼ì— ë‚¨ê¸°ê¸°
        self.span_buffer = failed_spans
    
    def _start_async_flush(self):
        """ë¹„ë™ê¸° í”ŒëŸ¬ì‹œ ìŠ¤ë ˆë“œ"""
        def flush_periodically():
            while True:
                time.sleep(self.flush_interval)
                try:
                    self._flush_buffer()
                except Exception as e:
                    print(f"âš ï¸ Flush error: {e}")
        
        thread = threading.Thread(target=flush_periodically, daemon=True)
        thread.start()
        print(f"ğŸ”„ Started async flush thread (interval: {self.flush_interval}s)")
    
    def _start_metrics_reporter(self):
        """ë§¤íŠ¸ë¦­ ë¦¬í¬í„° ìŠ¤ë ˆë“œ"""
        def report_metrics():
            while True:
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ë¦¬í¬íŠ¸
                try:
                    self._report_metrics()
                except Exception as e:
                    print(f"âš ï¸ Metrics reporting error: {e}")
        
        thread = threading.Thread(target=report_metrics, daemon=True)
        thread.start()
    
    def _report_metrics(self):
        """ë§¤íŠ¸ë¦­ ë¦¬í¬íŠ¸"""
        total_spans = self.metrics["spans_created"]
        sampled_spans = self.metrics["spans_sampled"]
        dropped_spans = self.metrics["spans_dropped"]
        
        sampling_rate = (sampled_spans / max(total_spans, 1)) * 100
        drop_rate = (dropped_spans / max(total_spans, 1)) * 100
        
        budget_status = self.cost_sampler.get_budget_status()
        
        print(f"ğŸ“ˆ === Tracing Metrics Report ===")
        print(f"  â€¢ Total spans created: {total_spans:,}")
        print(f"  â€¢ Spans sampled: {sampled_spans:,} ({sampling_rate:.1f}%)")
        print(f"  â€¢ Spans dropped: {dropped_spans:,} ({drop_rate:.1f}%)")
        print(f"  â€¢ Buffer size: {len(self.span_buffer)}")
        print(f"  â€¢ Budget used: ${budget_status['used_budget']:.2f} ({budget_status['usage_percentage']:.1f}%)")
        print(f"  â€¢ Budget remaining: ${budget_status['remaining_budget']:.2f}")
        print()
    
    def get_sampling_stats(self) -> Dict[str, Any]:
        """ìƒ˜í”Œë§ í†µê³„ ë°˜í™˜"""
        return {
            "metrics": self.metrics.copy(),
            "budget_status": self.cost_sampler.get_budget_status(),
            "buffer_size": len(self.span_buffer)
        }

class NoOpSpan:
    """ìƒ˜í”Œë§ë˜ì§€ ì•Šì€ ê²½ìš° ì‚¬ìš©í•˜ëŠ” No-Op Span"""
    
    def set_attribute(self, key: str, value: Any):
        pass
    
    def record_exception(self, exception: Exception):
        pass
    
    def set_status(self, status):
        pass
    
    def end(self):
        pass
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        pass
```

## ì„±ëŠ¥ ìµœì í™” ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ë†’ì€ íŠ¸ë˜í”½ ìƒí™©

```python
def high_traffic_optimization_demo():
    """ë†’ì€ íŠ¸ë˜í”½ ìƒí™©ì—ì„œì˜ ìƒ˜í”Œë§ ìµœì í™”"""
    print("=== High Traffic Sampling Optimization ===")
    
    # ì˜ˆì‚° ì œì•½ì´ ìˆëŠ” ìƒí™© ì‹œë®¬ë ˆì´ì…˜
    tracer = OptimizedTracer("high-traffic-service", monthly_budget=50.0)  # $50/ì›”
    
    # ë‹¤ì–‘í•œ ì—”ë“œí¬ì¸íŠ¸ì™€ ì‚¬ìš©ì ë“±ê¸‰ ì‹œë®¬ë ˆì´ì…˜
    endpoints = [
        {
            "name": "/api/payment",
            "user_tiers": ["premium", "standard", "free"],
            "weight": 0.1  # ì „ì²´ íŠ¸ë˜í”½ì˜ 10%
        },
        {
            "name": "/api/order",
            "user_tiers": ["premium", "standard", "free"],
            "weight": 0.15  # 15%
        },
        {
            "name": "/api/health",
            "user_tiers": ["premium", "standard", "free"],
            "weight": 0.3  # 30% (í—¬ìŠ¤ì²´í¬ ë¹„ì¤‘ ë†’ìŒ)
        },
        {
            "name": "/api/search",
            "user_tiers": ["premium", "standard", "free"],
            "weight": 0.45  # 45%
        }
    ]
    
    # 1ì‹œê°„ ë™ì•ˆ íŠ¸ë˜í”½ ì‹œë®¬ë ˆì´ì…˜
    total_requests = 10000
    print(f"ğŸš€ Simulating {total_requests:,} requests over 1 hour...")
    
    for i in range(total_requests):
        # ì—”ë“œí¬ì¸íŠ¸ ì„ íƒ (ê°€ì¤‘ì¹˜ ê¸°ë°˜)
        endpoint = random.choices(
            [ep["name"] for ep in endpoints],
            weights=[ep["weight"] for ep in endpoints]
        )[0]
        
        # ì‚¬ìš©ì ë“±ê¸‰ ì„ íƒ
        user_tier = random.choices(
            ["premium", "standard", "free"],
            weights=[0.1, 0.3, 0.6]  # ëŒ€ë¶€ë¶„ free ì‚¬ìš©ì
        )[0]
        
        # ì—ëŸ¬ ìƒí™© ì‹œë®¬ë ˆì´ì…˜ (5% í™•ë¥ )
        has_error = random.random() < 0.05
        
        # ê³ ì•¡ ê±°ë˜ ì‹œë®¬ë ˆì´ì…˜ (ê²°ì œ APIì—ì„œ 10% í™•ë¥ )
        is_high_value = endpoint == "/api/payment" and random.random() < 0.1
        amount = random.uniform(1000, 5000) if is_high_value else random.uniform(10, 100)
        
        trace_context = {
            "has_error": has_error,
            "is_payment": endpoint == "/api/payment",
            "amount": amount,
            "user_id": f"user_{i % 1000}",
            "duration": random.uniform(0.1, 3.0) if not has_error else random.uniform(2.0, 5.0)
        }
        
        span = tracer.start_span_with_sampling(
            f"handle_{endpoint.split('/')[-1]}",
            endpoint=endpoint,
            user_tier=user_tier,
            trace_context=trace_context,
            user_id=trace_context["user_id"],
            amount=amount
        )
        
        # ì‹¤ì œ Span ì‚¬ìš© ì‹œë®¬ë ˆì´ì…˜
        if not isinstance(span, NoOpSpan):
            if has_error:
                span.record_exception(Exception("Simulated error"))
                span.set_status(trace.Status(trace.StatusCode.ERROR, "Request failed"))
            
            span.end()
        
        # ì§„í–‰ìƒí™© ì¶œë ¥ (1000ê°œë§ˆë‹¤)
        if (i + 1) % 1000 == 0:
            stats = tracer.get_sampling_stats()
            sampling_rate = (stats["metrics"]["spans_sampled"] / max(stats["metrics"]["spans_created"], 1)) * 100
            print(f"  Progress: {i + 1:,}/{total_requests:,} requests, Sampling rate: {sampling_rate:.1f}%")
    
    # ìµœì¢… í†µê³„
    final_stats = tracer.get_sampling_stats()
    print(f"
ğŸ“ˆ Final Statistics:")
    print(f"  â€¢ Total requests: {total_requests:,}")
    print(f"  â€¢ Spans created: {final_stats['metrics']['spans_created']:,}")
    print(f"  â€¢ Spans sampled: {final_stats['metrics']['spans_sampled']:,}")
    print(f"  â€¢ Spans dropped: {final_stats['metrics']['spans_dropped']:,}")
    
    budget = final_stats['budget_status']
    print(f"  â€¢ Budget utilization: {budget['usage_percentage']:.1f}%")
    print(f"  â€¢ Estimated monthly cost: ${budget['used_budget']:.2f}")
    print(f"  â€¢ Cost per request: ${budget['used_budget']/total_requests:.6f}")
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ì—ëŸ¬ ìƒí™© ëŒ€ì‘

```python
def error_scenario_demo():
    """ì—ëŸ¬ ìƒí™©ì—ì„œì˜ ì ì‘í˜• ìƒ˜í”Œë§"""
    print("\n=== Error Scenario Adaptive Sampling ===")
    
    tracer = OptimizedTracer("error-prone-service", monthly_budget=30.0)
    
    # ì •ìƒ ìš´ì˜ ìƒí™© (10ë¶„)
    print("ğŸŸ¢ Phase 1: Normal operation (10 minutes)...")
    for i in range(1000):
        span = tracer.start_span_with_sampling(
            "normal_operation",
            endpoint="/api/service",
            trace_context={
                "has_error": False,
                "duration": random.uniform(0.1, 0.5)
            }
        )
        if not isinstance(span, NoOpSpan):
            span.end()
    
    # ì—ëŸ¬ ë°œìƒ ì‹œì‘ (5ë¶„)
    print("ğŸŸ¡ Phase 2: Errors starting to occur (5 minutes)...")
    for i in range(500):
        has_error = random.random() < 0.2  # 20% ì—ëŸ¬ë¥ 
        span = tracer.start_span_with_sampling(
            "degraded_operation",
            endpoint="/api/service", 
            trace_context={
                "has_error": has_error,
                "duration": random.uniform(0.5, 2.0) if has_error else random.uniform(0.1, 0.5)
            }
        )
        if not isinstance(span, NoOpSpan):
            if has_error:
                span.record_exception(Exception("Service degradation"))
                span.set_status(trace.Status(trace.StatusCode.ERROR, "Degraded performance"))
            span.end()
    
    # ì—ëŸ¬ ì¦ê°€ (5ë¶„)
    print("ğŸ”´ Phase 3: High error rate (5 minutes)...")
    for i in range(500):
        has_error = random.random() < 0.5  # 50% ì—ëŸ¬ë¥ 
        span = tracer.start_span_with_sampling(
            "high_error_operation",
            endpoint="/api/service",
            trace_context={
                "has_error": has_error,
                "duration": random.uniform(1.0, 4.0) if has_error else random.uniform(0.1, 0.5)
            }
        )
        if not isinstance(span, NoOpSpan):
            if has_error:
                span.record_exception(Exception("Critical service error"))
                span.set_status(trace.Status(trace.StatusCode.ERROR, "Service failure"))
            span.end()
    
    # ë³µêµ¬ (10ë¶„)
    print("ğŸŸ¢ Phase 4: Recovery (10 minutes)...")
    for i in range(1000):
        has_error = random.random() < 0.05  # 5% ì—ëŸ¬ë¥ 
        span = tracer.start_span_with_sampling(
            "recovery_operation",
            endpoint="/api/service",
            trace_context={
                "has_error": has_error,
                "duration": random.uniform(0.1, 0.8)
            }
        )
        if not isinstance(span, NoOpSpan):
            if has_error:
                span.record_exception(Exception("Residual error"))
                span.set_status(trace.Status(trace.StatusCode.ERROR, "Minor issue"))
            span.end()
    
    final_stats = tracer.get_sampling_stats()
    print(f"
ğŸ“‹ Error Scenario Results:")
    print(f"  â€¢ Total operations: 3,000")
    print(f"  â€¢ Adaptive sampling captured critical errors")
    print(f"  â€¢ Budget efficiency maintained: {final_stats['budget_status']['usage_percentage']:.1f}%")
    print(f"  â€¢ Final sampling rate: {(final_stats['metrics']['spans_sampled']/final_stats['metrics']['spans_created'])*100:.1f}%")
```

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

```python
def sampling_performance_benchmark():
    """ìƒ˜í”Œë§ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    print("\n=== Sampling Performance Benchmark ===")
    
    # ë‹¤ë¥¸ ìƒ˜í”Œë§ ì „ëµ ë¹„êµ
    strategies = [
        ("Basic (10%)", lambda: random.random() < 0.1),
        ("Intelligent", IntelligentSampler().get_sampling_rate),
        ("Adaptive", AdaptiveSampler().should_sample),
        ("Cost-Aware", CostAwareSampler(100.0).should_sample)
    ]
    
    test_contexts = [
        {"endpoint": "/api/payment", "user_tier": "premium", "has_error": False, "duration": 0.5},
        {"endpoint": "/api/health", "user_tier": "free", "has_error": False, "duration": 0.1},
        {"endpoint": "/api/order", "user_tier": "standard", "has_error": True, "duration": 3.0},
    ]
    
    iterations = 10000
    
    for strategy_name, strategy_func in strategies:
        print(f"\nğŸ“ˆ Testing {strategy_name}:")
        
        start_time = time.time()
        sample_count = 0
        
        for i in range(iterations):
            context = random.choice(test_contexts)
            
            try:
                if strategy_name == "Intelligent":
                    should_sample = random.random() < strategy_func(
                        context["endpoint"], context["user_tier"]
                    )
                elif strategy_name in ["Adaptive", "Cost-Aware"]:
                    should_sample = strategy_func(context)
                else:
                    should_sample = strategy_func()
                
                if should_sample:
                    sample_count += 1
                    
            except Exception as e:
                print(f"  âš ï¸ Error in {strategy_name}: {e}")
        
        duration = time.time() - start_time
        sampling_rate = (sample_count / iterations) * 100
        ops_per_sec = iterations / duration
        
        print(f"  â€¢ Duration: {duration:.3f}s")
        print(f"  â€¢ Operations/sec: {ops_per_sec:,.0f}")
        print(f"  â€¢ Sampling rate: {sampling_rate:.1f}%")
        print(f"  â€¢ Samples collected: {sample_count:,}")
```

## í†µí•© í…ŒìŠ¤íŠ¸

```python
def comprehensive_sampling_test():
    """í¬ê´„ì ì¸ ìƒ˜í”Œë§ ìµœì í™” í…ŒìŠ¤íŠ¸"""
    print("=== Comprehensive Sampling Optimization Test ===")
    
    # ê° ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
    high_traffic_optimization_demo()
    error_scenario_demo()
    sampling_performance_benchmark()
    
    print("\nğŸ Test completed successfully!")
    print("ğŸ’¡ Key takeaways:")
    print("  â€¢ Intelligent sampling reduces costs while maintaining visibility")
    print("  â€¢ Adaptive sampling automatically responds to system health")
    print("  â€¢ Cost-aware sampling prevents budget overruns")
    print("  â€¢ Multi-layered approach provides comprehensive optimization")

if __name__ == "__main__":
    comprehensive_sampling_test()
```

## í•µì‹¬ ìš”ì 

### 1.**ë‹¤ë‹¨ê³„ ìƒ˜í”Œë§ ì „ëµ**

- ê°•ì œ ìƒ˜í”Œë§: ì¤‘ìš” ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë²¤íŠ¸
- ì ì‘í˜• ìƒ˜í”Œë§: ì—ëŸ¬/ì§€ì—° ìƒí™© ëŒ€ì‘
- ì§€ëŠ¥í˜• ìƒ˜í”Œë§: ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ìš”ë„ ë°˜ì˜
- ë¹„ìš© ì¸ì§€ ìƒ˜í”Œë§: ì˜ˆì‚° ê´€ë¦¬

### 2.**ì„±ëŠ¥ ìµœì í™” ê¸°ë²•**

- ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬
- Span ë°ì´í„° ì¤‘ë³µ ì œê±°
- ì§€ëŠ¥ì  ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜
- ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ë¦¬í¬íŒ…

### 3.**ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ê°•í™”**

- ROI ê¸°ë°˜ ìƒ˜í”Œë§ ì˜ˆì‚° ê´€ë¦¬
- ì‚¬ìš©ì ë“±ê¸‰ë³„ ì°¨ë³„í™”
- ì‹œê°„ëŒ€ë³„ ë™ì  ì¡°ì •
- SLA ì¤€ìˆ˜ë¥¼ ìœ„í•œ ìë™ ìƒ˜í”Œë§

---

**ì´ì „**: [12-03-02-opentelemetry-implementation.md](12-03-02-opentelemetry-implementation.md)  
**ë‹¤ìŒ**: [12.4.2 ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§](./12-04-02-performance-profiling.md)ì—ì„œ ì„±ëŠ¥ ë³‘ëª© ì  ë¶„ì„ ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

### ğŸ“– í˜„ì¬ ë¬¸ì„œ ì •ë³´

-**ë‚œì´ë„**: ADVANCED
-**ì£¼ì œ**: ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜
-**ì˜ˆìƒ ì‹œê°„**: 8-12ì‹œê°„

### ğŸ¯ í•™ìŠµ ê²½ë¡œ

- [ğŸ“š ADVANCED ë ˆë²¨ ì „ì²´ ë³´ê¸°](../learning-paths/advanced/)
- [ğŸ  ë©”ì¸ í•™ìŠµ ê²½ë¡œ](../learning-paths/)
- [ğŸ“‹ ì „ì²´ ê°€ì´ë“œ ëª©ë¡](../README.md)

### ğŸ“‚ ê°™ì€ ì±•í„° (chapter-12-observability-debugging)

- [13.1 ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ - ì‹œìŠ¤í…œì˜ ëˆˆê³¼ ê·€ ê°œìš”](./12-02-03-logging-monitoring.md)
- [13.1A ê´€ì°° ê°€ëŠ¥ì„± ê¸°ì´ˆ - ì‹œìŠ¤í…œì„ ë³´ëŠ” ëˆˆ](./12-01-01-observability-foundations.md)
- [13.1a êµ¬ì¡°í™”ëœ ë¡œê¹… - ê²€ìƒ‰ ê°€ëŠ¥í•œ ë¡œê·¸ ì‹œìŠ¤í…œ](./12-02-01-structured-logging.md)
- [13.1b ë©”íŠ¸ë¦­ ìˆ˜ì§‘ - ì‹œìŠ¤í…œ ê±´ê°•ë„ ì¸¡ì •](./12-02-02-metrics-collection.md)
- [13.1B êµ¬ì¡°í™”ëœ ë¡œê¹… - ê²€ìƒ‰ ê°€ëŠ¥í•œ ë¡œê·¸](./12-03-04-advanced-structured-logging.md)

### ğŸ·ï¸ ê´€ë ¨ í‚¤ì›Œë“œ

`distributed-tracing`, `sampling-optimization`, `cost-management`, `performance-tuning`, `opentelemetry`

### â­ï¸ ë‹¤ìŒ ë‹¨ê³„ ê°€ì´ë“œ

- ì‹œìŠ¤í…œ ì „ì²´ì˜ ê´€ì ì—ì„œ ì´í•´í•˜ë ¤ ë…¸ë ¥í•˜ì„¸ìš”
- ë‹¤ë¥¸ ê³ ê¸‰ ì£¼ì œë“¤ê³¼ì˜ ì—°ê´€ì„±ì„ íŒŒì•…í•´ë³´ì„¸ìš”
