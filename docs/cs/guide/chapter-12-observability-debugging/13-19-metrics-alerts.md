---
tags:
  - alerting
  - four_golden_signals
  - hands-on
  - intermediate
  - medium-read
  - metrics
  - observability
  - prometheus
  - ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜
difficulty: INTERMEDIATE
learning_time: "4-6ì‹œê°„"
main_topic: "ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜"
priority_score: 4
---

# 13.3 ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ

## 2024ë…„ 1ì›”, ì¹¨ë¬µí•˜ëŠ” ì‹œìŠ¤í…œì˜ ë¹„ëª…

2024ë…„ 1ì›” 15ì¼ ì˜¤ì „ 10ì‹œ, í‰í™”ë¡œìš´ ì›”ìš”ì¼ ì•„ì¹¨ì´ì—ˆë‹¤. ì»¤í”¼ í•œ ì”ì„ ë§ˆì‹œë©° ìƒˆí•´ ê³„íšì„ ì„¸ìš°ê³  ìˆë˜ ë‚˜ì—ê²Œ ìŠ¬ë™ ë©”ì‹œì§€ í•˜ë‚˜ê°€ ë„ì°©í–ˆë‹¤.

"ê¹€ íŒ€ì¥ë‹˜, ì‡¼í•‘ëª° ì‚¬ì´íŠ¸ê°€ êµ‰ì¥íˆ ëŠë ¤ìš”. ê³ ê°ë“¤ì´ ë¶ˆë§Œì„ ì œê¸°í•˜ê³  ìˆì–´ìš”."

ë‹¹í™©í•œ ë§ˆìŒìœ¼ë¡œ ì‹œìŠ¤í…œì„ í™•ì¸í•´ë³´ë‹ˆ, ëª¨ë“  ì§€í‘œê°€ ì •ìƒìœ¼ë¡œ ë³´ì˜€ë‹¤. CPUëŠ” 50%, ë©”ëª¨ë¦¬ëŠ” 60%, ì‘ë‹µ ì‹œê°„ì€... ì–´ë¼? ì‘ë‹µ ì‹œê°„ ë°ì´í„°ê°€ ì—†ì—ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ë³´ë‹ˆ ì—ëŸ¬ëŠ” ì—†ì—ˆì§€ë§Œ, ì‹¤ì œ ì‚¬ìš©ì ì²´ê° ì„±ëŠ¥ì€ ìµœì•…ì´ì—ˆë‹¤.

**ë¬¸ì œëŠ” ìš°ë¦¬ê°€ ì˜ëª»ëœ ì§€í‘œë¥¼ ë³´ê³  ìˆì—ˆë‹¤ëŠ” ê²ƒì´ë‹¤.**

ì„œë²„ì˜ ê¸°ë³¸ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­(CPU, ë©”ëª¨ë¦¬)ë§Œ ëª¨ë‹ˆí„°ë§í•˜ê³  ìˆì—ˆê³ , ì •ì‘ ì¤‘ìš”í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­(ì‹¤ì œ í˜ì´ì§€ ë¡œë”© ì‹œê°„, ê²°ì œ ì™„ë£Œìœ¨, ì‚¬ìš©ì ë§Œì¡±ë„)ì€ ì „í˜€ ì¸¡ì •í•˜ì§€ ì•Šê³  ìˆì—ˆë˜ ê²ƒì´ë‹¤.

ê·¸ë‚ ë¶€í„° ìš°ë¦¬ëŠ” **ì§„ì§œ ì¤‘ìš”í•œ ë©”íŠ¸ë¦­**ì„ ì •ì˜í•˜ê³ , **ì˜ë¯¸ ìˆëŠ” ì•Œë¦¼**ì„ êµ¬ì¶•í•˜ê¸° ì‹œì‘í–ˆë‹¤.

## ë©”íŠ¸ë¦­ì˜ 4ê°€ì§€ í™©ê¸ˆ ì‹ í˜¸

êµ¬ê¸€ SRE íŒ€ì´ ì œì‹œí•œ **Four Golden Signals**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì „ëµì„ ì„¸ì›Œë³´ì.

### 1. Latency (ì§€ì—° ì‹œê°„)

```python
import time
import threading
from collections import defaultdict
from typing import Dict, List
import numpy as np  # pip install numpy

class LatencyTracker:
    def __init__(self, name: str):
        self.name = name
        self._measurements: Dict[str, List[float]] = defaultdict(list)
        self._lock = threading.Lock()
    
    def record(self, value: float, labels: Dict[str, str] = None):
        """ì§€ì—° ì‹œê°„ ì¸¡ì •ê°’ì„ ê¸°ë¡"""
        labels_key = self._labels_to_key(labels or {})
        
        with self._lock:
            self._measurements[labels_key].append(value)
    
    def get_percentiles(self, labels: Dict[str, str] = None) -> Dict[str, float]:
        """P50, P95, P99 ì§€ì—° ì‹œê°„ ë°˜í™˜"""
        labels_key = self._labels_to_key(labels or {})
        
        with self._lock:
            measurements = self._measurements[labels_key]
            if not measurements:
                return {}
            
            return {
                'p50': np.percentile(measurements, 50),
                'p95': np.percentile(measurements, 95),
                'p99': np.percentile(measurements, 99),
                'avg': np.mean(measurements),
                'count': len(measurements)
            }
    
    def _labels_to_key(self, labels: Dict[str, str]) -> str:
        return ','.join(f"{k}={v}" for k, v in sorted(labels.items()))

# ì‚¬ìš© ì˜ˆì‹œ
latency_tracker = LatencyTracker("api_request_duration")

def track_request_time(func):
    """ë°ì½”ë ˆì´í„°ë¡œ í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ ì¶”ì """
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            status = 'success'
        except Exception as e:
            status = 'error'
            raise
        finally:
            duration = time.time() - start_time
            latency_tracker.record(duration, {'endpoint': func.__name__, 'status': status})
        return result
    return wrapper

@track_request_time
def get_user_profile(user_id: str):
    # ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
    time.sleep(0.1)  # DB ì¡°íšŒ ì‹œë®¬ë ˆì´ì…˜
    return {"user_id": user_id, "name": "John Doe"}
```

### 2. Traffic (íŠ¸ë˜í”½)

```python
import time
import threading
from collections import deque, defaultdict

class TrafficCounter:
    def __init__(self, window_size: int = 300):  # 5ë¶„ ìœˆë„ìš°
        self.window_size = window_size
        self._counts = defaultdict(deque)
        self._lock = threading.Lock()
    
    def increment(self, metric_name: str, labels: Dict[str, str] = None):
        """íŠ¸ë˜í”½ ì¹´ìš´íŠ¸ ì¦ê°€"""
        labels_key = self._labels_to_key(labels or {})
        key = f"{metric_name}:{labels_key}"
        
        with self._lock:
            current_time = time.time()
            self._counts[key].append(current_time)
            
            # ìœˆë„ìš° ë°–ì˜ ì˜¤ë˜ëœ ë°ì´í„° ì œê±°
            cutoff_time = current_time - self.window_size
            while self._counts[key] and self._counts[key][0] < cutoff_time:
                self._counts[key].popleft()
    
    def get_rate(self, metric_name: str, labels: Dict[str, str] = None) -> float:
        """ì´ˆë‹¹ ìš”ì²­ ìˆ˜ (RPS) ë°˜í™˜"""
        labels_key = self._labels_to_key(labels or {})
        key = f"{metric_name}:{labels_key}"
        
        with self._lock:
            current_time = time.time()
            cutoff_time = current_time - self.window_size
            
            # ìœˆë„ìš° ë‚´ì˜ ìš”ì²­ ìˆ˜ ê³„ì‚°
            valid_requests = sum(1 for timestamp in self._counts[key] if timestamp >= cutoff_time)
            return valid_requests / self.window_size
    
    def _labels_to_key(self, labels: Dict[str, str]) -> str:
        return ','.join(f"{k}={v}" for k, v in sorted(labels.items()))

# ì‚¬ìš© ì˜ˆì‹œ
traffic_counter = TrafficCounter()

def count_request(endpoint: str, method: str):
    traffic_counter.increment("http_requests_total", {
        'endpoint': endpoint,
        'method': method
    })

# API ìš”ì²­ë§ˆë‹¤ í˜¸ì¶œ
count_request('/api/users', 'GET')
count_request('/api/orders', 'POST')
```

### 3. Errors (ì—ëŸ¬ìœ¨)

```python
import time
from enum import Enum
from typing import Dict, Optional

class ErrorSeverity(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class ErrorTracker:
    def __init__(self):
        self._error_counts = defaultdict(int)
        self._total_counts = defaultdict(int)
        self._recent_errors = deque(maxlen=1000)  # ìµœê·¼ 1000ê°œ ì—ëŸ¬ ë³´ê´€
        self._lock = threading.Lock()
    
    def record_success(self, operation: str, labels: Dict[str, str] = None):
        """ì„±ê³µí•œ ì‘ì—… ê¸°ë¡"""
        key = self._make_key(operation, labels)
        with self._lock:
            self._total_counts[key] += 1
    
    def record_error(self, operation: str, error: Exception, 
                    severity: ErrorSeverity = ErrorSeverity.MEDIUM,
                    labels: Dict[str, str] = None):
        """ì—ëŸ¬ ë°œìƒ ê¸°ë¡"""
        key = self._make_key(operation, labels)
        
        with self._lock:
            self._error_counts[key] += 1
            self._total_counts[key] += 1
            
            # ì—ëŸ¬ ìƒì„¸ ì •ë³´ ì €ì¥
            self._recent_errors.append({
                'timestamp': time.time(),
                'operation': operation,
                'error_type': type(error).__name__,
                'error_message': str(error),
                'severity': severity.value,
                'labels': labels or {}
            })
    
    def get_error_rate(self, operation: str, labels: Dict[str, str] = None) -> float:
        """ì—ëŸ¬ìœ¨ ê³„ì‚° (0.0 ~ 1.0)"""
        key = self._make_key(operation, labels)
        
        with self._lock:
            total = self._total_counts[key]
            errors = self._error_counts[key]
            
            if total == 0:
                return 0.0
            return errors / total
    
    def get_recent_errors(self, limit: int = 10) -> List[Dict]:
        """ìµœê·¼ ë°œìƒí•œ ì—ëŸ¬ ëª©ë¡"""
        with self._lock:
            return list(self._recent_errors)[-limit:]
    
    def _make_key(self, operation: str, labels: Dict[str, str] = None) -> str:
        labels_key = ','.join(f"{k}={v}" for k, v in sorted((labels or {}).items()))
        return f"{operation}:{labels_key}"

# ì‚¬ìš© ì˜ˆì‹œ
error_tracker = ErrorTracker()

def safe_database_operation(func):
    """ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì„ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•˜ê³  ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    def wrapper(*args, **kwargs):
        operation_name = f"db_{func.__name__}"
        try:
            result = func(*args, **kwargs)
            error_tracker.record_success(operation_name)
            return result
        except ConnectionError as e:
            error_tracker.record_error(operation_name, e, ErrorSeverity.HIGH)
            raise
        except TimeoutError as e:
            error_tracker.record_error(operation_name, e, ErrorSeverity.MEDIUM)
            raise
        except Exception as e:
            error_tracker.record_error(operation_name, e, ErrorSeverity.LOW)
            raise
    return wrapper

@safe_database_operation
def get_user_orders(user_id: str):
    # ì‹¤ì œ DB ì¡°íšŒ ë¡œì§
    pass
```

### 4. Saturation (í¬í™”ë„)

```python
import psutil
import threading
import time
from typing import Dict, List

class SaturationMonitor:
    def __init__(self, sample_interval: int = 10):
        self.sample_interval = sample_interval
        self._metrics_history: Dict[str, List[float]] = defaultdict(list)
        self._running = False
        self._thread = None
        self._lock = threading.Lock()
    
    def start(self):
        """í¬í™”ë„ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self._running = True
        self._thread = threading.Thread(target=self._collect_metrics, daemon=True)
        self._thread.start()
    
    def stop(self):
        """í¬í™”ë„ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self._running = False
        if self._thread:
            self._thread.join()
    
    def _collect_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì£¼ê¸°ì  ìˆ˜ì§‘"""
        while self._running:
            try:
                # CPU ì‚¬ìš©ë¥ 
                cpu_percent = psutil.cpu_percent(interval=1)
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
                memory = psutil.virtual_memory()
                memory_percent = memory.percent
                
                # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
                disk = psutil.disk_usage('/')
                disk_percent = disk.percent
                
                # ë„¤íŠ¸ì›Œí¬ I/O
                net_io = psutil.net_io_counters()
                
                with self._lock:
                    current_time = time.time()
                    
                    # ë©”íŠ¸ë¦­ ê¸°ë¡ (ìµœê·¼ 100ê°œ ìƒ˜í”Œë§Œ ìœ ì§€)
                    for metric_name, value in [
                        ('cpu_usage', cpu_percent),
                        ('memory_usage', memory_percent),
                        ('disk_usage', disk_percent),
                        ('network_bytes_sent', net_io.bytes_sent),
                        ('network_bytes_recv', net_io.bytes_recv)
                    ]:
                        history = self._metrics_history[metric_name]
                        history.append((current_time, value))
                        
                        # ì˜¤ë˜ëœ ë°ì´í„° ì œê±° (10ë¶„ ì´ìƒ)
                        cutoff_time = current_time - 600
                        while history and history[0][0] < cutoff_time:
                            history.pop(0)
                
                time.sleep(self.sample_interval)
                
            except Exception as e:
                print(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
                time.sleep(self.sample_interval)
    
    def get_current_saturation(self) -> Dict[str, float]:
        """í˜„ì¬ ì‹œìŠ¤í…œ í¬í™”ë„ ë°˜í™˜"""
        with self._lock:
            result = {}
            for metric_name, history in self._metrics_history.items():
                if history:
                    latest_value = history[-1][1]
                    result[metric_name] = latest_value
            return result
    
    def get_saturation_trend(self, metric_name: str, minutes: int = 5) -> List[tuple]:
        """íŠ¹ì • ë©”íŠ¸ë¦­ì˜ ì‹œê°„ë³„ íŠ¸ë Œë“œ ë°˜í™˜"""
        with self._lock:
            history = self._metrics_history.get(metric_name, [])
            cutoff_time = time.time() - (minutes * 60)
            return [(timestamp, value) for timestamp, value in history if timestamp >= cutoff_time]

# ì‚¬ìš© ì˜ˆì‹œ
saturation_monitor = SaturationMonitor()
saturation_monitor.start()
```

## Prometheus í†µí•© ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°

ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” Prometheusì™€ ê°™ì€ ê²€ì¦ëœ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•œë‹¤.

```python
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time
import functools

# Prometheus ë©”íŠ¸ë¦­ ì •ì˜
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration', ['method', 'endpoint'])
ACTIVE_CONNECTIONS = Gauge('active_connections', 'Number of active connections')
ERROR_RATE = Gauge('error_rate', 'Current error rate', ['service'])

class PrometheusMetricsCollector:
    def __init__(self, port: int = 8000):
        self.port = port
        self._server_started = False
    
    def start_server(self):
        """Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘"""
        if not self._server_started:
            start_http_server(self.port)
            self._server_started = True
            print(f"Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘: http://localhost:{self.port}/metrics")
    
    def track_requests(self, func):
        """HTTP ìš”ì²­ ì¶”ì  ë°ì½”ë ˆì´í„°"""
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            method = getattr(func, '__method__', 'unknown')
            endpoint = func.__name__
            
            with REQUEST_DURATION.labels(method=method, endpoint=endpoint).time():
                try:
                    result = func(*args, **kwargs)
                    REQUEST_COUNT.labels(method=method, endpoint=endpoint, status='success').inc()
                    return result
                except Exception as e:
                    REQUEST_COUNT.labels(method=method, endpoint=endpoint, status='error').inc()
                    raise
        return wrapper

# ì‚¬ìš© ì˜ˆì‹œ
metrics_collector = PrometheusMetricsCollector()
metrics_collector.start_server()

@metrics_collector.track_requests
def api_get_user(user_id: str):
    # API ë¡œì§
    time.sleep(0.1)
    return {"user_id": user_id}

# í™œì„± ì—°ê²° ìˆ˜ ì—…ë°ì´íŠ¸
ACTIVE_CONNECTIONS.set(42)

# ì—ëŸ¬ìœ¨ ì—…ë°ì´íŠ¸
ERROR_RATE.labels(service='user-service').set(0.05)
```

## ì§€ëŠ¥í˜• ì•Œë¦¼ ì‹œìŠ¤í…œ

ë‹¨ìˆœíˆ ì„ê³„ê°’ì„ ë„˜ì—ˆì„ ë•Œë§Œ ì•Œë¦¼ì„ ë³´ë‚´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ëŠ” ì•Œë¦¼**ì„ êµ¬ì¶•í•´ë³´ì.

```python
import asyncio
import aiohttp
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dataclasses import dataclass
from enum import Enum

class AlertSeverity(Enum):
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"

class AlertState(Enum):
    FIRING = "firing"
    RESOLVED = "resolved"
    SILENCED = "silenced"

@dataclass
class Alert:
    id: str
    title: str
    description: str
    severity: AlertSeverity
    state: AlertState
    timestamp: datetime
    labels: Dict[str, str]
    annotations: Dict[str, str]
    resolution_time: Optional[datetime] = None

class IntelligentAlertManager:
    def __init__(self):
        self._active_alerts: Dict[str, Alert] = {}
        self._alert_history: List[Alert] = []
        self._notification_channels: List['NotificationChannel'] = []
        self._suppression_rules: List['SuppressionRule'] = []
        
    async def evaluate_alert(self, metric_name: str, current_value: float, 
                           threshold: float, comparison: str = 'greater') -> Optional[Alert]:
        """ë©”íŠ¸ë¦­ ê¸°ë°˜ ì•Œë¦¼ í‰ê°€"""
        
        # ê¸°ë³¸ ì¡°ê±´ í‰ê°€
        should_fire = False
        if comparison == 'greater':
            should_fire = current_value > threshold
        elif comparison == 'less':
            should_fire = current_value < threshold
        
        alert_id = f"{metric_name}_threshold"
        
        if should_fire:
            # ìƒˆë¡œìš´ ì•Œë¦¼ ìƒì„±
            if alert_id not in self._active_alerts:
                alert = Alert(
                    id=alert_id,
                    title=f"{metric_name} ì„ê³„ê°’ ì´ˆê³¼",
                    description=f"{metric_name} ê°’ì´ {current_value}ë¡œ ì„ê³„ê°’ {threshold}ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤",
                    severity=self._calculate_severity(metric_name, current_value, threshold),
                    state=AlertState.FIRING,
                    timestamp=datetime.now(),
                    labels={'metric': metric_name, 'type': 'threshold'},
                    annotations={'current_value': str(current_value), 'threshold': str(threshold)}
                )
                
                # ì–µì œ ê·œì¹™ í™•ì¸
                if not self._is_suppressed(alert):
                    self._active_alerts[alert_id] = alert
                    await self._send_notifications(alert)
                    return alert
        else:
            # ì•Œë¦¼ í•´ê²°
            if alert_id in self._active_alerts:
                alert = self._active_alerts[alert_id]
                alert.state = AlertState.RESOLVED
                alert.resolution_time = datetime.now()
                
                del self._active_alerts[alert_id]
                self._alert_history.append(alert)
                
                await self._send_notifications(alert)
                return alert
        
        return None
    
    def _calculate_severity(self, metric_name: str, current_value: float, threshold: float) -> AlertSeverity:
        """ë™ì  ì‹¬ê°ë„ ê³„ì‚°"""
        excess_ratio = current_value / threshold
        
        if metric_name.startswith('error_rate'):
            if excess_ratio > 5:
                return AlertSeverity.CRITICAL
            elif excess_ratio > 2:
                return AlertSeverity.WARNING
            else:
                return AlertSeverity.INFO
        
        # CPU, ë©”ëª¨ë¦¬ ë“±ì˜ ê²½ìš°
        if excess_ratio > 1.5:
            return AlertSeverity.CRITICAL
        elif excess_ratio > 1.2:
            return AlertSeverity.WARNING
        else:
            return AlertSeverity.INFO
    
    def _is_suppressed(self, alert: Alert) -> bool:
        """ì–µì œ ê·œì¹™ í™•ì¸"""
        for rule in self._suppression_rules:
            if rule.matches(alert):
                return True
        return False
    
    async def _send_notifications(self, alert: Alert):
        """ëª¨ë“  ì•Œë¦¼ ì±„ë„ë¡œ ì „ì†¡"""
        tasks = []
        for channel in self._notification_channels:
            if channel.should_notify(alert):
                tasks.append(channel.send(alert))
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)

class SlackNotificationChannel:
    def __init__(self, webhook_url: str, min_severity: AlertSeverity = AlertSeverity.WARNING):
        self.webhook_url = webhook_url
        self.min_severity = min_severity
    
    def should_notify(self, alert: Alert) -> bool:
        """ì•Œë¦¼ ì „ì†¡ ì—¬ë¶€ ê²°ì •"""
        severity_order = {AlertSeverity.INFO: 1, AlertSeverity.WARNING: 2, AlertSeverity.CRITICAL: 3}
        return severity_order[alert.severity] >= severity_order[self.min_severity]
    
    async def send(self, alert: Alert):
        """Slackìœ¼ë¡œ ì•Œë¦¼ ì „ì†¡"""
        color_map = {
            AlertSeverity.INFO: "#36a64f",
            AlertSeverity.WARNING: "#ff9500", 
            AlertSeverity.CRITICAL: "#ff0000"
        }
        
        state_emoji = {
            AlertState.FIRING: "ğŸ”¥",
            AlertState.RESOLVED: "âœ…"
        }
        
        payload = {
            "attachments": [{
                "color": color_map[alert.severity],
                "title": f"{state_emoji[alert.state]} {alert.title}",
                "text": alert.description,
                "fields": [
                    {"title": "ì‹¬ê°ë„", "value": alert.severity.value, "short": True},
                    {"title": "ìƒíƒœ", "value": alert.state.value, "short": True},
                    {"title": "ì‹œê°„", "value": alert.timestamp.strftime("%Y-%m-%d %H:%M:%S"), "short": True}
                ],
                "footer": "System Monitoring",
                "ts": int(alert.timestamp.timestamp())
            }]
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(self.webhook_url, json=payload) as response:
                if response.status != 200:
                    print(f"Slack ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {response.status}")

# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    # ì•Œë¦¼ ë§¤ë‹ˆì € ì„¤ì •
    alert_manager = IntelligentAlertManager()
    
    # Slack ì±„ë„ ì¶”ê°€
    slack_channel = SlackNotificationChannel(
        webhook_url="https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK",
        min_severity=AlertSeverity.WARNING
    )
    alert_manager._notification_channels.append(slack_channel)
    
    # ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§ ë£¨í”„
    while True:
        # í˜„ì¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        current_metrics = {
            'cpu_usage': 85.0,
            'memory_usage': 78.5,
            'error_rate': 0.05,
            'response_time_p99': 1.2
        }
        
        # ê° ë©”íŠ¸ë¦­ì— ëŒ€í•´ ì•Œë¦¼ í‰ê°€
        for metric_name, value in current_metrics.items():
            thresholds = {
                'cpu_usage': 80.0,
                'memory_usage': 75.0,
                'error_rate': 0.02,
                'response_time_p99': 1.0
            }
            
            if metric_name in thresholds:
                await alert_manager.evaluate_alert(
                    metric_name=metric_name,
                    current_value=value,
                    threshold=thresholds[metric_name]
                )
        
        await asyncio.sleep(30)  # 30ì´ˆë§ˆë‹¤ í‰ê°€

# asyncio.run(main())
```

## ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ì¶”ì 

ê¸°ìˆ ì  ë©”íŠ¸ë¦­ë¿ë§Œ ì•„ë‹ˆë¼ **ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸**ë¥¼ ì¸¡ì •í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.

```python
class BusinessMetricsTracker:
    def __init__(self):
        self._daily_metrics = defaultdict(lambda: defaultdict(float))
        self._hourly_metrics = defaultdict(lambda: defaultdict(float))
    
    def track_conversion(self, user_id: str, event_type: str, value: float = 1.0):
        """ì „í™˜ ì´ë²¤íŠ¸ ì¶”ì """
        current_time = datetime.now()
        date_key = current_time.strftime("%Y-%m-%d")
        hour_key = current_time.strftime("%Y-%m-%d-%H")
        
        # ì¼ë³„ ë©”íŠ¸ë¦­
        self._daily_metrics[date_key][event_type] += value
        
        # ì‹œê°„ë³„ ë©”íŠ¸ë¦­
        self._hourly_metrics[hour_key][event_type] += value
        
        # Prometheusì—ë„ ê¸°ë¡
        if event_type == 'purchase':
            BUSINESS_EVENTS.labels(event='purchase').inc(value)
        elif event_type == 'signup':
            BUSINESS_EVENTS.labels(event='signup').inc()
    
    def get_conversion_rate(self, date: str) -> Dict[str, float]:
        """ì¼ë³„ ì „í™˜ìœ¨ ê³„ì‚°"""
        daily_data = self._daily_metrics[date]
        
        if 'page_views' in daily_data and daily_data['page_views'] > 0:
            return {
                'signup_rate': daily_data.get('signup', 0) / daily_data['page_views'],
                'purchase_rate': daily_data.get('purchase', 0) / daily_data['page_views'],
                'cart_abandonment_rate': 1 - (daily_data.get('purchase', 0) / max(daily_data.get('add_to_cart', 1), 1))
            }
        return {}

# Prometheus ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
BUSINESS_EVENTS = Counter('business_events_total', 'Business events', ['event'])

# ì‚¬ìš© ì˜ˆì‹œ
business_tracker = BusinessMetricsTracker()

def track_user_action(action_type: str):
    def decorator(func):
        def wrapper(*args, **kwargs):
            result = func(*args, **kwargs)
            
            # ì‚¬ìš©ì ID ì¶”ì¶œ (ì˜ˆì‹œ)
            user_id = kwargs.get('user_id') or getattr(result, 'user_id', 'anonymous')
            
            business_tracker.track_conversion(user_id, action_type)
            return result
        return wrapper
    return decorator

@track_user_action('page_view')
def view_product_page(product_id: str, user_id: str = None):
    return {"product_id": product_id}

@track_user_action('purchase')
def complete_purchase(order_id: str, user_id: str, amount: float):
    business_tracker.track_conversion(user_id, 'purchase', amount)
    return {"order_id": order_id, "amount": amount}
```

## ëŒ€ì‹œë³´ë“œì™€ ì‹œê°í™”

```python
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Tuple
import pandas as pd

class MetricsDashboard:
    def __init__(self, metrics_collector):
        self.metrics = metrics_collector
        
    def generate_sre_dashboard(self) -> str:
        """SRE ëŒ€ì‹œë³´ë“œ HTML ìƒì„±"""
        html = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>SRE Dashboard</title>
            <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                .metric-card { 
                    border: 1px solid #ddd; 
                    padding: 20px; 
                    margin: 10px;
                    border-radius: 8px;
                    background: #f9f9f9;
                }
                .critical { border-left: 5px solid #ff4444; }
                .warning { border-left: 5px solid #ffaa00; }
                .normal { border-left: 5px solid #44ff44; }
            </style>
        </head>
        <body>
            <h1>ğŸ”¥ Site Reliability Engineering Dashboard</h1>
            
            <!-- Golden Signals -->
            <div class="golden-signals">
                <h2>ğŸ“Š Four Golden Signals</h2>
                <div class="metric-card normal">
                    <h3>Latency</h3>
                    <p>P99: 120ms | P95: 80ms | P50: 45ms</p>
                </div>
                <div class="metric-card warning">
                    <h3>Traffic</h3>
                    <p>Current RPS: 1,247 | Peak: 2,100</p>
                </div>
                <div class="metric-card normal">
                    <h3>Errors</h3>
                    <p>Error Rate: 0.12% | Total Errors: 156</p>
                </div>
                <div class="metric-card critical">
                    <h3>Saturation</h3>
                    <p>CPU: 87% | Memory: 76% | Disk: 23%</p>
                </div>
            </div>
            
            <!-- Business Metrics -->
            <div class="business-metrics">
                <h2>ğŸ’° Business Impact</h2>
                <div class="metric-card normal">
                    <h3>Revenue</h3>
                    <p>Today: $12,450 | Yesterday: $11,890 (+4.7%)</p>
                </div>
                <div class="metric-card normal">
                    <h3>Conversions</h3>
                    <p>Signup Rate: 2.3% | Purchase Rate: 1.8%</p>
                </div>
            </div>
            
            <div id="latency-chart" style="width:100%;height:400px;"></div>
            
            <script>
                // ì§€ì—° ì‹œê°„ ì°¨íŠ¸ ìƒì„±
                var trace = {
                    x: ['00:00', '01:00', '02:00', '03:00', '04:00', '05:00'],
                    y: [45, 52, 48, 67, 89, 76],
                    type: 'scatter',
                    name: 'P99 Latency'
                };
                
                var layout = {
                    title: 'Response Time Trend',
                    xaxis: { title: 'Time' },
                    yaxis: { title: 'Latency (ms)' }
                };
                
                Plotly.newPlot('latency-chart', [trace], layout);
            </script>
        </body>
        </html>
        """
        return html
```

## ë ˆìŠ¨ ëŸ°

### 1. ë©”íŠ¸ë¦­ì˜ ê³„ì¸µêµ¬ì¡°ë¥¼ ì´í•´í•˜ë¼

**ê¸°ìˆ  ë©”íŠ¸ë¦­ â†’ ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ â†’ ì‚¬ìš©ì ê²½í—˜**ì˜ ì—°ê²°ê³ ë¦¬ë¥¼ íŒŒì•…í•´ì•¼ í•œë‹¤.

- CPU ì‚¬ìš©ë¥  â†— â†’ ì‘ë‹µ ì‹œê°„ â†— â†’ ì‚¬ìš©ì ì´íƒˆë¥  â†— â†’ ë§¤ì¶œ â†˜

### 2. ì•Œë¦¼ í”¼ë¡œë„ë¥¼ ì¤„ì—¬ë¼

ë„ˆë¬´ ë§ì€ ì•Œë¦¼ì€ **ì¤‘ìš”í•œ ì•Œë¦¼ì„ ë¬»ì–´ë²„ë¦°ë‹¤**. ì§€ëŠ¥í˜• ì•Œë¦¼ ì‹œìŠ¤í…œìœ¼ë¡œ ë…¸ì´ì¦ˆë¥¼ ì¤„ì´ì.

### 3. ì»¨í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ë¼

ë‹¨ìˆœí•œ ìˆ˜ì¹˜ê°€ ì•„ë‹ˆë¼ **ì™œ ê·¸ëŸ° ê°’ì´ ë‚˜ì™”ëŠ”ì§€** ì•Œ ìˆ˜ ìˆëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ìˆ˜ì§‘í•˜ì.

### 4. ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ë¥¼ ì¸¡ì •í•˜ë¼

ê¸°ìˆ ì  ë¬¸ì œê°€ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë¯¸ì¹˜ëŠ” **ì‹¤ì œ ì˜í–¥**ì„ ì •ëŸ‰í™”í•´ì•¼ í•œë‹¤.

---

**ë‹¤ìŒ ì¥ì—ì„œëŠ”** ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ê¸°ë²•ì„ í†µí•´ ì‹œìŠ¤í…œ ë³‘ëª©ì„ ì •í™•íˆ ì°¾ì•„ë‚´ëŠ” ë°©ë²•ì„ í•™ìŠµí•œë‹¤. ë©”íŠ¸ë¦­ìœ¼ë¡œ ë¬¸ì œë¥¼ ê°ì§€í–ˆë‹¤ë©´, í”„ë¡œíŒŒì¼ë§ìœ¼ë¡œ ê·¼ë³¸ ì›ì¸ì„ íŒŒì•…í•´ì•¼ í•œë‹¤.

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

### ğŸ“– í˜„ì¬ ë¬¸ì„œ ì •ë³´

- **ë‚œì´ë„**: INTERMEDIATE
- **ì£¼ì œ**: ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜
- **ì˜ˆìƒ ì‹œê°„**: 4-6ì‹œê°„

### ğŸ¯ í•™ìŠµ ê²½ë¡œ

- [ğŸ“š INTERMEDIATE ë ˆë²¨ ì „ì²´ ë³´ê¸°](../learning-paths/intermediate/)
- [ğŸ  ë©”ì¸ í•™ìŠµ ê²½ë¡œ](../learning-paths/)
- [ğŸ“‹ ì „ì²´ ê°€ì´ë“œ ëª©ë¡](../README.md)

### ğŸ“‚ ê°™ì€ ì±•í„° (chapter-13-observability-debugging)

- [13.1 ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ - ì‹œìŠ¤í…œì˜ ëˆˆê³¼ ê·€ ê°œìš”](./12-40-logging-monitoring.md)
- [13.1A ê´€ì°° ê°€ëŠ¥ì„± ê¸°ì´ˆ - ì‹œìŠ¤í…œì„ ë³´ëŠ” ëˆˆ](./12-10-observability-foundations.md)
- [13.1a êµ¬ì¡°í™”ëœ ë¡œê¹… - ê²€ìƒ‰ ê°€ëŠ¥í•œ ë¡œê·¸ ì‹œìŠ¤í…œ](./12-11-structured-logging.md)
- [13.1b ë©”íŠ¸ë¦­ ìˆ˜ì§‘ - ì‹œìŠ¤í…œ ê±´ê°•ë„ ì¸¡ì •](./12-12-metrics-collection.md)
- [13.1B êµ¬ì¡°í™”ëœ ë¡œê¹… - ê²€ìƒ‰ ê°€ëŠ¥í•œ ë¡œê·¸](./12-13-structured-logging.md)

### ğŸ·ï¸ ê´€ë ¨ í‚¤ì›Œë“œ

`observability`, `metrics`, `alerting`, `prometheus`, `four_golden_signals`

### â­ï¸ ë‹¤ìŒ ë‹¨ê³„ ê°€ì´ë“œ

- ì‹¤ë¬´ ì ìš©ì„ ì—¼ë‘ì— ë‘ê³  í”„ë¡œì íŠ¸ì— ì ìš©í•´ë³´ì„¸ìš”
- ê´€ë ¨ ë„êµ¬ë“¤ì„ ì§ì ‘ ì‚¬ìš©í•´ë³´ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤
