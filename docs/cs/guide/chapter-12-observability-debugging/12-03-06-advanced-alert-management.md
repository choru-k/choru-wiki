---
tags:
  - alert_management
  - hands-on
  - incident_response
  - intermediate
  - medium-read
  - monitoring_automation
  - notification_routing
  - observability
  - ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜
difficulty: INTERMEDIATE
learning_time: "4-6ì‹œê°„"
main_topic: "ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜"
priority_score: 4
---

# 12.3.6: ê³ ê¸‰ ì•Œë¦¼ ê´€ë¦¬

ì•Œë¦¼ ê´€ë¦¬ ì‹œìŠ¤í…œì€ ì‹œìŠ¤í…œì—ì„œ ë°œìƒí•˜ëŠ” ë¹„ì •ìƒì ì¸ ìƒí™©ì„**ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì§€**í•˜ê³ , ì ì ˆí•œ ë‹´ë‹¹ìì—ê²Œ**ìë™ìœ¼ë¡œ ì•Œë¦¼**ì„ ì „ì†¡í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì§€ëŠ¥ì ì¸ ì•Œë¦¼ ê·œì¹™, ì¤‘ë³µ ë°©ì§€, ì‹¬ê°ë„ ê¸°ë°˜ ë¼ìš°íŒ… ë“±ì„ í†µí•´ ì•Œë¦¼ í”¼ë¡œë„ë¥¼ ë°©ì§€í•˜ê³  íš¨ìœ¨ì ì¸ ì‚¬ê³  ëŒ€ì‘ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

## ğŸš¨ ì§€ëŠ¥ì ì¸ ì•Œë¦¼ ì‹œìŠ¤í…œ

### ì•Œë¦¼ ì‹œìŠ¤í…œì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œ

```python
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import List, Dict, Any, Callable, Optional
from datetime import datetime, timedelta
from enum import Enum
import threading
import time
import smtplib
import json
from email.mime.text import MimeText
from email.mime.multipart import MimeMultipart

class AlertSeverity(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class AlertStatus(Enum):
    TRIGGERED = "triggered"
    ACKNOWLEDGED = "acknowledged"
    RESOLVED = "resolved"
    SUPPRESSED = "suppressed"

@dataclass
class Alert:
    id: str
    title: str
    description: str
    severity: AlertSeverity
    status: AlertStatus = AlertStatus.TRIGGERED
    timestamp: datetime = field(default_factory=datetime.now)
    labels: Dict[str, str] = field(default_factory=dict)
    annotations: Dict[str, str] = field(default_factory=dict)
    resolved_at: Optional[datetime] = None
    acknowledged_by: Optional[str] = None
```

### ë‹¤ì–‘í•œ ì•Œë¦¼ ì±„ë„ ì§€ì›

```python
class NotificationChannel(ABC):
    """ì•Œë¦¼ ì±„ë„ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def send(self, alert: Alert) -> bool:
        pass

class EmailNotification(NotificationChannel):
    """ì´ë©”ì¼ ì•Œë¦¼ ì±„ë„"""
    
    def __init__(self, smtp_server: str, smtp_port: int, username: str, password: str):
        self.smtp_server = smtp_server
        self.smtp_port = smtp_port
        self.username = username
        self.password = password
    
    def send(self, alert: Alert) -> bool:
        """ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡"""
        try:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” SMTP ì„œë²„ ì—°ê²°
            print(f"ğŸ“§ Email sent: {alert.title} ({alert.severity.value})")
            
            # ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•œ ì´ë©”ì¼ ë‚´ìš© ì¶œë ¥
            email_content = self._format_email(alert)
            print(f"   Content: {email_content[:100]}...")
            
            return True
        except Exception as e:
            print(f"\u274c Email send failed: {e}")
            return False
    
    def _format_email(self, alert: Alert) -> str:
        """ì´ë©”ì¼ ë‚´ìš© í¬ë§¤íŒ…"""
        return f"""
Alert: {alert.title}
Severity: {alert.severity.value.upper()}
Time: {alert.timestamp.isoformat()}

Description: {alert.description}

Labels: {json.dumps(alert.labels, indent=2)}
Annotations: {json.dumps(alert.annotations, indent=2)}

Please check the monitoring dashboard for more details.
        """

class SlackNotification(NotificationChannel):
    """ìŠ¬ë™ ì•Œë¦¼ ì±„ë„"""
    
    def __init__(self, webhook_url: str):
        self.webhook_url = webhook_url
    
    def send(self, alert: Alert) -> bool:
        """ìŠ¬ë™ ì•Œë¦¼ ì „ì†¡"""
        try:
            # ì‹¤ì œë¡œëŠ” Slack ì›¹í›… í˜¸ì¶œ
            print(f"ğŸ’¬ Slack notification: {alert.title}")
            
            slack_message = self._format_slack_message(alert)
            print(f"   Message: {slack_message}")
            
            return True
        except Exception as e:
            print(f"\u274c Slack send failed: {e}")
            return False
    
    def _format_slack_message(self, alert: Alert) -> str:
        """ìŠ¬ë™ ë©”ì‹œì§€ í¬ë§¤íŒ…"""
        emoji_map = {
            AlertSeverity.LOW: "ğŸŸ¢",
            AlertSeverity.MEDIUM: "ğŸŸ¡", 
            AlertSeverity.HIGH: "ğŸŸ ",
            AlertSeverity.CRITICAL: "ğŸ”´"
        }
        
        emoji = emoji_map.get(alert.severity, "\u26a0\ufe0f")
        
        return f"{emoji} *{alert.title}* ({alert.severity.value}), {alert.description}"

class PagerDutyNotification(NotificationChannel):
    """PagerDuty ì•Œë¦¼ ì±„ë„"""
    
    def __init__(self, integration_key: str):
        self.integration_key = integration_key
    
    def send(self, alert: Alert) -> bool:
        """PagerDuty ì•Œë¦¼ ì „ì†¡"""
        try:
            # ì‹¤ì œë¡œëŠ” PagerDuty API í˜¸ì¶œ
            print(f"ğŸ“Ÿ PagerDuty incident: {alert.title}")
            return True
        except Exception as e:
            print(f"\u274c PagerDuty send failed: {e}")
            return False
```

### ì•Œë¦¼ ê·œì¹™ ë° ê´€ë¦¬ì

```python
@dataclass
class AlertRule:
    """ì•Œë¦¼ ê·œì¹™"""
    id: str
    name: str
    condition: str  # ì‹¤ì œë¡œëŠ” PromQL ì¿¼ë¦¬ ë“±
    severity: AlertSeverity
    for_duration: timedelta = timedelta(minutes=5)  # ì§€ì† ì‹œê°„
    labels: Dict[str, str] = field(default_factory=dict)
    annotations: Dict[str, str] = field(default_factory=dict)
    enabled: bool = True

class AlertManager:
    """ì•Œë¦¼ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.alerts: Dict[str, Alert] = {}
        self.alert_rules: Dict[str, AlertRule] = {}
        self.notification_channels: List[NotificationChannel] = []
        self.routing_rules: List[Dict] = []
        self.suppression_rules: List[Dict] = []
        self.lock = threading.Lock()
        
        # ì•Œë¦¼ í†µê³„
        self.stats = {
            'total_alerts': 0,
            'alerts_by_severity': {severity: 0 for severity in AlertSeverity},
            'notification_success_rate': 0.0
        }
    
    def add_notification_channel(self, channel: NotificationChannel):
        """ì•Œë¦¼ ì±„ë„ ì¶”ê°€"""
        self.notification_channels.append(channel)
    
    def add_routing_rule(self, rule: Dict[str, Any]):
        """ë¼ìš°íŒ… ê·œì¹™ ì¶”ê°€"""
        # ì˜ˆ: {'match': {'severity': 'critical'}, 'channels': ['pagerduty', 'email']}
        self.routing_rules.append(rule)
    
    def add_suppression_rule(self, rule: Dict[str, Any]):
        """ì–µì œ ê·œì¹™ ì¶”ê°€ (ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€)"""
        # ì˜ˆ: {'match': {'service': 'payment'}, 'duration': 3600}
        self.suppression_rules.append(rule)
    
    def add_alert_rule(self, rule: AlertRule):
        """ì•Œë¦¼ ê·œì¹™ ì¶”ê°€"""
        self.alert_rules[rule.id] = rule
    
    def trigger_alert(self, rule_id: str, metric_value: float, context: Dict[str, Any] = None):
        """ì•Œë¦¼ ë°œìƒ"""
        if rule_id not in self.alert_rules:
            return
        
        rule = self.alert_rules[rule_id]
        
        if not rule.enabled:
            return
        
        # ì•Œë¦¼ ìƒì„±
        alert_id = f"{rule_id}_{int(time.time())}"
        alert = Alert(
            id=alert_id,
            title=rule.name,
            description=rule.annotations.get('description', ''),
            severity=rule.severity,
            labels=rule.labels.copy(),
            annotations=rule.annotations.copy()
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        if context:
            alert.annotations.update({
                'metric_value': str(metric_value),
                'context': json.dumps(context)
            })
        
        with self.lock:
            # ì–µì œ ê·œì¹™ í™•ì¸
            if self._is_suppressed(alert):
                print(f"ğŸ”‡ Alert suppressed: {alert.title}")
                return
            
            # ì•Œë¦¼ ì €ì¥
            self.alerts[alert_id] = alert
            self.stats['total_alerts'] += 1
            self.stats['alerts_by_severity'][alert.severity] += 1
        
        print(f"ğŸš¨ Alert triggered: {alert.title} (severity: {alert.severity.value})")
        
        # ì•Œë¦¼ ì „ì†¡
        self._send_notifications(alert)
    
    def _is_suppressed(self, alert: Alert) -> bool:
        """ì•Œë¦¼ ì–µì œ ì—¬ë¶€ í™•ì¸"""
        for rule in self.suppression_rules:
            if self._matches_labels(alert.labels, rule.get('match', {})):
                # ì–µì œ ê¸°ê°„ í™•ì¸
                suppression_duration = rule.get('duration', 3600)  # ê¸°ë³¸ 1ì‹œê°„
                
                # ê°™ì€ ë ˆì´ë¸” ì¡°í•©ì˜ ìµœê·¼ ì•Œë¦¼ í™•ì¸
                for existing_alert in self.alerts.values():
                    if (self._matches_labels(existing_alert.labels, rule.get('match', {})) and
                        (alert.timestamp - existing_alert.timestamp).total_seconds() < suppression_duration):
                        return True
        
        return False
    
    def _matches_labels(self, alert_labels: Dict[str, str], match_criteria: Dict[str, str]) -> bool:
        """ë ˆì´ë¸” ë§¤ì¹­ í™•ì¸"""
        for key, value in match_criteria.items():
            if alert_labels.get(key) != value:
                return False
        return True
    
    def _send_notifications(self, alert: Alert):
        """ì•Œë¦¼ ì „ì†¡"""
        # ë¼ìš°íŒ… ê·œì¹™ì— ë”°ë¥¸ ì±„ë„ ì„ íƒ
        target_channels = self._get_target_channels(alert)
        
        successful_sends = 0
        total_sends = 0
        
        for channel in target_channels:
            total_sends += 1
            if channel.send(alert):
                successful_sends += 1
        
        # ì„±ê³µë¥  ì—…ë°ì´íŠ¸
        if total_sends > 0:
            success_rate = successful_sends / total_sends
            self.stats['notification_success_rate'] = (
                self.stats['notification_success_rate'] * 0.9 + success_rate * 0.1
            )
    
    def _get_target_channels(self, alert: Alert) -> List[NotificationChannel]:
        """ë¼ìš°íŒ… ê·œì¹™ì— ë”°ë¥¸ íƒ€ê²Ÿ ì±„ë„ ì„ íƒ"""
        target_channels = []
        
        for rule in self.routing_rules:
            if self._matches_labels(alert.labels, rule.get('match', {})):
                # ì±„ë„ íƒ€ì…ì— ë”°ë¥¸ ë§¤í•‘ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§)
                for channel_type in rule.get('channels', []):
                    if channel_type == 'email' and len(self.notification_channels) > 0:
                        target_channels.append(self.notification_channels[0])
                    elif channel_type == 'slack' and len(self.notification_channels) > 1:
                        target_channels.append(self.notification_channels[1])
                    elif channel_type == 'pagerduty' and len(self.notification_channels) > 2:
                        target_channels.append(self.notification_channels[2])
                break
        
        # ê¸°ë³¸ ì±„ë„ (ê·œì¹™ì´ ì—†ìœ¼ë©´ ëª¨ë“  ì±„ë„)
        if not target_channels:
            target_channels = self.notification_channels
        
        return target_channels
    
    def acknowledge_alert(self, alert_id: str, acknowledged_by: str):
        """ì•Œë¦¼ í™•ì¸"""
        if alert_id in self.alerts:
            alert = self.alerts[alert_id]
            alert.status = AlertStatus.ACKNOWLEDGED
            alert.acknowledged_by = acknowledged_by
            print(f"\u2705 Alert acknowledged: {alert.title} by {acknowledged_by}")
    
    def resolve_alert(self, alert_id: str):
        """ì•Œë¦¼ í•´ê²°"""
        if alert_id in self.alerts:
            alert = self.alerts[alert_id]
            alert.status = AlertStatus.RESOLVED
            alert.resolved_at = datetime.now()
            print(f"ğŸ¯ Alert resolved: {alert.title}")
    
    def get_active_alerts(self) -> List[Alert]:
        """í™œì„± ì•Œë¦¼ ëª©ë¡"""
        return [alert for alert in self.alerts.values() 
                if alert.status == AlertStatus.TRIGGERED]
    
    def get_statistics(self) -> Dict[str, Any]:
        """ì•Œë¦¼ í†µê³„"""
        active_alerts = len(self.get_active_alerts())
        
        return {
          **self.stats,
            'active_alerts': active_alerts,
            'total_rules': len(self.alert_rules),
            'notification_channels': len(self.notification_channels)
        }
```

## ğŸ‘ï¸ ë©”íŠ¸ë¦­ ê°ì‹œê¸°

### ì‹¤ì‹œê°„ ì„ê³„ê°’ ëª¨ë‹ˆí„°ë§

```python
# ì‹¤ì œ ëª¨ë‹ˆí„°ë§ê³¼ ì—°ë™í•˜ëŠ” ë©”íŠ¸ë¦­ ê°ì‹œê¸°
class MetricWatcher:
    """ë©”íŠ¸ë¦­ ê°ì‹œê¸°"""
    
    def __init__(self, metrics_collector: 'MetricsCollector', alert_manager: AlertManager):
        self.metrics = metrics_collector
        self.alert_manager = alert_manager
        self.monitoring = True
        self.check_interval = 10  # 10ì´ˆë§ˆë‹¤ ì²´í¬
        
        # ë©”íŠ¸ë¦­ ì„ê³„ê°’ë“¤
        self.thresholds = {
            'error_rate_high': 0.05,  # 5% ì—ëŸ¬ìœ¨
            'response_time_high': 2.0,  # 2ì´ˆ ì‘ë‹µì‹œê°„
            'db_connections_high': 18,  # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìˆ˜
            'memory_usage_high': 0.85,  # 85% ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            'payment_success_rate_low': 0.95  # 95% ê²°ì œ ì„±ê³µë¥ 
        }
    
    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        def monitor():
            while self.monitoring:
                try:
                    self._check_metrics()
                    time.sleep(self.check_interval)
                except Exception as e:
                    print(f"\u274c Monitoring error: {e}")
                    time.sleep(self.check_interval)
        
        threading.Thread(target=monitor, daemon=True).start()
        print("ğŸ‘€ Metric monitoring started")
    
    def _check_metrics(self):
        """ë©”íŠ¸ë¦­ ì²´í¬"""
        # ì‹¤ì œë¡œëŠ” Prometheusì—ì„œ ë©”íŠ¸ë¦­ì„ ì¿¼ë¦¬
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
        
        # ì—ëŸ¬ìœ¨ ì²´í¬
        error_rate = random.uniform(0, 0.1)
        if error_rate > self.thresholds['error_rate_high']:
            self.alert_manager.trigger_alert(
                'high_error_rate',
                error_rate,
                {'service': 'payment', 'environment': 'production'}
            )
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì²´í¬
        db_connections = random.randint(15, 20)
        if db_connections > self.thresholds['db_connections_high']:
            self.alert_manager.trigger_alert(
                'high_db_connections',
                db_connections,
                {'database': 'payment_db', 'pool': 'main'}
            )
    
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring = False
```

## ğŸ“ˆ ì•Œë¦¼ í”¼ë¡œë„ ë°©ì§€ ì „ëµ

### 1. ì–µì œ ê·œì¹™ (Suppression Rules)

```python
# ì˜ˆì‹œ: ê°™ì€ ì„œë¹„ìŠ¤ì—ì„œ 30ë¶„ê°„ ë™ì¼í•œ ì•Œë¦¼ ì–µì œ
alert_manager.add_suppression_rule({
    'match': {'service': 'payment'},
    'duration': 1800  # 30ë¶„
})

# ì˜ˆì‹œ: íƒ€ì„ì•„ì›ƒ ì—ëŸ¬ì˜ ê²½ìš° 5ë¶„ê°„ ì–µì œ
alert_manager.add_suppression_rule({
    'match': {'error_type': 'TimeoutException'},
    'duration': 300  # 5ë¶„
})
```

### 2. ì‹¬ê°ë„ ê¸°ë°˜ ë¼ìš°íŒ…

```python
# CRITICAL: PagerDuty + Slack + Email
alert_manager.add_routing_rule({
    'match': {'severity': 'critical'},
    'channels': ['pagerduty', 'slack', 'email']
})

# HIGH: Slack + Email
alert_manager.add_routing_rule({
    'match': {'severity': 'high'},
    'channels': ['slack', 'email']
})

# MEDIUM: Email ë§Œ
alert_manager.add_routing_rule({
    'match': {'severity': 'medium'},
    'channels': ['email']
})

# LOW: ë¡œê·¸ë§Œ ê¸°ë¡ (ì•Œë¦¼ ë¯¸ì „ì†¡)
alert_manager.add_routing_rule({
    'match': {'severity': 'low'},
    'channels': []  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ = ì•Œë¦¼ ì „ì†¡ ì•ˆí•¨
})
```

### 3. ì‹œê°„ëŒ€ë³„ ì•Œë¦¼ ê·œì¹™

```python
from datetime import datetime, time as dt_time

class TimeBasedRouting:
    """ì‹œê°„ëŒ€ë³„ ë¼ìš°íŒ…"""
    
    @staticmethod
    def get_channels_for_time(alert: Alert, current_time: datetime = None) -> List[str]:
        if current_time is None:
            current_time = datetime.now()
        
        current_hour = current_time.hour
        is_weekend = current_time.weekday() >= 5  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
        
        # ì—…ë¬´ ì‹œê°„ (9-18ì‹œ, í‰ì¼)
        is_business_hours = (9 <= current_hour <= 18) and not is_weekend
        
        if alert.severity == AlertSeverity.CRITICAL:
            # ì‹¬ê°í•œ ì•Œë¦¼ì€ ì–¸ì œë‚˜ ëª¨ë“  ì±„ë„
            return ['pagerduty', 'slack', 'email']
        elif alert.severity == AlertSeverity.HIGH:
            if is_business_hours:
                return ['slack', 'email']
            else:
                # ë¹„ì—…ë¬´ì‹œê°„ì—ëŠ” ëŒ€ê¸° ê°€ëŠ¥í•œ ì±„ë„ë§Œ
                return ['email']
        else:
            if is_business_hours:
                return ['email']
            else:
                # ë¹„ì—…ë¬´ì‹œê°„ ì¼ë°˜ ì•Œë¦¼ì€ ëŒ€ê¸°ì—´ì— ì €ì¥
                return []
```

## ğŸ“Š ì•Œë¦¼ íš¨ê³¼ì„± ì¸¡ì •

### ì•Œë¦¼ ì„±ëŠ¥ ë©”íŠ¸ë¦­

```python
class AlertMetrics:
    """ì•Œë¦¼ ì‹œìŠ¤í…œ ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    
    def __init__(self):
        self.alert_response_times = []  # ì•Œë¦¼ ëŒ€ì‘ ì‹œê°„
        self.false_positive_count = 0   # ì˜¤íƒì§€ ì•Œë¦¼
        self.escalation_count = 0       # ì—ìŠ¤ì¹¼ë ˆì´ì…˜ ì•Œë¦¼
        self.resolution_times = []      # ë¬¸ì œ í•´ê²° ì‹œê°„
    
    def record_alert_acknowledged(self, alert: Alert, response_time_minutes: float):
        """ì•Œë¦¼ í™•ì¸ ê¸°ë¡"""
        self.alert_response_times.append(response_time_minutes)
        
        # ë¹ ë¥¸ ì‘ë‹µ (5ë¶„ ë‚´) ê¸°ì¤€ìœ¼ë¡œ íš¨ê³¼ì„± í‰ê°€
        if response_time_minutes <= 5:
            print(f"\u2705 ë¹ ë¥¸ ì‘ë‹µ: {response_time_minutes:.1f}ë¶„")
        elif response_time_minutes <= 15:
            print(f"\u26a0\ufe0f ë³´í†µ ì‘ë‹µ: {response_time_minutes:.1f}ë¶„")
        else:
            print(f"\u274c ëŠë¦° ì‘ë‹µ: {response_time_minutes:.1f}ë¶„")
    
    def record_false_positive(self, alert: Alert):
        """ì˜¤íƒì§€ ì•Œë¦¼ ê¸°ë¡"""
        self.false_positive_count += 1
        print(f"\ud83dï¿½ ì˜¤íƒì§€ ì•Œë¦¼ ê¸°ë¡: {alert.title}")
    
    def get_alert_effectiveness_report(self) -> Dict[str, Any]:
        """ì•Œë¦¼ íš¨ê³¼ì„± ë¦¬í¬íŠ¸"""
        if not self.alert_response_times:
            return {'error': 'ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
        
        avg_response_time = sum(self.alert_response_times) / len(self.alert_response_times)
        total_alerts = len(self.alert_response_times) + self.false_positive_count
        false_positive_rate = self.false_positive_count / total_alerts if total_alerts > 0 else 0
        
        return {
            'avg_response_time_minutes': round(avg_response_time, 2),
            'total_alerts': total_alerts,
            'false_positive_rate': round(false_positive_rate * 100, 2),
            'fast_response_rate': round(len([t for t in self.alert_response_times if t <= 5]) / len(self.alert_response_times) * 100, 2)
        }
```

## ğŸ”§ Alert Management ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

```python
# Alert Management ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
def test_alert_system():
    print("=== Alert Management ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")
    
    # Alert Manager ìƒì„±
    alert_manager = AlertManager()
    
    # ì•Œë¦¼ ì±„ë„ ì„¤ì •
    email_channel = EmailNotification("smtp.company.com", 587, "alerts@company.com", "password")
    slack_channel = SlackNotification("https://hooks.slack.com/services/...")
    pagerduty_channel = PagerDutyNotification("integration_key_123")
    
    alert_manager.add_notification_channel(email_channel)
    alert_manager.add_notification_channel(slack_channel)
    alert_manager.add_notification_channel(pagerduty_channel)
    
    # ë¼ìš°íŒ… ê·œì¹™ ì„¤ì •
    alert_manager.add_routing_rule({
        'match': {'severity': 'critical'},
        'channels': ['pagerduty', 'slack', 'email']
    })
    
    alert_manager.add_routing_rule({
        'match': {'severity': 'high'},
        'channels': ['slack', 'email']
    })
    
    alert_manager.add_routing_rule({
        'match': {'severity': 'medium'},
        'channels': ['email']
    })
    
    # ì–µì œ ê·œì¹™ ì„¤ì •
    alert_manager.add_suppression_rule({
        'match': {'service': 'payment'},
        'duration': 1800  # 30ë¶„ê°„ ê°™ì€ ì„œë¹„ìŠ¤ ì•Œë¦¼ ì–µì œ
    })
    
    # ì•Œë¦¼ ê·œì¹™ ì„¤ì •
    rules = [
        AlertRule(
            id="high_error_rate",
            name="High Error Rate Detected",
            condition="rate(errors_total[5m]) > 0.05",
            severity=AlertSeverity.HIGH,
            labels={'service': 'payment', 'team': 'backend'},
            annotations={
                'description': 'Error rate is above 5% threshold',
                'runbook_url': 'https://wiki.company.com/runbooks/high-error-rate'
            }
        ),
        AlertRule(
            id="high_db_connections",
            name="Database Connection Pool Near Exhaustion",
            condition="database_connections_active > 18",
            severity=AlertSeverity.CRITICAL,
            labels={'service': 'payment', 'component': 'database'},
            annotations={
                'description': 'Database connection pool is near exhaustion',
                'runbook_url': 'https://wiki.company.com/runbooks/db-connections'
            }
        ),
        AlertRule(
            id="low_payment_success",
            name="Payment Success Rate Too Low",
            condition="payment_success_rate < 95",
            severity=AlertSeverity.MEDIUM,
            labels={'service': 'payment', 'type': 'business'},
            annotations={'description': 'Payment success rate dropped below 95%'}
        )
    ]
    
    for rule in rules:
        alert_manager.add_alert_rule(rule)
    
    print(", --- ì•Œë¦¼ ê·œì¹™ íŠ¸ë¦¬ê±° í…ŒìŠ¤íŠ¸ ---")
    
    # ì•Œë¦¼ ë°œìƒ ì‹œë®¬ë ˆì´ì…˜
    test_scenarios = [
        ('high_error_rate', 0.08, {'current_rate': '8%'}),
        ('high_db_connections', 19, {'current_connections': 19}),
        ('low_payment_success', 0.92, {'current_rate': '92%'}),
        ('high_error_rate', 0.07, {'current_rate': '7%'})  # ì–µì œë˜ì–´ì•¼ í•¨
    ]
    
    for rule_id, value, context in test_scenarios:
        alert_manager.trigger_alert(rule_id, value, context)
        time.sleep(1)
    
    print(f", --- ì•Œë¦¼ ìƒíƒœ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ---")
    
    # í™œì„± ì•Œë¦¼ í™•ì¸
    active_alerts = alert_manager.get_active_alerts()
    print(f"í™œì„± ì•Œë¦¼: {len(active_alerts)}ê°œ")
    
    if active_alerts:
        # ì²« ë²ˆì§¸ ì•Œë¦¼ í™•ì¸
        first_alert = active_alerts[0]
        alert_manager.acknowledge_alert(first_alert.id, "john.doe@company.com")
        
        # ë‘ ë²ˆì§¸ ì•Œë¦¼ í•´ê²°
        if len(active_alerts) > 1:
            second_alert = active_alerts[1]
            alert_manager.resolve_alert(second_alert.id)
    
    # í†µê³„ ì¶œë ¥
    stats = alert_manager.get_statistics()
    print(f", ğŸ“Š Alert Manager í†µê³„:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    print(f", ğŸ‘€ ë©”íŠ¸ë¦­ ê°ì‹œê¸° ì‹œì‘...")
    
    # ë©”íŠ¸ë¦­ ê°ì‹œê¸° í…ŒìŠ¤íŠ¸ (ì´ì „ ì„¹ì…˜ì˜ MetricsCollector ì‚¬ìš©)
    from unittest.mock import Mock
    metrics_collector = Mock()  # Mock ê°ì²´ ì‚¬ìš©
    watcher = MetricWatcher(metrics_collector, alert_manager)
    watcher.start_monitoring()
    
    print("   10ì´ˆê°„ ë©”íŠ¸ë¦­ ê°ì‹œ...")
    time.sleep(10)
    
    watcher.stop_monitoring()
    print("\u2705 Alert Management ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

# ì‹¤í–‰
if __name__ == "__main__":
    import random
    test_alert_system()
```

## í•µì‹¬ ìš”ì 

### 1. ì§€ëŠ¥ì ì¸ ì•Œë¦¼ ë¼ìš°íŒ…

ì‹¬ê°ë„ì™€ ìƒí™©ì— ë”°ë¼ ì ì ˆí•œ ì±„ë„ë¡œ ì•Œë¦¼ì„ ì „ì†¡í•˜ì—¬ ì•Œë¦¼ í”¼ë¡œë„ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.

### 2. ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€

ì–µì œ ê·œì¹™ì„ í†µí•´ ë™ì¼í•œ ë¬¸ì œì— ëŒ€í•œ ì¤‘ë³µ ì•Œë¦¼ì„ ë°©ì§€í•˜ê³  ì§‘ì¤‘ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

### 3. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

ë©”íŠ¸ë¦­ ê°ì‹œê¸°ë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì„ê³„ê°’ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ë¬¸ì œë¥¼ ì¡°ê¸°ì— ë°œê²¬í•©ë‹ˆë‹¤.

### 4. ì„±ëŠ¥ ì¸¡ì •ê³¼ ê°œì„ 

ì•Œë¦¼ ì‹œìŠ¤í…œ ìì²´ì˜ íš¨ê³¼ì„±ì„ ì¸¡ì •í•˜ê³  ì§€ì†ì ìœ¼ë¡œ ê°œì„ í•˜ì—¬ ë³´ë‹¤ íš¨ìœ¨ì ì¸ ì•Œë¦¼ ì‹œìŠ¤í…œì„ ìš´ì˜í•©ë‹ˆë‹¤.

---

**ì´ì „**: [13.1C ë©”íŠ¸ë¦­ ìˆ˜ì§‘](12-03-05-advanced-metrics-collection.md)  
**ë‹¤ìŒ**: [12.6.1 ëª¨ë²” ì‚¬ë¡€ì™€ ê²½í—˜ ê³µìœ ](./12-06-01-best-practices-lessons.md)ì—ì„œ ë¡œê¹…, ë©”íŠ¸ë¦­, ì•Œë¦¼ì„ í†µí•©í•œ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

### ğŸ“– í˜„ì¬ ë¬¸ì„œ ì •ë³´

-**ë‚œì´ë„**: INTERMEDIATE
-**ì£¼ì œ**: ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜
-**ì˜ˆìƒ ì‹œê°„**: 4-6ì‹œê°„

### ğŸ¯ í•™ìŠµ ê²½ë¡œ

- [ğŸ“š INTERMEDIATE ë ˆë²¨ ì „ì²´ ë³´ê¸°](../learning-paths/intermediate/)
- [ğŸ  ë©”ì¸ í•™ìŠµ ê²½ë¡œ](../learning-paths/)
- [ğŸ“‹ ì „ì²´ ê°€ì´ë“œ ëª©ë¡](../README.md)

### ğŸ“‚ ê°™ì€ ì±•í„° (chapter-12-observability-debugging)

- [13.1 ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ - ì‹œìŠ¤í…œì˜ ëˆˆê³¼ ê·€ ê°œìš”](./12-02-03-logging-monitoring.md)
- [13.1A ê´€ì°° ê°€ëŠ¥ì„± ê¸°ì´ˆ - ì‹œìŠ¤í…œì„ ë³´ëŠ” ëˆˆ](./12-01-01-observability-foundations.md)
- [13.1a êµ¬ì¡°í™”ëœ ë¡œê¹… - ê²€ìƒ‰ ê°€ëŠ¥í•œ ë¡œê·¸ ì‹œìŠ¤í…œ](./12-02-01-structured-logging.md)
- [13.1b ë©”íŠ¸ë¦­ ìˆ˜ì§‘ - ì‹œìŠ¤í…œ ê±´ê°•ë„ ì¸¡ì •](./12-02-02-metrics-collection.md)
- [13.1B êµ¬ì¡°í™”ëœ ë¡œê¹… - ê²€ìƒ‰ ê°€ëŠ¥í•œ ë¡œê·¸](./12-03-04-advanced-structured-logging.md)

### ğŸ·ï¸ ê´€ë ¨ í‚¤ì›Œë“œ

`alert_management`, `notification_routing`, `observability`, `incident_response`, `monitoring_automation`

### â­ï¸ ë‹¤ìŒ ë‹¨ê³„ ê°€ì´ë“œ

- ì‹¤ë¬´ ì ìš©ì„ ì—¼ë‘ì— ë‘ê³  í”„ë¡œì íŠ¸ì— ì ìš©í•´ë³´ì„¸ìš”
- ê´€ë ¨ ë„êµ¬ë“¤ì„ ì§ì ‘ ì‚¬ìš©í•´ë³´ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤
