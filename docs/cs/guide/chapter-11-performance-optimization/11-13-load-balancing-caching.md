---
tags:
  - deep-study
  - hands-on
  - intermediate
  - load_balancing
  - nginx_optimization
  - performance_monitoring
  - redis_caching
  - system_tuning
  - ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜
difficulty: INTERMEDIATE
learning_time: "6-8ì‹œê°„"
main_topic: "ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜"
priority_score: 4
---

# 11.5d ë¡œë“œ ë°¸ëŸ°ì‹±ê³¼ ìºì‹± ì „ëµ

ë¡œë“œ ë°¸ëŸ°ì‹±ê³¼ ìºì‹±ì€ ëŒ€ê·œëª¨ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ê³¼ í™•ì¥ì„±ì„ ë³´ì¥í•˜ëŠ” í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤. ì ì ˆí•œ ë¡œë“œ ë°¸ëŸ°ì‹± ì „ëµê³¼ ìºì‹± ì‹œìŠ¤í…œì„ í†µí•´ ì „ì²´ì ì¸ ì‹œìŠ¤í…œ ì²˜ë¦¬ëŸ‰ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## Nginx ë¡œë“œ ë°¸ëŸ°ì„œ ìµœì í™”

```nginx
# nginx_optimization.conf - Nginx ì„±ëŠ¥ ìµœì í™” ì„¤ì •

# ============ ì „ì—­ ì„¤ì • ============
user nginx;
worker_processes auto;                    # CPU ì½”ì–´ ìˆ˜ë§Œí¼ ìë™ ì„¤ì •
worker_rlimit_nofile 65535;              # íŒŒì¼ ë””ìŠ¤í¬ë¦½í„° í•œê³„

error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 4096;              # workerë‹¹ ìµœëŒ€ ì—°ê²° ìˆ˜
    use epoll;                           # Linuxì—ì„œ ê°€ì¥ íš¨ìœ¨ì 
    multi_accept on;                     # í•œ ë²ˆì— ì—¬ëŸ¬ ì—°ê²° ìˆ˜ë½
    accept_mutex off;                    # ì—°ê²° ë¶„ì‚°ì„ ìœ„í•´ ë¹„í™œì„±í™”
}

http {
    # ============ ê¸°ë³¸ ì„¤ì • ============
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    # ============ ë¡œê¹… ìµœì í™” ============
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                   '$status $body_bytes_sent "$http_referer" '
                   '"$http_user_agent" $request_time $upstream_response_time';
    
    # ë¡œê·¸ ë²„í¼ë§ìœ¼ë¡œ I/O ìµœì í™”
    access_log /var/log/nginx/access.log main buffer=64k flush=5s;
    
    # ============ ì„±ëŠ¥ ìµœì í™” ============
    sendfile on;                         # ì»¤ë„ì—ì„œ ì§ì ‘ íŒŒì¼ ì „ì†¡
    tcp_nopush on;                       # sendfileê³¼ í•¨ê»˜ ì‚¬ìš©
    tcp_nodelay on;                      # keep-alive ì—°ê²°ì—ì„œ ì§€ì—° ì—†ì• ê¸°
    
    keepalive_timeout 30s;               # Keep-alive ì—°ê²° ìœ ì§€ ì‹œê°„
    keepalive_requests 1000;             # Keep-alive ì—°ê²°ë‹¹ ìµœëŒ€ ìš”ì²­ ìˆ˜
    
    # ============ ì••ì¶• ì„¤ì • ============
    gzip on;
    gzip_vary on;
    gzip_min_length 1000;
    gzip_comp_level 6;
    gzip_types
        application/atom+xml
        application/geo+json
        application/javascript
        application/x-javascript
        application/json
        application/ld+json
        application/manifest+json
        application/rdf+xml
        application/rss+xml
        application/xhtml+xml
        application/xml
        font/eot
        font/otf
        font/ttf
        image/svg+xml
        text/css
        text/javascript
        text/plain
        text/xml;
    
    # ============ ë²„í¼ í¬ê¸° ìµœì í™” ============
    client_body_buffer_size 16k;
    client_header_buffer_size 1k;
    client_max_body_size 8m;
    large_client_header_buffers 4 16k;
    
    # ============ íƒ€ì„ì•„ì›ƒ ì„¤ì • ============
    client_body_timeout 12s;
    client_header_timeout 12s;
    send_timeout 10s;
    
    # ============ ì—…ìŠ¤íŠ¸ë¦¼ ì„œë²„ ì •ì˜ ============
    upstream app_servers {
        # ë¡œë“œ ë°¸ëŸ°ì‹± ë°©ì‹
        least_conn;                      # ìµœì†Œ ì—°ê²° ë°©ì‹
        
        # ë°±ì—”ë“œ ì„œë²„ë“¤
        server 192.168.1.10:8080 max_fails=3 fail_timeout=30s weight=3;
        server 192.168.1.11:8080 max_fails=3 fail_timeout=30s weight=3;
        server 192.168.1.12:8080 max_fails=3 fail_timeout=30s weight=2;
        
        # ì—°ê²° í’€ë§
        keepalive 32;                    # ì—…ìŠ¤íŠ¸ë¦¼ê³¼ì˜ ì—°ê²° ìœ ì§€
        keepalive_requests 100;
        keepalive_timeout 60s;
    }
    
    # ============ ìºì‹± ì„¤ì • ============
    proxy_cache_path /var/cache/nginx/app
                     levels=1:2
                     keys_zone=app_cache:10m
                     max_size=1g
                     inactive=60m
                     use_temp_path=off;
    
    server {
        listen 80 default_server reuseport;
        server_name _;
        
        # ============ ì •ì  íŒŒì¼ ìµœì í™” ============
        location ~* \.(jpg|jpeg|png|gif|ico|css|js)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            add_header Vary Accept-Encoding;
            
            # ì •ì  íŒŒì¼ì€ ì§ì ‘ ì„œë¹™
            root /var/www/html;
        }
        
        # ============ API í”„ë¡ì‹œ ì„¤ì • ============
        location /api/ {
            # í”„ë¡ì‹œ í—¤ë” ì„¤ì •
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # ì—°ê²° ì¬ì‚¬ìš©
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            
            # íƒ€ì„ì•„ì›ƒ ì„¤ì •
            proxy_connect_timeout 5s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            
            # ë²„í¼ ì„¤ì •
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_busy_buffers_size 8k;
            
            # ìºì‹± ì„¤ì • (ì ì ˆí•œ ê²½ìš°ì—ë§Œ)
            proxy_cache app_cache;
            proxy_cache_valid 200 302 10m;
            proxy_cache_valid 404 1m;
            proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
            proxy_cache_background_update on;
            proxy_cache_lock on;
            
            # ì—…ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì „ë‹¬
            proxy_pass http://app_servers;
        }
        
        # ============ í—¬ìŠ¤ ì²´í¬ ============
        location /nginx-health {
            access_log off;
            return 200 "healthy, ";
            add_header Content-Type text/plain;
        }
        
        # ============ ë³´ì•ˆ í—¤ë” ============
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header Referrer-Policy "no-referrer-when-downgrade" always;
        
        # ì„œë²„ ì •ë³´ ìˆ¨ê¸°ê¸°
        server_tokens off;
    }
}
```

## Redis ìºì‹± ìµœì í™”

```python
# redis_optimization.py - Redis ìºì‹± ìµœì í™”
import redis
import time
import json
import hashlib
from typing import Any, Optional, Callable
import functools
import asyncio
import aioredis
import logging

class OptimizedRedisCache:
    def __init__(self, 
                 host='localhost', 
                 port=6379, 
                 db=0,
                 max_connections=50,
                 connection_pool_class=redis.BlockingConnectionPool):
        
        # ì—°ê²° í’€ ìµœì í™”
        self.pool = connection_pool_class(
            host=host,
            port=port,
            db=db,
            max_connections=max_connections,
            retry_on_timeout=True,
            health_check_interval=30,
            socket_keepalive=True,
            socket_keepalive_options={
                1: 1,  # TCP_KEEPIDLE
                2: 3,  # TCP_KEEPINTVL  
                3: 5,  # TCP_KEEPCNT
            }
        )
        
        self.redis_client = redis.Redis(connection_pool=self.pool)
        
        # ìºì‹œ í†µê³„
        self.stats = {
            'hits': 0,
            'misses': 0,
            'errors': 0
        }
        
        logging.info(f"Redis ìºì‹œ ì´ˆê¸°í™”: {host}:{port}")
    
    def _make_key(self, prefix: str, *args, **kwargs) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_parts = [prefix]
        key_parts.extend(str(arg) for arg in args)
        key_parts.extend(f"{k}={v}" for k, v in sorted(kwargs.items()))
        
        key_string = ":".join(key_parts)
        
        # ê¸´ í‚¤ëŠ” í•´ì‹œë¡œ ì¶•ì•½
        if len(key_string) > 200:
            key_hash = hashlib.md5(key_string.encode()).hexdigest()
            return f"{prefix}:hash:{key_hash}"
        
        return key_string
    
    def cache_result(self, 
                    prefix: str, 
                    ttl: int = 3600,
                    serialize_func: Callable = json.dumps,
                    deserialize_func: Callable = json.loads):
        """ê²°ê³¼ ìºì‹± ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                cache_key = self._make_key(prefix, *args, **kwargs)
                
                try:
                    # ìºì‹œì—ì„œ ì¡°íšŒ
                    cached_result = self.redis_client.get(cache_key)
                    
                    if cached_result is not None:
                        self.stats['hits'] += 1
                        logging.debug(f"ìºì‹œ íˆíŠ¸: {cache_key}")
                        return deserialize_func(cached_result)
                    
                    # ìºì‹œ ë¯¸ìŠ¤ - í•¨ìˆ˜ ì‹¤í–‰
                    self.stats['misses'] += 1
                    result = func(*args, **kwargs)
                    
                    # ê²°ê³¼ ìºì‹±
                    serialized_result = serialize_func(result)
                    self.redis_client.setex(cache_key, ttl, serialized_result)
                    
                    logging.debug(f"ìºì‹œ ì €ì¥: {cache_key}")
                    return result
                    
                except Exception as e:
                    self.stats['errors'] += 1
                    logging.error(f"ìºì‹œ ì˜¤ë¥˜: {e}")
                    # ìºì‹œ ì˜¤ë¥˜ ì‹œì—ë„ í•¨ìˆ˜ëŠ” ì •ìƒ ì‹¤í–‰
                    return func(*args, **kwargs)
            
            return wrapper
        return decorator
    
    def bulk_cache_results(self, items: dict, prefix: str, ttl: int = 3600):
        """ëŒ€ëŸ‰ ìºì‹œ ì €ì¥ (íŒŒì´í”„ë¼ì¸ ì‚¬ìš©)"""
        pipeline = self.redis_client.pipeline()
        
        for key, value in items.items():
            cache_key = self._make_key(prefix, key)
            serialized_value = json.dumps(value)
            pipeline.setex(cache_key, ttl, serialized_value)
        
        pipeline.execute()
        logging.info(f"ëŒ€ëŸ‰ ìºì‹œ ì €ì¥: {len(items)}ê°œ ì•„ì´í…œ")
    
    def get_cache_stats(self):
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        total_requests = self.stats['hits'] + self.stats['misses']
        hit_rate = (self.stats['hits'] / total_requests * 100) if total_requests > 0 else 0
        
        return {
            'hit_rate': f"{hit_rate:.2f}%",
            'hits': self.stats['hits'],
            'misses': self.stats['misses'],
            'errors': self.stats['errors'],
            'total_requests': total_requests
        }
    
    def warm_up_cache(self, warm_up_func: Callable):
        """ìºì‹œ ì›œì—…"""
        start_time = time.time()
        warm_up_func()
        duration = time.time() - start_time
        
        logging.info(f"ìºì‹œ ì›œì—… ì™„ë£Œ: {duration:.2f}ì´ˆ")

# ì‚¬ìš© ì˜ˆì œ
cache = OptimizedRedisCache(max_connections=100)

@cache.cache_result("user_profile", ttl=1800)  # 30ë¶„ ìºì‹±
def get_user_profile(user_id: int):
    """ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ (DBì—ì„œ)"""
    # ì‹¤ì œë¡œëŠ” DB ì¡°íšŒ
    time.sleep(0.1)  # DB ì¡°íšŒ ì‹œë®¤ë ˆì´ì…˜
    return {
        'user_id': user_id,
        'name': f'User {user_id}',
        'email': f'user{user_id}@example.com'
    }

@cache.cache_result("expensive_calculation", ttl=7200)  # 2ì‹œê°„ ìºì‹±
def expensive_calculation(n: int):
    """ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ê³„ì‚°"""
    time.sleep(1)  # ê³„ì‚° ì‹œë®¤ë ˆì´ì…˜
    return sum(i * i for i in range(n))

def benchmark_cache_performance():
    """ìºì‹œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    print("=== ìºì‹œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ===")
    
    # ì²« ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œ ë¯¸ìŠ¤)
    start = time.time()
    for i in range(100):
        get_user_profile(i % 10)  # 10ëª…ì˜ ì‚¬ìš©ìë¥¼ ë°˜ë³µ ì¡°íšŒ
    first_run = time.time() - start
    
    # ë‘ ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œ íˆíŠ¸)
    start = time.time()
    for i in range(100):
        get_user_profile(i % 10)
    second_run = time.time() - start
    
    print(f"ì²« ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ ë¯¸ìŠ¤): {first_run:.3f}ì´ˆ")
    print(f"ë‘ ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ íˆíŠ¸): {second_run:.3f}ì´ˆ")
    print(f"ì„±ëŠ¥ í–¥ìƒ: {first_run / second_run:.1f}ë°°")
    
    # ìºì‹œ í†µê³„ ì¶œë ¥
    stats = cache.get_cache_stats()
    print(f"ìºì‹œ í†µê³„: {stats}")

if __name__ == "__main__":
    benchmark_cache_performance()
```

## ì‹œìŠ¤í…œ ì„±ëŠ¥ ì¢…í•© ëª¨ë‹ˆí„°ë§

### í†µí•© ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ

```python
# performance_dashboard.py - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
import psutil
import time
import json
import threading
from datetime import datetime, timedelta
from collections import deque, defaultdict
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from typing import Dict, List, Deque

class SystemPerformanceMonitor:
    def __init__(self, history_size: int = 300):  # 5ë¶„ê°„ ë°ì´í„° (1ì´ˆ ê°„ê²©)
        self.history_size = history_size
        
        # ì„±ëŠ¥ ë°ì´í„° íˆìŠ¤í† ë¦¬
        self.cpu_history: Deque[float] = deque(maxlen=history_size)
        self.memory_history: Deque[float] = deque(maxlen=history_size)
        self.disk_io_history: Deque[Dict] = deque(maxlen=history_size)
        self.network_io_history: Deque[Dict] = deque(maxlen=history_size)
        self.timestamps: Deque[datetime] = deque(maxlen=history_size)
        
        # í”„ë¡œì„¸ìŠ¤ë³„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
        self.process_stats: Dict[str, Dict] = {}
        
        # ì•Œë¦¼ ì„ê³„ê°’
        self.thresholds = {
            'cpu': 80.0,
            'memory': 85.0,
            'disk_io': 90.0,
            'network_io': 80.0
        }
        
        # ëª¨ë‹ˆí„°ë§ ìƒíƒœ
        self.monitoring = False
        self.monitor_thread = None
        
        print("ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª¨ë‹ˆí„° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if not self.monitoring:
            self.monitoring = True
            self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
            self.monitor_thread.start()
            print("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
        print("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def get_current_stats(self) -> Dict:
        """í˜„ì¬ ì‹œìŠ¤í…œ í†µê³„ ë°˜í™˜"""
        if not self.cpu_history:
            return {}
        
        # ìµœê·¼ 1ë¶„ê°„ í‰ê· 
        recent_size = min(60, len(self.cpu_history))
        
        return {
            'timestamp': datetime.now().isoformat(),
            'cpu': {
                'current': self.cpu_history[-1],
                'avg_1min': sum(list(self.cpu_history)[-recent_size:]) / recent_size,
                'cores': psutil.cpu_count()
            },
            'memory': {
                'current': self.memory_history[-1],
                'avg_1min': sum(list(self.memory_history)[-recent_size:]) / recent_size,
                'total_gb': psutil.virtual_memory().total / (1024**3)
            },
            'disk_io': {
                'total_read_mb': sum(io.get('read_bytes', 0) for io in self.disk_io_history) / (1024**2),
                'total_write_mb': sum(io.get('write_bytes', 0) for io in self.disk_io_history) / (1024**2),
            },
            'network_io': {
                'total_sent_mb': sum(io.get('bytes_sent', 0) for io in self.network_io_history) / (1024**2),
                'total_recv_mb': sum(io.get('bytes_recv', 0) for io in self.network_io_history) / (1024**2),
            },
            'top_processes': self.process_stats
        }
    
    def generate_report(self, duration_minutes: int = 5) -> str:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        stats = self.get_current_stats()
        if not stats:
            return "ë°ì´í„° ì—†ìŒ"
        
        report = f"""
=== ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ({duration_minutes}ë¶„ê°„) ===
ìƒì„± ì‹œê°„: {stats['timestamp']}

ğŸ–¥ï¸  CPU:
   í˜„ì¬: {stats['cpu']['current']:.1f}%
   í‰ê· : {stats['cpu']['avg_1min']:.1f}%
   ì½”ì–´: {stats['cpu']['cores']}ê°œ

ğŸ§  ë©”ëª¨ë¦¬:
   í˜„ì¬: {stats['memory']['current']:.1f}%
   í‰ê· : {stats['memory']['avg_1min']:.1f}%
   ì´ëŸ‰: {stats['memory']['total_gb']:.1f}GB

ğŸ’¾ ë””ìŠ¤í¬ I/O:
   ì½ê¸°: {stats['disk_io']['total_read_mb']:.1f}MB
   ì“°ê¸°: {stats['disk_io']['total_write_mb']:.1f}MB

ğŸŒ ë„¤íŠ¸ì›Œí¬ I/O:
   ì†¡ì‹ : {stats['network_io']['total_sent_mb']:.1f}MB
   ìˆ˜ì‹ : {stats['network_io']['total_recv_mb']:.1f}MB

ğŸ”¥ ë¦¬ì†ŒìŠ¤ ì§‘ì•½ì  í”„ë¡œì„¸ìŠ¤:
"""
        
        for process_name, proc_stats in list(stats['top_processes'].items())[:5]:
            report += f"   {process_name}: CPU {proc_stats['cpu_percent']:.1f}%, MEM {proc_stats['memory_percent']:.1f}%, "
        
        return report

def main():
    # ì„±ëŠ¥ ëª¨ë‹ˆí„° ìƒì„± ë° ì‹œì‘
    monitor = SystemPerformanceMonitor()
    monitor.start_monitoring()
    
    try:
        # 5ë¶„ê°„ ëª¨ë‹ˆí„°ë§
        print("5ë¶„ê°„ ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤...")
        time.sleep(300)  # 5ë¶„
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        print(monitor.generate_report())
        
    except KeyboardInterrupt:
        print(", ëª¨ë‹ˆí„°ë§ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
    
    finally:
        monitor.stop_monitoring()

if __name__ == "__main__":
    main()
```

## í•µì‹¬ ìš”ì 

### 1. ë¡œë“œ ë°¸ëŸ°ì‹± ì „ëµ ìµœì í™”

ì—…ìŠ¤íŠ¸ë¦¼ ì„œë²„ ê°„ íŠ¸ë˜í”½ ë¶„ì‚°, í—¬ìŠ¤ ì²´í¬, ì—°ê²° í’€ë§ì„ í†µí•œ ì „ì²´ì ì¸ ì‹œìŠ¤í…œ ì•ˆì •ì„± í–¥ìƒ

### 2. ë‹¤ì¸µ ìºì‹± ì•„í‚¤í…ì²˜

Nginx í”„ë¡ì‹œ ìºì‹œ, Redis ë°ì´í„° ìºì‹œ, ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ìºì‹œë¥¼ ì¡°í•©í•œ ì¢…í•©ì  ì„±ëŠ¥ ìµœì í™”

### 3. ì‹¤ì‹œê°„ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ

ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ , ìºì‹œ íˆíŠ¸ìœ¨, ë¡œë“œ ë°¸ëŸ°ì‹± ìƒíƒœë¥¼ í†µí•© ëª¨ë‹ˆí„°ë§í•˜ì—¬ ì „ì²´ì ì¸ ì‹œìŠ¤í…œ ìƒíƒœ íŒŒì•…

---

**ì´ì „**: [11-38-application-optimization.md](11-38-application-optimization.md)  
**ë‹¤ìŒ**: ë‹¤ìŒ ë‹¨ê³„ëŠ” ì „ì²´ ì‹œìŠ¤í…œ íŠœë‹ ê°€ì´ë“œì˜ [11-36-system-tuning.md](11-36-system-tuning.md)ì—ì„œ ì¢…í•©ì ì¸ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

### ğŸ“– í˜„ì¬ ë¬¸ì„œ ì •ë³´

- **ë‚œì´ë„**: INTERMEDIATE
- **ì£¼ì œ**: ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜
- **ì˜ˆìƒ ì‹œê°„**: 6-8ì‹œê°„

### ğŸ¯ í•™ìŠµ ê²½ë¡œ

- [ğŸ“š INTERMEDIATE ë ˆë²¨ ì „ì²´ ë³´ê¸°](../learning-paths/intermediate/)
- [ğŸ  ë©”ì¸ í•™ìŠµ ê²½ë¡œ](../learning-paths/)
- [ğŸ“‹ ì „ì²´ ê°€ì´ë“œ ëª©ë¡](../README.md)

### ğŸ“‚ ê°™ì€ ì±•í„° (chapter-11-performance-optimization)

- [Chapter 11-1: ì„±ëŠ¥ ë¶„ì„ ë°©ë²•ë¡ ](./11-30-performance-methodology.md)
- [11.2 CPU ì„±ëŠ¥ ìµœì í™”](./11-31-cpu-optimization.md)
- [11.3 ë©”ëª¨ë¦¬ ì„±ëŠ¥ ìµœì í™”](./11-32-memory-optimization.md)
- [11.3a ë©”ëª¨ë¦¬ ê³„ì¸µêµ¬ì¡°ì™€ ìºì‹œ ìµœì í™”](./11-10-memory-hierarchy-cache.md)
- [11.3b ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”](./11-11-memory-allocation.md)

### ğŸ·ï¸ ê´€ë ¨ í‚¤ì›Œë“œ

`load_balancing`, `nginx_optimization`, `redis_caching`, `performance_monitoring`, `system_tuning`

### â­ï¸ ë‹¤ìŒ ë‹¨ê³„ ê°€ì´ë“œ

- ì‹¤ë¬´ ì ìš©ì„ ì—¼ë‘ì— ë‘ê³  í”„ë¡œì íŠ¸ì— ì ìš©í•´ë³´ì„¸ìš”
- ê´€ë ¨ ë„êµ¬ë“¤ì„ ì§ì ‘ ì‚¬ìš©í•´ë³´ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤
