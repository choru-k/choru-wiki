---
tags:
  - Debugging
  - Observability
  - Monitoring
  - Tracing
---

# Chapter 12: 관찰가능성과 디버깅

## 이 문서를 읽으면 이런 질문에 대해서 대답할 수 있습니다

1. **관찰가능성(Observability)의 3가지 축은 무엇인가요?**
   - Metrics, Logs, Traces의 역할
   - 각 축의 상호 보완 관계
   - 통합 관찰가능성 플랫폼

2. **분산 트레이싱은 어떻게 동작하나요?**
   - Span과 Trace의 개념
   - Context propagation
   - OpenTelemetry 표준

3. **효과적인 디버깅 전략은 무엇인가요?**
   - 체계적인 문제 해결 접근법
   - 디버거 활용 기법
   - 프로덕션 디버깅

4. **eBPF로 무엇을 할 수 있나요?**
   - 커널 레벨 관찰
   - 성능 분석과 보안
   - 런타임 프로그래밍

5. **카오스 엔지니어링은 왜 필요한가요?**
   - 시스템 회복력 테스트
   - 장애 주입 기법
   - 관찰가능성과의 연계

## 1. 관찰가능성의 기초

### 1.1 Three Pillars of Observability

```mermaid
graph TB
    subgraph "Observability"
        M[Metrics<br/>What?]
        L[Logs<br/>Why?]
        T[Traces<br/>Where?]
    end
    
    subgraph "Use Cases"
        M --> M1[Performance]
        M --> M2[Capacity]
        M --> M3[Alerts]
        
        L --> L1[Errors]
        L --> L2[Audit]
        L --> L3[Debug]
        
        T --> T1[Latency]
        T --> T2[Dependencies]
        T --> T3[Flow]
    end
    
    M -.-> L
    L -.-> T
    T -.-> M
    
    style M fill:#9f9,stroke:#333,stroke-width:2px
    style L fill:#99f,stroke:#333,stroke-width:2px
    style T fill:#f99,stroke:#333,stroke-width:2px
```

### 1.2 메트릭 수집과 모니터링

```go
// Prometheus 메트릭 구현
package main

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    // Counter: 단조 증가
    requestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )
    
    // Gauge: 증감 가능
    activeConnections = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "active_connections",
            Help: "Number of active connections",
        },
    )
    
    // Histogram: 분포
    requestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "http_request_duration_seconds",
            Help: "HTTP request latency",
            Buckets: prometheus.DefBuckets,
        },
        []string{"method", "endpoint"},
    )
    
    // Summary: 백분위수
    requestSize = promauto.NewSummaryVec(
        prometheus.SummaryOpts{
            Name: "http_request_size_bytes",
            Help: "HTTP request size",
            Objectives: map[float64]float64{
                0.5:  0.05,  // 50th percentile
                0.9:  0.01,  // 90th percentile
                0.99: 0.001, // 99th percentile
            },
        },
        []string{"method"},
    )
)

// 미들웨어로 메트릭 수집
func MetricsMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        timer := prometheus.NewTimer(
            requestDuration.WithLabelValues(r.Method, r.URL.Path),
        )
        defer timer.ObserveDuration()
        
        wrapped := &responseWriter{ResponseWriter: w}
        
        activeConnections.Inc()
        defer activeConnections.Dec()
        
        next.ServeHTTP(wrapped, r)
        
        requestsTotal.WithLabelValues(
            r.Method, 
            r.URL.Path, 
            strconv.Itoa(wrapped.statusCode),
        ).Inc()
        
        requestSize.WithLabelValues(r.Method).Observe(
            float64(r.ContentLength),
        )
    })
}
```

### 1.3 구조화된 로깅

```go
// 구조화된 로그 with context
package main

import (
    "go.uber.org/zap"
    "go.uber.org/zap/zapcore"
)

type Logger struct {
    *zap.Logger
}

func NewLogger() *Logger {
    config := zap.NewProductionConfig()
    config.EncoderConfig.TimeKey = "timestamp"
    config.EncoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder
    
    // 샘플링 설정 (초당 100개, 이후 10개)
    config.Sampling = &zap.SamplingConfig{
        Initial:    100,
        Thereafter: 10,
    }
    
    logger, _ := config.Build(
        zap.AddCaller(),
        zap.AddStacktrace(zapcore.ErrorLevel),
    )
    
    return &Logger{logger}
}

// 컨텍스트 포함 로깅
func (l *Logger) LogRequest(ctx context.Context, 
                           method, path string, 
                           duration time.Duration, 
                           err error) {
    
    // 트레이스 ID 추출
    span := trace.SpanFromContext(ctx)
    traceID := span.SpanContext().TraceID().String()
    
    fields := []zap.Field{
        zap.String("trace_id", traceID),
        zap.String("method", method),
        zap.String("path", path),
        zap.Duration("duration", duration),
        zap.String("user_id", getUserID(ctx)),
    }
    
    if err != nil {
        l.Error("request failed", 
            append(fields, zap.Error(err))...)
    } else {
        l.Info("request completed", fields...)
    }
}

// 로그 집계 및 분석
type LogAggregator struct {
    errorCounts   map[string]int
    slowRequests  []RequestLog
    mu            sync.RWMutex
}

func (la *LogAggregator) Analyze(logs []LogEntry) {
    for _, log := range logs {
        // 에러 패턴 분석
        if log.Level == "ERROR" {
            la.mu.Lock()
            la.errorCounts[log.Error]++
            la.mu.Unlock()
        }
        
        // 느린 요청 추적
        if log.Duration > 1*time.Second {
            la.mu.Lock()
            la.slowRequests = append(la.slowRequests, log)
            la.mu.Unlock()
        }
    }
}
```

## 2. 분산 트레이싱

### 2.1 OpenTelemetry 구현

```go
// OpenTelemetry 설정
package main

import (
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/exporters/jaeger"
    "go.opentelemetry.io/otel/propagation"
    "go.opentelemetry.io/otel/sdk/trace"
)

func InitTracer() func() {
    // Jaeger exporter 생성
    exp, err := jaeger.New(
        jaeger.WithCollectorEndpoint(
            jaeger.WithEndpoint("http://localhost:14268/api/traces"),
        ),
    )
    
    // Trace provider 설정
    tp := trace.NewTracerProvider(
        trace.WithBatcher(exp),
        trace.WithResource(resource.NewWithAttributes(
            semconv.SchemaURL,
            semconv.ServiceNameKey.String("my-service"),
            semconv.ServiceVersionKey.String("1.0.0"),
        )),
        trace.WithSampler(trace.AlwaysSample()),
    )
    
    otel.SetTracerProvider(tp)
    otel.SetTextMapPropagator(
        propagation.NewCompositeTextMapPropagator(
            propagation.TraceContext{},
            propagation.Baggage{},
        ),
    )
    
    return func() {
        tp.Shutdown(context.Background())
    }
}

// 분산 트레이싱 미들웨어
func TracingMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // 컨텍스트에서 span 추출 또는 생성
        ctx := otel.GetTextMapPropagator().Extract(
            r.Context(),
            propagation.HeaderCarrier(r.Header),
        )
        
        tracer := otel.Tracer("http-server")
        ctx, span := tracer.Start(ctx, r.URL.Path)
        defer span.End()
        
        // Span 속성 추가
        span.SetAttributes(
            attribute.String("http.method", r.Method),
            attribute.String("http.url", r.URL.String()),
            attribute.String("http.user_agent", r.UserAgent()),
            attribute.String("user.id", getUserID(r)),
        )
        
        // 다음 핸들러 실행
        wrapped := &statusRecorder{ResponseWriter: w}
        next.ServeHTTP(wrapped, r.WithContext(ctx))
        
        // 응답 정보 기록
        span.SetAttributes(
            attribute.Int("http.status_code", wrapped.status),
        )
        
        if wrapped.status >= 400 {
            span.SetStatus(codes.Error, "HTTP error")
        }
    })
}

// 데이터베이스 트레이싱
func (db *DB) QueryWithTracing(ctx context.Context, query string, args ...interface{}) (*sql.Rows, error) {
    _, span := otel.Tracer("database").Start(ctx, "db.query")
    defer span.End()
    
    span.SetAttributes(
        attribute.String("db.statement", query),
        attribute.String("db.system", "postgresql"),
    )
    
    start := time.Now()
    rows, err := db.QueryContext(ctx, query, args...)
    
    span.SetAttributes(
        attribute.Int64("db.rows_affected", rowsAffected),
        attribute.Float64("db.duration", time.Since(start).Seconds()),
    )
    
    if err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, err.Error())
    }
    
    return rows, err
}
```

### 2.2 Context Propagation

```python
# Python에서의 분산 트레이싱
from opentelemetry import trace, propagate
from opentelemetry.trace import Status, StatusCode

tracer = trace.get_tracer(__name__)

class DistributedService:
    async def handle_request(self, request):
        # 부모 span 추출
        ctx = propagate.extract(request.headers)
        
        with tracer.start_as_current_span(
            "handle_request", 
            context=ctx,
            kind=trace.SpanKind.SERVER
        ) as span:
            
            # Baggage 전파
            baggage = propagate.get_current()
            user_id = baggage.get("user_id")
            
            span.set_attribute("user.id", user_id)
            
            try:
                # 다른 서비스 호출
                result = await self.call_downstream_service()
                
                span.set_attribute("result.size", len(result))
                return result
                
            except Exception as e:
                span.record_exception(e)
                span.set_status(Status(StatusCode.ERROR))
                raise
    
    async def call_downstream_service(self):
        with tracer.start_as_current_span(
            "downstream_call",
            kind=trace.SpanKind.CLIENT
        ) as span:
            
            # 헤더에 trace context 주입
            headers = {}
            propagate.inject(headers)
            
            response = await http_client.get(
                "http://downstream-service",
                headers=headers
            )
            
            span.set_attribute("http.status_code", response.status)
            
            return response.json()
```

## 3. 시스템 디버깅

### 3.1 GDB 고급 기법

```bash
# GDB 스크립트
cat > debug.gdb << 'EOF'
# 브레이크포인트 설정
break main
break *0x400540 if $rdi > 100

# 조건부 브레이크포인트
break process_request if request->type == REQUEST_TYPE_CRITICAL

# 워치포인트 (메모리 변경 감지)
watch *(int*)0x7fffffffe000
rwatch global_counter  # 읽기 감지
awatch buffer[10]      # 읽기/쓰기 감지

# 캐치포인트
catch syscall open
catch signal SIGSEGV

# 스택 프레임 분석
define analyze_stack
    info frame
    info locals
    info args
    x/10x $rsp
end

# 메모리 덤프
define dump_memory
    dump binary memory dump.bin 0x400000 0x401000
    x/100x 0x400000
end

# 자동 실행
define hook-stop
    where
    info registers
    disassemble $pc,+10
end

# Python 스크립트
python
import gdb

class MemoryLeakDetector(gdb.Command):
    def __init__(self):
        super().__init__("detect-leaks", gdb.COMMAND_USER)
        self.allocations = {}
    
    def invoke(self, arg, from_tty):
        # malloc 후킹
        gdb.execute("break malloc")
        gdb.execute("commands")
        gdb.execute("python track_allocation()")
        gdb.execute("continue")
        gdb.execute("end")

def track_allocation():
    # 할당 추적
    size = gdb.parse_and_eval("$rdi")
    ret_addr = gdb.parse_and_eval("$rsp")
    print(f"Allocation: {size} bytes at {ret_addr}")

MemoryLeakDetector()
end

EOF

# GDB 실행
gdb -x debug.gdb ./program
```

### 3.2 strace와 시스템 콜 분석

```bash
# strace 고급 사용법

# 특정 시스템 콜만 추적
strace -e trace=open,read,write ./program

# 네트워크 관련 시스템 콜
strace -e trace=network ./server

# 파일 관련 시스템 콜
strace -e trace=file ./program

# 통계 모드
strace -c ./program

# 시간 정보 포함
strace -T -tt ./program  # -T: 시스템 콜 소요 시간, -tt: 마이크로초 타임스탬프

# 자식 프로세스 추적
strace -f ./program

# 출력을 파일로 저장
strace -o trace.log ./program

# 실패한 시스템 콜만 표시
strace -Z ./program

# 시스템 콜 필터링과 분석
strace -e trace=open -o - ./program 2>&1 | grep -v ENOENT
```

```c
// ptrace를 사용한 커스텀 트레이서
#include <sys/ptrace.h>
#include <sys/wait.h>
#include <sys/user.h>

void trace_syscalls(pid_t child) {
    int status;
    struct user_regs_struct regs;
    
    waitpid(child, &status, 0);
    ptrace(PTRACE_SETOPTIONS, child, 0, PTRACE_O_TRACESYSGOOD);
    
    while (1) {
        // 시스템 콜 진입 대기
        ptrace(PTRACE_SYSCALL, child, 0, 0);
        waitpid(child, &status, 0);
        
        if (WIFEXITED(status)) break;
        
        // 레지스터 읽기
        ptrace(PTRACE_GETREGS, child, 0, &regs);
        
        // 시스템 콜 번호와 인자
        printf("Syscall: %lld(%lld, %lld, %lld)\n",
               regs.orig_rax, regs.rdi, regs.rsi, regs.rdx);
        
        // 시스템 콜 완료 대기
        ptrace(PTRACE_SYSCALL, child, 0, 0);
        waitpid(child, &status, 0);
        
        // 반환 값
        ptrace(PTRACE_GETREGS, child, 0, &regs);
        printf("  = %lld\n", regs.rax);
    }
}
```

## 4. eBPF 프로그래밍

### 4.1 eBPF 기초

```c
// eBPF 프로그램 (커널 공간)
#include <linux/bpf.h>
#include <linux/ptrace.h>

// Map 정의 (커널-유저 통신)
struct {
    __uint(type, BPF_MAP_TYPE_HASH);
    __uint(max_entries, 10240);
    __type(key, u32);
    __type(value, u64);
} syscall_count SEC(".maps");

// 시스템 콜 추적
SEC("tracepoint/raw_syscalls/sys_enter")
int trace_sys_enter(struct trace_event_raw_sys_enter* ctx) {
    u32 pid = bpf_get_current_pid_tgid() >> 32;
    u64 *count, init_val = 1;
    
    // 시스템 콜 카운트 증가
    count = bpf_map_lookup_elem(&syscall_count, &pid);
    if (count) {
        (*count)++;
    } else {
        bpf_map_update_elem(&syscall_count, &pid, &init_val, BPF_ANY);
    }
    
    return 0;
}

// TCP 연결 추적
struct {
    __uint(type, BPF_MAP_TYPE_HASH);
    __uint(max_entries, 10240);
    __type(key, struct sock*);
    __type(value, u64);
} tcp_connections SEC(".maps");

SEC("kprobe/tcp_v4_connect")
int trace_tcp_connect(struct pt_regs* ctx) {
    struct sock* sk = (struct sock*)PT_REGS_PARM1(ctx);
    u64 ts = bpf_ktime_get_ns();
    
    bpf_map_update_elem(&tcp_connections, &sk, &ts, BPF_ANY);
    
    // 연결 정보 출력
    struct inet_sock* inet = inet_sk(sk);
    u32 saddr = inet->inet_saddr;
    u32 daddr = inet->inet_daddr;
    u16 sport = inet->inet_sport;
    u16 dport = inet->inet_dport;
    
    bpf_printk("TCP connect: %pI4:%d -> %pI4:%d\n",
               &saddr, sport, &daddr, dport);
    
    return 0;
}
```

### 4.2 eBPF 유저 공간 프로그램

```python
# Python BCC를 사용한 eBPF
from bcc import BPF
import time

# eBPF 프로그램
bpf_text = """
#include <uapi/linux/ptrace.h>
#include <linux/sched.h>

// 레이턴시 히스토그램
BPF_HISTOGRAM(latency_hist, u64);

// 함수 진입 시간 저장
BPF_HASH(start_times, u32, u64);

int trace_function_entry(struct pt_regs *ctx) {
    u32 pid = bpf_get_current_pid_tgid();
    u64 ts = bpf_ktime_get_ns();
    
    start_times.update(&pid, &ts);
    return 0;
}

int trace_function_exit(struct pt_regs *ctx) {
    u32 pid = bpf_get_current_pid_tgid();
    u64 *start_ts = start_times.lookup(&pid);
    
    if (start_ts) {
        u64 delta = bpf_ktime_get_ns() - *start_ts;
        latency_hist.increment(bpf_log2l(delta));
        start_times.delete(&pid);
    }
    
    return 0;
}
"""

# BPF 프로그램 로드
b = BPF(text=bpf_text)

# 함수 추적 연결
b.attach_uprobe(name="./myapp", sym="process_request", 
                fn_name="trace_function_entry")
b.attach_uretprobe(name="./myapp", sym="process_request",
                   fn_name="trace_function_exit")

# 결과 출력
while True:
    time.sleep(1)
    print("Latency histogram:")
    b["latency_hist"].print_log2_hist("usecs")
    b["latency_hist"].clear()
```

### 4.3 XDP (eXpress Data Path)

```c
// XDP를 사용한 패킷 필터링
#include <linux/bpf.h>
#include <linux/if_ether.h>
#include <linux/ip.h>
#include <linux/tcp.h>

// 차단할 IP 목록
struct {
    __uint(type, BPF_MAP_TYPE_HASH);
    __uint(max_entries, 10000);
    __type(key, __u32);
    __type(value, __u8);
} blocked_ips SEC(".maps");

SEC("xdp")
int xdp_filter(struct xdp_md* ctx) {
    void* data = (void*)(long)ctx->data;
    void* data_end = (void*)(long)ctx->data_end;
    
    // Ethernet 헤더 파싱
    struct ethhdr* eth = data;
    if ((void*)eth + sizeof(*eth) > data_end)
        return XDP_PASS;
    
    // IP 헤더 파싱
    struct iphdr* ip = data + sizeof(*eth);
    if ((void*)ip + sizeof(*ip) > data_end)
        return XDP_PASS;
    
    // 차단 IP 확인
    __u8* blocked = bpf_map_lookup_elem(&blocked_ips, &ip->saddr);
    if (blocked) {
        return XDP_DROP;  // 패킷 드롭
    }
    
    // TCP SYN flood 방어
    if (ip->protocol == IPPROTO_TCP) {
        struct tcphdr* tcp = (void*)ip + sizeof(*ip);
        if ((void*)tcp + sizeof(*tcp) > data_end)
            return XDP_PASS;
        
        // SYN 패킷 rate limiting
        if (tcp->syn && !tcp->ack) {
            // Rate limiting 로직
            static __u64 last_syn = 0;
            __u64 now = bpf_ktime_get_ns();
            
            if (now - last_syn < 1000000) {  // 1ms 이내
                return XDP_DROP;
            }
            last_syn = now;
        }
    }
    
    return XDP_PASS;
}
```

## 5. 프로덕션 디버깅

### 5.1 Core Dump 분석

```bash
# Core dump 설정
ulimit -c unlimited
echo "/tmp/core-%e-%p-%t" > /proc/sys/kernel/core_pattern

# systemd-coredump 설정
cat > /etc/systemd/coredump.conf << EOF
[Coredump]
Storage=external
Compress=yes
ProcessSizeMax=2G
ExternalSizeMax=2G
JournalSizeMax=767M
MaxUse=1G
KeepFree=1G
EOF

# Core dump 분석
gdb ./program core.12345

# GDB 명령어
(gdb) bt full           # 전체 백트레이스
(gdb) info threads      # 모든 스레드 정보
(gdb) thread apply all bt  # 모든 스레드 백트레이스
(gdb) info registers    # 레지스터 상태
(gdb) x/100x $rsp      # 스택 메모리 덤프
(gdb) info sharedlibrary  # 로드된 라이브러리
```

```c
// 프로그램에서 core dump 생성
#include <signal.h>
#include <execinfo.h>

void crash_handler(int sig) {
    void* array[100];
    size_t size;
    
    // 백트레이스 획득
    size = backtrace(array, 100);
    
    // 백트레이스 출력
    fprintf(stderr, "Error: signal %d:\n", sig);
    backtrace_symbols_fd(array, size, STDERR_FILENO);
    
    // Core dump 생성
    signal(sig, SIG_DFL);
    kill(getpid(), sig);
}

void setup_crash_handler() {
    signal(SIGSEGV, crash_handler);
    signal(SIGABRT, crash_handler);
    signal(SIGFPE, crash_handler);
    signal(SIGILL, crash_handler);
}
```

### 5.2 Live Debugging

```python
# Python 원격 디버깅
import debugpy

# 프로덕션에서 디버거 활성화
if os.getenv("ENABLE_DEBUGGER"):
    debugpy.listen(("0.0.0.0", 5678))
    print("Debugger listening on port 5678")
    # debugpy.wait_for_client()  # 옵션: 클라이언트 대기

# 조건부 브레이크포인트
def process_request(request):
    if request.user_id == "debug_user":
        debugpy.breakpoint()  # 특정 조건에서만 중단
    
    # 처리 로직
    return handle(request)

# 런타임 프로파일링
import cProfile
import pstats
from io import StringIO

def profile_endpoint(func):
    def wrapper(*args, **kwargs):
        if os.getenv("ENABLE_PROFILING"):
            profiler = cProfile.Profile()
            profiler.enable()
            
            result = func(*args, **kwargs)
            
            profiler.disable()
            s = StringIO()
            ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')
            ps.print_stats(20)
            
            # 프로파일 결과 로깅
            logger.info(f"Profile for {func.__name__}:\n{s.getvalue()}")
            
            return result
        return func(*args, **kwargs)
    return wrapper
```

## 6. 성능 프로파일링

### 6.1 Continuous Profiling

```go
// Go pprof 연속 프로파일링
package main

import (
    "net/http"
    _ "net/http/pprof"
    "runtime"
    "time"
)

func EnableProfiling() {
    // pprof 엔드포인트 활성화
    go func() {
        runtime.SetBlockProfileRate(1)
        runtime.SetMutexProfileFraction(1)
        
        http.ListenAndServe("localhost:6060", nil)
    }()
    
    // 주기적 프로파일 수집
    go collectProfiles()
}

func collectProfiles() {
    ticker := time.NewTicker(1 * time.Minute)
    
    for range ticker.C {
        // CPU 프로파일
        f, _ := os.Create(fmt.Sprintf("cpu-%d.prof", time.Now().Unix()))
        pprof.StartCPUProfile(f)
        time.Sleep(30 * time.Second)
        pprof.StopCPUProfile()
        f.Close()
        
        // 메모리 프로파일
        f, _ = os.Create(fmt.Sprintf("mem-%d.prof", time.Now().Unix()))
        pprof.WriteHeapProfile(f)
        f.Close()
        
        // 고루틴 프로파일
        f, _ = os.Create(fmt.Sprintf("goroutine-%d.prof", time.Now().Unix()))
        pprof.Lookup("goroutine").WriteTo(f, 0)
        f.Close()
    }
}

// 프로파일 분석
// go tool pprof -http=:8080 cpu-*.prof
// go tool pprof -diff_base=baseline.prof current.prof
```

### 6.2 Flame Graphs

```bash
# Flame graph 생성 스크립트
#!/bin/bash

# perf로 데이터 수집
sudo perf record -F 99 -ag -- sleep 60
sudo perf script > out.perf

# Flame graph 생성
git clone https://github.com/brendangregg/FlameGraph
./FlameGraph/stackcollapse-perf.pl out.perf > out.folded
./FlameGraph/flamegraph.pl out.folded > flamegraph.svg

# 차이 분석 (Differential Flame Graph)
./FlameGraph/difffolded.pl baseline.folded current.folded | \
    ./FlameGraph/flamegraph.pl > diff.svg
```

## 7. 카오스 엔지니어링

### 7.1 장애 주입

```go
// 카오스 엔지니어링 라이브러리
package chaos

import (
    "math/rand"
    "time"
    "context"
)

type ChaosMonkey struct {
    Enabled bool
    Config  ChaosConfig
}

type ChaosConfig struct {
    LatencyProbability float64
    LatencyMs          int
    ErrorProbability   float64
    PanicProbability   float64
}

// 네트워크 지연 주입
func (c *ChaosMonkey) InjectLatency() {
    if !c.Enabled {
        return
    }
    
    if rand.Float64() < c.Config.LatencyProbability {
        time.Sleep(time.Duration(c.Config.LatencyMs) * time.Millisecond)
    }
}

// 에러 주입
func (c *ChaosMonkey) InjectError() error {
    if !c.Enabled {
        return nil
    }
    
    if rand.Float64() < c.Config.ErrorProbability {
        return fmt.Errorf("chaos: injected error")
    }
    
    return nil
}

// 패닉 주입
func (c *ChaosMonkey) InjectPanic() {
    if !c.Enabled {
        return
    }
    
    if rand.Float64() < c.Config.PanicProbability {
        panic("chaos: injected panic")
    }
}

// 미들웨어로 적용
func ChaosMiddleware(chaos *ChaosMonkey) func(http.Handler) http.Handler {
    return func(next http.Handler) http.Handler {
        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            // 지연 주입
            chaos.InjectLatency()
            
            // 에러 주입
            if err := chaos.InjectError(); err != nil {
                http.Error(w, err.Error(), http.StatusInternalServerError)
                return
            }
            
            // 패닉 주입 (recover 필요)
            defer func() {
                if r := recover(); r != nil {
                    http.Error(w, "Internal Server Error", 500)
                }
            }()
            chaos.InjectPanic()
            
            next.ServeHTTP(w, r)
        })
    }
}
```

### 7.2 Litmus 실험

```yaml
# Kubernetes Litmus ChaosEngine
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: nginx-chaos
spec:
  appinfo:
    appns: default
    applabel: app=nginx
  chaosServiceAccount: pod-delete-sa
  experiments:
  - name: pod-delete
    spec:
      components:
        env:
        - name: TOTAL_CHAOS_DURATION
          value: '30'
        - name: CHAOS_INTERVAL
          value: '10'
        - name: FORCE
          value: 'false'
  
  - name: pod-network-latency
    spec:
      components:
        env:
        - name: NETWORK_INTERFACE
          value: 'eth0'
        - name: NETWORK_LATENCY
          value: '2000'  # 2초 지연
        - name: TOTAL_CHAOS_DURATION
          value: '60'
  
  - name: pod-cpu-hog
    spec:
      components:
        env:
        - name: CPU_CORES
          value: '1'
        - name: TOTAL_CHAOS_DURATION
          value: '60'
```

## 8. 로그 집계와 분석

### 8.1 ELK Stack 구성

```yaml
# Filebeat 설정
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/app/*.log
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after
  
  processors:
  - add_host_metadata:
      when.not.contains:
        tags: forwarded
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~
  
  fields:
    env: production
    service: api

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "app-logs-%{+yyyy.MM.dd}"

# Logstash 파이프라인
input {
  beats {
    port => 5044
  }
}

filter {
  grok {
    match => {
      "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:logger} - %{GREEDYDATA:msg}"
    }
  }
  
  date {
    match => ["timestamp", "ISO8601"]
  }
  
  if [level] == "ERROR" {
    mutate {
      add_tag => ["error", "alert"]
    }
  }
  
  # 트레이스 ID 추출
  grok {
    match => {
      "msg" => "trace_id=%{DATA:trace_id}"
    }
    tag_on_failure => []
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{[@metadata][beat]}-%{+YYYY.MM.dd}"
  }
  
  # 에러 알림
  if "error" in [tags] {
    email {
      to => "ops@example.com"
      subject => "Error Alert: %{[host][name]}"
      body => "%{message}"
    }
  }
}
```

## 9. 합성 모니터링

### 9.1 Synthetic Monitoring

```javascript
// Puppeteer를 사용한 합성 모니터링
const puppeteer = require('puppeteer');
const { performance } = require('perf_hooks');

class SyntheticMonitor {
    async runTest(url) {
        const browser = await puppeteer.launch({
            headless: true,
            args: ['--no-sandbox']
        });
        
        const page = await browser.newPage();
        const metrics = {};
        
        // 성능 측정 시작
        const startTime = performance.now();
        
        // 네트워크 추적
        await page.setCacheEnabled(false);
        await page.setRequestInterception(true);
        
        const requests = [];
        page.on('request', request => {
            requests.push({
                url: request.url(),
                method: request.method(),
                timestamp: performance.now()
            });
            request.continue();
        });
        
        // 페이지 로드
        await page.goto(url, { waitUntil: 'networkidle2' });
        
        // Core Web Vitals 측정
        const vitals = await page.evaluate(() => {
            return {
                FCP: performance.getEntriesByName('first-contentful-paint')[0]?.startTime,
                LCP: new Promise(resolve => {
                    new PerformanceObserver((list) => {
                        const entries = list.getEntries();
                        resolve(entries[entries.length - 1].startTime);
                    }).observe({ type: 'largest-contentful-paint', buffered: true });
                }),
                CLS: new Promise(resolve => {
                    let cls = 0;
                    new PerformanceObserver((list) => {
                        for (const entry of list.getEntries()) {
                            if (!entry.hadRecentInput) {
                                cls += entry.value;
                            }
                        }
                        resolve(cls);
                    }).observe({ type: 'layout-shift', buffered: true });
                }),
                FID: performance.getEntriesByType('first-input')[0]?.processingStart
            };
        });
        
        metrics.loadTime = performance.now() - startTime;
        metrics.requests = requests.length;
        metrics.vitals = vitals;
        
        // 스크린샷
        await page.screenshot({ path: 'monitoring.png' });
        
        await browser.close();
        
        return metrics;
    }
    
    async continuousMonitor(url, interval = 60000) {
        setInterval(async () => {
            try {
                const metrics = await this.runTest(url);
                
                // 메트릭 전송
                await this.sendMetrics(metrics);
                
                // 임계값 확인
                if (metrics.loadTime > 3000) {
                    await this.sendAlert('Page load time exceeded 3s', metrics);
                }
                
            } catch (error) {
                await this.sendAlert('Synthetic test failed', error);
            }
        }, interval);
    }
}
```

## 10. 통합 관찰가능성

### 10.1 OpenTelemetry Collector

```yaml
# OpenTelemetry Collector 설정
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
  
  prometheus:
    config:
      scrape_configs:
      - job_name: 'app-metrics'
        static_configs:
        - targets: ['app:8080']
  
  filelog:
    include: [/var/log/**/*.log]
    operators:
    - type: json_parser
    - type: trace_parser
      trace_id:
        parse_from: attributes.trace_id

processors:
  batch:
    timeout: 10s
    send_batch_size: 1024
  
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
  
  attributes:
    actions:
    - key: environment
      value: production
      action: insert
    - key: service.name
      from_attribute: service
      action: insert
  
  tail_sampling:
    policies:
    - name: errors-policy
      type: status_code
      status_code: {status_codes: [ERROR]}
    - name: slow-traces
      type: latency
      latency: {threshold_ms: 1000}

exporters:
  jaeger:
    endpoint: jaeger:14250
    tls:
      insecure: true
  
  prometheus:
    endpoint: 0.0.0.0:8889
  
  loki:
    endpoint: http://loki:3100/loki/api/v1/push

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch, tail_sampling]
      exporters: [jaeger]
    
    metrics:
      receivers: [otlp, prometheus]
      processors: [memory_limiter, batch]
      exporters: [prometheus]
    
    logs:
      receivers: [otlp, filelog]
      processors: [memory_limiter, batch, attributes]
      exporters: [loki]
```

## 정리

관찰가능성과 디버깅은 현대 시스템의 필수 요소입니다:

1. **Three Pillars**: Metrics, Logs, Traces의 통합
2. **분산 트레이싱**: 마이크로서비스 환경의 요청 추적
3. **eBPF**: 커널 레벨의 깊은 관찰
4. **프로덕션 디버깅**: 실시간 문제 해결
5. **카오스 엔지니어링**: 선제적 장애 대응

이 12개 장을 통해 컴퓨터 시스템의 기초부터 현대적인 운영 기술까지 폭넓게 다루었습니다. 각 주제는 서로 연결되어 있으며, 전체적인 이해가 더 나은 엔지니어링 결정을 내리는 데 도움이 될 것입니다.

## 참고 자료

- [OpenTelemetry Documentation](https://opentelemetry.io/docs/)
- [BPF Performance Tools](http://www.brendangregg.com/bpf-performance-tools-book.html)
- [Site Reliability Engineering](https://sre.google/books/)
- [Distributed Systems Observability](https://www.oreilly.com/library/view/distributed-systems-observability/9781492033431/)