---
tags:
  - Consistent_Hashing
  - Data_Distribution
  - Hash_Sharding
  - Range_Sharding
  - Sharding
  - advanced
  - deep-study
  - hands-on
  - ì‹œìŠ¤í…œí”„ë¡œê·¸ë˜ë°
difficulty: ADVANCED
learning_time: "8-12ì‹œê°„"
main_topic: "ì‹œìŠ¤í…œ í”„ë¡œê·¸ë˜ë°"
priority_score: 5
---

# 14.2.3: ìƒ¤ë”© ì „ëµ

## ì„œë¡ : 2021ë…„ 7ì›”, ë°ì´í„°ë² ì´ìŠ¤ê°€ í„°ì§„ ë‚ 

ìš°ë¦¬ ì†Œì…œë¯¸ë””ì–´ í”Œë«í¼ì´ ê°‘ìê¸° ì¸ê¸°ë¥¼ ëŒë©´ì„œ ì‚¬ìš©ì ìˆ˜ê°€ 10ë§Œ ëª…ì—ì„œ 1000ë§Œ ëª…ìœ¼ë¡œ í­ì¦í–ˆë˜ ë•Œì…ë‹ˆë‹¤. ë‹¨ì¼ MySQL ì„œë²„ë¡œëŠ” ë” ì´ìƒ ê°ë‹¹í•  ìˆ˜ ì—†ëŠ” ìƒí™©ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.

### ğŸ”¥ 7ì›” 15ì¼ ìƒˆë²½ 3ì‹œ: ë°ì´í„°ë² ì´ìŠ¤ì˜ í•œê³„

```bash
# ê¸°ì¡´ ì‹œìŠ¤í…œ (ë‹¨ì¼ MySQL)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        MySQL Server             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚     Users Table             â”‚â”‚
â”‚  â”‚  - 10,000,000 rows         â”‚â”‚  
â”‚  â”‚  - 500GB data              â”‚â”‚
â”‚  â”‚  - 2GB RAM buffer          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# ì„±ëŠ¥ ì§€í‘œ (ì°¸ì‚¬ ìƒí™©)
Query Average Time: 15.3ì´ˆ  # í‰ì†Œ 0.1ì´ˆ
Active Connections: 2000/2000  # í’€ ê³ ê°ˆ
Lock Wait Time: 45ì´ˆ
Disk I/O: 98% ì‚¬ìš©ë¥ 
CPU: 99% ì§€ì†ì  ì‚¬ìš©

# ì‹¤ì œ ì¿¼ë¦¬ ì„±ëŠ¥
mysql> SELECT * FROM users WHERE id = 5000000;
# 15ì´ˆ í›„ì— ê²°ê³¼ ë°˜í™˜... ğŸ˜±

mysql> INSERT INTO posts (user_id, content) VALUES (1234567, 'Hello');
# 30ì´ˆ í›„ì— ì™„ë£Œ... ğŸ˜­
```

**ìƒˆë²½ 3:30 - CTOì˜ ê¸´ê¸‰ ê²°ì •**

"ë‹¨ì¼ ì„œë²„ë¡œëŠ” í•œê³„ë‹¤. ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì!"

í•˜ì§€ë§Œ ì–´ë–»ê²Œ ë‚˜ëˆŒ ê²ƒì¸ê°€? ì–´ë–»ê²Œ ë³µì œí•  ê²ƒì¸ê°€? ë°ì´í„° ì¼ê´€ì„±ì€ ì–´ë–»ê²Œ ë³´ì¥í•  ê²ƒì¸ê°€?

ì´ë•Œë¶€í„°**ë¶„ì‚° ë°ì´í„° ê´€ë¦¬**ì˜ ì—¬ì •ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ”„ ë°ì´í„° ë¶„ì‚°ì˜ ë‘ ê°€ì§€ ì¶•

```mermaid
graph TD
    subgraph "ë°ì´í„° ë¶„ì‚° ì „ëµ"
        H["Horizontal Partitioning, ìˆ˜í‰ ë¶„í• , Sharding"]
        V["Vertical Partitioning, ìˆ˜ì§ ë¶„í• , Column ë¶„ë¦¬"]
    end
    
    subgraph "ë°ì´í„° ë³µì œ ì „ëµ"
        R1["Master-Slave, Replication"]
        R2["Master-Master, Replication"]
        R3["Multi-Master, with Conflict Resolution"]
    end
    
    subgraph "ê²°í•©ëœ ì•„í‚¤í…ì²˜"
        SR["Sharded Replication, ê° ìƒ¤ë“œë¥¼ ë³µì œ"]
        RS["Replicated Sharding, ë³µì œë³¸ì„ ìƒ¤ë”©"]
    end
    
    H --> SR
    R1 --> SR
    H --> RS
    R2 --> RS
    
    style H fill:#e3f2fd
    style R1 fill:#c8e6c9
    style SR fill:#fff3e0
```

## ğŸ”ª Sharding: ë°ì´í„°ë¥¼ ë‚˜ëˆ„ëŠ” ê¸°ìˆ 

### ğŸ“Š Sharding ì „ëµ ë¹„êµ

#### 1. Range-based Sharding (ë²”ìœ„ ê¸°ë°˜ ìƒ¤ë”©)

```python
class RangeBasedSharding:
    def __init__(self):
        self.shards = {
            'shard1': {'range': (0, 3333333), 'server': 'db1.company.com'},
            'shard2': {'range': (3333334, 6666666), 'server': 'db2.company.com'},
            'shard3': {'range': (6666667, 9999999), 'server': 'db3.company.com'}
        }
    
    def get_shard(self, user_id):
        """ì‚¬ìš©ì ID ë²”ìœ„ì— ë”°ë¥¸ ìƒ¤ë“œ ê²°ì •"""
        for shard_name, config in self.shards.items():
            start, end = config['range']
            if start <= user_id <= end:
                return config['server']
        
        raise ValueError(f"No shard found for user_id: {user_id}")
    
    def query_user(self, user_id):
        """ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ"""
        shard_server = self.get_shard(user_id)
        
        # í•´ë‹¹ ìƒ¤ë“œì—ì„œ ì¿¼ë¦¬ ì‹¤í–‰
        db = connect_to_database(shard_server)
        result = db.execute("""
            SELECT * FROM users WHERE id = %s
        """, user_id)
        
        return result

# ì‹¤ì œ ì‚¬ìš©
sharding = RangeBasedSharding()

# ë‹¤ë¥¸ ìƒ¤ë“œë“¤ì— ë¶„ì‚° ì €ì¥
print(sharding.get_shard(1000000))    # db1.company.com
print(sharding.get_shard(5000000))    # db2.company.com  
print(sharding.get_shard(8000000))    # db3.company.com

# ì¥ì : ë²”ìœ„ ì¿¼ë¦¬ íš¨ìœ¨ì 
# SELECT * FROM users WHERE id BETWEEN 1000000 AND 2000000
# â†’ í•˜ë‚˜ì˜ ìƒ¤ë“œì—ì„œë§Œ ì‹¤í–‰

# ë‹¨ì : Hot Spot ë¬¸ì œ
# ìƒˆ ì‚¬ìš©ìë“¤ì´ ê³„ì† ë†’ì€ IDë¥¼ ê°€ì§ â†’ shard3ì— ë¶€í•˜ ì§‘ì¤‘
```

**Range Shardingì˜ Hot Spot ë¬¸ì œ í•´ê²°**:

```python
class ImprovedRangeSharding:
    def __init__(self):
        # ë™ì  ë²”ìœ„ ì¡°ì •ì„ ìœ„í•œ ë©”íƒ€ë°ì´í„°
        self.shard_metadata = {
            'shard1': {'range': (0, 2000000), 'load': 0.3},
            'shard2': {'range': (2000001, 5000000), 'load': 0.5}, 
            'shard3': {'range': (5000001, 10000000), 'load': 0.9}  # í•«ìŠ¤íŒŸ!
        }
    
    def rebalance_shards(self):
        """ë¶€í•˜ê°€ ë†’ì€ ìƒ¤ë“œ ë¶„í• """
        for shard_id, metadata in self.shard_metadata.items():
            if metadata['load'] > 0.8:  # 80% ì´ìƒ ë¶€í•˜
                print(f"Rebalancing {shard_id} (load: {metadata['load']})")
                
                # ìƒˆ ìƒ¤ë“œ ìƒì„±
                self.split_shard(shard_id)
    
    def split_shard(self, shard_id):
        """ìƒ¤ë“œ ë¶„í• """
        old_metadata = self.shard_metadata[shard_id]
        start, end = old_metadata['range']
        mid = (start + end) // 2
        
        # ê¸°ì¡´ ìƒ¤ë“œ ë²”ìœ„ ì¶•ì†Œ
        self.shard_metadata[shard_id]['range'] = (start, mid)
        
        # ìƒˆ ìƒ¤ë“œ ìƒì„±  
        new_shard_id = f"{shard_id}_split"
        self.shard_metadata[new_shard_id] = {
            'range': (mid + 1, end),
            'load': 0.0
        }
        
        print(f"Created {new_shard_id} for range ({mid+1}, {end})")
```

#### 2. Hash-based Sharding (í•´ì‹œ ê¸°ë°˜ ìƒ¤ë”©)

```python
import hashlib

class HashBasedSharding:
    def __init__(self, num_shards=8):
        self.num_shards = num_shards
        self.shards = {
            i: f"db{i}.company.com" for i in range(num_shards)
        }
    
    def get_shard(self, key):
        """í‚¤ì˜ í•´ì‹œê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒ¤ë“œ ê²°ì •"""
        hash_value = int(hashlib.md5(str(key).encode()).hexdigest(), 16)
        shard_id = hash_value % self.num_shards
        return self.shards[shard_id]
    
    def query_user(self, user_id):
        """ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ"""
        shard_server = self.get_shard(user_id)
        
        db = connect_to_database(shard_server)
        result = db.execute("""
            SELECT * FROM users WHERE id = %s
        """, user_id)
        
        return result
    
    def query_by_email(self, email):
        """ì´ë©”ì¼ë¡œ ì‚¬ìš©ì ê²€ìƒ‰ (ëª¨ë“  ìƒ¤ë“œ ì¡°íšŒ í•„ìš”)"""
        results = []
        
        # ğŸš¨ ë¬¸ì œ: ëª¨ë“  ìƒ¤ë“œë¥¼ ì¡°íšŒí•´ì•¼ í•¨
        for shard_id, server in self.shards.items():
            db = connect_to_database(server)
            result = db.execute("""
                SELECT * FROM users WHERE email = %s
            """, email)
            if result:
                results.extend(result)
        
        return results

# ì‹¤ì œ ì‚¬ìš©
hash_sharding = HashBasedSharding(num_shards=8)

# ë™ì¼í•œ í‚¤ëŠ” í•­ìƒ ê°™ì€ ìƒ¤ë“œ
print(hash_sharding.get_shard("user123"))  # db3.company.com
print(hash_sharding.get_shard("user123"))  # db3.company.com (ë™ì¼)

# ë‹¤ë¥¸ í‚¤ëŠ” ê³ ë¥´ê²Œ ë¶„ì‚°
print(hash_sharding.get_shard("user456"))  # db7.company.com
print(hash_sharding.get_shard("user789"))  # db1.company.com

# ì¥ì : ê· ë“±í•œ ë¶„ì‚°, Hot Spot ë°©ì§€
# ë‹¨ì : ë²”ìœ„ ì¿¼ë¦¬ ë¶ˆê°€, ìƒ¤ë“œ ì¶”ê°€ ì‹œ ëŒ€ê·œëª¨ ì¬ë°°ì¹˜ í•„ìš”
```

**Hash Shardingì˜ í™•ì¥ì„± ë¬¸ì œ**:

```python
# ë¬¸ì œ ìƒí™©: ìƒ¤ë“œ ì¶”ê°€ ì‹œ ëŒ€ë¶€ë¶„ ë°ì´í„° ì´ë™ í•„ìš”
class NaiveHashSharding:
    def __init__(self, num_shards):
        self.num_shards = num_shards
    
    def get_shard(self, key):
        return hash(key) % self.num_shards

# ê¸°ì¡´: 8ê°œ ìƒ¤ë“œ
old_sharding = NaiveHashSharding(8)
user_123_shard = old_sharding.get_shard("user123")  # shard 3

# í™•ì¥: 16ê°œ ìƒ¤ë“œ
new_sharding = NaiveHashSharding(16) 
user_123_new_shard = new_sharding.get_shard("user123")  # shard 11

# ğŸ˜± ê²°ê³¼: ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°ê°€ ë‹¤ë¥¸ ìƒ¤ë“œë¡œ ì´ë™í•´ì•¼ í•¨!
# í™•ì¥ ì‹œ ì „ì²´ ì‹œìŠ¤í…œ ë‹¤ìš´íƒ€ì„ ë°œìƒ
```

#### 3. Consistent Hashing (ì¼ê´€ëœ í•´ì‹±)

ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê²ƒì´**Consistent Hashing**ì…ë‹ˆë‹¤:

```python
import hashlib
import bisect

class ConsistentHashing:
    def __init__(self, nodes=None, replicas=3):
        self.replicas = replicas  # ê°€ìƒ ë…¸ë“œ ê°œìˆ˜
        self.ring = {}           # í•´ì‹œë§
        self.sorted_keys = []    # ì •ë ¬ëœ í‚¤ ëª©ë¡
        
        if nodes:
            for node in nodes:
                self.add_node(node)
    
    def _hash(self, key):
        """SHA-1 í•´ì‹œ í•¨ìˆ˜"""
        return int(hashlib.sha1(str(key).encode()).hexdigest(), 16)
    
    def add_node(self, node):
        """ë…¸ë“œ ì¶”ê°€ (ê°€ìƒ ë…¸ë“œë“¤ ìƒì„±)"""
        for i in range(self.replicas):
            virtual_key = self._hash(f"{node}:{i}")
            self.ring[virtual_key] = node
            bisect.insort(self.sorted_keys, virtual_key)
        
        print(f"Added node {node} with {self.replicas} virtual nodes")
    
    def remove_node(self, node):
        """ë…¸ë“œ ì œê±°"""
        for i in range(self.replicas):
            virtual_key = self._hash(f"{node}:{i}")
            del self.ring[virtual_key]
            self.sorted_keys.remove(virtual_key)
        
        print(f"Removed node {node}")
    
    def get_node(self, key):
        """í‚¤ì— í•´ë‹¹í•˜ëŠ” ë…¸ë“œ ì°¾ê¸°"""
        if not self.ring:
            return None
        
        hash_key = self._hash(key)
        
        # ì‹œê³„ë°©í–¥ìœ¼ë¡œ ì²« ë²ˆì§¸ ë…¸ë“œ ì°¾ê¸°
        idx = bisect.bisect_right(self.sorted_keys, hash_key)
        
        # ë§ì˜ ëì— ë„ë‹¬í•˜ë©´ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°
        if idx == len(self.sorted_keys):
            idx = 0
        
        return self.ring[self.sorted_keys[idx]]
    
    def get_nodes(self, key, count=3):
        """í‚¤ì— í•´ë‹¹í•˜ëŠ” ì—¬ëŸ¬ ë…¸ë“œ ì°¾ê¸° (ë³µì œìš©)"""
        if not self.ring:
            return []
        
        hash_key = self._hash(key)
        idx = bisect.bisect_right(self.sorted_keys, hash_key)
        
        nodes = []
        seen = set()
        
        for _ in range(count):
            if idx >= len(self.sorted_keys):
                idx = 0
            
            node = self.ring[self.sorted_keys[idx]]
            if node not in seen:
                nodes.append(node)
                seen.add(node)
            
            idx += 1
            
            if len(nodes) == count or len(seen) == len(set(self.ring.values())):
                break
        
        return nodes

# Consistent Hashing ì‹œë®¬ë ˆì´ì…˜
def simulate_consistent_hashing():
    print("=== Consistent Hashing ì‹œë®¬ë ˆì´ì…˜ ===")
    
    # ì´ˆê¸° 4ê°œ ë…¸ë“œ
    ch = ConsistentHashing(['server1', 'server2', 'server3', 'server4'])
    
    # í…ŒìŠ¤íŠ¸ í‚¤ë“¤ì˜ ì´ˆê¸° ë°°ì¹˜
    test_keys = ['user123', 'user456', 'user789', 'user111', 'user222']
    
    print("\n--- ì´ˆê¸° ë°°ì¹˜ ---")
    initial_placement = {}
    for key in test_keys:
        node = ch.get_node(key)
        initial_placement[key] = node
        print(f"{key} â†’ {node}")
    
    # ìƒˆ ë…¸ë“œ ì¶”ê°€
    print("\n--- server5 ì¶”ê°€ í›„ ---")
    ch.add_node('server5')
    
    moved_keys = 0
    for key in test_keys:
        old_node = initial_placement[key]
        new_node = ch.get_node(key) 
        
        if old_node != new_node:
            moved_keys += 1
            print(f"{key}: {old_node} â†’ {new_node} âœ¨ ì´ë™")
        else:
            print(f"{key}: {old_node} (ê·¸ëŒ€ë¡œ)")
    
    print(f"\nì´ë™ëœ í‚¤: {moved_keys}/{len(test_keys)} ({moved_keys/len(test_keys)*100:.1f}%)")
    print("ğŸ‘ ì¼ë°˜ í•´ì‹±ì´ë¼ë©´ 80% ì´ìƒ ì´ë™í–ˆì„ ê²ƒ!")

# ì‹¤í–‰
simulate_consistent_hashing()

# ì˜ˆìƒ ì¶œë ¥:
# === Consistent Hashing ì‹œë®¬ë ˆì´ì…˜ ===
# Added node server1 with 3 virtual nodes
# Added node server2 with 3 virtual nodes  
# Added node server3 with 3 virtual nodes
# Added node server4 with 3 virtual nodes
#
# --- ì´ˆê¸° ë°°ì¹˜ ---
# user123 â†’ server2
# user456 â†’ server4
# user789 â†’ server1
# user111 â†’ server3
# user222 â†’ server2
#
# --- server5 ì¶”ê°€ í›„ ---
# Added node server5 with 3 virtual nodes
# user123: server2 (ê·¸ëŒ€ë¡œ)
# user456: server4 (ê·¸ëŒ€ë¡œ)  
# user789: server5 âœ¨ ì´ë™
# user111: server3 (ê·¸ëŒ€ë¡œ)
# user222: server2 (ê·¸ëŒ€ë¡œ)
#
# ì´ë™ëœ í‚¤: 1/5 (20.0%)
# ğŸ‘ ì¼ë°˜ í•´ì‹±ì´ë¼ë©´ 80% ì´ìƒ ì´ë™í–ˆì„ ê²ƒ!
```

### ğŸ¯ ì‹¤ì „ ìƒ¤ë”© ì•„í‚¤í…ì²˜ ì„¤ê³„

```python
class ProductionShardingSystem:
    """ì‹¤ì œ ìš´ì˜ í™˜ê²½ì„ ê³ ë ¤í•œ ìƒ¤ë”© ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.consistent_hash = ConsistentHashing()
        self.shard_metadata = {}  # ìƒ¤ë“œë³„ ë©”íƒ€ë°ì´í„°
        self.connection_pools = {}  # ì»¤ë„¥ì…˜ í’€
        
        # ì´ˆê¸° ìƒ¤ë“œ ì„¤ì •
        self.initialize_shards()
    
    def initialize_shards(self):
        """ì´ˆê¸° ìƒ¤ë“œ êµ¬ì„±"""
        initial_shards = [
            'shard1-primary.db.company.com',
            'shard2-primary.db.company.com', 
            'shard3-primary.db.company.com',
            'shard4-primary.db.company.com'
        ]
        
        for shard in initial_shards:
            self.add_shard(shard)
    
    def add_shard(self, shard_address):
        """ìƒˆ ìƒ¤ë“œ ì¶”ê°€"""
        # Consistent Hashì— ì¶”ê°€
        self.consistent_hash.add_node(shard_address)
        
        # ë©”íƒ€ë°ì´í„° ì„¤ì •
        self.shard_metadata[shard_address] = {
            'status': 'active',
            'created_at': time.time(),
            'replica_addresses': [
                shard_address.replace('primary', 'replica1'),
                shard_address.replace('primary', 'replica2')
            ]
        }
        
        # ì»¤ë„¥ì…˜ í’€ ìƒì„±
        self.connection_pools[shard_address] = create_connection_pool(
            shard_address, 
            pool_size=20
        )
        
        print(f"Shard added: {shard_address}")
    
    def write_data(self, key, data):
        """ë°ì´í„° ì“°ê¸° (ë³µì œ í¬í•¨)"""
        # Primary ìƒ¤ë“œ ê²°ì •
        primary_shard = self.consistent_hash.get_node(key)
        
        # ë³µì œë³¸ ìƒ¤ë“œë“¤ ê²°ì •
        replica_shards = self.shard_metadata[primary_shard]['replica_addresses']
        
        try:
            # 1. Primaryì— ì“°ê¸°
            primary_conn = self.connection_pools[primary_shard]
            primary_conn.execute("""
                INSERT INTO data_table (key, value, created_at) 
                VALUES (%s, %s, %s)
            """, key, data, time.time())
            
            # 2. ë³µì œë³¸ë“¤ì— ë¹„ë™ê¸° ì“°ê¸°
            for replica in replica_shards:
                self.async_write_to_replica(replica, key, data)
            
            return {'status': 'success', 'shard': primary_shard}
            
        except DatabaseException as e:
            # Primary ì¥ì•  ì‹œ ë³µì œë³¸ì„ Primaryë¡œ ìŠ¹ê²©
            return self.handle_primary_failure(primary_shard, key, data)
    
    def read_data(self, key, consistency_level='eventual'):
        """ë°ì´í„° ì½ê¸° (ì¼ê´€ì„± ë ˆë²¨ ì„ íƒ)"""
        primary_shard = self.consistent_hash.get_node(key)
        
        if consistency_level == 'strong':
            # ê°•í•œ ì¼ê´€ì„±: Primaryì—ì„œë§Œ ì½ê¸°
            conn = self.connection_pools[primary_shard]
            result = conn.execute("""
                SELECT value FROM data_table WHERE key = %s
            """, key)
            return result
            
        elif consistency_level == 'eventual':
            # ìµœì¢… ì¼ê´€ì„±: ì•„ë¬´ ë³µì œë³¸ì—ì„œ ì½ê¸° (ì„±ëŠ¥ ìš°ì„ )
            all_shards = [primary_shard] + \
                        self.shard_metadata[primary_shard]['replica_addresses']
            
            # ê°€ì¥ ë¹ ë¥¸ ì‘ë‹µì„ ì£¼ëŠ” ìƒ¤ë“œì—ì„œ ì½ê¸°
            return self.read_from_fastest_replica(all_shards, key)
    
    def read_from_fastest_replica(self, shards, key):
        """ì—¬ëŸ¬ ë³µì œë³¸ ì¤‘ ê°€ì¥ ë¹ ë¥¸ ì‘ë‹µ ì‚¬ìš©"""
        import asyncio
        import concurrent.futures
        
        async def read_from_shard(shard):
            conn = self.connection_pools[shard]
            return conn.execute("""
                SELECT value FROM data_table WHERE key = %s
            """, key)
        
        # ëª¨ë“  ë³µì œë³¸ì—ì„œ ë™ì‹œì— ì½ê¸° ì‹œë„
        with concurrent.futures.ThreadPoolExecutor() as executor:
            futures = [
                executor.submit(self.read_from_single_shard, shard, key) 
                for shard in shards
            ]
            
            # ì²« ë²ˆì§¸ë¡œ ì™„ë£Œëœ ê²°ê³¼ ë°˜í™˜
            for future in concurrent.futures.as_completed(futures):
                try:
                    result = future.result(timeout=1.0)  # 1ì´ˆ íƒ€ì„ì•„ì›ƒ
                    return result
                except Exception:
                    continue
        
        raise Exception("All replicas failed")
    
    def rebalance_data(self):
        """ë°ì´í„° ë¦¬ë°¸ëŸ°ì‹±"""
        print("Starting data rebalancing...")
        
        # ê° ìƒ¤ë“œì˜ ë¶€í•˜ í™•ì¸
        shard_loads = self.analyze_shard_loads()
        
        for shard, load in shard_loads.items():
            if load > 0.8:  # 80% ì´ìƒ ë¶€í•˜
                print(f"High load detected on {shard}: {load:.2f}")
                self.scale_out_shard(shard)
    
    def scale_out_shard(self, overloaded_shard):
        """ê³¼ë¶€í•˜ ìƒ¤ë“œ í™•ì¥"""
        # ìƒˆ ìƒ¤ë“œ ìƒì„±
        new_shard = self.create_new_shard()
        
        # ë°ì´í„° ì´ë™ (ë°±ê·¸ë¼ìš´ë“œ)
        self.migrate_data_async(overloaded_shard, new_shard)
        
        print(f"Scaling out {overloaded_shard} â†’ {new_shard}")

# ì‚¬ìš© ì˜ˆì‹œ
sharding_system = ProductionShardingSystem()

# ë°ì´í„° ì“°ê¸° (ìë™ ìƒ¤ë”©)
result = sharding_system.write_data("user:123456", {
    "name": "John Doe",
    "email": "john@example.com",  
    "created_at": "2023-07-15T10:30:00Z"
})
print(f"Write result: {result}")

# ë°ì´í„° ì½ê¸° (ê°•í•œ ì¼ê´€ì„±)
user_data = sharding_system.read_data("user:123456", consistency_level='strong')
print(f"User data: {user_data}")

# ë°ì´í„° ì½ê¸° (ìµœì¢… ì¼ê´€ì„± - ë¹ ë¥¸ ì„±ëŠ¥)
user_data_fast = sharding_system.read_data("user:123456", consistency_level='eventual')
print(f"User data (fast): {user_data_fast}")
```

## í•µì‹¬ ìš”ì 

### 1. ìƒ¤ë”© ì „ëµë³„ íŠ¹ì„± ì´í•´

-**Range Sharding**: ë²”ìœ„ ì¿¼ë¦¬ íš¨ìœ¨ì ì´ì§€ë§Œ Hot Spot ìœ„í—˜
-**Hash Sharding**: ê· ë“± ë¶„ì‚°ì´ì§€ë§Œ í™•ì¥ ì‹œ ëŒ€ê·œëª¨ ì´ë™
-**Consistent Hashing**: í™•ì¥ì„±ì´ ì¢‹ì§€ë§Œ êµ¬í˜„ ë³µì¡ë„ ì¦ê°€

### 2. í™•ì¥ì„±ê³¼ ì„±ëŠ¥ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„

- ìƒ¤ë“œ ìˆ˜ ì¦ê°€ â†’ ë¶„ì‚° íš¨ê³¼ ì¦ê°€, ë³µì¡ì„± ì¦ê°€
- ê°€ìƒ ë…¸ë“œ ìˆ˜ ì¦ê°€ â†’ ë¶„ì‚° ê· ë“±ì„± í–¥ìƒ, ì˜¤ë²„í—¤ë“œ ì¦ê°€

### 3. ì‹¤ì „ ê³ ë ¤ì‚¬í•­

- ì»¤ë„¥ì…˜ í’€ ê´€ë¦¬ì™€ ë¹„ë™ê¸° ì²˜ë¦¬ í•„ìˆ˜
- ìƒ¤ë“œ ì¥ì•  ì‹œ ìë™ Failover ë©”ì»¤ë‹ˆì¦˜
- ë¶€í•˜ ëª¨ë‹ˆí„°ë§ê³¼ ë™ì  ë¦¬ë°¸ëŸ°ì‹±

---

**ì´ì „**: [ë¶„ì‚° ë°ì´í„° ê´€ë¦¬ ê°œìš”](14-02-02-distributed-data.md)  
**ë‹¤ìŒ**: [Replication íŒ¨í„´](14-05-01-replication-patterns.md)ì—ì„œ ë°ì´í„° ë³µì œë¥¼ í†µí•œ ê°€ìš©ì„± í™•ë³´ ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

### ğŸ“– í˜„ì¬ ë¬¸ì„œ ì •ë³´

-**ë‚œì´ë„**: ADVANCED
-**ì£¼ì œ**: ì‹œìŠ¤í…œ í”„ë¡œê·¸ë˜ë°
-**ì˜ˆìƒ ì‹œê°„**: 8-12ì‹œê°„

### ğŸ¯ í•™ìŠµ ê²½ë¡œ

- [ğŸ“š ADVANCED ë ˆë²¨ ì „ì²´ ë³´ê¸°](../learning-paths/advanced/)
- [ğŸ  ë©”ì¸ í•™ìŠµ ê²½ë¡œ](../learning-paths/)
- [ğŸ“‹ ì „ì²´ ê°€ì´ë“œ ëª©ë¡](../README.md)

### ğŸ“‚ ê°™ì€ ì±•í„° (chapter-14-distributed-systems)

- [14.1 ë¶„ì‚° ì‹œìŠ¤í…œ ê¸°ì´ˆ ì´ë¡  - CAP ì •ë¦¬ì™€ ì¼ê´€ì„±ì˜ ê³¼í•™](./14-01-01-distributed-fundamentals.md)
- [14.2 í•©ì˜ ì•Œê³ ë¦¬ì¦˜ - ë¶„ì‚°ëœ ë…¸ë“œë“¤ì´ í•˜ë‚˜ê°€ ë˜ëŠ” ë°©ë²•](./14-02-01-consensus-algorithms.md)
- [14.3 ë¶„ì‚° ë°ì´í„° ê´€ë¦¬ ê°œìš”](./14-02-02-distributed-data.md)
- [14.3B Replication íŒ¨í„´ê³¼ êµ¬í˜„](./14-05-01-replication-patterns.md)
- [14.3C Vector Clockê³¼ ì¶©ëŒ í•´ê²°](./14-02-04-vector-clocks.md)

### ğŸ·ï¸ ê´€ë ¨ í‚¤ì›Œë“œ

`Sharding`, `Consistent_Hashing`, `Range_Sharding`, `Hash_Sharding`, `Data_Distribution`

### â­ï¸ ë‹¤ìŒ ë‹¨ê³„ ê°€ì´ë“œ

- ì‹œìŠ¤í…œ ì „ì²´ì˜ ê´€ì ì—ì„œ ì´í•´í•˜ë ¤ ë…¸ë ¥í•˜ì„¸ìš”
- ë‹¤ë¥¸ ê³ ê¸‰ ì£¼ì œë“¤ê³¼ì˜ ì—°ê´€ì„±ì„ íŒŒì•…í•´ë³´ì„¸ìš”
