---
tags:
  - DistributedSystems
  - EventDriven
  - EventSourcing
  - MessageQueue
  - Streaming
  - Guide
---

# 14.5 Event-Driven Architecture - ì´ë²¤íŠ¸ë¡œ ì—°ê²°ë˜ëŠ” ëŠìŠ¨í•œ ê²°í•© ì‹œìŠ¤í…œ

## ì„œë¡ : 2023ë…„ 5ì›”, ì‹¤ì‹œê°„ ì¶”ì²œ ì‹œìŠ¤í…œì„ ë§Œë“  ë‚ 

ìš°ë¦¬ ìŠ¤íŠ¸ë¦¬ë° í”Œë«í¼ì—ì„œ "ì‚¬ìš©ìê°€ ì˜í™”ë¥¼ ì‹œì²­í•˜ëŠ” ìˆœê°„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë§ì¶¤í˜• ì¶”ì²œì„ ì œê³µí•˜ì"ëŠ” í”„ë¡œì íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ë¬¸ì œëŠ” ì´ ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ë ¤ë©´ 7ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ì‹œìŠ¤í…œì´ ì‹¤ì‹œê°„ìœ¼ë¡œ í˜‘ë ¥í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì´ì—ˆìŠµë‹ˆë‹¤.

### ğŸ¬ ê¸°ì¡´ ì•„í‚¤í…ì²˜ì˜ í•œê³„

```bash
# ê¸°ì¡´ ë™ê¸° ë°©ì‹ (Request-Response)
ì‚¬ìš©ìê°€ "ì–´ë²¤ì ¸ìŠ¤" ì‹œì²­ ì‹œì‘
    â†“
ğŸ¬ Video Service: ì‹œì²­ ê¸°ë¡ ì €ì¥
    â†“ (ë™ê¸° í˜¸ì¶œ)
ğŸ‘¤ User Service: ì‚¬ìš©ì ì·¨í–¥ ì—…ë°ì´íŠ¸  
    â†“ (ë™ê¸° í˜¸ì¶œ)
ğŸ¤– ML Service: ì¶”ì²œ ëª¨ë¸ ì¬í•™ìŠµ
    â†“ (ë™ê¸° í˜¸ì¶œ)  
ğŸ“Š Analytics Service: í†µê³„ ì—…ë°ì´íŠ¸
    â†“ (ë™ê¸° í˜¸ì¶œ)
ğŸ“§ Notification Service: ì¹œêµ¬ë“¤ì—ê²Œ ì•Œë¦¼
    â†“ (ë™ê¸° í˜¸ì¶œ)
ğŸ’ Badge Service: ì‹œì²­ ë±ƒì§€ ì§€ê¸‰
    â†“ (ë™ê¸° í˜¸ì¶œ) 
ğŸ† Ranking Service: ë­í‚¹ ì—…ë°ì´íŠ¸

# ë¬¸ì œì ë“¤
ì´ ì‘ë‹µ ì‹œê°„: 2.3ì´ˆ (ê° ì„œë¹„ìŠ¤ 0.3ì´ˆì”©)
ì¥ì•  ì „íŒŒ: ML Service ë‹¤ìš´ ì‹œ ì „ì²´ ì‹œì²­ ë¶ˆê°€
ê°•í•œ ê²°í•©: ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • í•„ìš”
í™•ì¥ì„± ë¶€ì¡±: ì‚¬ìš©ì ì¦ê°€ ì‹œ ëª¨ë“  ì„œë¹„ìŠ¤ì— ë¶€í•˜ ì§‘ì¤‘
```

**5ì›” 12ì¼ ì˜¤í›„ 4ì‹œ: ì‹œìŠ¤í…œ ë§ˆë¹„**

```python
# Video Service ë¡œê·¸
[16:00:15] INFO: User 12345 started watching "Avengers"
[16:00:15] DEBUG: Calling user-service for preference update...
[16:00:20] ERROR: user-service timeout after 5 seconds
[16:00:20] DEBUG: Retrying user-service call...
[16:00:25] ERROR: user-service timeout after 5 seconds
[16:00:25] FATAL: Unable to record watch event - rolling back
[16:00:25] ERROR: Video playback failed for user 12345

# ê²°ê³¼: ML Service ì¥ì• ë¡œ ì•„ë¬´ë„ ì˜í™”ë¥¼ ë³¼ ìˆ˜ ì—†ëŠ” ìƒí™© ğŸ˜±
```

**5ì›” 15ì¼: Event-Driven Architecture ë„ì… ê²°ì •**

ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” **Event-Driven Architecture**ë¡œ ì‹œìŠ¤í…œì„ ì¬êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ğŸŒŠ Event-Driven Architectureì˜ í•µì‹¬ ê°œë…

### ğŸ“¡ ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹  íŒ¨ëŸ¬ë‹¤ì„

```mermaid
graph TD
    subgraph "ê¸°ì¡´ ë™ê¸° ë°©ì‹"
        A1[Service A] --> B1[Service B]
        B1 --> C1[Service C] 
        C1 --> D1[Service D]
        
        note1[ìˆœì°¨ ì²˜ë¦¬<br/>ê°•í•œ ê²°í•©<br/>ì¥ì•  ì „íŒŒ]
    end
    
    subgraph "ì´ë²¤íŠ¸ ê¸°ë°˜ ë°©ì‹"
        A2[Service A] --> EB[Event Bus]
        EB --> B2[Service B]
        EB --> C2[Service C]
        EB --> D2[Service D]
        
        note2[ë³‘ë ¬ ì²˜ë¦¬<br/>ëŠìŠ¨í•œ ê²°í•©<br/>ì¥ì•  ê²©ë¦¬]
    end
    
    style A1 fill:#ffcdd2
    style B1 fill:#ffcdd2
    style C1 fill:#ffcdd2
    style D1 fill:#ffcdd2
    
    style A2 fill:#c8e6c9
    style B2 fill:#c8e6c9
    style C2 fill:#c8e6c9
    style D2 fill:#c8e6c9
    style EB fill:#fff3e0
```

## ğŸšŒ Message Queue vs Event Streaming

### ğŸ“® Message Queue ë°©ì‹ (Apache RabbitMQ)

**íŠ¹ì§•**: ë©”ì‹œì§€ë¥¼ í•œ ë²ˆë§Œ ì†Œë¹„í•˜ëŠ” ì ëŒ€ì  í†µì‹ 

```python
import pika
import json
import threading
import time
from typing import Dict, List, Callable

class RabbitMQEventBus:
    """RabbitMQ ê¸°ë°˜ ì´ë²¤íŠ¸ ë²„ìŠ¤"""
    
    def __init__(self, connection_url="amqp://localhost"):
        self.connection_url = connection_url
        self.connection = None
        self.channel = None
        self.subscribers = {}
        self.connect()
    
    def connect(self):
        """RabbitMQ ì—°ê²°"""
        self.connection = pika.BlockingConnection(
            pika.URLParameters(self.connection_url)
        )
        self.channel = self.connection.channel()
        print("ğŸ° Connected to RabbitMQ")
    
    def publish(self, event_type: str, payload: Dict, routing_key: str = ""):
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        # Exchange ì„ ì–¸ (Topic íƒ€ì… - ë¼ìš°íŒ… í‚¤ ê¸°ë°˜)
        self.channel.exchange_declare(
            exchange='events',
            exchange_type='topic',
            durable=True
        )
        
        message = {
            'event_type': event_type,
            'payload': payload,
            'timestamp': time.time()
        }
        
        # ë©”ì‹œì§€ ë°œí–‰
        self.channel.basic_publish(
            exchange='events',
            routing_key=routing_key or event_type,
            body=json.dumps(message),
            properties=pika.BasicProperties(
                delivery_mode=2  # ë©”ì‹œì§€ ì˜ì†í™”
            )
        )
        
        print(f"ğŸ“¢ Event published: {event_type} (routing_key: {routing_key})")
    
    def subscribe(self, event_pattern: str, handler: Callable, queue_name: str = None):
        """ì´ë²¤íŠ¸ êµ¬ë…"""
        if not queue_name:
            queue_name = f"queue_{event_pattern}_{int(time.time())}"
        
        # í ì„ ì–¸
        self.channel.queue_declare(queue=queue_name, durable=True)
        
        # íë¥¼ exchangeì— ë°”ì¸ë”©
        self.channel.queue_bind(
            exchange='events',
            queue=queue_name,
            routing_key=event_pattern
        )
        
        # ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜
        def callback(ch, method, properties, body):
            try:
                message = json.loads(body)
                print(f"ğŸ“¨ Received: {message['event_type']}")
                
                # í•¸ë“¤ëŸ¬ ì‹¤í–‰
                handler(message)
                
                # ë©”ì‹œì§€ ACK
                ch.basic_ack(delivery_tag=method.delivery_tag)
                
            except Exception as e:
                print(f"âŒ Handler error: {e}")
                # NACK - ë©”ì‹œì§€ë¥¼ ë‹¤ì‹œ íì— ë„£ê±°ë‚˜ Dead Letter Queueë¡œ ì „ì†¡
                ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
        
        # ì†Œë¹„ì ì„¤ì •
        self.channel.basic_qos(prefetch_count=1)  # í•œ ë²ˆì— í•˜ë‚˜ì”© ì²˜ë¦¬
        self.channel.basic_consume(
            queue=queue_name,
            on_message_callback=callback
        )
        
        print(f"ğŸ” Subscribed to pattern '{event_pattern}' with queue '{queue_name}'")
        
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë©”ì‹œì§€ ì†Œë¹„
        def consume():
            self.channel.start_consuming()
        
        consumer_thread = threading.Thread(target=consume, daemon=True)
        consumer_thread.start()

# RabbitMQë¥¼ ì‚¬ìš©í•œ ì˜í™” ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤
class VideoService:
    """ë¹„ë””ì˜¤ ì„œë¹„ìŠ¤ (ì´ë²¤íŠ¸ ë°œí–‰ì)"""
    
    def __init__(self, event_bus: RabbitMQEventBus):
        self.event_bus = event_bus
        self.active_sessions = {}
    
    def start_watching(self, user_id: str, video_id: str, video_title: str):
        """ì‹œì²­ ì‹œì‘ (ì´ë²¤íŠ¸ ë°œí–‰)"""
        session_id = f"session_{user_id}_{int(time.time())}"
        
        # ì„¸ì…˜ ì €ì¥ (ë¡œì»¬ ìƒíƒœ)
        self.active_sessions[session_id] = {
            'user_id': user_id,
            'video_id': video_id,
            'video_title': video_title,
            'start_time': time.time()
        }
        
        print(f"ğŸ¬ User {user_id} started watching '{video_title}'")
        
        # ì‹œì²­ ì‹œì‘ ì´ë²¤íŠ¸ ë°œí–‰
        self.event_bus.publish(
            event_type='video.watch_started',
            payload={
                'user_id': user_id,
                'video_id': video_id,
                'video_title': video_title,
                'session_id': session_id
            },
            routing_key='video.watch_started'
        )
        
        # ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜ (ë‹¤ë¥¸ ì„œë¹„ìŠ¤ë“¤ì€ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬)
        return {
            'status': 'success',
            'session_id': session_id,
            'message': 'Video started successfully'
        }

class RecommendationService:
    """ì¶”ì²œ ì„œë¹„ìŠ¤ (ì´ë²¤íŠ¸ ì†Œë¹„ì)"""
    
    def __init__(self, event_bus: RabbitMQEventBus):
        self.event_bus = event_bus
        self.user_preferences = {}
        
        # ì´ë²¤íŠ¸ êµ¬ë…
        self.event_bus.subscribe(
            event_pattern='video.watch_started',
            handler=self.handle_watch_started,
            queue_name='recommendation_service_queue'
        )
    
    def handle_watch_started(self, message):
        """ì‹œì²­ ì‹œì‘ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        payload = message['payload']
        user_id = payload['user_id']
        video_title = payload['video_title']
        
        print(f"ğŸ¤– Updating recommendations for user {user_id} based on '{video_title}'")
        
        # ì‚¬ìš©ì ì·¨í–¥ ì—…ë°ì´íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)
        if user_id not in self.user_preferences:
            self.user_preferences[user_id] = {'genres': [], 'actors': []}
        
        # ML ë¡œì§ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ë³µì¡í•œ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜)
        time.sleep(0.5)  # ML ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        
        if 'Marvel' in video_title:
            self.user_preferences[user_id]['genres'].append('superhero')
        
        # ì¶”ì²œ ì—…ë°ì´íŠ¸ ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰
        self.event_bus.publish(
            event_type='recommendation.updated',
            payload={
                'user_id': user_id,
                'recommendations': self.get_recommendations(user_id)
            },
            routing_key='recommendation.updated'
        )
    
    def get_recommendations(self, user_id: str) -> List[str]:
        """ì‚¬ìš©ì ì¶”ì²œ ëª©ë¡ ìƒì„±"""
        preferences = self.user_preferences.get(user_id, {})
        
        if 'superhero' in preferences.get('genres', []):
            return ['Iron Man', 'Thor', 'Captain America', 'Spider-Man']
        else:
            return ['The Matrix', 'Inception', 'Interstellar', 'The Dark Knight']

class NotificationService:
    """ì•Œë¦¼ ì„œë¹„ìŠ¤ (ì´ë²¤íŠ¸ ì†Œë¹„ì)"""
    
    def __init__(self, event_bus: RabbitMQEventBus):
        self.event_bus = event_bus
        self.sent_notifications = []
        
        # ì—¬ëŸ¬ ì´ë²¤íŠ¸ íƒ€ì… êµ¬ë…
        self.event_bus.subscribe(
            event_pattern='video.watch_started',
            handler=self.handle_watch_started,
            queue_name='notification_service_queue'
        )
        
        self.event_bus.subscribe(
            event_pattern='recommendation.updated', 
            handler=self.handle_recommendation_updated,
            queue_name='notification_recommendation_queue'
        )
    
    def handle_watch_started(self, message):
        """ì‹œì²­ ì‹œì‘ ì•Œë¦¼"""
        payload = message['payload']
        user_id = payload['user_id']
        video_title = payload['video_title']
        
        print(f"ğŸ“§ Sending notification: User {user_id} is watching '{video_title}'")
        
        # ì¹œêµ¬ë“¤ì—ê²Œ ì•Œë¦¼ ì „ì†¡ (ì‹œë®¬ë ˆì´ì…˜)
        notification = {
            'type': 'watch_started',
            'user_id': user_id,
            'message': f"Your friend started watching {video_title}!",
            'timestamp': time.time()
        }
        
        self.sent_notifications.append(notification)
    
    def handle_recommendation_updated(self, message):
        """ì¶”ì²œ ì—…ë°ì´íŠ¸ ì•Œë¦¼"""
        payload = message['payload']
        user_id = payload['user_id']
        recommendations = payload['recommendations']
        
        print(f"ğŸ“± Sending push notification: New recommendations for user {user_id}")
        
        notification = {
            'type': 'recommendation_updated',
            'user_id': user_id,
            'message': f"We have new recommendations for you: {', '.join(recommendations[:2])}...",
            'timestamp': time.time()
        }
        
        self.sent_notifications.append(notification)

# ì¥ì•  ë‚´ì„±ì„ ê°€ì§„ ì„œë¹„ìŠ¤ (ì¼ë¶€ ì‹¤íŒ¨í•´ë„ ì‹œìŠ¤í…œ ë™ì‘)
class AnalyticsService:
    """ë¶„ì„ ì„œë¹„ìŠ¤ (ì¥ì•  ì‹œë®¬ë ˆì´ì…˜)"""
    
    def __init__(self, event_bus: RabbitMQEventBus):
        self.event_bus = event_bus
        self.failure_rate = 0.3  # 30% í™•ë¥ ë¡œ ì‹¤íŒ¨
        
        self.event_bus.subscribe(
            event_pattern='video.*',  # ëª¨ë“  ë¹„ë””ì˜¤ ê´€ë ¨ ì´ë²¤íŠ¸
            handler=self.handle_video_event,
            queue_name='analytics_service_queue'
        )
    
    def handle_video_event(self, message):
        """ë¹„ë””ì˜¤ ì´ë²¤íŠ¸ ë¶„ì„ (ì¼ë¶€ëŸ¬ ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜)"""
        import random
        
        if random.random() < self.failure_rate:
            print(f"ğŸ’¥ Analytics service failed to process {message['event_type']}")
            raise Exception("Analytics processing failed")
        
        print(f"ğŸ“Š Analytics processed: {message['event_type']}")

# Message Queue ì‹œë®¬ë ˆì´ì…˜  
def simulate_message_queue():
    print("=== Message Queue (RabbitMQ) ì‹œë®¬ë ˆì´ì…˜ ===")
    
    # RabbitMQ ì—°ê²°ì´ ì—†ìœ¼ë©´ Mock ì‚¬ìš©
    try:
        event_bus = RabbitMQEventBus()
    except Exception:
        print("âš ï¸  RabbitMQ not available, using mock implementation")
        event_bus = MockEventBus()
    
    # ì„œë¹„ìŠ¤ë“¤ ìƒì„±
    video_service = VideoService(event_bus)
    recommendation_service = RecommendationService(event_bus)
    notification_service = NotificationService(event_bus)
    analytics_service = AnalyticsService(event_bus)
    
    print("\n--- ì˜í™” ì‹œì²­ ì‹œì‘ ---")
    
    # ì‚¬ìš©ìë“¤ì´ ì˜í™” ì‹œì²­ ì‹œì‘
    users = [
        ('user123', 'video456', 'Avengers: Endgame'),
        ('user789', 'video123', 'The Dark Knight'),
        ('user456', 'video789', 'Iron Man')
    ]
    
    for user_id, video_id, video_title in users:
        result = video_service.start_watching(user_id, video_id, video_title)
        print(f"âœ… {result['message']} (session: {result['session_id']})")
    
    print("\n--- ì´ë²¤íŠ¸ ì²˜ë¦¬ ëŒ€ê¸° ---")
    time.sleep(3)  # ë¹„ë™ê¸° ì´ë²¤íŠ¸ ì²˜ë¦¬ ëŒ€ê¸°
    
    print(f"\n--- ê²°ê³¼ í™•ì¸ ---")
    print(f"ì¶”ì²œ ì„œë¹„ìŠ¤: {len(recommendation_service.user_preferences)}ëª…ì˜ ì·¨í–¥ ì—…ë°ì´íŠ¸")
    print(f"ì•Œë¦¼ ì„œë¹„ìŠ¤: {len(notification_service.sent_notifications)}ê°œ ì•Œë¦¼ ì „ì†¡")
    print("ğŸ“ˆ Analytics Service: ì¼ë¶€ ì‹¤íŒ¨í–ˆì§€ë§Œ ì „ì²´ ì‹œìŠ¤í…œì€ ì •ìƒ ë™ì‘")

# Mock Event Bus (RabbitMQ ì—†ì„ ë•Œ ì‚¬ìš©)
class MockEventBus:
    def __init__(self):
        self.subscribers = {}
        
    def publish(self, event_type, payload, routing_key=""):
        print(f"ğŸ“¢ [MOCK] Event published: {event_type}")
        # êµ¬ë…ìë“¤ì—ê²Œ ì „ë‹¬
        for pattern, handlers in self.subscribers.items():
            if self.matches_pattern(routing_key or event_type, pattern):
                for handler in handlers:
                    try:
                        message = {'event_type': event_type, 'payload': payload}
                        threading.Thread(target=handler, args=(message,), daemon=True).start()
                    except Exception as e:
                        print(f"âŒ Handler error: {e}")
    
    def subscribe(self, event_pattern, handler, queue_name=None):
        if event_pattern not in self.subscribers:
            self.subscribers[event_pattern] = []
        self.subscribers[event_pattern].append(handler)
        print(f"ğŸ” [MOCK] Subscribed to pattern '{event_pattern}'")
    
    def matches_pattern(self, event, pattern):
        # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡)
        if pattern.endswith('*'):
            return event.startswith(pattern[:-1])
        return event == pattern

# ì‹¤í–‰
simulate_message_queue()
```

### ğŸŒŠ Event Streaming ë°©ì‹ (Apache Kafka)

**íŠ¹ì§•**: ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ì„ ì—¬ëŸ¬ ì†Œë¹„ìê°€ ë…ë¦½ì ìœ¼ë¡œ ì†Œë¹„

```python
from kafka import KafkaProducer, KafkaConsumer
import json
import threading
import time
from typing import Dict, List

class KafkaEventStream:
    """Kafka ê¸°ë°˜ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°"""
    
    def __init__(self, bootstrap_servers=['localhost:9092']):
        self.bootstrap_servers = bootstrap_servers
        self.producer = None
        self.consumers = {}
        self.connect()
    
    def connect(self):
        """Kafka í”„ë¡œë“€ì„œ ì—°ê²°"""
        try:
            self.producer = KafkaProducer(
                bootstrap_servers=self.bootstrap_servers,
                value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                key_serializer=lambda k: k.encode('utf-8') if k else None,
                acks='all',  # ëª¨ë“  ë³µì œë³¸ì— ì“°ê¸° í™•ì¸
                retries=3,
                batch_size=16384,
                linger_ms=10
            )
            print("ğŸš€ Connected to Kafka")
        except Exception as e:
            print(f"âš ï¸  Kafka not available: {e}")
            self.producer = None
    
    def publish(self, topic: str, event_data: Dict, key: str = None):
        """ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰"""
        if not self.producer:
            print(f"ğŸ“¢ [MOCK] Publishing to {topic}: {event_data['event_type']}")
            return
        
        message = {
            'event_type': event_data.get('event_type', 'unknown'),
            'payload': event_data.get('payload', {}),
            'timestamp': time.time()
        }
        
        try:
            # ë¹„ë™ê¸° ì „ì†¡
            future = self.producer.send(
                topic=topic,
                value=message,
                key=key
            )
            
            # ì „ì†¡ í™•ì¸ (ì„ íƒì )
            record_metadata = future.get(timeout=10)
            print(f"ğŸ“¢ Event published to {topic} (partition: {record_metadata.partition}, offset: {record_metadata.offset})")
            
        except Exception as e:
            print(f"âŒ Failed to publish event: {e}")
    
    def subscribe(self, topics: List[str], group_id: str, handler):
        """ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ êµ¬ë…"""
        if not self.producer:  # Kafka ì‚¬ìš© ë¶ˆê°€ì‹œ Mock
            print(f"ğŸ” [MOCK] Subscribed to topics {topics} with group {group_id}")
            return
        
        try:
            consumer = KafkaConsumer(
                *topics,
                bootstrap_servers=self.bootstrap_servers,
                group_id=group_id,
                value_deserializer=lambda m: json.loads(m.decode('utf-8')),
                key_deserializer=lambda k: k.decode('utf-8') if k else None,
                auto_offset_reset='latest',  # ìµœì‹  ë©”ì‹œì§€ë¶€í„°
                enable_auto_commit=True
            )
            
            self.consumers[group_id] = consumer
            
            def consume_messages():
                print(f"ğŸ” Starting consumer {group_id} for topics {topics}")
                
                for message in consumer:
                    try:
                        print(f"ğŸ“¨ [{group_id}] Received from {message.topic}: {message.value['event_type']}")
                        
                        # í•¸ë“¤ëŸ¬ ì‹¤í–‰
                        handler(message.value, message.topic, message.partition, message.offset)
                        
                    except Exception as e:
                        print(f"âŒ [{group_id}] Handler error: {e}")
            
            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë©”ì‹œì§€ ì†Œë¹„
            consumer_thread = threading.Thread(target=consume_messages, daemon=True)
            consumer_thread.start()
            
        except Exception as e:
            print(f"âŒ Failed to create consumer {group_id}: {e}")

# Kafkaë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í”Œë«í¼
class StreamingVideoService:
    """ìŠ¤íŠ¸ë¦¬ë° ë¹„ë””ì˜¤ ì„œë¹„ìŠ¤"""
    
    def __init__(self, event_stream: KafkaEventStream):
        self.event_stream = event_stream
        self.viewing_sessions = {}
    
    def start_streaming(self, user_id: str, video_id: str, quality: str = "1080p"):
        """ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘"""
        session_id = f"stream_{user_id}_{int(time.time())}"
        
        session_data = {
            'user_id': user_id,
            'video_id': video_id,
            'quality': quality,
            'start_time': time.time(),
            'session_id': session_id
        }
        
        self.viewing_sessions[session_id] = session_data
        
        print(f"ğŸ¥ Streaming started: {video_id} for user {user_id} in {quality}")
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì´ë²¤íŠ¸ ë°œí–‰ (íŒŒí‹°ì…”ë‹ í‚¤: user_id)
        self.event_stream.publish(
            topic='video-events',
            event_data={
                'event_type': 'streaming.started',
                'payload': session_data
            },
            key=user_id  # ê°™ì€ ì‚¬ìš©ìì˜ ì´ë²¤íŠ¸ëŠ” ê°™ì€ íŒŒí‹°ì…˜ìœ¼ë¡œ
        )
        
        return {'status': 'success', 'session_id': session_id}
    
    def update_quality(self, session_id: str, new_quality: str):
        """ìŠ¤íŠ¸ë¦¬ë° í’ˆì§ˆ ë³€ê²½"""
        if session_id not in self.viewing_sessions:
            raise ValueError(f"Session {session_id} not found")
        
        session = self.viewing_sessions[session_id]
        old_quality = session['quality']
        session['quality'] = new_quality
        
        print(f"ğŸ“Š Quality changed: {old_quality} â†’ {new_quality} for session {session_id}")
        
        # í’ˆì§ˆ ë³€ê²½ ì´ë²¤íŠ¸ ë°œí–‰
        self.event_stream.publish(
            topic='video-events',
            event_data={
                'event_type': 'streaming.quality_changed',
                'payload': {
                    'session_id': session_id,
                    'user_id': session['user_id'],
                    'old_quality': old_quality,
                    'new_quality': new_quality
                }
            },
            key=session['user_id']
        )
    
    def send_heartbeat(self, session_id: str):
        """í•˜íŠ¸ë¹„íŠ¸ ì „ì†¡ (ì‹œì²­ ì§„í–‰ ìƒí™©)"""
        if session_id not in self.viewing_sessions:
            return
        
        session = self.viewing_sessions[session_id]
        
        # í•˜íŠ¸ë¹„íŠ¸ ì´ë²¤íŠ¸ ë°œí–‰ (ê³ ë¹ˆë„)
        self.event_stream.publish(
            topic='video-heartbeat',  # ë³„ë„ í† í”½ (ê³ ë¹ˆë„ ì´ë²¤íŠ¸)
            event_data={
                'event_type': 'streaming.heartbeat',
                'payload': {
                    'session_id': session_id,
                    'user_id': session['user_id'],
                    'current_time': time.time() - session['start_time']
                }
            },
            key=session['user_id']
        )

class RealTimeAnalyticsService:
    """ì‹¤ì‹œê°„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, event_stream: KafkaEventStream):
        self.event_stream = event_stream
        self.metrics = {
            'concurrent_viewers': 0,
            'quality_distribution': {},
            'user_sessions': {}
        }
        
        # ì—¬ëŸ¬ í† í”½ êµ¬ë…
        self.event_stream.subscribe(
            topics=['video-events', 'video-heartbeat'],
            group_id='realtime_analytics',
            handler=self.process_event
        )
    
    def process_event(self, message, topic, partition, offset):
        """ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        event_type = message['event_type']
        payload = message['payload']
        
        if event_type == 'streaming.started':
            self._handle_streaming_started(payload)
        elif event_type == 'streaming.quality_changed':
            self._handle_quality_changed(payload)
        elif event_type == 'streaming.heartbeat':
            self._handle_heartbeat(payload)
    
    def _handle_streaming_started(self, payload):
        """ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì²˜ë¦¬"""
        self.metrics['concurrent_viewers'] += 1
        
        quality = payload['quality']
        if quality not in self.metrics['quality_distribution']:
            self.metrics['quality_distribution'][quality] = 0
        self.metrics['quality_distribution'][quality] += 1
        
        self.metrics['user_sessions'][payload['session_id']] = payload
        
        print(f"ğŸ“Š Analytics: Concurrent viewers = {self.metrics['concurrent_viewers']}")
    
    def _handle_quality_changed(self, payload):
        """í’ˆì§ˆ ë³€ê²½ ì²˜ë¦¬"""
        old_quality = payload['old_quality']
        new_quality = payload['new_quality']
        
        # í’ˆì§ˆ ë¶„í¬ ì—…ë°ì´íŠ¸
        self.metrics['quality_distribution'][old_quality] -= 1
        if new_quality not in self.metrics['quality_distribution']:
            self.metrics['quality_distribution'][new_quality] = 0
        self.metrics['quality_distribution'][new_quality] += 1
        
        print(f"ğŸ“Š Quality distribution updated: {self.metrics['quality_distribution']}")
    
    def _handle_heartbeat(self, payload):
        """í•˜íŠ¸ë¹„íŠ¸ ì²˜ë¦¬ (ì„¸ì…˜ í™œì„±ë„ ì¶”ì )"""
        session_id = payload['session_id']
        if session_id in self.metrics['user_sessions']:
            self.metrics['user_sessions'][session_id]['last_heartbeat'] = time.time()
    
    def get_real_time_metrics(self):
        """ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        # ë¹„í™œì„± ì„¸ì…˜ ì •ë¦¬ (ë§ˆì§€ë§‰ í•˜íŠ¸ë¹„íŠ¸ í›„ 30ì´ˆ ê²½ê³¼)
        current_time = time.time()
        inactive_sessions = []
        
        for session_id, session_data in self.metrics['user_sessions'].items():
            if current_time - session_data.get('last_heartbeat', 0) > 30:
                inactive_sessions.append(session_id)
        
        for session_id in inactive_sessions:
            del self.metrics['user_sessions'][session_id]
            self.metrics['concurrent_viewers'] -= 1
        
        return self.metrics.copy()

class PersonalizationService:
    """ê°œì¸í™” ì„œë¹„ìŠ¤ (ML ê¸°ë°˜)"""
    
    def __init__(self, event_stream: KafkaEventStream):
        self.event_stream = event_stream
        self.user_profiles = {}
        
        # ì´ë²¤íŠ¸ êµ¬ë… (ë³„ë„ ì»¨ìŠˆë¨¸ ê·¸ë£¹)
        self.event_stream.subscribe(
            topics=['video-events'],
            group_id='personalization_ml',
            handler=self.update_user_profile
        )
    
    def update_user_profile(self, message, topic, partition, offset):
        """ì‚¬ìš©ì í”„ë¡œí•„ ì—…ë°ì´íŠ¸"""
        event_type = message['event_type']
        
        if event_type == 'streaming.started':
            payload = message['payload']
            user_id = payload['user_id']
            video_id = payload['video_id']
            quality = payload['quality']
            
            # ì‚¬ìš©ì í”„ë¡œí•„ ì—…ë°ì´íŠ¸
            if user_id not in self.user_profiles:
                self.user_profiles[user_id] = {
                    'watched_videos': [],
                    'preferred_quality': '1080p',
                    'viewing_hours': 0
                }
            
            profile = self.user_profiles[user_id]
            profile['watched_videos'].append(video_id)
            profile['preferred_quality'] = quality  # ìµœê·¼ ì„ íƒí•œ í’ˆì§ˆë¡œ ì—…ë°ì´íŠ¸
            
            # ML ëª¨ë¸ ì—…ë°ì´íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)
            print(f"ğŸ¤– Updating ML model for user {user_id} (watched: {len(profile['watched_videos'])} videos)")
            
            # ê°œì¸í™”ëœ ì¶”ì²œ ìƒì„± í›„ ì´ë²¤íŠ¸ ë°œí–‰
            recommendations = self.generate_recommendations(user_id)
            
            self.event_stream.publish(
                topic='recommendation-events',
                event_data={
                    'event_type': 'recommendation.updated',
                    'payload': {
                        'user_id': user_id,
                        'recommendations': recommendations,
                        'model_version': 'v2.1'
                    }
                },
                key=user_id
            )
    
    def generate_recommendations(self, user_id: str) -> List[str]:
        """ê°œì¸í™”ëœ ì¶”ì²œ ìƒì„±"""
        profile = self.user_profiles.get(user_id, {})
        watched_count = len(profile.get('watched_videos', []))
        
        # ê°„ë‹¨í•œ ì¶”ì²œ ë¡œì§
        if watched_count > 5:
            return ['Premium Content A', 'Premium Content B', 'Premium Content C']
        else:
            return ['Popular Content 1', 'Popular Content 2', 'Popular Content 3']

# Event Streaming ì‹œë®¬ë ˆì´ì…˜
def simulate_event_streaming():
    print("=== Event Streaming (Kafka) ì‹œë®¬ë ˆì´ì…˜ ===")
    
    # Kafka ì—°ê²°
    event_stream = KafkaEventStream()
    
    # ì„œë¹„ìŠ¤ë“¤ ìƒì„±
    video_service = StreamingVideoService(event_stream)
    analytics_service = RealTimeAnalyticsService(event_stream)
    personalization_service = PersonalizationService(event_stream)
    
    print("\n--- ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ---")
    
    # ì—¬ëŸ¬ ì‚¬ìš©ìê°€ ë™ì‹œ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    users = [
        ('alice', 'video_marvel_endgame', '4K'),
        ('bob', 'video_dark_knight', '1080p'),
        ('carol', 'video_inception', '720p'),
        ('david', 'video_matrix', '1080p')
    ]
    
    sessions = []
    for user_id, video_id, quality in users:
        result = video_service.start_streaming(user_id, video_id, quality)
        sessions.append(result['session_id'])
        time.sleep(0.1)  # ì•½ê°„ì˜ ì‹œê°„ì°¨
    
    print("\n--- ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì´ë²¤íŠ¸ë“¤ ---")
    
    # í’ˆì§ˆ ë³€ê²½
    video_service.update_quality(sessions[0], '1080p')  # Alice: 4K â†’ 1080p
    video_service.update_quality(sessions[2], '1080p')  # Carol: 720p â†’ 1080p
    
    # í•˜íŠ¸ë¹„íŠ¸ ì „ì†¡ (ì‹œë®¬ë ˆì´ì…˜)
    for _ in range(3):
        for session_id in sessions:
            video_service.send_heartbeat(session_id)
        time.sleep(1)
    
    print("\n--- ì´ë²¤íŠ¸ ì²˜ë¦¬ ëŒ€ê¸° ---")
    time.sleep(2)
    
    print("\n--- ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ í™•ì¸ ---")
    metrics = analytics_service.get_real_time_metrics()
    print(f"ë™ì‹œ ì‹œì²­ì: {metrics['concurrent_viewers']}ëª…")
    print(f"í’ˆì§ˆ ë¶„í¬: {metrics['quality_distribution']}")
    print(f"ê°œì¸í™” í”„ë¡œí•„: {len(personalization_service.user_profiles)}ëª…")

# ì‹¤í–‰
simulate_event_streaming()
```

## ğŸ“Š Event Sourcing: ëª¨ë“  ë³€ê²½ì„ ì´ë²¤íŠ¸ë¡œ ì €ì¥

### ğŸ—ƒï¸ Event Store êµ¬í˜„

ëª¨ë“  ë°ì´í„° ë³€ê²½ì„ ì´ë²¤íŠ¸ë¡œ ì €ì¥í•˜ì—¬ ì™„ì „í•œ ê°ì‚¬ ì¶”ì ê³¼ ì‹œì ë³„ ìƒíƒœ ë³µì›ì„ ì œê³µ:

```python
from dataclasses import dataclass
from datetime import datetime
from typing import List, Dict, Any, Optional
import json
import threading

@dataclass
class DomainEvent:
    """ë„ë©”ì¸ ì´ë²¤íŠ¸ ê¸°ë³¸ í´ë˜ìŠ¤"""
    aggregate_id: str
    event_type: str
    event_data: Dict[str, Any]
    event_version: int
    timestamp: datetime
    correlation_id: str = None
    causation_id: str = None

class EventStore:
    """ì´ë²¤íŠ¸ ì €ì¥ì†Œ"""
    
    def __init__(self):
        self.events: Dict[str, List[DomainEvent]] = {}  # aggregate_id -> events
        self.global_sequence = 0
        self.snapshots: Dict[str, Dict] = {}  # aggregate_id -> snapshot
        self.lock = threading.RLock()
        self.subscribers = []
    
    def append_events(self, aggregate_id: str, expected_version: int, events: List[DomainEvent]):
        """ì´ë²¤íŠ¸ ì¶”ê°€ (ë‚™ê´€ì  ë™ì‹œì„± ì œì–´)"""
        with self.lock:
            current_events = self.events.get(aggregate_id, [])
            current_version = len(current_events)
            
            # ë²„ì „ ì¶©ëŒ ê²€ì‚¬
            if expected_version != current_version:
                raise ConcurrencyException(
                    f"Expected version {expected_version}, but current version is {current_version}"
                )
            
            # ì´ë²¤íŠ¸ ì¶”ê°€
            if aggregate_id not in self.events:
                self.events[aggregate_id] = []
            
            for i, event in enumerate(events):
                event.event_version = current_version + i + 1
                self.events[aggregate_id].append(event)
                self.global_sequence += 1
                
                print(f"ğŸ“ Event stored: {event.event_type} v{event.event_version} for {aggregate_id}")
            
            # êµ¬ë…ìë“¤ì—ê²Œ ì•Œë¦¼
            for event in events:
                self._notify_subscribers(event)
    
    def get_events(self, aggregate_id: str, from_version: int = 0) -> List[DomainEvent]:
        """íŠ¹ì • Aggregateì˜ ì´ë²¤íŠ¸ ì¡°íšŒ"""
        events = self.events.get(aggregate_id, [])
        return [e for e in events if e.event_version > from_version]
    
    def save_snapshot(self, aggregate_id: str, snapshot: Dict[str, Any], version: int):
        """ìŠ¤ëƒ…ìƒ· ì €ì¥ (ì„±ëŠ¥ ìµœì í™”)"""
        self.snapshots[aggregate_id] = {
            'data': snapshot,
            'version': version,
            'timestamp': datetime.now()
        }
        print(f"ğŸ“¸ Snapshot saved for {aggregate_id} at version {version}")
    
    def get_snapshot(self, aggregate_id: str) -> Optional[Dict]:
        """ìŠ¤ëƒ…ìƒ· ì¡°íšŒ"""
        return self.snapshots.get(aggregate_id)
    
    def subscribe(self, handler):
        """ì´ë²¤íŠ¸ êµ¬ë…"""
        self.subscribers.append(handler)
    
    def _notify_subscribers(self, event: DomainEvent):
        """êµ¬ë…ìë“¤ì—ê²Œ ì´ë²¤íŠ¸ ì•Œë¦¼"""
        for subscriber in self.subscribers:
            try:
                threading.Thread(
                    target=subscriber,
                    args=(event,),
                    daemon=True
                ).start()
            except Exception as e:
                print(f"âŒ Subscriber notification failed: {e}")

class ConcurrencyException(Exception):
    """ë™ì‹œì„± ì¶©ëŒ ì˜ˆì™¸"""
    pass

# Event Sourcingì„ ì‚¬ìš©í•œ ì€í–‰ ê³„ì¢Œ ë„ë©”ì¸
class BankAccount:
    """ì€í–‰ ê³„ì¢Œ Aggregate"""
    
    def __init__(self, account_id: str):
        self.account_id = account_id
        self.balance = 0.0
        self.is_active = True
        self.overdraft_limit = 0.0
        self.version = 0
        self.uncommitted_events: List[DomainEvent] = []
    
    @classmethod
    def create_account(cls, account_id: str, initial_deposit: float, overdraft_limit: float = 0.0):
        """ìƒˆ ê³„ì¢Œ ìƒì„±"""
        account = cls(account_id)
        
        # ê³„ì¢Œ ìƒì„± ì´ë²¤íŠ¸ ì¶”ê°€
        event = DomainEvent(
            aggregate_id=account_id,
            event_type="AccountCreated",
            event_data={
                'initial_deposit': initial_deposit,
                'overdraft_limit': overdraft_limit
            },
            event_version=0,
            timestamp=datetime.now()
        )
        
        account._apply_event(event)
        return account
    
    def deposit(self, amount: float, description: str = ""):
        """ì…ê¸ˆ"""
        if amount <= 0:
            raise ValueError("Deposit amount must be positive")
        
        event = DomainEvent(
            aggregate_id=self.account_id,
            event_type="MoneyDeposited",
            event_data={
                'amount': amount,
                'description': description,
                'balance_before': self.balance
            },
            event_version=0,  # ì €ì¥ì‹œ ì„¤ì •ë¨
            timestamp=datetime.now()
        )
        
        self._apply_event(event)
    
    def withdraw(self, amount: float, description: str = ""):
        """ì¶œê¸ˆ"""
        if amount <= 0:
            raise ValueError("Withdrawal amount must be positive")
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§: ì”ê³  + ë§ˆì´ë„ˆìŠ¤ í•œë„ í™•ì¸
        available_balance = self.balance + self.overdraft_limit
        if amount > available_balance:
            raise InsufficientFundsException(
                f"Insufficient funds. Available: {available_balance}, Requested: {amount}"
            )
        
        event = DomainEvent(
            aggregate_id=self.account_id,
            event_type="MoneyWithdrawn",
            event_data={
                'amount': amount,
                'description': description,
                'balance_before': self.balance
            },
            event_version=0,
            timestamp=datetime.now()
        )
        
        self._apply_event(event)
    
    def close_account(self):
        """ê³„ì¢Œ í•´ì§€"""
        if not self.is_active:
            raise ValueError("Account is already closed")
        
        if self.balance < 0:
            raise ValueError("Cannot close account with negative balance")
        
        event = DomainEvent(
            aggregate_id=self.account_id,
            event_type="AccountClosed",
            event_data={
                'final_balance': self.balance
            },
            event_version=0,
            timestamp=datetime.now()
        )
        
        self._apply_event(event)
    
    def _apply_event(self, event: DomainEvent):
        """ì´ë²¤íŠ¸ ì ìš© (ìƒíƒœ ë³€ê²½)"""
        if event.event_type == "AccountCreated":
            self.balance = event.event_data['initial_deposit']
            self.overdraft_limit = event.event_data['overdraft_limit']
            self.is_active = True
            
        elif event.event_type == "MoneyDeposited":
            self.balance += event.event_data['amount']
            
        elif event.event_type == "MoneyWithdrawn":
            self.balance -= event.event_data['amount']
            
        elif event.event_type == "AccountClosed":
            self.is_active = False
        
        self.uncommitted_events.append(event)
    
    def mark_events_as_committed(self):
        """ì´ë²¤íŠ¸ ì»¤ë°‹ í‘œì‹œ"""
        self.version += len(self.uncommitted_events)
        self.uncommitted_events.clear()
    
    def get_uncommitted_events(self) -> List[DomainEvent]:
        """ë¯¸ì»¤ë°‹ ì´ë²¤íŠ¸ ì¡°íšŒ"""
        return self.uncommitted_events.copy()
    
    @classmethod
    def from_history(cls, account_id: str, events: List[DomainEvent]):
        """ì´ë²¤íŠ¸ íˆìŠ¤í† ë¦¬ë¡œë¶€í„° Aggregate ì¬êµ¬ì„±"""
        account = cls(account_id)
        
        for event in events:
            account._apply_event_without_recording(event)
        
        account.version = len(events)
        account.uncommitted_events.clear()
        return account
    
    def _apply_event_without_recording(self, event: DomainEvent):
        """ì´ë²¤íŠ¸ ì ìš© (ê¸°ë¡ ì—†ì´ - íˆìŠ¤í† ë¦¬ ì¬êµ¬ì„±ìš©)"""
        if event.event_type == "AccountCreated":
            self.balance = event.event_data['initial_deposit']
            self.overdraft_limit = event.event_data['overdraft_limit']
            self.is_active = True
            
        elif event.event_type == "MoneyDeposited":
            self.balance += event.event_data['amount']
            
        elif event.event_type == "MoneyWithdrawn":
            self.balance -= event.event_data['amount']
            
        elif event.event_type == "AccountClosed":
            self.is_active = False

class InsufficientFundsException(Exception):
    pass

# Repository íŒ¨í„´ with Event Sourcing
class EventSourcedAccountRepository:
    """Event Sourcing ê¸°ë°˜ ê³„ì¢Œ ë¦¬í¬ì§€í† ë¦¬"""
    
    def __init__(self, event_store: EventStore):
        self.event_store = event_store
    
    def save(self, account: BankAccount):
        """ê³„ì¢Œ ì €ì¥ (ì´ë²¤íŠ¸ ì €ì¥)"""
        uncommitted_events = account.get_uncommitted_events()
        
        if uncommitted_events:
            self.event_store.append_events(
                account.account_id,
                account.version,
                uncommitted_events
            )
            account.mark_events_as_committed()
    
    def get_by_id(self, account_id: str) -> Optional[BankAccount]:
        """IDë¡œ ê³„ì¢Œ ì¡°íšŒ (ì´ë²¤íŠ¸ ì¬êµ¬ì„±)"""
        # ìŠ¤ëƒ…ìƒ· í™•ì¸
        snapshot = self.event_store.get_snapshot(account_id)
        
        if snapshot:
            # ìŠ¤ëƒ…ìƒ·ì´ ìˆìœ¼ë©´ ìŠ¤ëƒ…ìƒ· ì´í›„ ì´ë²¤íŠ¸ë§Œ ì¡°íšŒ
            account = BankAccount(account_id)
            account.balance = snapshot['data']['balance']
            account.is_active = snapshot['data']['is_active']
            account.overdraft_limit = snapshot['data']['overdraft_limit']
            account.version = snapshot['version']
            
            # ìŠ¤ëƒ…ìƒ· ì´í›„ ì´ë²¤íŠ¸ë“¤ ì ìš©
            events_after_snapshot = self.event_store.get_events(account_id, snapshot['version'])
            for event in events_after_snapshot:
                account._apply_event_without_recording(event)
            
            account.version = snapshot['version'] + len(events_after_snapshot)
        else:
            # ìŠ¤ëƒ…ìƒ·ì´ ì—†ìœ¼ë©´ ëª¨ë“  ì´ë²¤íŠ¸ë¡œ ì¬êµ¬ì„±
            events = self.event_store.get_events(account_id)
            
            if not events:
                return None
                
            account = BankAccount.from_history(account_id, events)
        
        account.uncommitted_events.clear()
        return account
    
    def create_snapshot(self, account_id: str):
        """ìŠ¤ëƒ…ìƒ· ìƒì„± (ì„±ëŠ¥ ìµœì í™”)"""
        account = self.get_by_id(account_id)
        if account:
            snapshot_data = {
                'balance': account.balance,
                'is_active': account.is_active,
                'overdraft_limit': account.overdraft_limit
            }
            
            self.event_store.save_snapshot(account_id, snapshot_data, account.version)

# Event Sourcing ì‹œë®¬ë ˆì´ì…˜
def simulate_event_sourcing():
    print("=== Event Sourcing ì‹œë®¬ë ˆì´ì…˜ ===")
    
    # Event Storeì™€ Repository ìƒì„±
    event_store = EventStore()
    account_repo = EventSourcedAccountRepository(event_store)
    
    print("\n--- ê³„ì¢Œ ìƒì„± ë° ê±°ë˜ ---")
    
    # ìƒˆ ê³„ì¢Œ ìƒì„±
    account = BankAccount.create_account("ACC001", initial_deposit=1000.0, overdraft_limit=500.0)
    account_repo.save(account)
    
    print(f"âœ… ê³„ì¢Œ ìƒì„±: ACC001, ì´ˆê¸° ì”ê³ : $1000")
    
    # ê±°ë˜ ì‹¤í–‰
    transactions = [
        ('deposit', 500.0, 'ê¸‰ì—¬ ì…ê¸ˆ'),
        ('withdraw', 200.0, 'ATM ì¶œê¸ˆ'),
        ('withdraw', 800.0, 'ì„ëŒ€ë£Œ ì§€ë¶ˆ'),  
        ('deposit', 300.0, 'í™˜ê¸‰'),
        ('withdraw', 1200.0, 'ëŒ€ì¶œ ìƒí™˜')  # ë§ˆì´ë„ˆìŠ¤ í•œë„ ì‚¬ìš©
    ]
    
    for transaction_type, amount, description in transactions:
        try:
            if transaction_type == 'deposit':
                account.deposit(amount, description)
            else:
                account.withdraw(amount, description)
            
            account_repo.save(account)
            print(f"âœ… {transaction_type.title()}: ${amount} - {description} (ì”ê³ : ${account.balance})")
            
        except Exception as e:
            print(f"âŒ {transaction_type.title()} ì‹¤íŒ¨: {e}")
    
    print(f"\ní˜„ì¬ ì”ê³ : ${account.balance}")
    
    print("\n--- ì´ë²¤íŠ¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ---")
    events = event_store.get_events("ACC001")
    for event in events:
        print(f"ğŸ“ {event.timestamp.strftime('%H:%M:%S')} - {event.event_type}: {event.event_data}")
    
    print("\n--- íŠ¹ì • ì‹œì  ìƒíƒœ ë³µì› ---")
    # ì²˜ìŒ 3ê°œ ì´ë²¤íŠ¸ë§Œìœ¼ë¡œ ìƒíƒœ ë³µì›
    partial_events = events[:3]
    past_account = BankAccount.from_history("ACC001", partial_events)
    print(f"ğŸ“… 3ë²ˆì§¸ ì´ë²¤íŠ¸ ì‹œì  ì”ê³ : ${past_account.balance}")
    
    print("\n--- ìŠ¤ëƒ…ìƒ· ìƒì„± ë° í™œìš© ---")
    account_repo.create_snapshot("ACC001")
    
    # ìŠ¤ëƒ…ìƒ· ê¸°ë°˜ìœ¼ë¡œ ê³„ì¢Œ ì¬êµ¬ì„±
    recovered_account = account_repo.get_by_id("ACC001")
    print(f"ğŸ“¸ ìŠ¤ëƒ…ìƒ· ê¸°ë°˜ ë³µêµ¬ ì”ê³ : ${recovered_account.balance}")
    
    print("\n--- ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ---")
    try:
        # ë™ì‹œì— ë‘ ê°œì˜ ê±°ë˜ ì‹œë„ (ë²„ì „ ì¶©ëŒ)
        account1 = account_repo.get_by_id("ACC001")
        account2 = account_repo.get_by_id("ACC001")
        
        account1.deposit(100.0, "Transaction 1")
        account2.deposit(200.0, "Transaction 2")
        
        account_repo.save(account1)  # ì„±ê³µ
        account_repo.save(account2)  # ë²„ì „ ì¶©ëŒë¡œ ì‹¤íŒ¨í•´ì•¼ í•¨
        
    except ConcurrencyException as e:
        print(f"âœ… ë™ì‹œì„± ì¶©ëŒ ê°ì§€: {e}")

# ì‹¤í–‰
simulate_event_sourcing()
```

## ğŸ’¡ Event-Driven Architectureì—ì„œ ë°°ìš´ í•µì‹¬ êµí›ˆ

### 1. ë™ê¸° vs ë¹„ë™ê¸°ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„

```bash
ğŸš€ ë¹„ë™ê¸° ì´ë²¤íŠ¸ ì²˜ë¦¬ì˜ ì¥ì :
- ë†’ì€ ì²˜ë¦¬ëŸ‰ê³¼ í™•ì¥ì„±
- ì„œë¹„ìŠ¤ ê°„ ëŠìŠ¨í•œ ê²°í•©
- ì¥ì•  ê²©ë¦¬ì™€ ë‚´ì„±
- ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ìš©ì´

âš ï¸ ë¹„ë™ê¸°ì˜ ë³µì¡ì„±:
- ìµœì¢… ì¼ê´€ì„± (Eventual Consistency)
- ì´ë²¤íŠ¸ ìˆœì„œ ë³´ì¥ ì–´ë ¤ì›€
- ë””ë²„ê¹…ê³¼ ì¶”ì ì˜ ë³µì¡ì„±
- ì¤‘ë³µ ì²˜ë¦¬ ê°€ëŠ¥ì„±
```

### 2. Message Queue vs Event Streaming ì„ íƒ

```bash
ğŸ“® Message Queue (RabbitMQ):
âœ… ì í•©í•œ ê²½ìš°: ì‘ì—… í, íŠ¸ëœì­ì…˜ ì²˜ë¦¬, ìˆœì„œ ë³´ì¥ í•„ìš”
âœ… ì¥ì : ë©”ì‹œì§€ ë³´ì¥, ë¼ìš°íŒ… ìœ ì—°ì„±, ë°±í”„ë ˆì…” ì²˜ë¦¬
âŒ ë‹¨ì : ë©”ì‹œì§€ ì†Œëª¨ í›„ ì‚¬ë¼ì§, ì¬ì²˜ë¦¬ ì–´ë ¤ì›€

ğŸŒŠ Event Streaming (Kafka):  
âœ… ì í•©í•œ ê²½ìš°: ì‹¤ì‹œê°„ ë¶„ì„, ì´ë²¤íŠ¸ ì†Œì‹±, ë‹¤ì¤‘ ì†Œë¹„ì
âœ… ì¥ì : ì´ë²¤íŠ¸ ë³´ì¡´, ì¬ì²˜ë¦¬ ê°€ëŠ¥, ë†’ì€ ì²˜ë¦¬ëŸ‰
âŒ ë‹¨ì : ë³µì¡í•œ ì„¤ì •, ì €ì¥ì†Œ ìš©ëŸ‰ í•„ìš”
```

### 3. Event Sourcingì˜ ê°•ë ¥í•¨ê³¼ ë³µì¡ì„±

```bash
ğŸ’ª Event Sourcing ì¥ì :
- ì™„ì „í•œ ê°ì‚¬ ì¶”ì 
- ì‹œì ë³„ ìƒíƒœ ë³µì› ê°€ëŠ¥
- ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì˜ ëª…í™•í•œ í‘œí˜„
- í™•ì¥ ê°€ëŠ¥í•œ ì½ê¸° ëª¨ë¸

âš ï¸ Event Sourcing ë„ì „ê³¼ì œ:
- ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ ì§„í™”
- ìŠ¤ëƒ…ìƒ· ê´€ë¦¬
- ì¿¼ë¦¬ì˜ ë³µì¡ì„±
- ê°œë°œì í•™ìŠµ ê³¡ì„ 
```

### 4. ì‹¤ë¬´ ì ìš© ê°€ì´ë“œë¼ì¸

```python
# ì–¸ì œ Event-Drivenì„ ì‚¬ìš©í• ê¹Œ?
âœ… ì‚¬ìš©í•˜ê¸° ì¢‹ì€ ê²½ìš°:
- ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°„ í†µì‹ 
- ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ
- ë°ì´í„° íŒŒì´í”„ë¼ì¸
- ê°ì‚¬ì™€ ë¡œê¹…
- ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë²¤íŠ¸ ì¶”ì 

âŒ í”¼í•´ì•¼ í•  ê²½ìš°:
- ë‹¨ìˆœí•œ CRUD ì• í”Œë¦¬ì¼€ì´ì…˜
- ê°•í•œ ì¼ê´€ì„±ì´ í•„ìˆ˜ì¸ ì‹œìŠ¤í…œ
- ì‹¤ì‹œê°„ ì‘ë‹µì´ ì¤‘ìš”í•œ ì¸í„°í˜ì´ìŠ¤
- íŒ€ì˜ ê¸°ìˆ  ì—­ëŸ‰ì´ ë¶€ì¡±í•œ ê²½ìš°
```

## ğŸ¯ Event-Driven Architecture ì„±ìˆ™ë„ ëª¨ë¸

### Level 1: Event Notification

```bash
ğŸ“¢ ê¸°ë³¸ ë ˆë²¨: ë‹¨ìˆœ ì´ë²¤íŠ¸ ì•Œë¦¼
íŠ¹ì§•:
- ì„œë¹„ìŠ¤ ê°„ ìƒíƒœ ë³€ê²½ ì•Œë¦¼
- ë™ê¸° í˜¸ì¶œ ëŒ€ì‹  ë¹„ë™ê¸° ì´ë²¤íŠ¸
- ê¸°ë³¸ì ì¸ ë””ì»¤í”Œë§

ì˜ˆì‹œ:
UserService â†’ UserCreated ì´ë²¤íŠ¸ â†’ EmailServiceê°€ í™˜ì˜ ì´ë©”ì¼ ë°œì†¡
```

### Level 2: Event-Carried State Transfer

```bash
ğŸ“¦ ì¤‘ê¸‰ ë ˆë²¨: ì´ë²¤íŠ¸ì— ìƒíƒœ ì •ë³´ í¬í•¨
íŠ¹ì§•:
- ì´ë²¤íŠ¸ì— í•„ìš”í•œ ëª¨ë“  ë°ì´í„° í¬í•¨
- ìˆ˜ì‹  ì„œë¹„ìŠ¤ê°€ ì™¸ë¶€ í˜¸ì¶œ ì—†ì´ ì²˜ë¦¬ ê°€ëŠ¥
- ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ê°ì†Œ

ì˜ˆì‹œ:
OrderCreated ì´ë²¤íŠ¸ì— ì‚¬ìš©ì ì •ë³´, ìƒí’ˆ ì •ë³´ ëª¨ë‘ í¬í•¨
```

### Level 3: Event Sourcing

```bash
ğŸ—„ï¸ ê³ ê¸‰ ë ˆë²¨: ì´ë²¤íŠ¸ê°€ ìœ ì¼í•œ ì§„ì‹¤ì˜ ì›ì²œ
íŠ¹ì§•:
- ëª¨ë“  ìƒíƒœ ë³€ê²½ì„ ì´ë²¤íŠ¸ë¡œ ì €ì¥
- ì–¸ì œë“  ê³¼ê±° ìƒíƒœ ë³µì› ê°€ëŠ¥
- ì™„ë²½í•œ ê°ì‚¬ ì¶”ì 

ì˜ˆì‹œ:
AccountCreated, MoneyDeposited, MoneyWithdrawn ì´ë²¤íŠ¸ë¡œ ê³„ì¢Œ ì”ê³  ê´€ë¦¬
```

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

Event-Driven Architectureì˜ í•µì‹¬ì„ ë§ˆìŠ¤í„°í–ˆìŠµë‹ˆë‹¤. ì´ì œ **14ì¥ Distributed Systems**ì˜ ëª¨ë“  ì£¼ì œë¥¼ ë‹¤ë¤˜ìœ¼ë‹ˆ, ì‹¤ì „ì—ì„œ ì´ëŸ° íŒ¨í„´ë“¤ì„ ì¡°í•©í•´ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì—°ìŠµí•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

"ì´ë²¤íŠ¸ëŠ” ì‹œìŠ¤í…œì„ ì—°ê²°í•˜ëŠ” í˜ˆê´€ì…ë‹ˆë‹¤. ì ì ˆí•œ ì´ë²¤íŠ¸ ì„¤ê³„ë¡œ í™•ì¥ ê°€ëŠ¥í•˜ê³  ìœ ì§€ë³´ìˆ˜ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!" ğŸŒŠâš¡
