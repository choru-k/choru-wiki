---
tags:
  - DistributedSystems
  - Sharding
  - Replication
  - ConsistentHashing
  - Guide
---

# 14.3 ë¶„ì‚° ë°ì´í„° ê´€ë¦¬ - ë°ì´í„°ë¥¼ ë‚˜ëˆ„ê³  ë³µì œí•˜ëŠ” ê¸°ìˆ 

## ì„œë¡ : 2021ë…„ 7ì›”, ë°ì´í„°ë² ì´ìŠ¤ê°€ í„°ì§„ ë‚ 

ìš°ë¦¬ ì†Œì…œë¯¸ë””ì–´ í”Œë«í¼ì´ ê°‘ìê¸° ì¸ê¸°ë¥¼ ëŒë©´ì„œ ì‚¬ìš©ì ìˆ˜ê°€ 10ë§Œ ëª…ì—ì„œ 1000ë§Œ ëª…ìœ¼ë¡œ í­ì¦í–ˆë˜ ë•Œì…ë‹ˆë‹¤. ë‹¨ì¼ MySQL ì„œë²„ë¡œëŠ” ë” ì´ìƒ ê°ë‹¹í•  ìˆ˜ ì—†ëŠ” ìƒí™©ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.

### ğŸ”¥ 7ì›” 15ì¼ ìƒˆë²½ 3ì‹œ: ë°ì´í„°ë² ì´ìŠ¤ì˜ í•œê³„

```bash
# ê¸°ì¡´ ì‹œìŠ¤í…œ (ë‹¨ì¼ MySQL)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        MySQL Server             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚     Users Table             â”‚â”‚
â”‚  â”‚  - 10,000,000 rows         â”‚â”‚  
â”‚  â”‚  - 500GB data              â”‚â”‚
â”‚  â”‚  - 2GB RAM buffer          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# ì„±ëŠ¥ ì§€í‘œ (ì°¸ì‚¬ ìƒí™©)
Query Average Time: 15.3ì´ˆ  # í‰ì†Œ 0.1ì´ˆ
Active Connections: 2000/2000  # í’€ ê³ ê°ˆ
Lock Wait Time: 45ì´ˆ
Disk I/O: 98% ì‚¬ìš©ë¥ 
CPU: 99% ì§€ì†ì  ì‚¬ìš©

# ì‹¤ì œ ì¿¼ë¦¬ ì„±ëŠ¥
mysql> SELECT * FROM users WHERE id = 5000000;
# 15ì´ˆ í›„ì— ê²°ê³¼ ë°˜í™˜... ğŸ˜±

mysql> INSERT INTO posts (user_id, content) VALUES (1234567, 'Hello');
# 30ì´ˆ í›„ì— ì™„ë£Œ... ğŸ˜­
```

**ìƒˆë²½ 3:30 - CTOì˜ ê¸´ê¸‰ ê²°ì •**

"ë‹¨ì¼ ì„œë²„ë¡œëŠ” í•œê³„ë‹¤. ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì!"

í•˜ì§€ë§Œ ì–´ë–»ê²Œ ë‚˜ëˆŒ ê²ƒì¸ê°€? ì–´ë–»ê²Œ ë³µì œí•  ê²ƒì¸ê°€? ë°ì´í„° ì¼ê´€ì„±ì€ ì–´ë–»ê²Œ ë³´ì¥í•  ê²ƒì¸ê°€?

ì´ë•Œë¶€í„° **ë¶„ì‚° ë°ì´í„° ê´€ë¦¬**ì˜ ì—¬ì •ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ”„ ë°ì´í„° ë¶„ì‚°ì˜ ë‘ ê°€ì§€ ì¶•

```mermaid
graph TD
    subgraph "ë°ì´í„° ë¶„ì‚° ì „ëµ"
        H[Horizontal Partitioning<br/>ìˆ˜í‰ ë¶„í• <br/>Sharding]
        V[Vertical Partitioning<br/>ìˆ˜ì§ ë¶„í• <br/>Column ë¶„ë¦¬]
    end
    
    subgraph "ë°ì´í„° ë³µì œ ì „ëµ"
        R1[Master-Slave<br/>Replication]
        R2[Master-Master<br/>Replication]
        R3[Multi-Master<br/>with Conflict Resolution]
    end
    
    subgraph "ê²°í•©ëœ ì•„í‚¤í…ì²˜"
        SR[Sharded Replication<br/>ê° ìƒ¤ë“œë¥¼ ë³µì œ]
        RS[Replicated Sharding<br/>ë³µì œë³¸ì„ ìƒ¤ë”©]
    end
    
    H --> SR
    R1 --> SR
    H --> RS
    R2 --> RS
    
    style H fill:#e3f2fd
    style R1 fill:#c8e6c9
    style SR fill:#fff3e0
```

## ğŸ”ª Sharding: ë°ì´í„°ë¥¼ ë‚˜ëˆ„ëŠ” ê¸°ìˆ 

### ğŸ“Š Sharding ì „ëµ ë¹„êµ

#### 1. Range-based Sharding (ë²”ìœ„ ê¸°ë°˜ ìƒ¤ë”©)

```python
class RangeBasedSharding:
    def __init__(self):
        self.shards = {
            'shard1': {'range': (0, 3333333), 'server': 'db1.company.com'},
            'shard2': {'range': (3333334, 6666666), 'server': 'db2.company.com'},
            'shard3': {'range': (6666667, 9999999), 'server': 'db3.company.com'}
        }
    
    def get_shard(self, user_id):
        """ì‚¬ìš©ì ID ë²”ìœ„ì— ë”°ë¥¸ ìƒ¤ë“œ ê²°ì •"""
        for shard_name, config in self.shards.items():
            start, end = config['range']
            if start <= user_id <= end:
                return config['server']
        
        raise ValueError(f"No shard found for user_id: {user_id}")
    
    def query_user(self, user_id):
        """ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ"""
        shard_server = self.get_shard(user_id)
        
        # í•´ë‹¹ ìƒ¤ë“œì—ì„œ ì¿¼ë¦¬ ì‹¤í–‰
        db = connect_to_database(shard_server)
        result = db.execute("""
            SELECT * FROM users WHERE id = %s
        """, user_id)
        
        return result

# ì‹¤ì œ ì‚¬ìš©
sharding = RangeBasedSharding()

# ë‹¤ë¥¸ ìƒ¤ë“œë“¤ì— ë¶„ì‚° ì €ì¥
print(sharding.get_shard(1000000))    # db1.company.com
print(sharding.get_shard(5000000))    # db2.company.com  
print(sharding.get_shard(8000000))    # db3.company.com

# ì¥ì : ë²”ìœ„ ì¿¼ë¦¬ íš¨ìœ¨ì 
# SELECT * FROM users WHERE id BETWEEN 1000000 AND 2000000
# â†’ í•˜ë‚˜ì˜ ìƒ¤ë“œì—ì„œë§Œ ì‹¤í–‰

# ë‹¨ì : Hot Spot ë¬¸ì œ
# ìƒˆ ì‚¬ìš©ìë“¤ì´ ê³„ì† ë†’ì€ IDë¥¼ ê°€ì§ â†’ shard3ì— ë¶€í•˜ ì§‘ì¤‘
```

**Range Shardingì˜ Hot Spot ë¬¸ì œ í•´ê²°**:

```python
class ImprovedRangeSharding:
    def __init__(self):
        # ë™ì  ë²”ìœ„ ì¡°ì •ì„ ìœ„í•œ ë©”íƒ€ë°ì´í„°
        self.shard_metadata = {
            'shard1': {'range': (0, 2000000), 'load': 0.3},
            'shard2': {'range': (2000001, 5000000), 'load': 0.5}, 
            'shard3': {'range': (5000001, 10000000), 'load': 0.9}  # í•«ìŠ¤íŒŸ!
        }
    
    def rebalance_shards(self):
        """ë¶€í•˜ê°€ ë†’ì€ ìƒ¤ë“œ ë¶„í• """
        for shard_id, metadata in self.shard_metadata.items():
            if metadata['load'] > 0.8:  # 80% ì´ìƒ ë¶€í•˜
                print(f"Rebalancing {shard_id} (load: {metadata['load']})")
                
                # ìƒˆ ìƒ¤ë“œ ìƒì„±
                self.split_shard(shard_id)
    
    def split_shard(self, shard_id):
        """ìƒ¤ë“œ ë¶„í• """
        old_metadata = self.shard_metadata[shard_id]
        start, end = old_metadata['range']
        mid = (start + end) // 2
        
        # ê¸°ì¡´ ìƒ¤ë“œ ë²”ìœ„ ì¶•ì†Œ
        self.shard_metadata[shard_id]['range'] = (start, mid)
        
        # ìƒˆ ìƒ¤ë“œ ìƒì„±  
        new_shard_id = f"{shard_id}_split"
        self.shard_metadata[new_shard_id] = {
            'range': (mid + 1, end),
            'load': 0.0
        }
        
        print(f"Created {new_shard_id} for range ({mid+1}, {end})")
```

#### 2. Hash-based Sharding (í•´ì‹œ ê¸°ë°˜ ìƒ¤ë”©)

```python
import hashlib

class HashBasedSharding:
    def __init__(self, num_shards=8):
        self.num_shards = num_shards
        self.shards = {
            i: f"db{i}.company.com" for i in range(num_shards)
        }
    
    def get_shard(self, key):
        """í‚¤ì˜ í•´ì‹œê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒ¤ë“œ ê²°ì •"""
        hash_value = int(hashlib.md5(str(key).encode()).hexdigest(), 16)
        shard_id = hash_value % self.num_shards
        return self.shards[shard_id]
    
    def query_user(self, user_id):
        """ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ"""
        shard_server = self.get_shard(user_id)
        
        db = connect_to_database(shard_server)
        result = db.execute("""
            SELECT * FROM users WHERE id = %s
        """, user_id)
        
        return result
    
    def query_by_email(self, email):
        """ì´ë©”ì¼ë¡œ ì‚¬ìš©ì ê²€ìƒ‰ (ëª¨ë“  ìƒ¤ë“œ ì¡°íšŒ í•„ìš”)"""
        results = []
        
        # ğŸš¨ ë¬¸ì œ: ëª¨ë“  ìƒ¤ë“œë¥¼ ì¡°íšŒí•´ì•¼ í•¨
        for shard_id, server in self.shards.items():
            db = connect_to_database(server)
            result = db.execute("""
                SELECT * FROM users WHERE email = %s
            """, email)
            if result:
                results.extend(result)
        
        return results

# ì‹¤ì œ ì‚¬ìš©
hash_sharding = HashBasedSharding(num_shards=8)

# ë™ì¼í•œ í‚¤ëŠ” í•­ìƒ ê°™ì€ ìƒ¤ë“œ
print(hash_sharding.get_shard("user123"))  # db3.company.com
print(hash_sharding.get_shard("user123"))  # db3.company.com (ë™ì¼)

# ë‹¤ë¥¸ í‚¤ëŠ” ê³ ë¥´ê²Œ ë¶„ì‚°
print(hash_sharding.get_shard("user456"))  # db7.company.com
print(hash_sharding.get_shard("user789"))  # db1.company.com

# ì¥ì : ê· ë“±í•œ ë¶„ì‚°, Hot Spot ë°©ì§€
# ë‹¨ì : ë²”ìœ„ ì¿¼ë¦¬ ë¶ˆê°€, ìƒ¤ë“œ ì¶”ê°€ ì‹œ ëŒ€ê·œëª¨ ì¬ë°°ì¹˜ í•„ìš”
```

**Hash Shardingì˜ í™•ì¥ì„± ë¬¸ì œ**:

```python
# ë¬¸ì œ ìƒí™©: ìƒ¤ë“œ ì¶”ê°€ ì‹œ ëŒ€ë¶€ë¶„ ë°ì´í„° ì´ë™ í•„ìš”
class NaiveHashSharding:
    def __init__(self, num_shards):
        self.num_shards = num_shards
    
    def get_shard(self, key):
        return hash(key) % self.num_shards

# ê¸°ì¡´: 8ê°œ ìƒ¤ë“œ
old_sharding = NaiveHashSharding(8)
user_123_shard = old_sharding.get_shard("user123")  # shard 3

# í™•ì¥: 16ê°œ ìƒ¤ë“œ
new_sharding = NaiveHashSharding(16) 
user_123_new_shard = new_sharding.get_shard("user123")  # shard 11

# ğŸ˜± ê²°ê³¼: ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°ê°€ ë‹¤ë¥¸ ìƒ¤ë“œë¡œ ì´ë™í•´ì•¼ í•¨!
# í™•ì¥ ì‹œ ì „ì²´ ì‹œìŠ¤í…œ ë‹¤ìš´íƒ€ì„ ë°œìƒ
```

#### 3. Consistent Hashing (ì¼ê´€ëœ í•´ì‹±)

ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê²ƒì´ **Consistent Hashing**ì…ë‹ˆë‹¤:

```python
import hashlib
import bisect

class ConsistentHashing:
    def __init__(self, nodes=None, replicas=3):
        self.replicas = replicas  # ê°€ìƒ ë…¸ë“œ ê°œìˆ˜
        self.ring = {}           # í•´ì‹œë§
        self.sorted_keys = []    # ì •ë ¬ëœ í‚¤ ëª©ë¡
        
        if nodes:
            for node in nodes:
                self.add_node(node)
    
    def _hash(self, key):
        """SHA-1 í•´ì‹œ í•¨ìˆ˜"""
        return int(hashlib.sha1(str(key).encode()).hexdigest(), 16)
    
    def add_node(self, node):
        """ë…¸ë“œ ì¶”ê°€ (ê°€ìƒ ë…¸ë“œë“¤ ìƒì„±)"""
        for i in range(self.replicas):
            virtual_key = self._hash(f"{node}:{i}")
            self.ring[virtual_key] = node
            bisect.insort(self.sorted_keys, virtual_key)
        
        print(f"Added node {node} with {self.replicas} virtual nodes")
    
    def remove_node(self, node):
        """ë…¸ë“œ ì œê±°"""
        for i in range(self.replicas):
            virtual_key = self._hash(f"{node}:{i}")
            del self.ring[virtual_key]
            self.sorted_keys.remove(virtual_key)
        
        print(f"Removed node {node}")
    
    def get_node(self, key):
        """í‚¤ì— í•´ë‹¹í•˜ëŠ” ë…¸ë“œ ì°¾ê¸°"""
        if not self.ring:
            return None
        
        hash_key = self._hash(key)
        
        # ì‹œê³„ë°©í–¥ìœ¼ë¡œ ì²« ë²ˆì§¸ ë…¸ë“œ ì°¾ê¸°
        idx = bisect.bisect_right(self.sorted_keys, hash_key)
        
        # ë§ì˜ ëì— ë„ë‹¬í•˜ë©´ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°
        if idx == len(self.sorted_keys):
            idx = 0
        
        return self.ring[self.sorted_keys[idx]]
    
    def get_nodes(self, key, count=3):
        """í‚¤ì— í•´ë‹¹í•˜ëŠ” ì—¬ëŸ¬ ë…¸ë“œ ì°¾ê¸° (ë³µì œìš©)"""
        if not self.ring:
            return []
        
        hash_key = self._hash(key)
        idx = bisect.bisect_right(self.sorted_keys, hash_key)
        
        nodes = []
        seen = set()
        
        for _ in range(count):
            if idx >= len(self.sorted_keys):
                idx = 0
            
            node = self.ring[self.sorted_keys[idx]]
            if node not in seen:
                nodes.append(node)
                seen.add(node)
            
            idx += 1
            
            if len(nodes) == count or len(seen) == len(set(self.ring.values())):
                break
        
        return nodes

# Consistent Hashing ì‹œë®¬ë ˆì´ì…˜
def simulate_consistent_hashing():
    print("=== Consistent Hashing ì‹œë®¬ë ˆì´ì…˜ ===")
    
    # ì´ˆê¸° 4ê°œ ë…¸ë“œ
    ch = ConsistentHashing(['server1', 'server2', 'server3', 'server4'])
    
    # í…ŒìŠ¤íŠ¸ í‚¤ë“¤ì˜ ì´ˆê¸° ë°°ì¹˜
    test_keys = ['user123', 'user456', 'user789', 'user111', 'user222']
    
    print("\n--- ì´ˆê¸° ë°°ì¹˜ ---")
    initial_placement = {}
    for key in test_keys:
        node = ch.get_node(key)
        initial_placement[key] = node
        print(f"{key} â†’ {node}")
    
    # ìƒˆ ë…¸ë“œ ì¶”ê°€
    print("\n--- server5 ì¶”ê°€ í›„ ---")
    ch.add_node('server5')
    
    moved_keys = 0
    for key in test_keys:
        old_node = initial_placement[key]
        new_node = ch.get_node(key) 
        
        if old_node != new_node:
            moved_keys += 1
            print(f"{key}: {old_node} â†’ {new_node} âœ¨ ì´ë™")
        else:
            print(f"{key}: {old_node} (ê·¸ëŒ€ë¡œ)")
    
    print(f"\nì´ë™ëœ í‚¤: {moved_keys}/{len(test_keys)} ({moved_keys/len(test_keys)*100:.1f}%)")
    print("ğŸ‘ ì¼ë°˜ í•´ì‹±ì´ë¼ë©´ 80% ì´ìƒ ì´ë™í–ˆì„ ê²ƒ!")

# ì‹¤í–‰
simulate_consistent_hashing()

# ì˜ˆìƒ ì¶œë ¥:
# === Consistent Hashing ì‹œë®¬ë ˆì´ì…˜ ===
# Added node server1 with 3 virtual nodes
# Added node server2 with 3 virtual nodes  
# Added node server3 with 3 virtual nodes
# Added node server4 with 3 virtual nodes
#
# --- ì´ˆê¸° ë°°ì¹˜ ---
# user123 â†’ server2
# user456 â†’ server4
# user789 â†’ server1
# user111 â†’ server3
# user222 â†’ server2
#
# --- server5 ì¶”ê°€ í›„ ---
# Added node server5 with 3 virtual nodes
# user123: server2 (ê·¸ëŒ€ë¡œ)
# user456: server4 (ê·¸ëŒ€ë¡œ)  
# user789: server5 âœ¨ ì´ë™
# user111: server3 (ê·¸ëŒ€ë¡œ)
# user222: server2 (ê·¸ëŒ€ë¡œ)
#
# ì´ë™ëœ í‚¤: 1/5 (20.0%)
# ğŸ‘ ì¼ë°˜ í•´ì‹±ì´ë¼ë©´ 80% ì´ìƒ ì´ë™í–ˆì„ ê²ƒ!
```

### ğŸ¯ ì‹¤ì „ ìƒ¤ë”© ì•„í‚¤í…ì²˜ ì„¤ê³„

```python
class ProductionShardingSystem:
    """ì‹¤ì œ ìš´ì˜ í™˜ê²½ì„ ê³ ë ¤í•œ ìƒ¤ë”© ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.consistent_hash = ConsistentHashing()
        self.shard_metadata = {}  # ìƒ¤ë“œë³„ ë©”íƒ€ë°ì´í„°
        self.connection_pools = {}  # ì»¤ë„¥ì…˜ í’€
        
        # ì´ˆê¸° ìƒ¤ë“œ ì„¤ì •
        self.initialize_shards()
    
    def initialize_shards(self):
        """ì´ˆê¸° ìƒ¤ë“œ êµ¬ì„±"""
        initial_shards = [
            'shard1-primary.db.company.com',
            'shard2-primary.db.company.com', 
            'shard3-primary.db.company.com',
            'shard4-primary.db.company.com'
        ]
        
        for shard in initial_shards:
            self.add_shard(shard)
    
    def add_shard(self, shard_address):
        """ìƒˆ ìƒ¤ë“œ ì¶”ê°€"""
        # Consistent Hashì— ì¶”ê°€
        self.consistent_hash.add_node(shard_address)
        
        # ë©”íƒ€ë°ì´í„° ì„¤ì •
        self.shard_metadata[shard_address] = {
            'status': 'active',
            'created_at': time.time(),
            'replica_addresses': [
                shard_address.replace('primary', 'replica1'),
                shard_address.replace('primary', 'replica2')
            ]
        }
        
        # ì»¤ë„¥ì…˜ í’€ ìƒì„±
        self.connection_pools[shard_address] = create_connection_pool(
            shard_address, 
            pool_size=20
        )
        
        print(f"Shard added: {shard_address}")
    
    def write_data(self, key, data):
        """ë°ì´í„° ì“°ê¸° (ë³µì œ í¬í•¨)"""
        # Primary ìƒ¤ë“œ ê²°ì •
        primary_shard = self.consistent_hash.get_node(key)
        
        # ë³µì œë³¸ ìƒ¤ë“œë“¤ ê²°ì •
        replica_shards = self.shard_metadata[primary_shard]['replica_addresses']
        
        try:
            # 1. Primaryì— ì“°ê¸°
            primary_conn = self.connection_pools[primary_shard]
            primary_conn.execute("""
                INSERT INTO data_table (key, value, created_at) 
                VALUES (%s, %s, %s)
            """, key, data, time.time())
            
            # 2. ë³µì œë³¸ë“¤ì— ë¹„ë™ê¸° ì“°ê¸°
            for replica in replica_shards:
                self.async_write_to_replica(replica, key, data)
            
            return {'status': 'success', 'shard': primary_shard}
            
        except DatabaseException as e:
            # Primary ì¥ì•  ì‹œ ë³µì œë³¸ì„ Primaryë¡œ ìŠ¹ê²©
            return self.handle_primary_failure(primary_shard, key, data)
    
    def read_data(self, key, consistency_level='eventual'):
        """ë°ì´í„° ì½ê¸° (ì¼ê´€ì„± ë ˆë²¨ ì„ íƒ)"""
        primary_shard = self.consistent_hash.get_node(key)
        
        if consistency_level == 'strong':
            # ê°•í•œ ì¼ê´€ì„±: Primaryì—ì„œë§Œ ì½ê¸°
            conn = self.connection_pools[primary_shard]
            result = conn.execute("""
                SELECT value FROM data_table WHERE key = %s
            """, key)
            return result
            
        elif consistency_level == 'eventual':
            # ìµœì¢… ì¼ê´€ì„±: ì•„ë¬´ ë³µì œë³¸ì—ì„œ ì½ê¸° (ì„±ëŠ¥ ìš°ì„ )
            all_shards = [primary_shard] + \
                        self.shard_metadata[primary_shard]['replica_addresses']
            
            # ê°€ì¥ ë¹ ë¥¸ ì‘ë‹µì„ ì£¼ëŠ” ìƒ¤ë“œì—ì„œ ì½ê¸°
            return self.read_from_fastest_replica(all_shards, key)
    
    def read_from_fastest_replica(self, shards, key):
        """ì—¬ëŸ¬ ë³µì œë³¸ ì¤‘ ê°€ì¥ ë¹ ë¥¸ ì‘ë‹µ ì‚¬ìš©"""
        import asyncio
        import concurrent.futures
        
        async def read_from_shard(shard):
            conn = self.connection_pools[shard]
            return conn.execute("""
                SELECT value FROM data_table WHERE key = %s
            """, key)
        
        # ëª¨ë“  ë³µì œë³¸ì—ì„œ ë™ì‹œì— ì½ê¸° ì‹œë„
        with concurrent.futures.ThreadPoolExecutor() as executor:
            futures = [
                executor.submit(self.read_from_single_shard, shard, key) 
                for shard in shards
            ]
            
            # ì²« ë²ˆì§¸ë¡œ ì™„ë£Œëœ ê²°ê³¼ ë°˜í™˜
            for future in concurrent.futures.as_completed(futures):
                try:
                    result = future.result(timeout=1.0)  # 1ì´ˆ íƒ€ì„ì•„ì›ƒ
                    return result
                except Exception:
                    continue
        
        raise Exception("All replicas failed")
    
    def rebalance_data(self):
        """ë°ì´í„° ë¦¬ë°¸ëŸ°ì‹±"""
        print("Starting data rebalancing...")
        
        # ê° ìƒ¤ë“œì˜ ë¶€í•˜ í™•ì¸
        shard_loads = self.analyze_shard_loads()
        
        for shard, load in shard_loads.items():
            if load > 0.8:  # 80% ì´ìƒ ë¶€í•˜
                print(f"High load detected on {shard}: {load:.2f}")
                self.scale_out_shard(shard)
    
    def scale_out_shard(self, overloaded_shard):
        """ê³¼ë¶€í•˜ ìƒ¤ë“œ í™•ì¥"""
        # ìƒˆ ìƒ¤ë“œ ìƒì„±
        new_shard = self.create_new_shard()
        
        # ë°ì´í„° ì´ë™ (ë°±ê·¸ë¼ìš´ë“œ)
        self.migrate_data_async(overloaded_shard, new_shard)
        
        print(f"Scaling out {overloaded_shard} â†’ {new_shard}")

# ì‚¬ìš© ì˜ˆì‹œ
sharding_system = ProductionShardingSystem()

# ë°ì´í„° ì“°ê¸° (ìë™ ìƒ¤ë”©)
result = sharding_system.write_data("user:123456", {
    "name": "John Doe",
    "email": "john@example.com",  
    "created_at": "2023-07-15T10:30:00Z"
})
print(f"Write result: {result}")

# ë°ì´í„° ì½ê¸° (ê°•í•œ ì¼ê´€ì„±)
user_data = sharding_system.read_data("user:123456", consistency_level='strong')
print(f"User data: {user_data}")

# ë°ì´í„° ì½ê¸° (ìµœì¢… ì¼ê´€ì„± - ë¹ ë¥¸ ì„±ëŠ¥)
user_data_fast = sharding_system.read_data("user:123456", consistency_level='eventual')
print(f"User data (fast): {user_data_fast}")
```

## ğŸ”„ Replication: ë°ì´í„°ë¥¼ ë³µì œí•˜ëŠ” ì „ëµ

### ğŸ“ˆ Master-Slave Replication

```python
class MasterSlaveReplication:
    def __init__(self, master_address, slave_addresses):
        self.master = DatabaseConnection(master_address)
        self.slaves = [DatabaseConnection(addr) for addr in slave_addresses]
        self.slave_lag_info = {}  # ë³µì œ ì§€ì—° ì •ë³´
        
    def write(self, query, params):
        """ì“°ê¸°ëŠ” Masterì—ë§Œ"""
        try:
            result = self.master.execute(query, params)
            
            # ë³µì œ ì§€ì—° ì‹œê°„ ì¶”ì 
            self.track_replication_lag()
            
            return result
        except Exception as e:
            raise MasterFailureException(f"Master write failed: {e}")
    
    def read(self, query, params, consistency_level='eventual'):
        """ì½ê¸° ì „ëµ ì„ íƒ"""
        if consistency_level == 'strong':
            # ê°•í•œ ì¼ê´€ì„±: Masterì—ì„œë§Œ ì½ê¸°
            return self.master.execute(query, params)
        
        elif consistency_level == 'eventual':
            # ìµœì¢… ì¼ê´€ì„±: ë¶€í•˜ ë¶„ì‚°ëœ ì½ê¸°
            return self.read_from_slave_with_load_balancing(query, params)
        
        elif consistency_level == 'read_your_writes':
            # Read-your-writes: ìµœê·¼ ì“´ ì‚¬ìš©ìëŠ” Masterì—ì„œ ì½ê¸°
            return self.read_with_session_consistency(query, params)
    
    def read_from_slave_with_load_balancing(self, query, params):
        """ìŠ¬ë ˆì´ë¸Œ ë¡œë“œë°¸ëŸ°ì‹± ì½ê¸°"""
        # ê±´ê°•í•œ ìŠ¬ë ˆì´ë¸Œë“¤ ì¤‘ì—ì„œ ì„ íƒ
        healthy_slaves = self.get_healthy_slaves()
        
        if not healthy_slaves:
            # ëª¨ë“  ìŠ¬ë ˆì´ë¸Œê°€ ì£½ì—ˆìœ¼ë©´ Masterì—ì„œ ì½ê¸°
            print("âš ï¸  All slaves down, reading from master")
            return self.master.execute(query, params)
        
        # Round-robin ë°©ì‹ìœ¼ë¡œ ìŠ¬ë ˆì´ë¸Œ ì„ íƒ
        selected_slave = self.select_slave_round_robin(healthy_slaves)
        
        try:
            return selected_slave.execute(query, params)
        except Exception as e:
            # ìŠ¬ë ˆì´ë¸Œ ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ìŠ¬ë ˆì´ë¸Œë‚˜ Masterë¡œ í´ë°±
            print(f"âš ï¸  Slave failed, trying fallback: {e}")
            return self.read_fallback(query, params, failed_slave=selected_slave)
    
    def track_replication_lag(self):
        """ë³µì œ ì§€ì—° ëª¨ë‹ˆí„°ë§"""
        master_position = self.master.execute("SHOW MASTER STATUS")[0]['Position']
        
        for i, slave in enumerate(self.slaves):
            try:
                slave_status = slave.execute("SHOW SLAVE STATUS")[0]
                slave_position = slave_status['Exec_Master_Log_Pos']
                
                lag = master_position - slave_position
                self.slave_lag_info[f"slave_{i}"] = {
                    'lag_bytes': lag,
                    'seconds_behind_master': slave_status['Seconds_Behind_Master'],
                    'last_checked': time.time()
                }
                
            except Exception as e:
                print(f"âš ï¸  Slave {i} health check failed: {e}")
                self.slave_lag_info[f"slave_{i}"] = {
                    'status': 'unhealthy',
                    'error': str(e),
                    'last_checked': time.time()
                }
    
    def get_healthy_slaves(self):
        """ê±´ê°•í•œ ìŠ¬ë ˆì´ë¸Œ ëª©ë¡ ë°˜í™˜"""
        healthy = []
        
        for i, slave in enumerate(self.slaves):
            slave_key = f"slave_{i}"
            if slave_key in self.slave_lag_info:
                lag_info = self.slave_lag_info[slave_key]
                
                # ë³µì œ ì§€ì—°ì´ 5ì´ˆ ì´ë‚´ì´ê³  ì—ëŸ¬ê°€ ì—†ìœ¼ë©´ ê±´ê°•í•¨
                if (lag_info.get('seconds_behind_master', 0) < 5 and 
                    'error' not in lag_info):
                    healthy.append(slave)
        
        return healthy

# ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ
replication = MasterSlaveReplication(
    master_address="master-db.company.com:3306",
    slave_addresses=[
        "slave1-db.company.com:3306", 
        "slave2-db.company.com:3306",
        "slave3-db.company.com:3306"
    ]
)

# ì“°ê¸° (Masterì—ë§Œ)
replication.write("""
    INSERT INTO posts (user_id, content, created_at) 
    VALUES (%s, %s, %s)
""", (12345, "Hello World", time.time()))

# ì½ê¸° (ìµœì¢… ì¼ê´€ì„± - ë¹ ë¦„)
posts = replication.read("""
    SELECT * FROM posts WHERE user_id = %s ORDER BY created_at DESC LIMIT 10
""", (12345,), consistency_level='eventual')

# ì½ê¸° (ê°•í•œ ì¼ê´€ì„± - ëŠë¦¼)
latest_post = replication.read("""
    SELECT * FROM posts WHERE user_id = %s ORDER BY created_at DESC LIMIT 1  
""", (12345,), consistency_level='strong')
```

### ğŸ”„ Master-Master Replication

```python
class MasterMasterReplication:
    def __init__(self, node_addresses):
        self.nodes = [DatabaseConnection(addr) for addr in node_addresses]
        self.current_node = 0  # í˜„ì¬ í™œì„± ë…¸ë“œ
        self.conflict_resolver = ConflictResolver()
        
    def write(self, query, params, node_preference=None):
        """ì–‘ë°©í–¥ ë³µì œ ì“°ê¸°"""
        target_node = node_preference or self.current_node
        
        try:
            # ì„ íƒëœ ë…¸ë“œì— ì“°ê¸°
            result = self.nodes[target_node].execute(query, params)
            
            # ë‹¤ë¥¸ ë…¸ë“œë“¤ë¡œ ë¹„ë™ê¸° ë³µì œ (MySQLì˜ ê²½ìš° ìë™)
            self.verify_replication_health()
            
            return result
            
        except Exception as e:
            # í˜„ì¬ ë…¸ë“œ ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ë…¸ë“œë¡œ ìë™ ì „í™˜
            return self.failover_write(query, params, failed_node=target_node)
    
    def failover_write(self, query, params, failed_node):
        """ì¥ì• ì¡°ì¹˜ ì“°ê¸°"""
        print(f"âš ï¸  Node {failed_node} failed, attempting failover")
        
        for i, node in enumerate(self.nodes):
            if i == failed_node:
                continue
                
            try:
                result = node.execute(query, params)
                self.current_node = i  # í™œì„± ë…¸ë“œ ë³€ê²½
                print(f"âœ… Failover successful to node {i}")
                return result
                
            except Exception as e:
                print(f"âš ï¸  Failover to node {i} also failed: {e}")
                continue
        
        raise AllNodesFailed("All master nodes are down")
    
    def read(self, query, params):
        """ì½ê¸° (ì•„ë¬´ ë…¸ë“œì—ì„œë‚˜)"""
        # ë¼ìš´ë“œ ë¡œë¹ˆìœ¼ë¡œ ë¶€í•˜ ë¶„ì‚°
        node_index = self.get_next_read_node()
        
        try:
            return self.nodes[node_index].execute(query, params)
        except Exception:
            # í•´ë‹¹ ë…¸ë“œ ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ë…¸ë“œì—ì„œ ì¬ì‹œë„
            return self.read_with_fallback(query, params, failed_node=node_index)
    
    def handle_write_conflict(self, table, record_id):
        """ì“°ê¸° ì¶©ëŒ í•´ê²°"""
        print(f"ğŸ”¥ Write conflict detected on {table}:{record_id}")
        
        # ê° ë…¸ë“œì—ì„œ í•´ë‹¹ ë ˆì½”ë“œ ë²„ì „ ìˆ˜ì§‘
        versions = {}
        for i, node in enumerate(self.nodes):
            try:
                record = node.execute(f"""
                    SELECT *, last_modified FROM {table} WHERE id = %s
                """, (record_id,))
                
                if record:
                    versions[f"node_{i}"] = record[0]
                    
            except Exception as e:
                print(f"Failed to get version from node {i}: {e}")
        
        if len(versions) > 1:
            # ì—¬ëŸ¬ ë²„ì „ì´ ì¡´ì¬ â†’ ì¶©ëŒ!
            resolved_version = self.conflict_resolver.resolve(versions)
            
            # í•´ê²°ëœ ë²„ì „ì„ ëª¨ë“  ë…¸ë“œì— ì ìš©
            self.apply_resolved_version(table, record_id, resolved_version)
            
            return resolved_version
        else:
            return list(versions.values())[0] if versions else None

class ConflictResolver:
    """ì¶©ëŒ í•´ê²° ì „ëµë“¤"""
    
    def resolve(self, versions):
        """ì¶©ëŒ í•´ê²° (ì—¬ëŸ¬ ì „ëµ ì¤‘ ì„ íƒ)"""
        # ì „ëµ 1: Last-Write-Wins (ë§ˆì§€ë§‰ ì“°ê¸° ìŠ¹ë¦¬)
        return self.last_write_wins(versions)
    
    def last_write_wins(self, versions):
        """ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì„ íƒ"""
        latest_version = None
        latest_timestamp = 0
        
        for node_id, version in versions.items():
            timestamp = version.get('last_modified', 0)
            if timestamp > latest_timestamp:
                latest_timestamp = timestamp
                latest_version = version
        
        print(f"âœ… Conflict resolved by Last-Write-Wins: {latest_timestamp}")
        return latest_version
    
    def vector_clock_resolution(self, versions):
        """Vector Clock ê¸°ë°˜ ì¶©ëŒ í•´ê²°"""
        # Vector Clock êµ¬í˜„ (ë³µì¡í•˜ë¯€ë¡œ ê°œë…ë§Œ)
        # ê° ë…¸ë“œë³„ë¡œ ë…¼ë¦¬ì  ì‹œê³„ë¥¼ ìœ ì§€í•˜ì—¬ ì¸ê³¼ê´€ê³„ íŒŒì•…
        pass
    
    def application_level_merge(self, versions):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ì—ì„œ ë³‘í•©"""
        # ì˜ˆ: ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ì˜ ê²½ìš° ê° í•„ë“œë³„ë¡œ ìµœì‹  ê°’ ì„ íƒ
        merged = {}
        
        for node_id, version in versions.items():
            for field, value in version.items():
                if field not in merged or version['last_modified'] > merged.get('last_modified', 0):
                    merged[field] = value
        
        return merged

# ì‚¬ìš© ì˜ˆì‹œ
mm_replication = MasterMasterReplication([
    "master1-db.company.com:3306",
    "master2-db.company.com:3306"  
])

# ì–‘ë°©í–¥ ë³µì œ ì“°ê¸°
mm_replication.write("""
    UPDATE users SET last_login = %s WHERE id = %s
""", (time.time(), 12345))

# ì¶©ëŒ ìƒí™© ì‹œë®¬ë ˆì´ì…˜
# Node 1: UPDATE users SET name = 'John' WHERE id = 12345 at 10:00:00
# Node 2: UPDATE users SET name = 'Johnny' WHERE id = 12345 at 10:00:05
# â†’ ì¶©ëŒ ê°ì§€ ë° í•´ê²° (Last-Write-Wins: 'Johnny')
```

## ğŸ¯ Vector Clocks: ë¶„ì‚° í™˜ê²½ì—ì„œì˜ ì‹œê°„ ì¶”ì 

```python
class VectorClock:
    """ë¶„ì‚° ì‹œìŠ¤í…œì˜ ë…¼ë¦¬ì  ì‹œê³„"""
    
    def __init__(self, node_id, nodes):
        self.node_id = node_id
        self.nodes = nodes
        self.clock = {node: 0 for node in nodes}  # ê° ë…¸ë“œë³„ ì‹œê³„
    
    def tick(self):
        """ë¡œì»¬ ì´ë²¤íŠ¸ ë°œìƒ ì‹œ ìì‹ ì˜ ì‹œê³„ ì¦ê°€"""
        self.clock[self.node_id] += 1
    
    def update(self, other_clock):
        """ë‹¤ë¥¸ ë…¸ë“œì˜ ë©”ì‹œì§€ ë°›ì„ ë•Œ ì‹œê³„ ì—…ë°ì´íŠ¸"""
        # ê° ë…¸ë“œë³„ë¡œ ìµœëŒ€ê°’ ì„ íƒ í›„ ìì‹ ì˜ ì‹œê³„ ì¦ê°€
        for node in self.nodes:
            self.clock[node] = max(self.clock[node], other_clock.get(node, 0))
        
        # ìì‹ ì˜ ì‹œê³„ ì¦ê°€
        self.clock[self.node_id] += 1
    
    def compare(self, other_clock):
        """ë‘ Vector Clock ë¹„êµ"""
        # self < other: ëª¨ë“  componentê°€ ì‘ê±°ë‚˜ ê°™ê³ , ì ì–´ë„ í•˜ë‚˜ëŠ” ì‘ìŒ
        self_less = all(self.clock[node] <= other_clock.get(node, 0) for node in self.nodes)
        any_smaller = any(self.clock[node] < other_clock.get(node, 0) for node in self.nodes)
        
        # other < self: ë°˜ëŒ€
        other_less = all(other_clock.get(node, 0) <= self.clock[node] for node in self.nodes) 
        any_other_smaller = any(other_clock.get(node, 0) < self.clock[node] for node in self.nodes)
        
        if self_less and any_smaller:
            return -1  # self < other (happens-before)
        elif other_less and any_other_smaller:
            return 1   # self > other  
        else:
            return 0   # concurrent (ë™ì‹œ ë°œìƒ)

# Vector Clockì„ í™œìš©í•œ ë¶„ì‚° ë°ì´í„° ë²„ì „ ê´€ë¦¬
class DistributedDataWithVectorClock:
    def __init__(self, node_id, peer_nodes):
        self.node_id = node_id
        self.vector_clock = VectorClock(node_id, [node_id] + peer_nodes)
        self.data_store = {}  # key -> {value, vector_clock}
        
    def write_local(self, key, value):
        """ë¡œì»¬ ì“°ê¸°"""
        # Vector Clock ì¦ê°€
        self.vector_clock.tick()
        
        # ë°ì´í„° ì €ì¥
        self.data_store[key] = {
            'value': value,
            'vector_clock': self.vector_clock.clock.copy(),
            'node_id': self.node_id,
            'timestamp': time.time()
        }
        
        print(f"Node {self.node_id}: Write {key}={value}, VC={self.vector_clock.clock}")
    
    def receive_update(self, key, value, sender_clock, sender_node):
        """ë‹¤ë¥¸ ë…¸ë“œë¡œë¶€í„° ì—…ë°ì´íŠ¸ ë°›ê¸°"""
        # Vector Clock ì—…ë°ì´íŠ¸
        self.vector_clock.update(sender_clock)
        
        if key not in self.data_store:
            # ìƒˆë¡œìš´ í‚¤: ê·¸ëŒ€ë¡œ ì €ì¥
            self.data_store[key] = {
                'value': value,
                'vector_clock': sender_clock.copy(),
                'node_id': sender_node,
                'timestamp': time.time()
            }
            print(f"Node {self.node_id}: New key {key}={value}")
            
        else:
            # ê¸°ì¡´ í‚¤: ì¶©ëŒ í•´ê²° í•„ìš”
            local_data = self.data_store[key]
            comparison = self.compare_vector_clocks(local_data['vector_clock'], sender_clock)
            
            if comparison == -1:
                # ë¡œì»¬ < ì›ê²©: ì›ê²© ë°ì´í„°ê°€ ë” ìƒˆë¡œì›€
                print(f"Node {self.node_id}: Updating {key}: {local_data['value']} â†’ {value}")
                self.data_store[key] = {
                    'value': value,
                    'vector_clock': sender_clock.copy(),
                    'node_id': sender_node,
                    'timestamp': time.time()
                }
                
            elif comparison == 1:
                # ë¡œì»¬ > ì›ê²©: ë¡œì»¬ ë°ì´í„°ê°€ ë” ìƒˆë¡œì›€  
                print(f"Node {self.node_id}: Ignoring older update for {key}")
                
            else:
                # ë™ì‹œ ë°œìƒ: ì¶©ëŒ!
                print(f"ğŸ”¥ Node {self.node_id}: Conflict detected for {key}!")
                self.handle_conflict(key, value, sender_clock, sender_node)
    
    def handle_conflict(self, key, remote_value, remote_clock, sender_node):
        """Vector Clock ì¶©ëŒ í•´ê²°"""
        local_data = self.data_store[key]
        
        print(f"Conflict resolution for {key}:")
        print(f"  Local: {local_data['value']} (VC: {local_data['vector_clock']})")
        print(f"  Remote: {remote_value} (VC: {remote_clock})")
        
        # í•´ê²° ì „ëµ 1: ë…¸ë“œ ID ê¸°ì¤€ (deterministic)
        if self.node_id < sender_node:
            # ë…¸ë“œ IDê°€ ì‘ì€ ìª½ ìš°ì„ 
            print(f"  Resolution: Keep local (node {self.node_id} < {sender_node})")
        else:
            # ì›ê²© ë°ì´í„° ì±„íƒ
            print(f"  Resolution: Accept remote (node {self.node_id} > {sender_node})")
            self.data_store[key] = {
                'value': remote_value,
                'vector_clock': remote_clock.copy(),
                'node_id': sender_node,
                'timestamp': time.time()
            }
        
        # í•´ê²° ì „ëµ 2: ì• í”Œë¦¬ì¼€ì´ì…˜ë³„ ë³‘í•©
        # ì˜ˆ: Setì˜ ê²½ìš° í•©ì§‘í•©, Counterì˜ ê²½ìš° í•©ê³„ ë“±

# Vector Clock ì‹œë®¬ë ˆì´ì…˜
def simulate_vector_clocks():
    print("=== Vector Clock Conflict Resolution ì‹œë®¬ë ˆì´ì…˜ ===")
    
    # 3ê°œ ë…¸ë“œ ë„¤íŠ¸ì›Œí¬
    nodes = ['A', 'B', 'C']
    node_a = DistributedDataWithVectorClock('A', ['B', 'C'])
    node_b = DistributedDataWithVectorClock('B', ['A', 'C']) 
    node_c = DistributedDataWithVectorClock('C', ['A', 'B'])
    
    print("\n--- ìˆœì°¨ì  ì—…ë°ì´íŠ¸ (ì¶©ëŒ ì—†ìŒ) ---")
    # 1. Aê°€ ì“°ê¸°
    node_a.write_local('user:123', 'Alice')
    
    # 2. Bê°€ Aì˜ ì—…ë°ì´íŠ¸ë¥¼ ë°›ìŒ
    node_b.receive_update('user:123', 'Alice', 
                         node_a.data_store['user:123']['vector_clock'], 'A')
    
    # 3. Bê°€ ì—…ë°ì´íŠ¸
    node_b.write_local('user:123', 'Alice Smith')
    
    # 4. Aê°€ Bì˜ ì—…ë°ì´íŠ¸ë¥¼ ë°›ìŒ  
    node_a.receive_update('user:123', 'Alice Smith',
                         node_b.data_store['user:123']['vector_clock'], 'B')
    
    print("\n--- ë™ì‹œ ì—…ë°ì´íŠ¸ (ì¶©ëŒ ë°œìƒ) ---")
    
    # 5. Aì™€ Cê°€ ë™ì‹œì— ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸ (ë„¤íŠ¸ì›Œí¬ ë¶„í•  ìƒí™©)
    node_a.write_local('user:456', 'Bob')
    node_c.write_local('user:456', 'Robert')
    
    # 6. ë„¤íŠ¸ì›Œí¬ ë³µêµ¬ í›„ ì„œë¡œì˜ ì—…ë°ì´íŠ¸ë¥¼ ë°›ìŒ
    print("\n--- ë„¤íŠ¸ì›Œí¬ ë³µêµ¬: ì¶©ëŒ ê°ì§€ ë° í•´ê²° ---")
    node_a.receive_update('user:456', 'Robert',
                         node_c.data_store['user:456']['vector_clock'], 'C')
    
    node_c.receive_update('user:456', 'Bob', 
                         node_a.data_store['user:456']['vector_clock'], 'A')

# ì‹¤í–‰
simulate_vector_clocks()
```

## ğŸ’¡ ë¶„ì‚° ë°ì´í„° ê´€ë¦¬ì—ì„œ ë°°ìš´ í•µì‹¬ êµí›ˆ

### 1. ì™„ë²½í•œ ë¶„ì‚° ë°ì´í„° ì‹œìŠ¤í…œì€ ì—†ë‹¤

```bash
âœ… ë°›ì•„ë“¤ì—¬ì•¼ í•  í˜„ì‹¤:
- Shardingí•˜ë©´ íŠ¸ëœì­ì…˜ ë³µì¡ì„± ì¦ê°€
- Replicationí•˜ë©´ ì¼ê´€ì„± ë¬¸ì œ ë°œìƒ
- í™•ì¥ì„±ê³¼ ì¼ê´€ì„±ì€ íŠ¸ë ˆì´ë“œì˜¤í”„
- ë„¤íŠ¸ì›Œí¬ ë¶„í• ê³¼ ì¶©ëŒì€ ì •ìƒ ìƒí™©
```

### 2. ë°ì´í„° íŠ¹ì„±ì— ë§ëŠ” ì „ëµ ì„ íƒ

```python
# ì‚¬ìš©ì í”„ë¡œí•„: ê°•í•œ ì¼ê´€ì„± í•„ìš”
user_data = read_with_strong_consistency(user_id)

# ìƒí’ˆ ì¶”ì²œ: ìµœì¢… ì¼ê´€ì„±ìœ¼ë¡œ ì¶©ë¶„  
recommendations = read_with_eventual_consistency(user_id)

# ì‹¤ì‹œê°„ í”¼ë“œ: ì•½í•œ ì¼ê´€ì„±ë„ í—ˆìš©
feed = read_from_nearest_replica(user_id)
```

### 3. ê´€ì°°ê³¼ ë³´ìƒì„ í†µí•œ ì‹¤ìš©ì  ì ‘ê·¼

```python
# ì´ìƒì ì¸ ACID ëŒ€ì‹  ì‹¤ìš©ì  í•´ê²°ì±…
def practical_distributed_transaction():
    try:
        # 1. ë‚™ê´€ì  ì²˜ë¦¬ (ë¹ ë¦„)
        result = process_optimistically()
        
        # 2. ë¹„ë™ê¸° ê²€ì¦
        schedule_async_validation(result.transaction_id)
        
        # 3. ë¬¸ì œ ë°œê²¬ ì‹œ ë³´ìƒ
        if validation_failed:
            compensate_transaction(result.transaction_id)
            notify_user_with_apology()
        
        return result
    except Exception:
        # 4. ì‹¤íŒ¨ ì‹œ ëª…í™•í•œ ì—ëŸ¬
        raise TransactionFailedException()
```

### 4. ëª¨ë‹ˆí„°ë§ê³¼ ìë™í™”ì˜ ì¤‘ìš”ì„±

```bash
ğŸ“Š ë¶„ì‚° ë°ì´í„° ì‹œìŠ¤í…œ í•„ìˆ˜ ì§€í‘œ:
- ìƒ¤ë“œë³„ ë¶€í•˜ ë¶„ì‚°
- ë³µì œ ì§€ì—° ì‹œê°„  
- ì¶©ëŒ ë°œìƒ ë¹ˆë„
- ë°ì´í„° ì´ë™ ì§„í–‰ë¥ 
- ë…¸ë“œ í—¬ìŠ¤ì²´í¬ ìƒíƒœ
```

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

ë¶„ì‚° ë°ì´í„° ê´€ë¦¬ì˜ ê¸°ë°˜ì„ ë‹¤ì¡Œìœ¼ë‹ˆ, [14.4 ë¶„ì‚° ì‹œìŠ¤í…œ íŒ¨í„´](04-distributed-patterns.md)ì—ì„œëŠ” Circuit Breaker, Saga, CQRS ê°™ì€ ì‹¤ì „ íŒ¨í„´ë“¤ì„ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤.

"ë°ì´í„°ë¥¼ ë‚˜ëˆ„ë©´ ë³µì¡í•´ì§€ì§€ë§Œ, ì˜¬ë°”ë¥¸ ì „ëµê³¼ ë„êµ¬ê°€ ìˆìœ¼ë©´ í™•ì¥ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!" ğŸ—„ï¸âš¡
