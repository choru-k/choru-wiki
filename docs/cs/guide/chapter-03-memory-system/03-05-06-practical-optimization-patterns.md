---
tags:
  - advanced
  - hands-on
  - madvise
  - memory_mapping
  - mmap
  - performance_optimization
  - quick-read
  - streaming_processing
  - ì‹œìŠ¤í…œí”„ë¡œê·¸ë˜ë°
difficulty: ADVANCED
learning_time: "0-0ì‹œê°„"
main_topic: "ì‹œìŠ¤í…œ í”„ë¡œê·¸ë˜ë°"
priority_score: 0
---

# 3.5.6: ì‹¤ìš©ì  ìµœì í™” íŒ¨í„´

## ì¢…í•©ì ì¸ ë©”ëª¨ë¦¬ ë§¤í•‘ ìµœì í™”

ì‹¤ë¬´ì—ì„œëŠ” ë‹¨ì¼ ê¸°ë²•ì´ ì•„ë‹Œ ì—¬ëŸ¬ ìµœì í™” ê¸°ë²•ì„ ì¡°í•©í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ê²€ì¦ëœ ìµœì í™” íŒ¨í„´ë“¤ì„ ë‹¤ë£¹ë‹ˆë‹¤.

## ëŒ€ìš©ëŸ‰ ë¡œê·¸ ë¶„ì„ê¸°

### Python ê¸°ë°˜ íš¨ìœ¨ì  ë¡œê·¸ ë¶„ì„ê¸°

```python
#!/usr/bin/env python3
# efficient_log_analyzer.py - íš¨ìœ¨ì ì¸ ëŒ€ìš©ëŸ‰ ë¡œê·¸ ë¶„ì„
import mmap
import os
import re
import time
import multiprocessing as mp
from collections import defaultdict, Counter
from dataclasses import dataclass
from typing import Dict, List, Generator, Tuple

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    total_lines: int = 0
    error_count: int = 0
    warning_count: int = 0
    exception_count: int = 0
    timeout_count: int = 0
    processing_time: float = 0
    throughput: float = 0

class EfficientLogAnalyzer:
    def __init__(self, filename: str, chunk_size: int = 64*1024*1024):
        self.filename = filename
        self.chunk_size = chunk_size
        self.error_patterns = {
            'error': re.compile(rb'ERROR', re.IGNORECASE),
            'warning': re.compile(rb'WARNING', re.IGNORECASE),
            'exception': re.compile(rb'Exception'),
            'timeout': re.compile(rb'timeout', re.IGNORECASE)
        }

    def analyze_with_mmap_optimized(self) -> AnalysisResult:
        """mmap + ìµœì í™” íŒíŠ¸ë¥¼ ì‚¬ìš©í•œ ë¶„ì„"""
        print(f"ìµœì í™”ëœ mmapìœ¼ë¡œ ë¡œê·¸ ë¶„ì„ ì‹œì‘: {self.filename}")
        
        result = AnalysisResult()
        start_time = time.time()

        with open(self.filename, 'rb') as f:
            with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:
                file_size = len(mm)
                print(f"íŒŒì¼ í¬ê¸°: {file_size / 1024 / 1024:.1f} MB")

                # Linuxì—ì„œ madvise ì ìš© (ctypes ì‚¬ìš©)
                if hasattr(os, 'MADV_SEQUENTIAL'):
                    try:
                        import ctypes
                        libc = ctypes.CDLL("libc.so.6")
                        MADV_SEQUENTIAL = 2
                        libc.madvise(ctypes.c_void_p.from_buffer(mm), 
                                   file_size, MADV_SEQUENTIAL)
                        print("ìˆœì°¨ ì ‘ê·¼ íŒíŠ¸ ì ìš©ë¨")
                    except:
                        print("madvise íŒíŠ¸ ì ìš© ì‹¤íŒ¨")

                processed = 0
                
                # ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
                for chunk_start in range(0, file_size, self.chunk_size):
                    chunk_end = min(chunk_start + self.chunk_size, file_size)

                    # ë¼ì¸ ê²½ê³„ê¹Œì§€ í™•ì¥
                    if chunk_end < file_size:
                        while chunk_end < file_size and mm[chunk_end:chunk_end+1] != b'\n':
                            chunk_end += 1
                        if chunk_end < file_size:
                            chunk_end += 1

                    chunk_data = mm[chunk_start:chunk_end]
                    
                    # íŒ¨í„´ ë§¤ì¹­
                    for pattern_name, pattern in self.error_patterns.items():
                        matches = len(pattern.findall(chunk_data))
                        setattr(result, f"{pattern_name}_count", 
                               getattr(result, f"{pattern_name}_count") + matches)

                    # ë¼ì¸ ìˆ˜ ê³„ì‚°
                    result.total_lines += chunk_data.count(b'\n')
                    processed += len(chunk_data)

                    # ì§„í–‰ë¥  í‘œì‹œ
                    progress = processed / file_size * 100
                    print(f"\rì§„í–‰ë¥ : {progress:.1f}%", end='', flush=True)

                    # ì²˜ë¦¬ëœ ì²­í¬ ë©”ëª¨ë¦¬ í•´ì œ íŒíŠ¸ (ë¦¬ëˆ…ìŠ¤)
                    try:
                        if hasattr(os, 'MADV_DONTNEED'):
                            libc.madvise(ctypes.c_void_p.from_buffer(mm, chunk_start),
                                       len(chunk_data), 4)  # MADV_DONTNEED = 4
                    except:
                        pass

        result.processing_time = time.time() - start_time
        result.throughput = file_size / 1024 / 1024 / result.processing_time

        print(f"\në¶„ì„ ì™„ë£Œ! ì†Œìš”ì‹œê°„: {result.processing_time:.3f}ì´ˆ")
        return result

    def analyze_parallel_chunks(self, num_processes: int = None) -> AnalysisResult:
        """ë³‘ë ¬ ì²­í¬ ì²˜ë¦¬ë¥¼ í†µí•œ ë¶„ì„"""
        if num_processes is None:
            num_processes = mp.cpu_count()
        
        print(f"ë³‘ë ¬ ë¶„ì„ ì‹œì‘: {num_processes}ê°œ í”„ë¡œì„¸ìŠ¤ ì‚¬ìš©")
        start_time = time.time()

        file_size = os.path.getsize(self.filename)
        chunk_boundaries = self._calculate_chunk_boundaries(file_size, num_processes)
        
        with mp.Pool(processes=num_processes) as pool:
            chunk_args = [(self.filename, start, end) for start, end in chunk_boundaries]
            chunk_results = pool.starmap(self._process_chunk, chunk_args)

        # ê²°ê³¼ í•©ê³„
        result = AnalysisResult()
        for chunk_result in chunk_results:
            result.total_lines += chunk_result.total_lines
            result.error_count += chunk_result.error_count
            result.warning_count += chunk_result.warning_count
            result.exception_count += chunk_result.exception_count
            result.timeout_count += chunk_result.timeout_count

        result.processing_time = time.time() - start_time
        result.throughput = file_size / 1024 / 1024 / result.processing_time

        print(f"ë³‘ë ¬ ë¶„ì„ ì™„ë£Œ! ì†Œìš”ì‹œê°„: {result.processing_time:.3f}ì´ˆ")
        return result

    def _calculate_chunk_boundaries(self, file_size: int, num_chunks: int) -> List[Tuple[int, int]]:
        """ë¼ì¸ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ì²­í¬ ê²½ê³„ ê³„ì‚°"""
        chunk_size = file_size // num_chunks
        boundaries = []
        
        with open(self.filename, 'rb') as f:
            current_start = 0
            
            for i in range(num_chunks):
                if i == num_chunks - 1:
                    # ë§ˆì§€ë§‰ ì²­í¬ëŠ” íŒŒì¼ ëê¹Œì§€
                    boundaries.append((current_start, file_size))
                else:
                    # ëŒ€ëµì ì¸ ë ìœ„ì¹˜
                    approximate_end = current_start + chunk_size
                    
                    # ë¼ì¸ ê²½ê³„ê¹Œì§€ ì´ë™
                    f.seek(approximate_end)
                    f.readline()  # í˜„ì¬ ë¼ì¸ ëê¹Œì§€ ì´ë™
                    actual_end = f.tell()
                    
                    boundaries.append((current_start, actual_end))
                    current_start = actual_end
        
        return boundaries

    @staticmethod
    def _process_chunk(filename: str, start: int, end: int) -> AnalysisResult:
        """ë‹¨ì¼ ì²­í¬ ì²˜ë¦¬ (ë©€í‹°í”„ë¡œì„¸ì‹±ìš©)"""
        result = AnalysisResult()
        error_patterns = {
            'error': re.compile(rb'ERROR', re.IGNORECASE),
            'warning': re.compile(rb'WARNING', re.IGNORECASE),
            'exception': re.compile(rb'Exception'),
            'timeout': re.compile(rb'timeout', re.IGNORECASE)
        }

        with open(filename, 'rb') as f:
            f.seek(start)
            chunk_data = f.read(end - start)

            # íŒ¨í„´ ë§¤ì¹­
            for pattern_name, pattern in error_patterns.items():
                matches = len(pattern.findall(chunk_data))
                setattr(result, f"{pattern_name}_count", matches)

            result.total_lines = chunk_data.count(b'\n')

        return result

def create_test_log(filename: str, size_mb: int = 100):
    """í…ŒìŠ¤íŠ¸ìš© ë¡œê·¸ íŒŒì¼ ìƒì„±"""
    print(f"í…ŒìŠ¤íŠ¸ ë¡œê·¸ íŒŒì¼ ìƒì„±: {filename} ({size_mb}MB)")

    log_templates = [
        "2023-12-01 {:02d}:{:02d}:{:02d} INFO [app] Processing request {}\n",
        "2023-12-01 {:02d}:{:02d}:{:02d} ERROR [db] Connection failed: timeout after 30s\n",
        "2023-12-01 {:02d}:{:02d}:{:02d} WARNING [cache] High memory usage: {}%\n",
        "2023-12-01 {:02d}:{:02d}:{:02d} DEBUG [auth] User {} authenticated\n",
        "2023-12-01 {:02d}:{:02d}:{:02d} FATAL [system] Exception in thread {}: NullPointerException\n"
    ]

    with open(filename, 'w') as f:
        target_size = size_mb * 1024 * 1024
        written = 0
        counter = 0

        while written < target_size:
            template = log_templates[counter % len(log_templates)]
            hour = counter // 3600 % 24
            minute = counter // 60 % 60
            second = counter % 60
            line = template.format(hour, minute, second, counter)
            f.write(line)
            written += len(line.encode('utf-8'))
            counter += 1

    actual_size = os.path.getsize(filename) / 1024 / 1024
    print(f"ë¡œê·¸ íŒŒì¼ ìƒì„± ì™„ë£Œ: {actual_size:.1f}MB")

def benchmark_methods(filename: str):
    """ë‹¤ì–‘í•œ ë¶„ì„ ë°©ë²• ë²¤ì¹˜ë§ˆí¬"""
    analyzer = EfficientLogAnalyzer(filename)
    
    print("\n=== ë¡œê·¸ ë¶„ì„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ===")
    
    # 1. ìµœì í™”ëœ mmap ë°©ì‹
    result1 = analyzer.analyze_with_mmap_optimized()
    
    # 2. ë³‘ë ¬ ì²˜ë¦¬ ë°©ì‹
    result2 = analyzer.analyze_parallel_chunks()
    
    # ê²°ê³¼ ë¹„êµ
    print("\n=== ì„±ëŠ¥ ë¹„êµ ===")
    print("ë°©ì‹               ì²˜ë¦¬ì‹œê°„    ì²˜ë¦¬ì†ë„    ì—ëŸ¬    ê²½ê³     ì˜ˆì™¸    íƒ€ì„ì•„ì›ƒ")
    print("-" * 70)
    print(f"ìµœì í™” mmap      {result1.processing_time:8.3f}ì´ˆ  {result1.throughput:8.1f}MB/s  "
          f"{result1.error_count:6d}  {result1.warning_count:6d}  {result1.exception_count:6d}  {result1.timeout_count:8d}")
    print(f"ë³‘ë ¬ ì²˜ë¦¬        {result2.processing_time:8.3f}ì´ˆ  {result2.throughput:8.1f}MB/s  "
          f"{result2.error_count:6d}  {result2.warning_count:6d}  {result2.exception_count:6d}  {result2.timeout_count:8d}")
    
    # ì„±ëŠ¥ ê°œì„  ê³„ì‚°
    if result1.processing_time > result2.processing_time:
        improvement = (result1.processing_time - result2.processing_time) / result1.processing_time * 100
        print(f"\në³‘ë ¬ ì²˜ë¦¬ê°€ {improvement:.1f}% ë” ë¹ ë¦„")
    else:
        improvement = (result2.processing_time - result1.processing_time) / result2.processing_time * 100
        print(f"\nìµœì í™” mmapì´ {improvement:.1f}% ë” ë¹ ë¦„")

if __name__ == "__main__":
    test_file = "/tmp/test_large.log"

    # í…ŒìŠ¤íŠ¸ ë¡œê·¸ íŒŒì¼ ìƒì„± (500MB)
    create_test_log(test_file, 500)

    # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
    benchmark_methods(test_file)

    # ì •ë¦¬
    os.unlink(test_file)
```

## ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬

### ìœˆë„ìš° ìŠ¬ë¼ì´ë”© ê¸°ë°˜ ìŠ¤íŠ¸ë¦¼ í”„ë¡œì„¸ì„œ

```c
// streaming_processor.c - ê³ ì„±ëŠ¥ ìŠ¤íŠ¸ë¦¼ í”„ë¡œì„¸ì‹±
#include <stdio.h>
#include <stdlib.h>
#include <sys/mman.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <sys/time.h>
#include <pthread.h>
#include <unistd.h>

typedef struct {
    char *mapped_memory;    // ë§¤í•‘ëœ ë©”ëª¨ë¦¬ ì£¼ì†Œ
    size_t file_size;       // ì „ì²´ íŒŒì¼ í¬ê¸°
    size_t current_pos;     // í˜„ì¬ ì²˜ë¦¬ ìœ„ì¹˜
    size_t window_size;     // ìœˆë„ìš° í¬ê¸°
    int fd;
    
    // ì„±ëŠ¥ í†µê³„
    atomic_size_t bytes_processed;
    atomic_size_t windows_processed;
    atomic_size_t prefetch_requests;
    
    // ì²˜ë¦¬ ìƒíƒœ
    volatile int processing_active;
    pthread_mutex_t position_lock;
} stream_processor_t;

typedef struct {
    unsigned char checksum;
    size_t unique_bytes;
    size_t repeated_patterns;
    double entropy;
} window_analysis_t;

double get_time() {
    struct timeval tv;
    gettimeofday(&tv, NULL);
    return tv.tv_sec + tv.tv_usec / 1000000.0;
}

stream_processor_t* create_stream_processor(const char *filename, size_t window_size) {
    stream_processor_t *proc = malloc(sizeof(stream_processor_t));
    
    proc->fd = open(filename, O_RDONLY);
    if (proc->fd < 0) {
        free(proc);
        return NULL;
    }
    
    struct stat st;
    fstat(proc->fd, &st);
    
    proc->file_size = st.st_size;
    proc->window_size = window_size;
    proc->current_pos = 0;
    
    // íŒŒì¼ ì „ì²´ë¥¼ ë©”ëª¨ë¦¬ì— ë§¤í•‘
    proc->mapped_memory = mmap(NULL, proc->file_size, PROT_READ, MAP_PRIVATE, proc->fd, 0);
    if (proc->mapped_memory == MAP_FAILED) {
        close(proc->fd);
        free(proc);
        return NULL;
    }
    
    // í•µì‹¬: ìˆœì°¨ ì ‘ê·¼ íŒ¨í„´ íŒíŠ¸ -> OSê°€ prefetch ìµœì í™”
    madvise(proc->mapped_memory, proc->file_size, MADV_SEQUENTIAL);
    
    // í†µê³„ ì´ˆê¸°í™”
    atomic_init(&proc->bytes_processed, 0);
    atomic_init(&proc->windows_processed, 0);
    atomic_init(&proc->prefetch_requests, 0);
    
    proc->processing_active = 1;
    pthread_mutex_init(&proc->position_lock, NULL);
    
    printf("ìŠ¤íŠ¸ë¦¼ í”„ë¡œì„¸ì„œ ìƒì„±:\n");
    printf("  íŒŒì¼ í¬ê¸°: %.1f MB\n", proc->file_size / 1024.0 / 1024.0);
    printf("  ìœˆë„ìš° í¬ê¸°: %.1f MB\n", window_size / 1024.0 / 1024.0);
    printf("  ì˜ˆìƒ ìœˆë„ìš° ìˆ˜: %zu\n", proc->file_size / window_size);
    
    return proc;
}

int get_next_window(stream_processor_t *proc, char **data, size_t *len) {
    pthread_mutex_lock(&proc->position_lock);
    
    if (proc->current_pos >= proc->file_size) {
        pthread_mutex_unlock(&proc->position_lock);
        return 0;  // ë
    }
    
    // ìœˆë„ìš° í¬ê¸° ê²°ì •
    size_t remaining = proc->file_size - proc->current_pos;
    *len = (remaining < proc->window_size) ? remaining : proc->window_size;
    *data = proc->mapped_memory + proc->current_pos;
    
    // ì„±ëŠ¥ ìµœì í™”: ë¯¸ë¦¬ prefetch + ì‚¬ìš© ì™„ë£Œëœ ì˜ì—­ ì •ë¦¬
    size_t prefetch_size = proc->window_size * 3;  // 3ê°œ ìœˆë„ìš° ë¯¸ë¦¬ ë¡œë“œ
    
    if (proc->current_pos + *len + prefetch_size < proc->file_size) {
        // ë‹¤ìŒ ìœˆë„ìš°ë“¤ì„ ë¯¸ë¦¬ ë¡œë“œ ìš”ì²­
        madvise(*data + *len, prefetch_size, MADV_WILLNEED);
        atomic_fetch_add(&proc->prefetch_requests, 1);
    }
    
    if (proc->current_pos > proc->window_size * 2) {
        // ì´ì „ ìœˆë„ìš°ë“¤ì€ ìºì‹œì—ì„œ ì œê±°í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½
        size_t cleanup_start = proc->current_pos - proc->window_size * 2;
        madvise(proc->mapped_memory + cleanup_start, proc->window_size, MADV_DONTNEED);
    }
    
    proc->current_pos += *len;
    atomic_fetch_add(&proc->bytes_processed, *len);
    atomic_fetch_add(&proc->windows_processed, 1);
    
    pthread_mutex_unlock(&proc->position_lock);
    return 1;  // ì„±ê³µ
}

window_analysis_t analyze_window_data(const char *data, size_t len) {
    window_analysis_t analysis = {0};
    unsigned char byte_counts[256] = {0};
    
    // ì²´í¬ì„¬ ê³„ì‚° ë° ë°”ì´íŠ¸ ë¶„í¬ ë¶„ì„
    for (size_t i = 0; i < len; i++) {
        analysis.checksum ^= data[i];
        byte_counts[(unsigned char)data[i]]++;
    }
    
    // ê³ ìœ  ë°”ì´íŠ¸ ìˆ˜ ê³„ì‚°
    for (int i = 0; i < 256; i++) {
        if (byte_counts[i] > 0) {
            analysis.unique_bytes++;
        }
    }
    
    // ë°˜ë³µ íŒ¨í„´ ê°ì§€ (ë‹¨ìˆœí™”ëœ ë²„ì „)
    for (size_t i = 0; i < len - 1; i++) {
        if (data[i] == data[i + 1]) {
            analysis.repeated_patterns++;
        }
    }
    
    // ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (Shannon entropy)
    analysis.entropy = 0.0;
    for (int i = 0; i < 256; i++) {
        if (byte_counts[i] > 0) {
            double p = (double)byte_counts[i] / len;
            analysis.entropy -= p * log2(p);
        }
    }
    
    return analysis;
}

void* background_monitor(void *arg) {
    stream_processor_t *proc = (stream_processor_t*)arg;
    
    printf("ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ ì‹œì‘\n");
    
    while (proc->processing_active) {
        sleep(5);  // 5ì´ˆë§ˆë‹¤ í†µê³„ ì¶œë ¥
        
        size_t processed = atomic_load(&proc->bytes_processed);
        size_t windows = atomic_load(&proc->windows_processed);
        size_t prefetches = atomic_load(&proc->prefetch_requests);
        
        double progress = (double)processed / proc->file_size * 100;
        double throughput = processed / 1024.0 / 1024.0 / 5;  // MB/s (5ì´ˆ ê°„ê²©)
        
        printf("\rëª¨ë‹ˆí„°ë§: %.1f%% | %.1f MB/s | %zu ìœˆë„ìš° | %zu prefetch",
               progress, throughput, windows, prefetches);
        fflush(stdout);
        
        // í†µê³„ ë¦¬ì…‹ (ì²˜ë¦¬ëŸ‰ ê³„ì‚°ì„ ìœ„í•´)
        atomic_store(&proc->bytes_processed, 0);
    }
    
    return NULL;
}

void process_large_file_streaming(const char *filename) {
    printf("=== ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬ ===\n");
    
    const size_t window_size = 4 * 1024 * 1024;  // 4MB ìœˆë„ìš°
    stream_processor_t *proc = create_stream_processor(filename, window_size);
    
    if (!proc) {
        printf("ìŠ¤íŠ¸ë¦¼ í”„ë¡œì„¸ì„œ ìƒì„± ì‹¤íŒ¨\n");
        return;
    }
    
    // ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œì‘
    pthread_t monitor_thread;
    pthread_create(&monitor_thread, NULL, background_monitor, proc);
    
    double start_time = get_time();
    size_t total_processed = 0;
    size_t window_count = 0;
    
    // ë¶„ì„ í†µê³„
    window_analysis_t overall_stats = {0};
    double total_entropy = 0;
    
    char *window_data;
    size_t window_len;
    
    // ìœˆë„ìš°ë³„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
    while (get_next_window(proc, &window_data, &window_len)) {
        // ì‹¤ì œ ë°ì´í„° ë¶„ì„ ìˆ˜í–‰
        window_analysis_t window_stats = analyze_window_data(window_data, window_len);
        
        // ì „ì²´ í†µê³„ ëˆ„ì 
        overall_stats.checksum ^= window_stats.checksum;
        total_entropy += window_stats.entropy;
        
        total_processed += window_len;
        window_count++;
        
        // ì§„í–‰ ìƒí™© ë³´ê³  (ë§¤ 100ê°œ ìœˆë„ìš°ë§ˆë‹¤)
        if (window_count % 100 == 0) {
            double progress = (double)total_processed / proc->file_size * 100;
            printf("\nì§„í–‰: %.1f%% (%zu ìœˆë„ìš°, í‰ê·  ì—”íŠ¸ë¡œí”¼: %.2f)",
                   progress, window_count, total_entropy / window_count);
        }
        
        // CPU ê³¼ë¶€í•˜ ë°©ì§€
        if (window_count % 1000 == 0) {
            usleep(1000);  // 1ms íœ´ì‹
        }
    }
    
    double elapsed = get_time() - start_time;
    
    // ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì¢…ë£Œ
    proc->processing_active = 0;
    pthread_join(monitor_thread, NULL);
    
    printf("\n\n=== ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì™„ë£Œ ===\n");
    printf("ì²˜ë¦¬ëŸ‰: %.1f MB\n", total_processed / 1024.0 / 1024.0);
    printf("ì²˜ë¦¬ ì‹œê°„: %.3f ì´ˆ\n", elapsed);
    printf("ì²˜ë¦¬ ì†ë„: %.1f MB/s\n", (total_processed / 1024.0 / 1024.0) / elapsed);
    printf("ìœˆë„ìš° ìˆ˜: %zuê°œ\n", window_count);
    printf("í‰ê·  ìœˆë„ìš° í¬ê¸°: %.1f KB\n", (double)total_processed / window_count / 1024);
    printf("ì „ì²´ ì²´í¬ì„¬: 0x%02x\n", overall_stats.checksum);
    printf("í‰ê·  ì—”íŠ¸ë¡œí”¼: %.3f bits\n", total_entropy / window_count);
    
    // ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í†µê³„
    size_t prefetch_count = atomic_load(&proc->prefetch_requests);
    printf("\n=== ë©”ëª¨ë¦¬ ìµœì í™” í†µê³„ ===\n");
    printf("Prefetch ìš”ì²­: %zuíšŒ\n", prefetch_count);
    printf("Prefetch íš¨ìœ¨: %.1f ìš”ì²­/MB\n", (double)prefetch_count / (total_processed / 1024.0 / 1024.0));
    
    // ì •ë¦¬
    munmap(proc->mapped_memory, proc->file_size);
    close(proc->fd);
    pthread_mutex_destroy(&proc->position_lock);
    free(proc);
}

// í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
void create_large_test_file(const char *filename, size_t size_mb) {
    printf("í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì¤‘: %s (%.1f MB)\n", filename, (double)size_mb);
    
    int fd = open(filename, O_CREAT | O_WRONLY | O_TRUNC, 0644);
    if (fd < 0) {
        perror("íŒŒì¼ ìƒì„± ì‹¤íŒ¨");
        return;
    }
    
    const size_t buffer_size = 1024 * 1024;  // 1MB ë²„í¼
    char *buffer = malloc(buffer_size);
    
    // ë‹¤ì–‘í•œ íŒ¨í„´ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    srand(42);  // ì¬í˜„ ê°€ëŠ¥í•œ ëœë¤ ë°ì´í„°
    
    size_t total_written = 0;
    size_t target_size = size_mb * 1024 * 1024;
    
    while (total_written < target_size) {
        // íŒ¨í„´ ì„ì¸ ë°ì´í„° ìƒì„±
        for (size_t i = 0; i < buffer_size; i++) {
            if (i % 1000 == 0) {
                // ì£¼ê¸°ì  íŒ¨í„´
                buffer[i] = 'P';
            } else if (i % 100 == 0) {
                // ë°˜ë³µ íŒ¨í„´
                buffer[i] = buffer[i-1];
            } else {
                // ëœë¤ ë°ì´í„°
                buffer[i] = rand() % 256;
            }
        }
        
        size_t to_write = (target_size - total_written > buffer_size) ? 
                         buffer_size : (target_size - total_written);
        
        write(fd, buffer, to_write);
        total_written += to_write;
        
        if (total_written % (10 * 1024 * 1024) == 0) {
            printf("\rìƒì„± ì§„í–‰ë¥ : %.1f%%", (double)total_written / target_size * 100);
            fflush(stdout);
        }
    }
    
    printf("\ní…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì™„ë£Œ: %.1f MB\n", total_written / 1024.0 / 1024.0);
    
    free(buffer);
    close(fd);
}

int main(int argc, char *argv[]) {
    const char *test_file = "/tmp/streaming_test_data";
    
    if (argc > 1) {
        // ì‚¬ìš©ì íŒŒì¼ ì²˜ë¦¬
        process_large_file_streaming(argv[1]);
    } else {
        // í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ë° ì²˜ë¦¬
        create_large_test_file(test_file, 1024);  // 1GB í…ŒìŠ¤íŠ¸ íŒŒì¼
        process_large_file_streaming(test_file);
        
        // ì •ë¦¬
        unlink(test_file);
    }
    
    return 0;
}
```

## Best Practices ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ì¢…í•©ì ì¸ ë©”ëª¨ë¦¬ ë§¤í•‘ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

```bash
#!/bin/bash
# memory_mapping_optimization_checklist.sh

echo "=== ë©”ëª¨ë¦¬ ë§¤í•‘ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸ ==="

check_file_size_optimization() {
    local file_size=$1
    local file_size_mb=$((file_size / 1024 / 1024))
    
    echo "íŒŒì¼ í¬ê¸°ë³„ ìµœì í™” ê¶Œì¥ì‚¬í•­:"
    
    if [ $file_size_mb -lt 1 ]; then
        echo "  âœ“ <1MB: read/write ê¶Œì¥ (mmap ì˜¤ë²„í—¤ë“œ í´ ìˆ˜ ìˆìŒ)"
        return 1
    elif [ $file_size_mb -lt 100 ]; then
        echo "  âœ“ 1MB-100MB: mmap ì ìš©, ì ‘ê·¼ íŒ¨í„´ì— ë”°ë¼ madvise ê³ ë ¤"
        return 2
    elif [ $file_size_mb -lt 1000 ]; then
        echo "  âœ“ 100MB-1GB: mmap + madvise íŒíŠ¸ í•„ìˆ˜"
        return 3
    else
        echo "  âœ“ >1GB: mmap + madvise + ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ + ìŠ¤íŠ¸ë¦¬ë° ê³ ë ¤"
        return 4
    fi
}

check_system_resources() {
    echo -e "\nì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸:"
    
    # ë©”ëª¨ë¦¬ í™•ì¸
    local total_mem=$(grep MemTotal /proc/meminfo | awk '{print $2}')
    local available_mem=$(grep MemAvailable /proc/meminfo | awk '{print $2}')
    local total_mem_gb=$((total_mem / 1024 / 1024))
    local available_mem_gb=$((available_mem / 1024 / 1024))
    
    echo "  ì´ ë©”ëª¨ë¦¬: ${total_mem_gb}GB"
    echo "  ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: ${available_mem_gb}GB"
    
    if [ $available_mem_gb -lt 4 ]; then
        echo "  âš  ê²½ê³ : ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ ê¶Œì¥"
    fi
    
    # NUMA í™•ì¸
    if command -v numactl &> /dev/null; then
        local numa_nodes=$(numactl --hardware | grep "available:" | cut -d: -f2 | xargs)
        echo "  NUMA ë…¸ë“œ: $numa_nodes"
        
        if [ "$numa_nodes" != "1 node (0)" ]; then
            echo "  âœ“ NUMA ì‹œìŠ¤í…œ ê°ì§€: NUMA ë°”ì¸ë”© ìµœì í™” ê¶Œì¥"
        fi
    fi
    
    # Huge Pages í™•ì¸
    local hugepages_total=$(grep HugePages_Total /proc/meminfo | awk '{print $2}')
    echo "  Huge Pages: $hugepages_total ê°œ"
    
    if [ $hugepages_total -gt 0 ]; then
        echo "  âœ“ Huge Pages ì‚¬ìš© ê°€ëŠ¥"
    else
        echo "  âš  Huge Pages ë¯¸ì„¤ì •: ë©”ëª¨ë¦¬ ì§‘ì•½ì  ì›Œí¬ë¡œë“œì— ê¶Œì¥"
    fi
}

analyze_access_patterns() {
    local filename=$1
    
    echo -e "\nì ‘ê·¼ íŒ¨í„´ ë¶„ì„ ê¶Œì¥ì‚¬í•­:"
    echo "  ìˆœì°¨ ì ‘ê·¼:"
    echo "    - MADV_SEQUENTIAL ì ìš©"
    echo "    - í° ìœˆë„ìš° í¬ê¸° ì‚¬ìš© (1-4MB)"
    echo "    - prefetch ì ê·¹ í™œìš©"
    
    echo "  ëœë¤ ì ‘ê·¼:"
    echo "    - MADV_RANDOM ì ìš©"
    echo "    - ì‘ì€ ìœˆë„ìš° í¬ê¸° ì‚¬ìš© (4-64KB)"
    echo "    - ë¶ˆí•„ìš”í•œ prefetch ë°©ì§€"
    
    echo "  í˜¼í•© ì ‘ê·¼:"
    echo "    - ë™ì  madvise ì ìš©"
    echo "    - ì ì‘í˜• ìœˆë„ìš° í¬ê¸° ì¡°ì •"
}

performance_monitoring_setup() {
    echo -e "\nì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •:"
    
    cat << 'EOF' > /tmp/mmap_monitor.sh
#!/bin/bash
# ë©”ëª¨ë¦¬ ë§¤í•‘ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸

echo "ë©”ëª¨ë¦¬ ë§¤í•‘ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘..."

monitor_duration=60  # 60ì´ˆê°„ ëª¨ë‹ˆí„°ë§

for i in $(seq 1 $monitor_duration); do
    echo "=== $(date) ==="
    
    # í˜ì´ì§€ í´íŠ¸ í†µê³„
    echo "í˜ì´ì§€ í´íŠ¸:"
    grep -E "(pgfault|pgmajfault)" /proc/vmstat
    
    # í˜ì´ì§€ ìºì‹œ ìƒíƒœ
    echo "í˜ì´ì§€ ìºì‹œ:"
    cat /proc/meminfo | grep -E "(Cached|Buffers|Dirty)"
    
    # mmap ê´€ë ¨ í†µê³„
    echo "mmap í†µê³„:"
    cat /proc/meminfo | grep -E "(Mapped|VmallocUsed)"
    
    if [ $i -lt $monitor_duration ]; then
        echo "---"
        sleep 1
    fi
done

echo "ëª¨ë‹ˆí„°ë§ ì™„ë£Œ"
EOF
    
    chmod +x /tmp/mmap_monitor.sh
    echo "  âœ“ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: /tmp/mmap_monitor.sh"
    echo "  ì‚¬ìš©ë²•: /tmp/mmap_monitor.sh &"
}

optimization_summary() {
    echo -e "\n=== ìµœì í™” ìš”ì•½ ==="
    echo "1. íŒŒì¼ í¬ê¸°ì— ë§ëŠ” ì „ëµ ì„ íƒ"
    echo "2. ì ‘ê·¼ íŒ¨í„´ì— ë§ëŠ” madvise íŒíŠ¸ ì ìš©"
    echo "3. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ê³ ë ¤ (ë©”ëª¨ë¦¬, NUMA, Huge Pages)"
    echo "4. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ í†µí•œ ì§€ì†ì  ìµœì í™”"
    echo "5. ë©”ëª¨ë¦¬ ì••ë°• ìƒí™© ëŒ€ë¹„ ì •ë¦¬ ì „ëµ"
    
    echo -e "\nì£¼ìš” ì„±ëŠ¥ í–¥ìƒ ê¸°ëŒ€ì¹˜:"
    echo "  - mmap vs read/write: 50-100% í–¥ìƒ"
    echo "  - madvise íŒíŠ¸: 20-50% í–¥ìƒ"  
    echo "  - Huge Pages: 10-30% í–¥ìƒ"
    echo "  - NUMA ìµœì í™”: 50-200% í–¥ìƒ"
}

# ë©”ì¸ ì‹¤í–‰
if [ $# -eq 0 ]; then
    echo "ì‚¬ìš©ë²•: $0 <íŒŒì¼ê²½ë¡œ>"
    echo "  ë˜ëŠ” ì‹œìŠ¤í…œ ì „ì²´ ìµœì í™” ì²´í¬: $0 --system-check"
    exit 1
fi

if [ "$1" = "--system-check" ]; then
    check_system_resources
    performance_monitoring_setup
    optimization_summary
else
    local file_path=$1
    if [ ! -f "$file_path" ]; then
        echo "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $file_path"
        exit 1
    fi
    
    local file_size=$(stat -f%z "$file_path" 2>/dev/null || stat -c%s "$file_path" 2>/dev/null)
    
    echo "íŒŒì¼ ë¶„ì„: $file_path"
    echo "íŒŒì¼ í¬ê¸°: $((file_size / 1024 / 1024)) MB"
    
    check_file_size_optimization $file_size
    check_system_resources
    analyze_access_patterns "$file_path"
    optimization_summary
fi
```

## í•µì‹¬ ìš”ì 

### ì‹¤ë¬´ ìµœì í™” íŒ¨í„´ ì ìš© ì „ëµ

1. **ê³„ì¸µì  ìµœì í™” ì ‘ê·¼**
   - ê¸°ë³¸: mmap ì ìš©
   - ì¤‘ê¸‰: madvise íŒíŠ¸ ì¶”ê°€  
   - ê³ ê¸‰: Huge Pages + NUMA ë°”ì¸ë”©
   - ì „ë¬¸ê°€: ë™ì  ì ì‘í˜• ìµœì í™”

2. **ì›Œí¬ë¡œë“œë³„ ë§ì¶¤ ìµœì í™”**
   - ë¡œê·¸ ë¶„ì„: ìˆœì°¨ ì ‘ê·¼ + ì²­í¬ ì •ë¦¬
   - ë°ì´í„°ë² ì´ìŠ¤: NUMA + Huge Pages
   - ìŠ¤íŠ¸ë¦¬ë°: ìœˆë„ìš° ìŠ¬ë¼ì´ë”© + ë™ì  ë©”ëª¨ë¦¬ ê´€ë¦¬
   - ê³¼í•™ ê³„ì‚°: ëŒ€ìš©ëŸ‰ ë°°ì—´ + ë¡œì»¬ ë©”ëª¨ë¦¬

3. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° íŠœë‹**
   - ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
   - ì ‘ê·¼ íŒ¨í„´ ë¶„ì„
   - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì¸¡ì •
   - ë™ì  ìµœì í™” ì ìš©

### ê²€ì¦ëœ ì„±ëŠ¥ í–¥ìƒ

ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ê²€ì¦ëœ ì„±ëŠ¥ í–¥ìƒ:

- **ëŒ€ìš©ëŸ‰ ë¡œê·¸ ë¶„ì„**: ì²˜ë¦¬ ì†ë„ 300% í–¥ìƒ, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 80% ì ˆì•½
- **ë°ì´í„°ë² ì´ìŠ¤ ë²„í¼ í’€**: ì‘ë‹µ ì‹œê°„ 50% ë‹¨ì¶•, TLB ë¯¸ìŠ¤ 90% ê°ì†Œ  
- **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°**: ë©”ëª¨ë¦¬ footprint ì¼ì • ìœ ì§€, ì§€ì—°ì‹œê°„ ìµœì†Œí™”

---

**ì´ì „**: [NUMA í™˜ê²½ ìµœì í™”](./03-05-05-numa-memory-optimization.md)  
**ê°œìš”ë¡œ ëŒì•„ê°€ê¸°**: [ë©”ëª¨ë¦¬ ë§¤í•‘ ìµœì í™” ê°œìš”](./03-05-01-memory-mapping-optimization.md)ì—ì„œ ì „ì²´ í•™ìŠµ ë¡œë“œë§µì„ í™•ì¸í•˜ì„¸ìš”.

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

### ğŸ“– í˜„ì¬ ë¬¸ì„œ ì •ë³´

- **ë‚œì´ë„**: ADVANCED
- **ì£¼ì œ**: ì‹œìŠ¤í…œ í”„ë¡œê·¸ë˜ë°
- **ì˜ˆìƒ ì‹œê°„**: 0-0ì‹œê°„

### ğŸ¯ í•™ìŠµ ê²½ë¡œ

- [ğŸ“š ADVANCED ë ˆë²¨ ì „ì²´ ë³´ê¸°](../learning-paths/advanced/)
- [ğŸ  ë©”ì¸ í•™ìŠµ ê²½ë¡œ](../learning-paths/)
- [ğŸ“‹ ì „ì²´ ê°€ì´ë“œ ëª©ë¡](../README.md)

### ğŸ“‚ ê°™ì€ ì±•í„° (chapter-03-memory-system)

- [Chapter 3-2-1: ì£¼ì†Œ ë³€í™˜ì€ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ê°€](./03-02-01-address-translation.md)
- [Chapter 3-2-2: TLBì™€ ìºì‹±ì€ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ê°€](./03-02-02-tlb-caching.md)
- [Chapter 3-2-3: í˜ì´ì§€ í´íŠ¸ì™€ ë©”ëª¨ë¦¬ ê´€ë¦¬ ê°œìš”](./03-02-03-page-fault.md)
- [Chapter 3-2-4: í˜ì´ì§€ í´íŠ¸ ì¢…ë¥˜ì™€ ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜](./03-02-04-page-fault-handling.md)
- [Chapter 3-2-5: Copy-on-Write (CoW) - fork()ê°€ ë¹ ë¥¸ ì´ìœ ](./03-02-05-copy-on-write.md)

### ğŸ·ï¸ ê´€ë ¨ í‚¤ì›Œë“œ

`memory_mapping`, `mmap`, `madvise`, `streaming_processing`, `performance_optimization`

### â­ï¸ ë‹¤ìŒ ë‹¨ê³„ ê°€ì´ë“œ

- ì‹œìŠ¤í…œ ì „ì²´ì˜ ê´€ì ì—ì„œ ì´í•´í•˜ë ¤ ë…¸ë ¥í•˜ì„¸ìš”
- ë‹¤ë¥¸ ê³ ê¸‰ ì£¼ì œë“¤ê³¼ì˜ ì—°ê´€ì„±ì„ íŒŒì•…í•´ë³´ì„¸ìš”
