---
tags:
  - gc-optimization
  - hands-on
  - intermediate
  - medium-read
  - memory-management
  - performance-tuning
  - python
  - slots
  - ì• í”Œë¦¬ì¼€ì´ì…˜ê°œë°œ
difficulty: INTERMEDIATE
learning_time: "3-5ì‹œê°„"
main_topic: "ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ"
priority_score: 4
---

# Chapter 9-3c2: Python GC ìµœì í™” ì „ëµê³¼ ê¸°ë²•

## ğŸ¯ ì‹¤ì „ ë©”ëª¨ë¦¬ ìµœì í™” ë§ˆìŠ¤í„°í•˜ê¸°

ì´ ë¬¸ì„œì—ì„œëŠ” Python ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê·¹ì ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ì „ì ì¸ ê¸°ë²•ë“¤ì„ ë‹¤ë£¹ë‹ˆë‹¤:

1. **GC ì œì–´ë¥¼ í†µí•œ ì„±ëŠ¥ í–¥ìƒ** - ë°°ì¹˜ ì‘ì—…ì—ì„œ 16% ì„±ëŠ¥ ê°œì„  ë‹¬ì„±
2. **__slots__ë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ì ˆì•½** - ê°ì²´ë‹¹ 40% ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
3. **WeakRefë¥¼ í™œìš©í•œ ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬** - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ì™€ ìºì‹œ ìµœì í™”
4. **ì‹¤ì œ ì¸¡ì • ê°€ëŠ¥í•œ ìµœì í™” ê²°ê³¼** - êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë²¤ì¹˜ë§ˆí¬ ì œê³µ

## 1. ì½”ë“œ ë ˆë²¨ ìµœì í™” ì „ëµ

### 1.1 GC ì œì–´ë¥¼ í†µí•œ ì„±ëŠ¥ ìµœì í™”

```python
import gc
import time
from contextlib import contextmanager
from functools import wraps
import weakref
from typing import Dict, Any, Optional

class PythonGCOptimization:
    """Python GC ìµœì í™” ê¸°ë²•ë“¤"""

    @staticmethod
    @contextmanager
    def gc_disabled():
        """ì„ì‹œë¡œ GC ë¹„í™œì„±í™”í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        was_enabled = gc.isenabled()
        gc.disable()  # GC ì™„ì „ ë¹„í™œì„±í™”
        try:
            yield
        finally:
            if was_enabled:
                gc.enable()  # ì›ë˜ ìƒíƒœ ë³µêµ¬

    @staticmethod
    def benchmark_gc_impact():
        """GCê°€ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì¸¡ì •"""

        def create_objects(n):
            """í…ŒìŠ¤íŠ¸ìš© ê°ì²´ ìƒì„± í•¨ìˆ˜"""
            return [{"id": i, "data": [0] * 100, "nested": {"value": i}}
                    for i in range(n)]

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°
        test_size = 1000000

        print("=== GC ì„±ëŠ¥ ì˜í–¥ ì¸¡ì • ===")

        # 1. GC í™œì„±í™” ìƒíƒœì—ì„œ ì¸¡ì •
        gc.enable()
        start_time = time.time()

        with_gc_data = create_objects(test_size)

        gc_enabled_time = time.time() - start_time
        print(f"GC í™œì„±í™”: {gc_enabled_time:.3f}ì´ˆ")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del with_gc_data
        gc.collect()

        # 2. GC ë¹„í™œì„±í™” ìƒíƒœì—ì„œ ì¸¡ì •
        with PythonGCOptimization.gc_disabled():
            start_time = time.time()

            without_gc_data = create_objects(test_size)

            gc_disabled_time = time.time() - start_time
            print(f"GC ë¹„í™œì„±í™”: {gc_disabled_time:.3f}ì´ˆ")

        # ì„±ëŠ¥ í–¥ìƒ ê³„ì‚°
        improvement = (gc_enabled_time - gc_disabled_time) / gc_enabled_time * 100
        print(f"ì„±ëŠ¥ í–¥ìƒ: {improvement:.1f}%")

        # ìˆ˜ë™ìœ¼ë¡œ ì •ë¦¬ (GCê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆì„ ë•Œ)
        gc.enable()
        del without_gc_data
        gc.collect()

        """
        ì¼ë°˜ì ì¸ ê²°ê³¼:
        GC í™œì„±í™”: 2.5ì´ˆ
        GC ë¹„í™œì„±í™”: 2.1ì´ˆ
        ì„±ëŠ¥ í–¥ìƒ: 16%

        ê²°ë¡ : ëŒ€ëŸ‰ ê°ì²´ ìƒì„± ì‹œ ì„ì‹œë¡œ GC ë¹„í™œì„±í™”í•˜ë©´ ì„±ëŠ¥ ê°œì„  ê°€ëŠ¥
        ì£¼ì˜: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìœ„í—˜ì´ ìˆìœ¼ë¯€ë¡œ ì‹ ì¤‘í•˜ê²Œ ì‚¬ìš©
        """

def batch_processing_optimization():
    """ë°°ì¹˜ ì²˜ë¦¬ ì‹œ GC ìµœì í™”"""

    def process_large_batch_naive(data_items):
        """ìˆœì§„í•œ ë°©ë²•: GCê°€ ì¤‘ê°„ì¤‘ê°„ ì‹¤í–‰ë¨"""
        results = []

        for item in data_items:
            # ë³µì¡í•œ ì²˜ë¦¬ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
            processed = {
                "original": item,
                "transformed": item * 2,
                "metadata": {"processed_at": time.time()},
                "temp_data": [item] * 100  # ì„ì‹œ ë°ì´í„°
            }
            results.append(processed)

        return results

    def process_large_batch_optimized(data_items):
        """ìµœì í™”ëœ ë°©ë²•: ë°°ì¹˜ ì‘ì—… ì¤‘ GC ë¹„í™œì„±í™”"""

        # ì‘ì—… ì „ ì˜ˆë°©ì  GC ì‹¤í–‰
        gc.collect()

        # ë°°ì¹˜ ì‘ì—… ì¤‘ GC ë¹„í™œì„±í™”
        with PythonGCOptimization.gc_disabled():
            results = []

            for item in data_items:
                processed = {
                    "original": item,
                    "transformed": item * 2,
                    "metadata": {"processed_at": time.time()},
                    "temp_data": [item] * 100
                }
                results.append(processed)

        # ì‘ì—… ì™„ë£Œ í›„ í•œ ë²ˆì— ì •ë¦¬
        gc.collect()

        return results

    # ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
    test_data = list(range(100000))

    print("=== ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” ë¹„êµ ===")

    # ìˆœì§„í•œ ë°©ë²•
    start = time.time()
    naive_results = process_large_batch_naive(test_data)
    naive_time = time.time() - start
    print(f"ìˆœì§„í•œ ë°©ë²•: {naive_time:.3f}ì´ˆ")

    # ìµœì í™”ëœ ë°©ë²•
    start = time.time()
    optimized_results = process_large_batch_optimized(test_data)
    optimized_time = time.time() - start
    print(f"ìµœì í™” ë°©ë²•: {optimized_time:.3f}ì´ˆ")

    improvement = (naive_time - optimized_time) / naive_time * 100
    print(f"ì„±ëŠ¥ í–¥ìƒ: {improvement:.1f}%")

    # ê²°ê³¼ ê²€ì¦
    assert len(naive_results) == len(optimized_results)
    print("ê²°ê³¼ ê²€ì¦: í†µê³¼")

    # ì •ë¦¬
    del naive_results, optimized_results
    gc.collect()
```

### 1.2 __slots__ë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ìµœì í™”

```python
import sys
import psutil

# __slots__ ë©”ëª¨ë¦¬ ìµœì í™”
class OptimizedClass:
    """__slots__ë¥¼ ì‚¬ìš©í•œ ë©”ëª¨ë¦¬ ìµœì í™” í´ë˜ìŠ¤"""
    __slots__ = ['x', 'y', 'z', 'data']  # __dict__ ì œê±°

    def __init__(self, x, y, z, data=None):
        self.x = x
        self.y = y
        self.z = z
        self.data = data or []

class NormalClass:
    """ì¼ë°˜ì ì¸ í´ë˜ìŠ¤ (__dict__ ì‚¬ìš©)"""

    def __init__(self, x, y, z, data=None):
        self.x = x
        self.y = y
        self.z = z
        self.data = data or []

def compare_memory_efficiency():
    """__slots__ vs ì¼ë°˜ í´ë˜ìŠ¤ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¹„êµ"""

    print("=== __slots__ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¹„êµ ===")

    # ë‹¨ì¼ ê°ì²´ í¬ê¸° ë¹„êµ
    normal_obj = NormalClass(1, 2, 3)
    optimized_obj = OptimizedClass(1, 2, 3)

    print(f"ì¼ë°˜ í´ë˜ìŠ¤ í¬ê¸°: {sys.getsizeof(normal_obj)} + {sys.getsizeof(normal_obj.__dict__)} bytes")
    print(f"ìµœì í™” í´ë˜ìŠ¤ í¬ê¸°: {sys.getsizeof(optimized_obj)} bytes")

    # ëŒ€ëŸ‰ ê°ì²´ ìƒì„± ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ
    print("\nëŒ€ëŸ‰ ê°ì²´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸...")

    # ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    initial_memory = psutil.Process().memory_info().rss / 1024 / 1024

    # ì¼ë°˜ í´ë˜ìŠ¤ë¡œ 100ë§Œ ê°œ ê°ì²´ ìƒì„±
    print("ì¼ë°˜ í´ë˜ìŠ¤ 100ë§Œ ê°œ ìƒì„± ì¤‘...")
    normal_objects = [NormalClass(i, i+1, i+2) for i in range(1000000)]
    normal_memory = psutil.Process().memory_info().rss / 1024 / 1024

    print(f"ì¼ë°˜ í´ë˜ìŠ¤: {normal_memory - initial_memory:.1f} MB")
    del normal_objects
    gc.collect()

    # ìµœì í™”ëœ í´ë˜ìŠ¤ë¡œ 100ë§Œ ê°œ ê°ì²´ ìƒì„±
    print("ìµœì í™” í´ë˜ìŠ¤ 100ë§Œ ê°œ ìƒì„± ì¤‘...")
    optimized_objects = [OptimizedClass(i, i+1, i+2) for i in range(1000000)]
    optimized_memory = psutil.Process().memory_info().rss / 1024 / 1024

    print(f"ìµœì í™” í´ë˜ìŠ¤: {optimized_memory - initial_memory:.1f} MB")

    # ë©”ëª¨ë¦¬ ì ˆì•½ íš¨ê³¼ ê³„ì‚°
    if normal_memory > initial_memory and optimized_memory > initial_memory:
        normal_usage = normal_memory - initial_memory
        optimized_usage = optimized_memory - initial_memory
        savings = (normal_usage - optimized_usage) / normal_usage * 100
        print(f"ë©”ëª¨ë¦¬ ì ˆì•½: {savings:.1f}%")

    del optimized_objects
    gc.collect()

    """
    ì¼ë°˜ì ì¸ ê²°ê³¼:
    ì¼ë°˜ í´ë˜ìŠ¤: 120.5 MB
    ìµœì í™” í´ë˜ìŠ¤: 76.3 MB
    ë©”ëª¨ë¦¬ ì ˆì•½: 36.7%

    í•µì‹¬ í¬ì¸íŠ¸:
    - __slots__ ì‚¬ìš© ì‹œ __dict__ ì œê±°ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëŒ€í­ ê°ì†Œ
    - íŠ¹íˆ ë§ì€ ìˆ˜ì˜ ì‘ì€ ê°ì²´ë¥¼ ë‹¤ë£° ë•Œ íš¨ê³¼ì 
    - ë™ì  ì†ì„± ì¶”ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ì„¤ê³„ ì‹œ ê³ ë ¤ í•„ìš”
    """
```

## 2. Weak Referenceë¥¼ í™œìš©í•œ ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬

### 2.1 ìŠ¤ë§ˆíŠ¸ ìºì‹œ êµ¬í˜„

```python
from collections import defaultdict

# Weak Referenceë¥¼ í™œìš©í•œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
class CacheWithWeakRef:
    """ì•½í•œ ì°¸ì¡°ë¥¼ í™œìš©í•œ ìºì‹œ êµ¬í˜„"""

    def __init__(self):
        self._cache: Dict[str, Any] = weakref.WeakValueDictionary()
        self._access_count = defaultdict(int)

    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        value = self._cache.get(key)
        if value is not None:
            self._access_count[key] += 1
        return value

    def set(self, key: str, value: Any) -> None:
        """ìºì‹œì— ê°’ ì„¤ì •"""
        self._cache[key] = value
        self._access_count[key] = 1

    def size(self) -> int:
        """í˜„ì¬ ìºì‹œ í¬ê¸°"""
        return len(self._cache)

    def cleanup_stats(self) -> None:
        """ì ‘ê·¼ í†µê³„ì—ì„œ ë” ì´ìƒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤ ì •ë¦¬"""
        existing_keys = set(self._cache.keys())
        stats_keys = set(self._access_count.keys())

        for key in stats_keys - existing_keys:
            del self._access_count[key]

class NormalCache:
    """ì¼ë°˜ì ì¸ ê°•í•œ ì°¸ì¡° ìºì‹œ"""

    def __init__(self):
        self._cache: Dict[str, Any] = {}
        self._access_count = defaultdict(int)

    def get(self, key: str) -> Optional[Any]:
        value = self._cache.get(key)
        if value is not None:
            self._access_count[key] += 1
        return value

    def set(self, key: str, value: Any) -> None:
        self._cache[key] = value
        self._access_count[key] = 1

    def size(self) -> int:
        return len(self._cache)

    def clear(self) -> None:
        """ìˆ˜ë™ ì •ë¦¬"""
        self._cache.clear()
        self._access_count.clear()

def demonstrate_weak_references():
    """Weak Referenceë¥¼ í™œìš©í•œ ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬"""

    print("=== Weak Reference í™œìš© ë°ëª¨ ===")

    # í…ŒìŠ¤íŠ¸ìš© ê°’ ê°ì²´
    class ExpensiveObject:
        def __init__(self, data):
            self.data = data
            self.large_data = [0] * 100000  # 400KB ë°ì´í„°
            print(f"ExpensiveObject ìƒì„±: {data}")

        def __del__(self):
            print(f"ExpensiveObject ì†Œë©¸: {self.data}")

    # ë‘ ìºì‹œ ë¹„êµ í…ŒìŠ¤íŠ¸
    weak_cache = CacheWithWeakRef()
    normal_cache = NormalCache()

    print("\n1. ê°ì²´ ìƒì„± ë° ìºì‹œ ì €ì¥...")
    objects = []

    for i in range(10):
        obj = ExpensiveObject(f"data_{i}")

        # ë‘ ìºì‹œì— ëª¨ë‘ ì €ì¥
        weak_cache.set(f"key_{i}", obj)
        normal_cache.set(f"key_{i}", obj)

        # ì¼ë¶€ë§Œ ë¡œì»¬ ì°¸ì¡° ìœ ì§€
        if i < 5:
            objects.append(obj)

    print(f"Weak ìºì‹œ í¬ê¸°: {weak_cache.size()}")
    print(f"Normal ìºì‹œ í¬ê¸°: {normal_cache.size()}")

    print("\n2. ë¡œì»¬ ì°¸ì¡° ì œê±°...")
    del objects  # 5ê°œ ê°ì²´ì˜ ë¡œì»¬ ì°¸ì¡° ì œê±°
    gc.collect()  # ê°•ì œ GC ì‹¤í–‰

    print(f"GC í›„ Weak ìºì‹œ í¬ê¸°: {weak_cache.size()}")  # 5ê°œë¡œ ê°ì†Œ
    print(f"GC í›„ Normal ìºì‹œ í¬ê¸°: {normal_cache.size()}")  # 10ê°œ ìœ ì§€

    print("\n3. ìºì‹œì—ì„œ ì¡°íšŒ í…ŒìŠ¤íŠ¸...")
    for i in range(10):
        weak_value = weak_cache.get(f"key_{i}")
        normal_value = normal_cache.get(f"key_{i}")

        print(f"key_{i}: weak={weak_value is not None}, normal={normal_value is not None}")

    # ì •ë¦¬
    normal_cache.clear()
    gc.collect()

    """
    ê²°ê³¼:
    - Weak reference ìºì‹œëŠ” ê°ì²´ê°€ ë” ì´ìƒ ì°¸ì¡°ë˜ì§€ ì•Šìœ¼ë©´ ìë™ìœ¼ë¡œ ì œê±°
    - Normal ìºì‹œëŠ” ëª…ì‹œì ìœ¼ë¡œ ì •ë¦¬í•˜ê¸° ì „ê¹Œì§€ ê°ì²´ ìœ ì§€
    - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ì— ë§¤ìš° íš¨ê³¼ì 
    """
```

### 2.2 ê³ ê¸‰ ë©”ëª¨ë¦¬ ìµœì í™” íŒ¨í„´

```python
class MemoryOptimizedContainer:
    """ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ì ìš©í•œ ì»¨í…Œì´ë„ˆ í´ë˜ìŠ¤"""
    
    __slots__ = ['_data', '_weak_refs', '_stats']
    
    def __init__(self):
        self._data = {}  # ê°•í•œ ì°¸ì¡°ë¡œ í•µì‹¬ ë°ì´í„° ìœ ì§€
        self._weak_refs = weakref.WeakValueDictionary()  # ìºì‹œ ë°ì´í„°
        self._stats = {'hits': 0, 'misses': 0}
    
    def store_core_data(self, key: str, value: Any) -> None:
        """í•µì‹¬ ë°ì´í„° ì €ì¥ (ê°•í•œ ì°¸ì¡°)"""
        self._data[key] = value
    
    def cache_derived_data(self, key: str, value: Any) -> None:
        """íŒŒìƒ ë°ì´í„° ìºì‹± (ì•½í•œ ì°¸ì¡°)"""
        self._weak_refs[key] = value
    
    def get_data(self, key: str) -> Optional[Any]:
        """ë°ì´í„° ì¡°íšŒ (í•µì‹¬ ë°ì´í„° ìš°ì„ )"""
        # 1. í•µì‹¬ ë°ì´í„° í™•ì¸
        if key in self._data:
            self._stats['hits'] += 1
            return self._data[key]
        
        # 2. ìºì‹œëœ íŒŒìƒ ë°ì´í„° í™•ì¸
        cached = self._weak_refs.get(key)
        if cached is not None:
            self._stats['hits'] += 1
            return cached
        
        # 3. ë°ì´í„° ì—†ìŒ
        self._stats['misses'] += 1
        return None
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        total = self._stats['hits'] + self._stats['misses']
        hit_rate = self._stats['hits'] / total if total > 0 else 0
        
        return {
            'core_data_count': len(self._data),
            'cached_data_count': len(self._weak_refs),
            'hit_rate': hit_rate,
            'total_requests': total
        }

def demonstrate_advanced_optimization():
    """ê³ ê¸‰ ë©”ëª¨ë¦¬ ìµœì í™” íŒ¨í„´ ë°ëª¨"""
    
    print("=== ê³ ê¸‰ ë©”ëª¨ë¦¬ ìµœì í™” íŒ¨í„´ ===")
    
    container = MemoryOptimizedContainer()
    
    # í•µì‹¬ ë°ì´í„° ì €ì¥
    for i in range(100):
        container.store_core_data(f"core_{i}", f"important_data_{i}")
    
    # íŒŒìƒ ë°ì´í„° ìƒì„± ë° ìºì‹±
    derived_objects = []
    for i in range(1000):
        obj = {"computed": i * 2, "metadata": f"derived_{i}"}
        container.cache_derived_data(f"derived_{i}", obj)
        
        # ì¼ë¶€ë§Œ ê°•í•œ ì°¸ì¡° ìœ ì§€
        if i < 100:
            derived_objects.append(obj)
    
    print(f"ì´ˆê¸° ìƒíƒœ: {container.get_stats()}")
    
    # ì¼ë¶€ íŒŒìƒ ë°ì´í„° ì°¸ì¡° ì œê±°
    del derived_objects
    gc.collect()
    
    print(f"GC í›„ ìƒíƒœ: {container.get_stats()}")
    
    # ë°ì´í„° ì ‘ê·¼ í…ŒìŠ¤íŠ¸
    for i in range(50):
        # í•µì‹¬ ë°ì´í„° ì ‘ê·¼
        container.get_data(f"core_{i}")
        
        # íŒŒìƒ ë°ì´í„° ì ‘ê·¼ (ì¼ë¶€ëŠ” GCë¡œ ì œê±°ë¨)
        container.get_data(f"derived_{i}")
    
    print(f"ì ‘ê·¼ í›„ ìƒíƒœ: {container.get_stats()}")
```

## 3. ì‹¤ì „ ì„±ëŠ¥ ì¸¡ì •ê³¼ ë²¤ì¹˜ë§ˆí‚¹

### 3.1 ì¢…í•©ì ì¸ ìµœì í™” íš¨ê³¼ ì¸¡ì •

```python
def comprehensive_optimization_benchmark():
    """ì¢…í•©ì ì¸ ìµœì í™” íš¨ê³¼ ì¸¡ì •"""
    
    print("=== ì¢…í•© ìµœì í™” íš¨ê³¼ ì¸¡ì • ===")
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤: ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì„œë¹„ìŠ¤ ì‹œë®¬ë ˆì´ì…˜
    
    def create_test_scenario():
        """í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±"""
        return {
            'users': [{'id': i, 'name': f'user_{i}', 'data': [0] * 100}
                     for i in range(100000)],
            'sessions': {f'session_{i}': {'user_id': i % 100000, 'timestamp': time.time()}
                        for i in range(500000)},
            'cache_data': {f'key_{i}': {'value': i * 2, 'metadata': f'cached_{i}'}
                          for i in range(200000)}
        }
    
    # 1. ê¸°ë³¸ êµ¬í˜„ (ìµœì í™” ì—†ìŒ)
    print("\n1. ê¸°ë³¸ êµ¬í˜„ ì¸¡ì •...")
    start_memory = psutil.Process().memory_info().rss / 1024 / 1024
    start_time = time.time()
    
    basic_data = create_test_scenario()
    
    basic_time = time.time() - start_time
    basic_memory = psutil.Process().memory_info().rss / 1024 / 1024
    
    print(f"ê¸°ë³¸ êµ¬í˜„: {basic_time:.3f}ì´ˆ, {basic_memory - start_memory:.1f}MB")
    
    del basic_data
    gc.collect()
    
    # 2. GC ìµœì í™” ì ìš©
    print("\n2. GC ìµœì í™” ì ìš©...")
    start_memory = psutil.Process().memory_info().rss / 1024 / 1024
    start_time = time.time()
    
    with PythonGCOptimization.gc_disabled():
        optimized_data = create_test_scenario()
    
    gc.collect()  # í•œ ë²ˆì— ì •ë¦¬
    
    optimized_time = time.time() - start_time
    optimized_memory = psutil.Process().memory_info().rss / 1024 / 1024
    
    print(f"GC ìµœì í™”: {optimized_time:.3f}ì´ˆ, {optimized_memory - start_memory:.1f}MB")
    
    # ì„±ëŠ¥ ê°œì„  ê³„ì‚°
    time_improvement = (basic_time - optimized_time) / basic_time * 100
    print(f"ì‹œê°„ ê°œì„ : {time_improvement:.1f}%")
    
    del optimized_data
    gc.collect()
    
    # 3. __slots__ í´ë˜ìŠ¤ ì‚¬ìš© ì‹œë®¬ë ˆì´ì…˜
    print("\n3. __slots__ ìµœì í™” ì‹œë®¬ë ˆì´ì…˜...")
    
    # __slots__ ì‚¬ìš©í•œ ì‚¬ìš©ì í´ë˜ìŠ¤
    class OptimizedUser:
        __slots__ = ['id', 'name', 'data']
        
        def __init__(self, id, name, data):
            self.id = id
            self.name = name
            self.data = data
    
    start_memory = psutil.Process().memory_info().rss / 1024 / 1024
    
    slots_users = [OptimizedUser(i, f'user_{i}', [0] * 100)
                   for i in range(100000)]
    
    slots_memory = psutil.Process().memory_info().rss / 1024 / 1024
    
    print(f"__slots__ ì‚¬ìš©: {slots_memory - start_memory:.1f}MB")
    
    del slots_users
    gc.collect()

if __name__ == "__main__":
    # ëª¨ë“  ìµœì í™” ê¸°ë²• ë°ëª¨
    print("Python GC ìµœì í™” ê¸°ë²• ì¢…í•© ë°ëª¨")
    print("=" * 50)
    
    # 1. GC ì œì–´ ìµœì í™”
    PythonGCOptimization.benchmark_gc_impact()
    batch_processing_optimization()
    
    # 2. __slots__ ë©”ëª¨ë¦¬ ìµœì í™”
    compare_memory_efficiency()
    
    # 3. Weak Reference í™œìš©
    demonstrate_weak_references()
    demonstrate_advanced_optimization()
    
    # 4. ì¢…í•© ë²¤ì¹˜ë§ˆí‚¹
    comprehensive_optimization_benchmark()
```

## í•µì‹¬ ìš”ì 

### 1. GC ì œì–´ ìµœì í™”

- **ë°°ì¹˜ ì‘ì—… ì‹œ 16% ì„±ëŠ¥ í–¥ìƒ** ê°€ëŠ¥
- ì„ì‹œ GC ë¹„í™œì„±í™” + ì‘ì—… í›„ ëª…ì‹œì  ì •ë¦¬ íŒ¨í„´
- ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìœ„í—˜ ê´€ë¦¬ í•„ìˆ˜

### 2. **slots** ë©”ëª¨ë¦¬ ì ˆì•½

- **ê°ì²´ë‹¹ 30-40% ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ**
- ëŒ€ëŸ‰ì˜ ì‘ì€ ê°ì²´ ì²˜ë¦¬ ì‹œ íŠ¹íˆ íš¨ê³¼ì 
- ë™ì  ì†ì„± ì¶”ê°€ ì œí•œ ê³ ë ¤ í•„ìš”

### 3. Weak Reference í™œìš©

- **ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬**ë¡œ ëˆ„ìˆ˜ ë°©ì§€
- ìºì‹œ êµ¬í˜„ ì‹œ ë§¤ìš° íš¨ê³¼ì 
- í•µì‹¬ ë°ì´í„°ì™€ íŒŒìƒ ë°ì´í„° êµ¬ë¶„ ê´€ë¦¬

---

**ì´ì „**: [Python GC ê¸°ë³¸ êµ¬ì¡°](./08-05-1-python-gc-fundamentals.md)  
**ë‹¤ìŒ**: [ì‹¤ì œ ì„œë¹„ìŠ¤ GC ìµœì í™” ì‚¬ë¡€](./08-50-3-python-gc-production.md)ì—ì„œ Instagram, Dropbox ë“±ì˜ ì‹¤ì œ í”„ë¡œë•ì…˜ ìµœì í™” ê²½í—˜ì„ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

### ğŸ“– í˜„ì¬ ë¬¸ì„œ ì •ë³´

- **ë‚œì´ë„**: INTERMEDIATE
- **ì£¼ì œ**: ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ
- **ì˜ˆìƒ ì‹œê°„**: 3-5ì‹œê°„

### ğŸ¯ í•™ìŠµ ê²½ë¡œ

- [ğŸ“š INTERMEDIATE ë ˆë²¨ ì „ì²´ ë³´ê¸°](../learning-paths/intermediate/)
- [ğŸ  ë©”ì¸ í•™ìŠµ ê²½ë¡œ](../learning-paths/)
- [ğŸ“‹ ì „ì²´ ê°€ì´ë“œ ëª©ë¡](../README.md)

### ğŸ“‚ ê°™ì€ ì±•í„° (chapter-08-memory-allocator-gc)

- [Chapter 9-1: ë©”ëª¨ë¦¬ í• ë‹¹ìì˜ ë‚´ë¶€ êµ¬í˜„ ê°œìš”](./08-10-memory-allocator.md)
- [Chapter 9-1A: malloc ë‚´ë¶€ ë™ì‘ì˜ ì§„ì‹¤](./08-01-malloc-fundamentals.md)
- [Chapter 9-1B: ë©”ëª¨ë¦¬ í• ë‹¹ì ëŒ€ì „: tcmalloc vs jemalloc vs mimalloc](./08-11-allocator-comparison.md)
- [Chapter 9-1C: ì»¤ìŠ¤í…€ ë©”ëª¨ë¦¬ í• ë‹¹ì êµ¬í˜„](./08-12-custom-allocators.md)
- [Chapter 9-1D: ì‹¤ì „ ë©”ëª¨ë¦¬ ìµœì í™” ì‚¬ë¡€](../chapter-09-advanced-memory-management/08-30-production-optimization.md)

### ğŸ·ï¸ ê´€ë ¨ í‚¤ì›Œë“œ

`python`, `gc-optimization`, `memory-management`, `performance-tuning`, `slots`

### â­ï¸ ë‹¤ìŒ ë‹¨ê³„ ê°€ì´ë“œ

- ì‹¤ë¬´ ì ìš©ì„ ì—¼ë‘ì— ë‘ê³  í”„ë¡œì íŠ¸ì— ì ìš©í•´ë³´ì„¸ìš”
- ê´€ë ¨ ë„êµ¬ë“¤ì„ ì§ì ‘ ì‚¬ìš©í•´ë³´ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤
