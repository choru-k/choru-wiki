---
tags:
  - Debugging
  - Troubleshooting
  - Problem Solving
  - Root Cause Analysis
  - Incident Management
---

# 13.5 ë””ë²„ê¹… ê¸°ë²• ë° ë¬¸ì œ í•´ê²°

## 2024ë…„ 8ì›”, ì‚¬ë¼ì§„ ì£¼ë¬¸ì˜ ë¯¸ìŠ¤í„°ë¦¬

2024ë…„ 8ì›” 3ì¼ ê¸ˆìš”ì¼ ì˜¤í›„ 7ì‹œ, ì£¼ë§ì„ ì•ë‘” í‰ì˜¨í•œ ì˜¤í›„ì˜€ë‹¤. ê°‘ìê¸° ê³ ê° ì„œë¹„ìŠ¤íŒ€ì—ì„œ ì—°ë½ì´ ì™”ë‹¤.

"ê°œë°œíŒ€! ê³ ê°ë“¤ì´ ì£¼ë¬¸ì„ í–ˆëŠ”ë° ì£¼ë¬¸ ë‚´ì—­ì´ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤ê³  í•´ìš”. ê²°ì œëŠ” ë˜ì—ˆëŠ”ë° ì£¼ë¬¸ì´ ì‚¬ë¼ì¡Œì–´ìš”!"

ë‹¹í™©í•œ ë§ˆìŒìœ¼ë¡œ ì‹œìŠ¤í…œì„ í™•ì¸í•´ë³´ë‹ˆ:

- ê²°ì œ ì„œë¹„ìŠ¤: ì •ìƒ ì‘ë™ âœ…
- ì£¼ë¬¸ ì„œë¹„ìŠ¤: ì •ìƒ ì‘ë™ âœ…  
- ì¬ê³  ì„œë¹„ìŠ¤: ì •ìƒ ì‘ë™ âœ…
- ì•Œë¦¼ ì„œë¹„ìŠ¤: ì •ìƒ ì‘ë™ âœ…

**ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ì •ìƒì¸ë° ì£¼ë¬¸ì´ ì‚¬ë¼ì§€ê³  ìˆì—ˆë‹¤.**

ë¡œê·¸ë¥¼ ë’¤ì§€ê³ , ë©”íŠ¸ë¦­ì„ í™•ì¸í•˜ê³ , ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¡°ì‚¬í–ˆì§€ë§Œ ëª…í™•í•œ ì›ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ì—ˆë‹¤. ë¬¸ì œëŠ” **ì‚°ë°œì **ì´ì—ˆê³ , **ì¬í˜„ë„ ì–´ë ¤ì› ë‹¤**.

ê·¸ë•Œ ê¹¨ë‹¬ì•˜ë‹¤. ìš°ë¦¬ì—ê²Œ í•„ìš”í•œ ê²ƒì€ **ì²´ê³„ì ì¸ ë””ë²„ê¹… ë°©ë²•ë¡ **ì´ì—ˆë‹¤.

## ì²´ê³„ì  ë¬¸ì œ í•´ê²° í”„ë ˆì„ì›Œí¬

### 1. OODA Loop ê¸°ë°˜ ë””ë²„ê¹…

êµ°ì‚¬ ì „ëµì—ì„œ ì‚¬ìš©í•˜ëŠ” OODA Loop(Observe-Orient-Decide-Act)ì„ ë””ë²„ê¹…ì— ì ìš©í•´ë³´ì.

```python
import time
import logging
from enum import Enum
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Any
from datetime import datetime

class IncidentSeverity(Enum):
    LOW = "low"
    MEDIUM = "medium" 
    HIGH = "high"
    CRITICAL = "critical"

class IncidentStatus(Enum):
    REPORTED = "reported"
    INVESTIGATING = "investigating"
    ROOT_CAUSE_FOUND = "root_cause_found"
    MITIGATING = "mitigating"
    RESOLVED = "resolved"
    CLOSED = "closed"

@dataclass
class Evidence:
    timestamp: datetime
    source: str
    data: Dict[str, Any]
    confidence: float  # 0.0 ~ 1.0
    description: str

@dataclass
class Hypothesis:
    id: str
    description: str
    confidence: float
    evidence_supporting: List[Evidence] = field(default_factory=list)
    evidence_contradicting: List[Evidence] = field(default_factory=list)
    tested: bool = False
    test_result: Optional[bool] = None

@dataclass
class Action:
    id: str
    description: str
    action_type: str  # investigate, mitigate, fix
    executed: bool = False
    result: Optional[str] = None
    execution_time: Optional[datetime] = None

class SystematicDebugger:
    def __init__(self, incident_description: str):
        self.incident_description = incident_description
        self.start_time = datetime.now()
        self.status = IncidentStatus.REPORTED
        self.severity = IncidentSeverity.MEDIUM
        
        # OODA Loop ì»´í¬ë„ŒíŠ¸ë“¤
        self.observations: List[Evidence] = []
        self.hypotheses: List[Hypothesis] = []
        self.actions_taken: List[Action] = []
        self.decisions_log: List[Dict] = []
        
        # ë””ë²„ê¹… ì»¨í…ìŠ¤íŠ¸
        self.affected_systems: List[str] = []
        self.timeline: List[Dict] = []
        self.root_cause: Optional[str] = None
        
        logging.info(f"ìƒˆë¡œìš´ ì‚¬ê±´ ì¡°ì‚¬ ì‹œì‘: {incident_description}")
    
    def observe(self, evidence: Evidence):
        """ê´€ì°°: ì¦ê±° ìˆ˜ì§‘"""
        self.observations.append(evidence)
        self.timeline.append({
            'timestamp': evidence.timestamp,
            'event_type': 'observation',
            'description': evidence.description,
            'source': evidence.source
        })
        
        logging.info(f"ìƒˆë¡œìš´ ì¦ê±° ìˆ˜ì§‘: {evidence.description} (ì‹ ë¢°ë„: {evidence.confidence})")
    
    def orient(self) -> List[Hypothesis]:
        """ë°©í–¥ì„¤ì •: ê°€ì„¤ ìƒì„± ë° ìš°ì„ ìˆœìœ„ ê²°ì •"""
        # ì¦ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì„¤ë“¤ì„ ìƒì„±/ì—…ë°ì´íŠ¸
        self._update_hypotheses()
        
        # ê°€ì„¤ë“¤ì„ ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_hypotheses = sorted(self.hypotheses, 
                                 key=lambda h: h.confidence, 
                                 reverse=True)
        
        self.decisions_log.append({
            'timestamp': datetime.now(),
            'decision_type': 'hypothesis_prioritization',
            'details': [{'hypothesis': h.description, 'confidence': h.confidence} 
                       for h in sorted_hypotheses[:3]]
        })
        
        return sorted_hypotheses
    
    def decide(self, top_hypothesis: Hypothesis) -> List[Action]:
        """ê²°ì •: ë‹¤ìŒ í–‰ë™ ê²°ì •"""
        if not top_hypothesis.tested:
            # ê°€ì„¤ ê²€ì¦ ì•¡ì…˜
            test_action = Action(
                id=f"test_hypothesis_{top_hypothesis.id}",
                description=f"ê°€ì„¤ '{top_hypothesis.description}' ê²€ì¦",
                action_type="investigate"
            )
            self.actions_taken.append(test_action)
            
        elif top_hypothesis.test_result:
            # ê°€ì„¤ì´ ì°¸ì´ë©´ ì™„í™”/ìˆ˜ì • ì•¡ì…˜
            fix_action = Action(
                id=f"fix_{top_hypothesis.id}",
                description=f"ê·¼ë³¸ ì›ì¸ '{top_hypothesis.description}' í•´ê²°",
                action_type="fix"
            )
            self.actions_taken.append(fix_action)
        
        self.decisions_log.append({
            'timestamp': datetime.now(),
            'decision_type': 'action_planning',
            'selected_hypothesis': top_hypothesis.description,
            'planned_actions': [a.description for a in self.actions_taken if not a.executed]
        })
        
        return [a for a in self.actions_taken if not a.executed]
    
    def act(self, action: Action, result: str):
        """í–‰ë™: ì•¡ì…˜ ì‹¤í–‰ ë° ê²°ê³¼ ê¸°ë¡"""
        action.executed = True
        action.result = result
        action.execution_time = datetime.now()
        
        self.timeline.append({
            'timestamp': action.execution_time,
            'event_type': 'action',
            'description': action.description,
            'result': result
        })
        
        logging.info(f"ì•¡ì…˜ ì‹¤í–‰: {action.description} â†’ {result}")
        
        # ê°€ì„¤ ê²€ì¦ ê²°ê³¼ ì—…ë°ì´íŠ¸
        if action.action_type == "investigate":
            for hypothesis in self.hypotheses:
                if f"test_hypothesis_{hypothesis.id}" == action.id:
                    hypothesis.tested = True
                    hypothesis.test_result = "confirmed" in result.lower()
                    break
    
    def _update_hypotheses(self):
        """ì¦ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì„¤ë“¤ ì—…ë°ì´íŠ¸"""
        # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ê°€ì„¤ ìƒì„± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”)
        error_evidence = [e for e in self.observations if "error" in e.description.lower()]
        network_evidence = [e for e in self.observations if "network" in e.description.lower()]
        database_evidence = [e for e in self.observations if "database" in e.description.lower()]
        
        if error_evidence and not any(h.id == "application_bug" for h in self.hypotheses):
            self.hypotheses.append(Hypothesis(
                id="application_bug",
                description="ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œì˜ ë²„ê·¸",
                confidence=0.7,
                evidence_supporting=error_evidence
            ))
        
        if network_evidence and not any(h.id == "network_issue" for h in self.hypotheses):
            self.hypotheses.append(Hypothesis(
                id="network_issue", 
                description="ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ",
                confidence=0.6,
                evidence_supporting=network_evidence
            ))
        
        if database_evidence and not any(h.id == "database_issue" for h in self.hypotheses):
            self.hypotheses.append(Hypothesis(
                id="database_issue",
                description="ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ë¬¸ì œ",
                confidence=0.8,
                evidence_supporting=database_evidence
            ))
    
    def get_debug_report(self) -> Dict:
        """í˜„ì¬ ë””ë²„ê¹… ìƒí™© ë¦¬í¬íŠ¸"""
        return {
            'incident': self.incident_description,
            'status': self.status.value,
            'severity': self.severity.value,
            'duration': str(datetime.now() - self.start_time),
            'observations_count': len(self.observations),
            'active_hypotheses': len([h for h in self.hypotheses if not h.tested]),
            'confirmed_hypotheses': len([h for h in self.hypotheses if h.test_result]),
            'actions_taken': len([a for a in self.actions_taken if a.executed]),
            'root_cause': self.root_cause,
            'timeline': self.timeline[-5:]  # ìµœê·¼ 5ê°œ ì´ë²¤íŠ¸
        }

# ì‹¤ì „ ë””ë²„ê¹… ì‹œë‚˜ë¦¬ì˜¤
debugger = SystematicDebugger("ì£¼ë¬¸ì´ ì‚¬ë¼ì§€ëŠ” ë¬¸ì œ")

# 1. Observe - ì¦ê±° ìˆ˜ì§‘
debugger.observe(Evidence(
    timestamp=datetime.now(),
    source="customer_service",
    data={"affected_orders": 23, "time_range": "14:00-19:00"},
    confidence=0.9,
    description="ê³ ê° ì„œë¹„ìŠ¤íŒ€ì—ì„œ ë³´ê³ ëœ ì£¼ë¬¸ ëˆ„ë½ ì‚¬ë¡€ 23ê±´"
))

debugger.observe(Evidence(
    timestamp=datetime.now(),
    source="application_logs",
    data={"error_count": 0, "warning_count": 5},
    confidence=0.8,
    description="ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ì—ì„œ ê´€ë ¨ ì—ëŸ¬ ì—†ìŒ, ê²½ê³  5ê±´"
))

debugger.observe(Evidence(
    timestamp=datetime.now(),
    source="database_logs",
    data={"deadlock_count": 12, "timeout_count": 8},
    confidence=0.9,
    description="ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ êµì°©ìƒíƒœ 12ê±´, íƒ€ì„ì•„ì›ƒ 8ê±´ ë°œìƒ"
))

# 2. Orient - ê°€ì„¤ ìƒì„±
top_hypotheses = debugger.orient()

# 3. Decide - ì•¡ì…˜ ê²°ì •  
if top_hypotheses:
    planned_actions = debugger.decide(top_hypotheses[0])
    
    # 4. Act - ì•¡ì…˜ ì‹¤í–‰
    for action in planned_actions:
        if action.action_type == "investigate":
            # ê°€ì„¤ ê²€ì¦ ì‹œë®¬ë ˆì´ì…˜
            if "database" in action.description:
                debugger.act(action, "confirmed: ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëœì­ì…˜ êµì°©ìƒíƒœë¡œ ì¸í•œ ì£¼ë¬¸ ë¡¤ë°±")
                debugger.root_cause = "ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëœì­ì…˜ êµì°©ìƒíƒœ"
                debugger.status = IncidentStatus.ROOT_CAUSE_FOUND

print("=== ë””ë²„ê¹… ë¦¬í¬íŠ¸ ===")
report = debugger.get_debug_report()
for key, value in report.items():
    print(f"{key}: {value}")
```

### 2. ë¶„ì‚° ì‹œìŠ¤í…œ ë””ë²„ê¹…

ë¶„ì‚° ì‹œìŠ¤í…œì—ì„œëŠ” **ì¸ê³¼ê´€ê³„ ì¶”ì **ì´ ê°€ì¥ ì¤‘ìš”í•˜ë‹¤.

```python
import asyncio
import aiohttp
from typing import Dict, List, Optional
import json
import traceback

class DistributedDebugger:
    def __init__(self):
        self.trace_contexts: Dict[str, Dict] = {}
        self.service_dependencies: Dict[str, List[str]] = {
            'frontend': ['user-service', 'order-service'],
            'order-service': ['payment-service', 'inventory-service'],
            'payment-service': ['external-payment-api'],
            'inventory-service': ['database']
        }
    
    async def debug_distributed_flow(self, trace_id: str, 
                                   failed_service: str) -> Dict[str, Any]:
        """ë¶„ì‚° í”Œë¡œìš° ë””ë²„ê¹…"""
        debug_info = {
            'trace_id': trace_id,
            'failed_service': failed_service,
            'cascade_analysis': {},
            'root_cause_candidates': [],
            'service_states': {},
            'recommendations': []
        }
        
        # 1. ì‹¤íŒ¨í•œ ì„œë¹„ìŠ¤ì˜ ì˜ì¡´ì„± íŠ¸ë¦¬ ë¶„ì„
        dependency_chain = self._build_dependency_chain(failed_service)
        debug_info['dependency_chain'] = dependency_chain
        
        # 2. ê° ì„œë¹„ìŠ¤ì˜ ìƒíƒœ í™•ì¸
        for service in dependency_chain:
            try:
                state = await self._check_service_health(service, trace_id)
                debug_info['service_states'][service] = state
                
                # ì ì¬ì  ê·¼ë³¸ ì›ì¸ ì‹ë³„
                if not state.get('healthy', True):
                    debug_info['root_cause_candidates'].append({
                        'service': service,
                        'issues': state.get('issues', []),
                        'impact_score': self._calculate_impact_score(service, dependency_chain)
                    })
                    
            except Exception as e:
                debug_info['service_states'][service] = {
                    'healthy': False,
                    'error': str(e),
                    'issues': [f'ì„œë¹„ìŠ¤ ì ‘ê·¼ ë¶ˆê°€: {str(e)}']
                }
        
        # 3. ê³„ë‹¨ì‹ ì‹¤íŒ¨ ë¶„ì„
        debug_info['cascade_analysis'] = await self._analyze_cascade_failure(
            trace_id, dependency_chain
        )
        
        # 4. ìˆ˜ì • ê¶Œì¥ì‚¬í•­ ìƒì„±
        debug_info['recommendations'] = self._generate_recommendations(debug_info)
        
        return debug_info
    
    def _build_dependency_chain(self, service: str) -> List[str]:
        """ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ì²´ì¸ êµ¬ì¶•"""
        visited = set()
        chain = []
        
        def dfs(current_service):
            if current_service in visited:
                return
            
            visited.add(current_service)
            chain.append(current_service)
            
            dependencies = self.service_dependencies.get(current_service, [])
            for dep in dependencies:
                dfs(dep)
        
        dfs(service)
        return chain
    
    async def _check_service_health(self, service: str, trace_id: str) -> Dict:
        """ì„œë¹„ìŠ¤ í—¬ìŠ¤ ì²´í¬"""
        health_info = {
            'healthy': True,
            'response_time': 0,
            'issues': [],
            'metrics': {}
        }
        
        try:
            # í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ (ì‹œë®¬ë ˆì´ì…˜)
            start_time = time.time()
            
            if service == 'database':
                # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
                health_info['metrics'] = await self._check_database_health()
            elif service == 'external-payment-api':
                # ì™¸ë¶€ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸
                health_info['metrics'] = await self._check_external_api_health()
            else:
                # ë‚´ë¶€ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì²´í¬
                health_info['metrics'] = await self._check_microservice_health(service)
            
            health_info['response_time'] = time.time() - start_time
            
            # ë©”íŠ¸ë¦­ ê¸°ë°˜ ì´ìŠˆ ê°ì§€
            metrics = health_info['metrics']
            if metrics.get('error_rate', 0) > 0.05:
                health_info['issues'].append(f'ë†’ì€ ì—ëŸ¬ìœ¨: {metrics["error_rate"]:.2%}')
                health_info['healthy'] = False
            
            if metrics.get('response_time_p99', 0) > 1.0:
                health_info['issues'].append(f'ëŠë¦° ì‘ë‹µì‹œê°„: P99 {metrics["response_time_p99"]:.2f}s')
            
            if metrics.get('cpu_usage', 0) > 0.8:
                health_info['issues'].append(f'ë†’ì€ CPU ì‚¬ìš©ë¥ : {metrics["cpu_usage"]:.1%}')
                
        except Exception as e:
            health_info['healthy'] = False
            health_info['issues'].append(f'í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {str(e)}')
        
        return health_info
    
    async def _check_database_health(self) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ í—¬ìŠ¤ ì²´í¬"""
        # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
        return {
            'connection_count': 45,
            'max_connections': 100,
            'deadlock_count': 12,
            'slow_query_count': 8,
            'error_rate': 0.02,
            'response_time_p99': 0.8
        }
    
    async def _check_external_api_health(self) -> Dict:
        """ì™¸ë¶€ API í—¬ìŠ¤ ì²´í¬"""
        return {
            'error_rate': 0.15,  # 15% ì—ëŸ¬ìœ¨ - ë¬¸ì œ ìˆìŒ
            'response_time_p99': 2.5,
            'timeout_count': 23,
            'rate_limit_hits': 5
        }
    
    async def _check_microservice_health(self, service: str) -> Dict:
        """ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í—¬ìŠ¤ ì²´í¬"""
        # ì„œë¹„ìŠ¤ë³„ ë‹¤ë¥¸ ìƒíƒœ ì‹œë®¬ë ˆì´ì…˜
        if service == 'payment-service':
            return {
                'error_rate': 0.01,
                'response_time_p99': 0.3,
                'cpu_usage': 0.6,
                'memory_usage': 0.7,
                'queue_depth': 156  # í ì ì²´
            }
        else:
            return {
                'error_rate': 0.005,
                'response_time_p99': 0.2,
                'cpu_usage': 0.4,
                'memory_usage': 0.5
            }
    
    def _calculate_impact_score(self, service: str, chain: List[str]) -> float:
        """ì„œë¹„ìŠ¤ ì˜í–¥ë„ ì ìˆ˜ ê³„ì‚°"""
        # ì˜ì¡´ì„± ì²´ì¸ì—ì„œì˜ ìœ„ì¹˜ì™€ ì˜ì¡´í•˜ëŠ” ì„œë¹„ìŠ¤ ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
        dependencies_count = len(self.service_dependencies.get(service, []))
        chain_position = chain.index(service) if service in chain else len(chain)
        
        # ìƒìœ„ ì„œë¹„ìŠ¤ì¼ìˆ˜ë¡, ì˜ì¡´ì„±ì´ ë§ì„ìˆ˜ë¡ ì˜í–¥ë„ê°€ í¼
        return (dependencies_count * 0.3) + ((len(chain) - chain_position) * 0.7)
    
    async def _analyze_cascade_failure(self, trace_id: str, 
                                     chain: List[str]) -> Dict:
        """ê³„ë‹¨ì‹ ì‹¤íŒ¨ ë¶„ì„"""
        cascade_info = {
            'failure_propagation': [],
            'blast_radius': 0,
            'critical_path': []
        }
        
        # ì‹¤íŒ¨ ì „íŒŒ ê²½ë¡œ ì¶”ì 
        failed_services = []
        for service in chain:
            service_state = await self._check_service_health(service, trace_id)
            if not service_state['healthy']:
                failed_services.append(service)
                
                # ì´ ì„œë¹„ìŠ¤ ì‹¤íŒ¨ê°€ ë‹¤ë¥¸ ì„œë¹„ìŠ¤ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„
                affected_services = [s for s, deps in self.service_dependencies.items() 
                                   if service in deps]
                
                cascade_info['failure_propagation'].append({
                    'failed_service': service,
                    'affected_services': affected_services,
                    'failure_reasons': service_state['issues']
                })
        
        cascade_info['blast_radius'] = len(failed_services)
        cascade_info['critical_path'] = failed_services
        
        return cascade_info
    
    def _generate_recommendations(self, debug_info: Dict) -> List[str]:
        """ìˆ˜ì • ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ê·¼ë³¸ ì›ì¸ í›„ë³´ë“¤ì„ ì˜í–¥ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        root_causes = sorted(debug_info['root_cause_candidates'], 
                           key=lambda x: x['impact_score'], reverse=True)
        
        for candidate in root_causes[:3]:  # ìƒìœ„ 3ê°œ
            service = candidate['service']
            issues = candidate['issues']
            
            for issue in issues:
                if 'ì—ëŸ¬ìœ¨' in issue:
                    recommendations.append(f"{service}: ì—ëŸ¬ìœ¨ ê°œì„ ì„ ìœ„í•œ ì½”ë“œ ë¦¬ë·° ë° ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”")
                elif 'ì‘ë‹µì‹œê°„' in issue:
                    recommendations.append(f"{service}: ì„±ëŠ¥ ìµœì í™” ë° ìºì‹± ë„ì… ê²€í† ")
                elif 'CPU' in issue:
                    recommendations.append(f"{service}: ë¦¬ì†ŒìŠ¤ ìŠ¤ì¼€ì¼ë§ ë˜ëŠ” ë¡œë“œ ë°¸ëŸ°ì‹± ê°œì„ ")
                elif 'ì ‘ê·¼ ë¶ˆê°€' in issue:
                    recommendations.append(f"{service}: ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ë° í—¬ìŠ¤ ì²´í¬ ê°œì„ ")
        
        # ì¼ë°˜ì ì¸ ë¶„ì‚° ì‹œìŠ¤í…œ ê¶Œì¥ì‚¬í•­
        if debug_info['cascade_analysis']['blast_radius'] > 2:
            recommendations.append("ì„œí‚· ë¸Œë ˆì´ì»¤ íŒ¨í„´ ë„ì…ìœ¼ë¡œ ê³„ë‹¨ì‹ ì‹¤íŒ¨ ë°©ì§€")
            recommendations.append("ì„œë¹„ìŠ¤ ê°„ ì˜ì¡´ì„± ê°ì†Œ ë° ë¹„ë™ê¸° ì²˜ë¦¬ ë„ì…")
        
        return recommendations

# ì‹¤ì „ ì‚¬ìš© ì˜ˆì‹œ
async def debug_missing_orders():
    """ì‚¬ë¼ì§„ ì£¼ë¬¸ ë¬¸ì œ ë””ë²„ê¹…"""
    debugger = DistributedDebugger()
    
    # ë¶„ì‚° í”Œë¡œìš° ë””ë²„ê¹… ì‹¤í–‰
    debug_result = await debugger.debug_distributed_flow(
        trace_id="order_issue_20240803_001",
        failed_service="order-service"
    )
    
    print("=== ë¶„ì‚° ì‹œìŠ¤í…œ ë””ë²„ê¹… ê²°ê³¼ ===")
    print(f"ì¶”ì  ID: {debug_result['trace_id']}")
    print(f"ì‹¤íŒ¨ ì„œë¹„ìŠ¤: {debug_result['failed_service']}")
    print(f"ì˜í–¥ ë²”ìœ„: {debug_result['cascade_analysis']['blast_radius']}ê°œ ì„œë¹„ìŠ¤")
    
    print("\n=== ê·¼ë³¸ ì›ì¸ í›„ë³´ ===")
    for candidate in debug_result['root_cause_candidates']:
        print(f"- {candidate['service']} (ì˜í–¥ë„: {candidate['impact_score']:.1f})")
        for issue in candidate['issues']:
            print(f"  â€¢ {issue}")
    
    print("\n=== ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­ ===")
    for i, rec in enumerate(debug_result['recommendations'], 1):
        print(f"{i}. {rec}")

# asyncio.run(debug_missing_orders())
```

### 3. ìƒì‚°ì„± ë†’ì€ ë””ë²„ê¹… ë„êµ¬ë“¤

ì‹¤ì „ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë””ë²„ê¹… ë„êµ¬ë“¤ì„ í™œìš©í•´ë³´ì.

```python
import pdb
import sys
import inspect
from functools import wraps
from contextlib import contextmanager

class SmartDebugger:
    def __init__(self):
        self.debug_sessions: List[Dict] = []
        self.breakpoint_conditions: Dict[str, callable] = {}
    
    def conditional_breakpoint(self, condition_func: callable):
        """ì¡°ê±´ë¶€ ë¸Œë ˆì´í¬í¬ì¸íŠ¸ ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # ì¡°ê±´ í™•ì¸
                if condition_func(*args, **kwargs):
                    print(f"ğŸ” ì¡°ê±´ë¶€ ë¸Œë ˆì´í¬í¬ì¸íŠ¸ í™œì„±í™”: {func.__name__}")
                    print(f"ì¸ìˆ˜: args={args}, kwargs={kwargs}")
                    
                    # í˜„ì¬ ìŠ¤íƒ ì •ë³´ ì¶œë ¥
                    frame = sys._getframe(1)
                    print(f"í˜¸ì¶œ ìœ„ì¹˜: {frame.f_code.co_filename}:{frame.f_lineno}")
                    
                    # ì§€ì—­ ë³€ìˆ˜ ì¶œë ¥
                    local_vars = frame.f_locals
                    print("ì§€ì—­ ë³€ìˆ˜:")
                    for name, value in local_vars.items():
                        if not name.startswith('_'):
                            print(f"  {name} = {repr(value)}")
                    
                    # ëŒ€í™”í˜• ë””ë²„ê±° ì‹œì‘
                    pdb.set_trace()
                
                return func(*args, **kwargs)
            return wrapper
        return decorator
    
    def auto_debug_on_exception(self, exception_types: tuple = (Exception,)):
        """ì˜ˆì™¸ ë°œìƒ ì‹œ ìë™ ë””ë²„ê¹… ëª¨ë“œ"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                try:
                    return func(*args, **kwargs)
                except exception_types as e:
                    print(f"ğŸš¨ ì˜ˆì™¸ ë°œìƒìœ¼ë¡œ ë””ë²„ê¹… ëª¨ë“œ ì§„ì…")
                    print(f"ì˜ˆì™¸: {type(e).__name__}: {str(e)}")
                    print(f"í•¨ìˆ˜: {func.__name__}")
                    
                    # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ë¶„ì„
                    import traceback
                    print("\nìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:")
                    traceback.print_exc()
                    
                    # ì˜ˆì™¸ ë°œìƒ ì§€ì ì˜ ë³€ìˆ˜ ìƒíƒœ ì¶œë ¥
                    frame = sys._getframe()
                    self._print_frame_variables(frame)
                    
                    # ë””ë²„ê±° ì‹œì‘
                    pdb.post_mortem()
                    raise
            return wrapper
        return decorator
    
    def _print_frame_variables(self, frame):
        """í”„ë ˆì„ì˜ ë³€ìˆ˜ë“¤ ì¶œë ¥"""
        print("\ní˜„ì¬ í”„ë ˆì„ ë³€ìˆ˜ë“¤:")
        local_vars = frame.f_locals
        for name, value in local_vars.items():
            if not name.startswith('_') and name != 'self':
                try:
                    print(f"  {name} = {repr(value)[:100]}")
                except:
                    print(f"  {name} = <ì¶œë ¥ ë¶ˆê°€ëŠ¥>")
    
    @contextmanager
    def debug_context(self, context_name: str):
        """ë””ë²„ê¹… ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        print(f"ğŸ” ë””ë²„ê¹… ì»¨í…ìŠ¤íŠ¸ ì‹œì‘: {context_name}")
        start_time = time.time()
        
        try:
            yield
        except Exception as e:
            print(f"âŒ ì»¨í…ìŠ¤íŠ¸ '{context_name}'ì—ì„œ ì˜ˆì™¸ ë°œìƒ: {e}")
            raise
        finally:
            duration = time.time() - start_time
            print(f"âœ… ë””ë²„ê¹… ì»¨í…ìŠ¤íŠ¸ ì¢…ë£Œ: {context_name} (ì†Œìš”ì‹œê°„: {duration:.3f}ì´ˆ)")
    
    def trace_function_calls(self, target_module: str = None):
        """í•¨ìˆ˜ í˜¸ì¶œ ì¶”ì """
        def trace_calls(frame, event, arg):
            if event == 'call':
                filename = frame.f_code.co_filename
                function_name = frame.f_code.co_name
                
                # íŠ¹ì • ëª¨ë“ˆë§Œ ì¶”ì 
                if target_module and target_module not in filename:
                    return
                
                # ë‚´ì¥ í•¨ìˆ˜ë‚˜ ì‹œìŠ¤í…œ í•¨ìˆ˜ ì œì™¸
                if '<' in filename or 'site-packages' in filename:
                    return
                
                print(f"ğŸ“ í•¨ìˆ˜ í˜¸ì¶œ: {function_name} ({filename}:{frame.f_lineno})")
                
                # ì¸ìˆ˜ ì •ë³´
                arg_info = inspect.getargvalues(frame)
                if arg_info.args:
                    args_str = ', '.join(f"{arg}={frame.f_locals.get(arg, '?')}" 
                                       for arg in arg_info.args[:3])  # ì²˜ìŒ 3ê°œë§Œ
                    print(f"   ì¸ìˆ˜: {args_str}")
            
            return trace_calls
        
        return trace_calls

# ì‹¤ì „ ì‚¬ìš© ì˜ˆì‹œ
smart_debugger = SmartDebugger()

# 1. ì¡°ê±´ë¶€ ë¸Œë ˆì´í¬í¬ì¸íŠ¸
@smart_debugger.conditional_breakpoint(
    lambda user_id, amount: amount > 10000  # 1ë§Œì› ì´ìƒ ê²°ì œì‹œë§Œ ë””ë²„ê¹…
)
def process_payment(user_id: str, amount: float):
    """ê²°ì œ ì²˜ë¦¬ í•¨ìˆ˜"""
    if amount <= 0:
        raise ValueError("ê²°ì œ ê¸ˆì•¡ì€ 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤")
    
    # ê²°ì œ ë¡œì§ (ë²„ê·¸ê°€ ìˆëŠ” ì½”ë“œ)
    if amount > 5000 and user_id == "suspicious_user":
        raise Exception("ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì‚¬ìš©ìì˜ ê³ ì•¡ ê²°ì œ")
    
    return {"transaction_id": f"tx_{int(time.time())}", "status": "completed"}

# 2. ì˜ˆì™¸ ë°œìƒì‹œ ìë™ ë””ë²„ê¹…
@smart_debugger.auto_debug_on_exception((ValueError, Exception))
def problematic_function(data: List[int]):
    """ë¬¸ì œê°€ ìˆëŠ” í•¨ìˆ˜"""
    result = []
    for i, value in enumerate(data):
        # ì˜ë„ì  ë²„ê·¸: 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
        processed = value / (i - 2)  # i=2ì¼ ë•Œ ZeroDivisionError
        result.append(processed)
    return result

# 3. ë””ë²„ê¹… ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
def complex_business_logic():
    """ë³µì¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§"""
    with smart_debugger.debug_context("ì‚¬ìš©ì ë°ì´í„° ì²˜ë¦¬"):
        user_data = {"id": 123, "name": "John"}
        
        with smart_debugger.debug_context("ê²°ì œ ê²€ì¦"):
            if user_data["id"] < 0:
                raise ValueError("ì˜ëª»ëœ ì‚¬ìš©ì ID")
        
        with smart_debugger.debug_context("ì£¼ë¬¸ ìƒì„±"):
            order = {"user_id": user_data["id"], "items": []}
            # ì£¼ë¬¸ ì²˜ë¦¬ ë¡œì§...
    
    return order

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    try:
        # ì¡°ê±´ë¶€ ë¸Œë ˆì´í¬í¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ (ê³ ì•¡ ê²°ì œ)
        result = process_payment("suspicious_user", 15000)
        print(f"ê²°ì œ ì„±ê³µ: {result}")
    except Exception as e:
        print(f"ê²°ì œ ì‹¤íŒ¨: {e}")
    
    try:
        # ì˜ˆì™¸ ìë™ ë””ë²„ê¹… í…ŒìŠ¤íŠ¸
        test_data = [1, 2, 3, 4, 5]
        result = problematic_function(test_data)
    except Exception as e:
        print(f"í•¨ìˆ˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
```

### 4. ë¡œê·¸ ê¸°ë°˜ ë””ë²„ê¹…

íš¨ê³¼ì ì¸ ë¡œê·¸ ë¶„ì„ì„ í†µí•œ ë””ë²„ê¹… ê¸°ë²•ì„ ì‚´í´ë³´ì.

```python
import re
import json
from collections import defaultdict, Counter
from typing import Dict, List, Pattern
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

class LogAnalyzer:
    def __init__(self):
        self.log_entries: List[Dict] = []
        self.patterns: Dict[str, Pattern] = {
            'error': re.compile(r'ERROR|FATAL|Exception|Error'),
            'warning': re.compile(r'WARN|WARNING'),
            'slow_query': re.compile(r'slow.*query|query.*took.*(\d+)ms'),
            'timeout': re.compile(r'timeout|timed.*out'),
            'memory_issue': re.compile(r'OutOfMemory|MemoryError|memory.*exceeded'),
            'connection_issue': re.compile(r'connection.*refused|connection.*lost|connection.*timeout')
        }
    
    def parse_log_file(self, log_file_path: str):
        """ë¡œê·¸ íŒŒì¼ íŒŒì‹±"""
        with open(log_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    # JSON í˜•íƒœì˜ êµ¬ì¡°í™”ëœ ë¡œê·¸ íŒŒì‹±
                    if line.strip().startswith('{'):
                        entry = json.loads(line.strip())
                    else:
                        # ì¼ë°˜ í…ìŠ¤íŠ¸ ë¡œê·¸ íŒŒì‹±
                        entry = self._parse_text_log(line)
                    
                    self.log_entries.append(entry)
                except Exception as e:
                    print(f"ë¡œê·¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
    
    def _parse_text_log(self, log_line: str) -> Dict:
        """í…ìŠ¤íŠ¸ ë¡œê·¸ íŒŒì‹±"""
        # ê°„ë‹¨í•œ ë¡œê·¸ í˜•ì‹: [2024-08-03 19:30:15] ERROR [service-name] ë©”ì‹œì§€
        log_pattern = re.compile(
            r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\] (\w+) \[([^\]]+)\] (.+)'
        )
        
        match = log_pattern.match(log_line.strip())
        if match:
            timestamp, level, service, message = match.groups()
            return {
                'timestamp': timestamp,
                'level': level,
                'service': service,
                'message': message,
                'raw_line': log_line.strip()
            }
        else:
            return {
                'timestamp': datetime.now().isoformat(),
                'level': 'UNKNOWN',
                'service': 'unknown',
                'message': log_line.strip(),
                'raw_line': log_line.strip()
            }
    
    def detect_anomalies(self, time_window_minutes: int = 30) -> Dict[str, List]:
        """ë¡œê·¸ íŒ¨í„´ ê¸°ë°˜ ì´ìƒ ì§•í›„ ê°ì§€"""
        anomalies = defaultdict(list)
        
        # ì‹œê°„ ìœˆë„ìš°ë³„ ë¡œê·¸ ë¶„ì„
        time_buckets = defaultdict(list)
        for entry in self.log_entries:
            try:
                timestamp = datetime.fromisoformat(entry['timestamp'].replace('T', ' '))
                bucket = timestamp.replace(minute=(timestamp.minute // time_window_minutes) * time_window_minutes, 
                                         second=0, microsecond=0)
                time_buckets[bucket].append(entry)
            except:
                continue
        
        for time_bucket, entries in time_buckets.items():
            # 1. ê¸‰ê²©í•œ ì—ëŸ¬ ì¦ê°€
            error_count = sum(1 for e in entries if self.patterns['error'].search(e.get('message', '')))
            total_count = len(entries)
            
            if total_count > 0:
                error_rate = error_count / total_count
                if error_rate > 0.1:  # 10% ì´ìƒ ì—ëŸ¬
                    anomalies['high_error_rate'].append({
                        'timestamp': time_bucket.isoformat(),
                        'error_rate': error_rate,
                        'error_count': error_count,
                        'total_count': total_count
                    })
            
            # 2. íŠ¹ì • íŒ¨í„´ì˜ ê¸‰ì¦
            for pattern_name, pattern in self.patterns.items():
                pattern_count = sum(1 for e in entries if pattern.search(e.get('message', '')))
                if pattern_count > 10:  # ì„ê³„ê°’
                    anomalies[f'pattern_spike_{pattern_name}'].append({
                        'timestamp': time_bucket.isoformat(),
                        'count': pattern_count,
                        'pattern': pattern_name
                    })
            
            # 3. ì„œë¹„ìŠ¤ë³„ ë¡œê·¸ ë³¼ë¥¨ ë¶„ì„
            service_counts = Counter(e.get('service', 'unknown') for e in entries)
            for service, count in service_counts.items():
                if count > 100:  # 30ë¶„ì— 100ê°œ ì´ìƒ ë¡œê·¸
                    anomalies['high_volume_service'].append({
                        'timestamp': time_bucket.isoformat(),
                        'service': service,
                        'count': count
                    })
        
        return dict(anomalies)
    
    def find_error_correlations(self) -> Dict[str, Any]:
        """ì—ëŸ¬ ê°„ì˜ ìƒê´€ê´€ê³„ ë¶„ì„"""
        correlations = {
            'error_sequences': [],
            'common_error_patterns': [],
            'service_error_propagation': {}
        }
        
        # ì—ëŸ¬ ì‹œí€€ìŠ¤ ë¶„ì„ (5ë¶„ ë‚´ì— ë°œìƒí•œ ì—°ê´€ëœ ì—ëŸ¬ë“¤)
        error_entries = [e for e in self.log_entries 
                        if self.patterns['error'].search(e.get('message', ''))]
        
        for i, error1 in enumerate(error_entries):
            try:
                timestamp1 = datetime.fromisoformat(error1['timestamp'].replace('T', ' '))
                
                related_errors = []
                for j, error2 in enumerate(error_entries[i+1:], i+1):
                    timestamp2 = datetime.fromisoformat(error2['timestamp'].replace('T', ' '))
                    
                    # 5ë¶„ ì´ë‚´ ë°œìƒí•œ ì—ëŸ¬ë“¤
                    if (timestamp2 - timestamp1).total_seconds() <= 300:
                        related_errors.append({
                            'service': error2.get('service'),
                            'message': error2.get('message'),
                            'time_diff_seconds': (timestamp2 - timestamp1).total_seconds()
                        })
                
                if len(related_errors) >= 2:  # 2ê°œ ì´ìƒì˜ ì—°ê´€ ì—ëŸ¬
                    correlations['error_sequences'].append({
                        'trigger_error': {
                            'service': error1.get('service'),
                            'message': error1.get('message'),
                            'timestamp': error1.get('timestamp')
                        },
                        'related_errors': related_errors
                    })
            except:
                continue
        
        return correlations
    
    def generate_debug_report(self) -> str:
        """ì¢…í•© ë””ë²„ê¹… ë¦¬í¬íŠ¸ ìƒì„±"""
        total_entries = len(self.log_entries)
        if total_entries == 0:
            return "ë¶„ì„í•  ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ê¸°ë³¸ í†µê³„
        level_counts = Counter(e.get('level', 'UNKNOWN') for e in self.log_entries)
        service_counts = Counter(e.get('service', 'unknown') for e in self.log_entries)
        
        # ì´ìƒ ì§•í›„ ê°ì§€
        anomalies = self.detect_anomalies()
        correlations = self.find_error_correlations()
        
        report = f"""
=== ë¡œê·¸ ë¶„ì„ ë””ë²„ê¹… ë¦¬í¬íŠ¸ ===

ğŸ“Š ê¸°ë³¸ í†µê³„:
- ì´ ë¡œê·¸ ì—”íŠ¸ë¦¬: {total_entries:,}ê°œ
- ë¡œê·¸ ë ˆë²¨ ë¶„í¬:
"""
        
        for level, count in level_counts.most_common():
            percentage = (count / total_entries) * 100
            report += f"  â€¢ {level}: {count:,}ê°œ ({percentage:.1f}%)\n"
        
        report += f"\nğŸ¢ ì„œë¹„ìŠ¤ë³„ ë¡œê·¸ ë¶„í¬:\n"
        for service, count in service_counts.most_common(10):
            percentage = (count / total_entries) * 100
            report += f"  â€¢ {service}: {count:,}ê°œ ({percentage:.1f}%)\n"
        
        report += f"\nğŸš¨ ê°ì§€ëœ ì´ìƒ ì§•í›„:\n"
        if not anomalies:
            report += "  â€¢ íŠ¹ë³„í•œ ì´ìƒ ì§•í›„ ì—†ìŒ\n"
        else:
            for anomaly_type, incidents in anomalies.items():
                report += f"  â€¢ {anomaly_type}: {len(incidents)}ê±´\n"
                for incident in incidents[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                    report += f"    - {incident}\n"
        
        report += f"\nğŸ”— ì—ëŸ¬ ìƒê´€ê´€ê³„ ë¶„ì„:\n"
        error_sequences = correlations.get('error_sequences', [])
        if not error_sequences:
            report += "  â€¢ ëª…í™•í•œ ì—ëŸ¬ ì—°ì‡„ íŒ¨í„´ ì—†ìŒ\n"
        else:
            report += f"  â€¢ {len(error_sequences)}ê°œì˜ ì—ëŸ¬ ì—°ì‡„ íŒ¨í„´ ë°œê²¬\n"
            for seq in error_sequences[:3]:
                trigger = seq['trigger_error']
                report += f"    - {trigger['service']}: {trigger['message'][:50]}...\n"
                report += f"      â†’ {len(seq['related_errors'])}ê°œì˜ í›„ì† ì—ëŸ¬ ë°œìƒ\n"
        
        # ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­
        report += f"\nğŸ’¡ ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­:\n"
        
        error_rate = level_counts.get('ERROR', 0) / total_entries
        if error_rate > 0.05:
            report += f"  â€¢ ë†’ì€ ì—ëŸ¬ìœ¨({error_rate:.1%}) - ì—ëŸ¬ ë¡œê·¸ ìƒì„¸ ë¶„ì„ í•„ìš”\n"
        
        if anomalies.get('high_error_rate'):
            report += f"  â€¢ íŠ¹ì • ì‹œê°„ëŒ€ ì—ëŸ¬ ê¸‰ì¦ - í•´ë‹¹ ì‹œê°„ ë°°í¬/ë³€ê²½ì‚¬í•­ í™•ì¸\n"
        
        if error_sequences:
            report += f"  â€¢ ì—ëŸ¬ ì—°ì‡„ íŒ¨í„´ ë°œê²¬ - ì„œë¹„ìŠ¤ ê°„ ì˜ì¡´ì„± ë° íƒ€ì„ì•„ì›ƒ ì„¤ì • ê²€í† \n"
        
        return report

# ì‚¬ìš© ì˜ˆì‹œ (ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±)
def simulate_log_data():
    """ì‹œë®¬ë ˆì´ì…˜ìš© ë¡œê·¸ ë°ì´í„° ìƒì„±"""
    log_analyzer = LogAnalyzer()
    
    # ìƒ˜í”Œ ë¡œê·¸ ë°ì´í„°
    sample_logs = [
        {"timestamp": "2024-08-03T19:30:15", "level": "INFO", "service": "user-service", 
         "message": "User login successful for user_id=12345"},
        {"timestamp": "2024-08-03T19:30:16", "level": "ERROR", "service": "payment-service", 
         "message": "Connection timeout to external payment API"},
        {"timestamp": "2024-08-03T19:30:17", "level": "ERROR", "service": "order-service", 
         "message": "Failed to create order: Payment service unavailable"},
        {"timestamp": "2024-08-03T19:30:18", "level": "WARN", "service": "inventory-service", 
         "message": "Low stock alert for product_id=67890"},
        {"timestamp": "2024-08-03T19:30:20", "level": "ERROR", "service": "notification-service", 
         "message": "Failed to send order confirmation: Order not found"}
    ] * 50  # 50ë²ˆ ë°˜ë³µí•˜ì—¬ íŒ¨í„´ ìƒì„±
    
    log_analyzer.log_entries = sample_logs
    
    # ë””ë²„ê¹… ë¦¬í¬íŠ¸ ìƒì„±
    report = log_analyzer.generate_debug_report()
    print(report)

# simulate_log_data()
```

## ë ˆìŠ¨ ëŸ°

### 1. ì²´ê³„ì  ì ‘ê·¼ë²•ì´ í•µì‹¬ì´ë‹¤

ê°ì— ì˜ì¡´í•˜ì§€ ë§ê³  **OODA Loop** ê°™ì€ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ì.

### 2. ë¶„ì‚° ì‹œìŠ¤í…œì—ì„œëŠ” ì˜ì¡´ì„± ì¶”ì ì´ í•„ìˆ˜ë‹¤

í•˜ë‚˜ì˜ ì„œë¹„ìŠ¤ ë¬¸ì œê°€ **ì „ì²´ ì‹œìŠ¤í…œ**ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ íŒŒì•…í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.

### 3. ì¡°ê±´ë¶€ ë””ë²„ê¹…ìœ¼ë¡œ íš¨ìœ¨ì„±ì„ ë†’ì—¬ë¼

ëª¨ë“  ê³³ì— ë¡œê·¸ë¥¼ ë‚¨ê¸°ì§€ ë§ê³ , **íŠ¹ì • ì¡°ê±´**ì—ì„œë§Œ ìƒì„¸ ë””ë²„ê¹…ì„ í™œì„±í™”í•˜ì.

### 4. ë¡œê·¸ ë¶„ì„ì˜ ìë™í™”ê°€ í•„ìš”í•˜ë‹¤

ìˆ˜ë§Œ ì¤„ì˜ ë¡œê·¸ë¥¼ ì‚¬ëŒì´ ì½ì„ ìˆ˜ëŠ” ì—†ë‹¤. **íŒ¨í„´ ì¸ì‹**ê³¼ **ì´ìƒ ì§•í›„ ê°ì§€**ë¥¼ ìë™í™”í•˜ì.

### 5. ì‚¬í›„ ë¶„ì„(Post-Mortem)ì„ ì²´ê³„í™”í•˜ë¼

ë¬¸ì œê°€ í•´ê²°ëœ í›„ì—ë„ **ê·¼ë³¸ ì›ì¸ ë¶„ì„**ê³¼ **ì¬ë°œ ë°©ì§€ì±…**ì„ ë¬¸ì„œí™”í•´ì•¼ í•œë‹¤.

---

**Chapter 13 Observability & Debuggingì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.** ì´ì œ ìš°ë¦¬ëŠ” ë¡œê¹…ë¶€í„° ë©”íŠ¸ë¦­, ë¶„ì‚° ì¶”ì , ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§, ê·¸ë¦¬ê³  ì²´ê³„ì  ë””ë²„ê¹…ê¹Œì§€ **ì™„ì „í•œ ê´€ì°° ê°€ëŠ¥ì„±**ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¤ìŒ ë‹¨ê³„ì—ì„œëŠ” **Chapter 12 (Container & Kubernetes)** ë˜ëŠ” **Chapter 11 (Performance Optimization)** ì¤‘ ì–´ëŠ ê²ƒì„ ì§„í–‰í• ì§€ ì•Œë ¤ì£¼ì„¸ìš”.
