---
tags:
  - Performance
  - Profiling
  - Optimization
  - Debugging
  - Python
---

# 13.4 ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§

## 2024ë…„ 5ì›”, ë¹¨ê°„ ë¶ˆì´ ì¼œì§„ ì„œë²„ì‹¤

2024ë…„ 5ì›” 23ì¼ ì˜¤í›„ 2ì‹œ, ëŒ€ê·œëª¨ ë§ˆì¼€íŒ… ìº í˜ì¸ì´ ì‹œì‘ë˜ì—ˆë‹¤. ì˜ˆìƒ íŠ¸ë˜í”½ì˜ 3ë°°ê°€ ëª°ë ¤ë“¤ì—ˆê³ , ì‘ë‹µ ì‹œê°„ì´ 300msì—ì„œ 5ì´ˆë¡œ ê¸‰ì¦í–ˆë‹¤.

"CPU ì‚¬ìš©ë¥ ì€ 30%ì¸ë° ì™œ ì´ë ‡ê²Œ ëŠë¦¬ì§€?"
"ë©”ëª¨ë¦¬ë„ ì¶©ë¶„íˆ ë‚¨ì•„ìˆëŠ”ë°..."
"ë””ìŠ¤í¬ I/Oë„ ì •ìƒì´ì•¼."

ëª¨ë“  ê¸°ë³¸ ë©”íŠ¸ë¦­ì€ ì •ìƒì´ì—ˆì§€ë§Œ, ì‚¬ìš©ìë“¤ì€ ë– ë‚˜ê°€ê³  ìˆì—ˆë‹¤. **ì§„ì§œ ë³‘ëª©ì´ ì–´ë””ì— ìˆëŠ”ì§€ ì°¾ì•„ì•¼ í–ˆë‹¤.**

ê·¸ë•Œ ê¹¨ë‹¬ì•˜ë‹¤. ìš°ë¦¬ì—ê²ŒëŠ” **ë”¥ ë‹¤ì´ë¹™**í•  ìˆ˜ ìˆëŠ” í”„ë¡œíŒŒì¼ë§ ë„êµ¬ê°€ ì—†ì—ˆë˜ ê²ƒì´ë‹¤. ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ì€ 'ë¬´ì—‡ì´' ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ì•Œë ¤ì£¼ì§€ë§Œ, í”„ë¡œíŒŒì¼ë§ì€ 'ì™œ' ê·¸ëŸ° ì¼ì´ ì¼ì–´ë‚˜ëŠ”ì§€ ì•Œë ¤ì¤€ë‹¤.

## cProfileê³¼ Line Profiler

ê°€ì¥ ê¸°ë³¸ì ì´ë©´ì„œë„ ê°•ë ¥í•œ Python í”„ë¡œíŒŒì¼ë§ ë„êµ¬ë“¤ë¶€í„° ì‚´í´ë³´ì.

### cProfileë¡œ í•¨ìˆ˜ë³„ ì„±ëŠ¥ ì¸¡ì •

```python
import cProfile
import pstats
import io
from functools import wraps
from typing import Dict, List, Any
import time

class ProfileAnalyzer:
    def __init__(self):
        self.profiles: Dict[str, pstats.Stats] = {}
    
    def profile_function(self, name: str):
        """í•¨ìˆ˜ í”„ë¡œíŒŒì¼ë§ ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # í”„ë¡œíŒŒì¼ëŸ¬ ìƒì„±
                pr = cProfile.Profile()
                
                # í”„ë¡œíŒŒì¼ë§ ì‹œì‘
                pr.enable()
                try:
                    result = func(*args, **kwargs)
                    return result
                finally:
                    pr.disable()
                    
                    # ê²°ê³¼ ì €ì¥
                    s = io.StringIO()
                    ps = pstats.Stats(pr, stream=s)
                    ps.sort_stats('cumulative')
                    
                    self.profiles[f"{name}_{int(time.time())}"] = ps
            
            return wrapper
        return decorator
    
    def analyze_bottlenecks(self, profile_name: str) -> Dict[str, Any]:
        """ë³‘ëª© ì§€ì  ë¶„ì„"""
        if profile_name not in self.profiles:
            return {}
        
        stats = self.profiles[profile_name]
        
        # í†µê³„ ìˆ˜ì§‘
        analysis = {
            'total_calls': stats.total_calls,
            'total_time': stats.total_tt,
            'top_functions': [],
            'hotspots': []
        }
        
        # ê°€ì¥ ì‹œê°„ì„ ë§ì´ ì†Œëª¨í•˜ëŠ” í•¨ìˆ˜ë“¤
        stats.sort_stats('cumulative')
        for func, (cc, nc, tt, ct, callers) in list(stats.stats.items())[:10]:
            analysis['top_functions'].append({
                'function': f"{func[0]}:{func[1]}({func[2]})",
                'calls': cc,
                'total_time': tt,
                'cumulative_time': ct,
                'per_call': ct/cc if cc > 0 else 0
            })
        
        # í˜¸ì¶œ íšŸìˆ˜ê°€ ë§ì€ í•«ìŠ¤íŒŸë“¤
        stats.sort_stats('ncalls')
        for func, (cc, nc, tt, ct, callers) in list(stats.stats.items())[:5]:
            if cc > 1000:  # 1000ë²ˆ ì´ìƒ í˜¸ì¶œëœ í•¨ìˆ˜ë“¤
                analysis['hotspots'].append({
                    'function': f"{func[0]}:{func[1]}({func[2]})",
                    'calls': cc,
                    'total_time': tt,
                    'avg_time': tt/cc if cc > 0 else 0
                })
        
        return analysis
    
    def compare_profiles(self, profile1: str, profile2: str) -> Dict[str, Any]:
        """ë‘ í”„ë¡œíŒŒì¼ ê²°ê³¼ ë¹„êµ"""
        if profile1 not in self.profiles or profile2 not in self.profiles:
            return {}
        
        stats1 = self.profiles[profile1]
        stats2 = self.profiles[profile2]
        
        comparison = {
            'time_diff': stats2.total_tt - stats1.total_tt,
            'calls_diff': stats2.total_calls - stats1.total_calls,
            'regression_functions': [],
            'improved_functions': []
        }
        
        # í•¨ìˆ˜ë³„ ì„±ëŠ¥ ë³€í™” ë¶„ì„
        for func in set(stats1.stats.keys()) & set(stats2.stats.keys()):
            time1 = stats1.stats[func][3]  # cumulative time
            time2 = stats2.stats[func][3]
            
            if time2 > time1 * 1.1:  # 10% ì´ìƒ ëŠë ¤ì§„ í•¨ìˆ˜
                comparison['regression_functions'].append({
                    'function': f"{func[0]}:{func[1]}({func[2]})",
                    'before': time1,
                    'after': time2,
                    'degradation': ((time2 - time1) / time1) * 100
                })
            elif time2 < time1 * 0.9:  # 10% ì´ìƒ ë¹¨ë¼ì§„ í•¨ìˆ˜
                comparison['improved_functions'].append({
                    'function': f"{func[0]}:{func[1]}({func[2]})",
                    'before': time1,
                    'after': time2,
                    'improvement': ((time1 - time2) / time1) * 100
                })
        
        return comparison

# ì‚¬ìš© ì˜ˆì‹œ
profiler = ProfileAnalyzer()

@profiler.profile_function("database_query")
def get_user_recommendations(user_id: str) -> List[Dict]:
    """ì‚¬ìš©ì ì¶”ì²œ ëª©ë¡ ì¡°íšŒ (ì„±ëŠ¥ ë¬¸ì œê°€ ìˆëŠ” ë²„ì „)"""
    # ë¹„íš¨ìœ¨ì ì¸ N+1 ì¿¼ë¦¬ íŒ¨í„´
    recommendations = []
    
    # 1. ì‚¬ìš©ì ê¸°ë³¸ ì •ë³´ ì¡°íšŒ
    user = query_database(f"SELECT * FROM users WHERE id = '{user_id}'")
    
    # 2. ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬ ì¡°íšŒ (N+1 ë¬¸ì œ ë°œìƒ)
    interests = []
    for interest_id in user.get('interest_ids', []):
        interest = query_database(f"SELECT * FROM interests WHERE id = '{interest_id}'")
        interests.append(interest)
    
    # 3. ê° ê´€ì‹¬ì‚¬ë³„ ì¶”ì²œ ìƒí’ˆ ì¡°íšŒ (ë˜ ë‹¤ë¥¸ N+1 ë¬¸ì œ)
    for interest in interests:
        products = []
        product_ids = get_products_by_interest(interest['id'])
        for product_id in product_ids:
            product = query_database(f"SELECT * FROM products WHERE id = '{product_id}'")
            products.append(product)
        
        recommendations.extend(products[:5])  # ê´€ì‹¬ì‚¬ë³„ ìƒìœ„ 5ê°œ
    
    return recommendations[:20]  # ìµœì¢… 20ê°œ ë°˜í™˜

def query_database(query: str) -> Dict:
    """DB ì¿¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (0.01ì´ˆ ì†Œìš”)"""
    time.sleep(0.01)
    return {"id": 1, "name": "Sample", "interest_ids": [1, 2, 3, 4, 5]}

def get_products_by_interest(interest_id: int) -> List[int]:
    """ê´€ì‹¬ì‚¬ë³„ ìƒí’ˆ ID ëª©ë¡"""
    return list(range(1, 11))  # 10ê°œ ìƒí’ˆ

# í”„ë¡œíŒŒì¼ë§ ì‹¤í–‰
result = get_user_recommendations("user123")
analysis = profiler.analyze_bottlenecks(list(profiler.profiles.keys())[-1])

print("=== ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ ===")
print(f"ì´ ì‹¤í–‰ ì‹œê°„: {analysis['total_time']:.3f}ì´ˆ")
print(f"ì´ í•¨ìˆ˜ í˜¸ì¶œ: {analysis['total_calls']}íšŒ")
print("\n=== ê°€ì¥ ì‹œê°„ì„ ë§ì´ ì†Œëª¨í•˜ëŠ” í•¨ìˆ˜ë“¤ ===")
for func in analysis['top_functions']:
    print(f"- {func['function']}: {func['cumulative_time']:.3f}ì´ˆ ({func['calls']}íšŒ í˜¸ì¶œ)")
```

### Line Profilerë¡œ ë¼ì¸ë³„ ë¶„ì„

```python
import time
import sys
from line_profiler import LineProfiler

class LineByLineProfiler:
    def __init__(self):
        self.profiler = LineProfiler()
    
    def profile_lines(self, func):
        """ë¼ì¸ë³„ í”„ë¡œíŒŒì¼ë§ ë°ì½”ë ˆì´í„°"""
        self.profiler.add_function(func)
        
        @wraps(func)
        def wrapper(*args, **kwargs):
            self.profiler.enable_by_count()
            try:
                result = func(*args, **kwargs)
                return result
            finally:
                self.profiler.disable_by_count()
        
        return wrapper
    
    def show_results(self):
        """í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ ì¶œë ¥"""
        self.profiler.print_stats()
    
    def get_line_analysis(self, filename: str) -> Dict[int, Dict]:
        """ë¼ì¸ë³„ ì„±ëŠ¥ ë¶„ì„"""
        stats = self.profiler.get_stats()
        if not stats or filename not in stats.timings:
            return {}
        
        timings = stats.timings[filename]
        analysis = {}
        
        for line_no, hits, time_per_hit in timings:
            if hits > 0:
                analysis[line_no] = {
                    'hits': hits,
                    'time_per_hit': time_per_hit,
                    'total_time': hits * time_per_hit,
                    'percentage': (hits * time_per_hit / stats.total_time) * 100 if stats.total_time > 0 else 0
                }
        
        return analysis

# ì‚¬ìš© ì˜ˆì‹œ
line_profiler = LineByLineProfiler()

@line_profiler.profile_lines
def slow_string_processing(data: List[str]) -> List[str]:
    """ë¬¸ìì—´ ì²˜ë¦¬ í•¨ìˆ˜ (ì„±ëŠ¥ ë¬¸ì œê°€ ìˆëŠ” ë²„ì „)"""
    result = []                           # Line 1
    
    for item in data:                     # Line 2 - ë°˜ë³µë¬¸
        processed = ""                    # Line 3 - ë¹„íš¨ìœ¨ì  ë¬¸ìì—´ ì—°ê²°
        
        for char in item:                 # Line 4 - ì¤‘ì²© ë°˜ë³µë¬¸
            if char.isalnum():           # Line 5 - ë¬¸ì ê²€ì‚¬
                processed += char.upper() # Line 6 - ë¹„íš¨ìœ¨ì  ë¬¸ìì—´ ì—°ê²°
            else:                        # Line 7
                processed += "_"         # Line 8 - ë¹„íš¨ìœ¨ì  ë¬¸ìì—´ ì—°ê²°
        
        # ë¹„íš¨ìœ¨ì ì¸ ì¤‘ë³µ ì œê±°
        final_processed = ""             # Line 9
        seen_chars = set()               # Line 10
        for char in processed:           # Line 11
            if char not in seen_chars:   # Line 12
                final_processed += char  # Line 13 - ë¹„íš¨ìœ¨ì  ë¬¸ìì—´ ì—°ê²°
                seen_chars.add(char)     # Line 14
        
        result.append(final_processed)   # Line 15
    
    return result                        # Line 16

# í…ŒìŠ¤íŠ¸ ë°ì´í„°
test_data = ["hello@world#123", "python@programming!", "performance#testing"] * 100

# í”„ë¡œíŒŒì¼ë§ ì‹¤í–‰
result = slow_string_processing(test_data)
line_profiler.show_results()
```

## ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§

ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ ì¶”ì í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•˜ë‹¤.

```python
import psutil
import gc
import sys
import tracemalloc
from typing import List, Tuple, Dict
from dataclasses import dataclass
from collections import defaultdict

@dataclass
class MemorySnapshot:
    timestamp: float
    total_memory: int
    available_memory: int
    process_memory: int
    object_counts: Dict[str, int]
    top_allocations: List[Tuple[str, int]]

class MemoryProfiler:
    def __init__(self):
        self.snapshots: List[MemorySnapshot] = []
        self.process = psutil.Process()
        tracemalloc.start()
    
    def take_snapshot(self) -> MemorySnapshot:
        """ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ· ì´¬ì˜"""
        # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë³´
        memory_info = psutil.virtual_memory()
        process_memory = self.process.memory_info()
        
        # ê°ì²´ íƒ€ì…ë³„ ê°œìˆ˜
        object_counts = defaultdict(int)
        for obj in gc.get_objects():
            object_counts[type(obj).__name__] += 1
        
        # ë©”ëª¨ë¦¬ í• ë‹¹ ì¶”ì 
        snapshot = tracemalloc.take_snapshot()
        top_stats = snapshot.statistics('lineno')[:10]
        
        top_allocations = []
        for stat in top_stats:
            top_allocations.append((str(stat.traceback), stat.size))
        
        snapshot_obj = MemorySnapshot(
            timestamp=time.time(),
            total_memory=memory_info.total,
            available_memory=memory_info.available,
            process_memory=process_memory.rss,
            object_counts=dict(object_counts),
            top_allocations=top_allocations
        )
        
        self.snapshots.append(snapshot_obj)
        return snapshot_obj
    
    def detect_memory_leaks(self) -> List[Dict]:
        """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€"""
        if len(self.snapshots) < 2:
            return []
        
        first_snapshot = self.snapshots[0]
        latest_snapshot = self.snapshots[-1]
        
        leaks = []
        
        # ê°ì²´ ê°œìˆ˜ ì¦ê°€ ì¶”ì´ ë¶„ì„
        for obj_type, latest_count in latest_snapshot.object_counts.items():
            initial_count = first_snapshot.object_counts.get(obj_type, 0)
            
            if latest_count > initial_count * 2 and latest_count > 1000:
                growth_rate = (latest_count - initial_count) / (latest_snapshot.timestamp - first_snapshot.timestamp)
                
                leaks.append({
                    'object_type': obj_type,
                    'initial_count': initial_count,
                    'current_count': latest_count,
                    'growth_rate': growth_rate,
                    'severity': 'high' if growth_rate > 100 else 'medium'
                })
        
        return sorted(leaks, key=lambda x: x['growth_rate'], reverse=True)
    
    def analyze_memory_usage_pattern(self) -> Dict:
        """ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ ë¶„ì„"""
        if len(self.snapshots) < 3:
            return {}
        
        memory_values = [s.process_memory for s in self.snapshots]
        timestamps = [s.timestamp for s in self.snapshots]
        
        # ë©”ëª¨ë¦¬ ì¦ê°€ ì¶”ì„¸ ê³„ì‚°
        memory_growth = []
        for i in range(1, len(memory_values)):
            growth = memory_values[i] - memory_values[i-1]
            time_diff = timestamps[i] - timestamps[i-1]
            memory_growth.append(growth / time_diff if time_diff > 0 else 0)
        
        avg_growth = sum(memory_growth) / len(memory_growth)
        max_memory = max(memory_values)
        min_memory = min(memory_values)
        
        return {
            'average_memory_growth_rate': avg_growth,
            'peak_memory_usage': max_memory,
            'baseline_memory_usage': min_memory,
            'memory_volatility': max_memory - min_memory,
            'trend': 'increasing' if avg_growth > 0 else 'stable' if abs(avg_growth) < 1000 else 'decreasing'
        }

# ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ê°€ ìˆëŠ” ì˜ˆì‹œ ì½”ë“œ
class LeakyCache:
    def __init__(self):
        self._cache = {}  # ì´ ìºì‹œê°€ ê³„ì† ì¦ê°€ë§Œ í•¨
    
    def get_data(self, key: str) -> str:
        if key not in self._cache:
            # ìºì‹œì— ë°ì´í„° ì €ì¥ (ì‚­ì œ ë¡œì§ ì—†ìŒ)
            self._cache[key] = f"data_for_{key}" * 1000  # í° ë°ì´í„°
        
        return self._cache[key]
    
    def process_requests(self, num_requests: int):
        for i in range(num_requests):
            # ë§¤ë²ˆ ìƒˆë¡œìš´ í‚¤ë¡œ ë°ì´í„° ìš”ì²­ (ìºì‹œ ë¬´í•œ ì¦ê°€)
            self.get_data(f"request_{i}")

# ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ì‹¤í–‰
memory_profiler = MemoryProfiler()
leaky_cache = LeakyCache()

# ì´ˆê¸° ìŠ¤ëƒ…ìƒ·
memory_profiler.take_snapshot()

# ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ ìœ ë°œí•˜ëŠ” ì‘ì—…
for batch in range(5):
    leaky_cache.process_requests(1000)
    memory_profiler.take_snapshot()
    time.sleep(1)

# ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë¶„ì„
leaks = memory_profiler.detect_memory_leaks()
pattern = memory_profiler.analyze_memory_usage_pattern()

print("=== ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ ê²°ê³¼ ===")
for leak in leaks:
    print(f"ê°ì²´ íƒ€ì…: {leak['object_type']}")
    print(f"ì´ˆê¸° ê°œìˆ˜: {leak['initial_count']} â†’ í˜„ì¬ ê°œìˆ˜: {leak['current_count']}")
    print(f"ì¦ê°€ìœ¨: {leak['growth_rate']:.1f} ê°ì²´/ì´ˆ")
    print(f"ì‹¬ê°ë„: {leak['severity']}")
    print("-" * 40)

print(f"\n=== ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ ===")
print(f"í‰ê·  ë©”ëª¨ë¦¬ ì¦ê°€ìœ¨: {pattern['average_memory_growth_rate']:.1f} bytes/ì´ˆ")
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš© ì¶”ì„¸: {pattern['trend']}")
print(f"í”¼í¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {pattern['peak_memory_usage'] / 1024 / 1024:.1f} MB")
```

## ë¹„ë™ê¸° ì½”ë“œ í”„ë¡œíŒŒì¼ë§

í˜„ëŒ€ì ì¸ Python ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ëŒ€ë¶€ë¶„ ë¹„ë™ê¸° íŒ¨í„´ì„ ì‚¬ìš©í•œë‹¤. asyncio ì½”ë“œë¥¼ í”„ë¡œíŒŒì¼ë§í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì.

```python
import asyncio
import time
import aiohttp
from contextlib import asynccontextmanager
from typing import Dict, List, Callable, Any
import functools

class AsyncProfiler:
    def __init__(self):
        self.function_times: Dict[str, List[float]] = defaultdict(list)
        self.concurrent_operations: Dict[float, List[str]] = defaultdict(list)
        self.start_time = time.time()
    
    def profile_async(self, name: str = None):
        """ë¹„ë™ê¸° í•¨ìˆ˜ í”„ë¡œíŒŒì¼ë§ ë°ì½”ë ˆì´í„°"""
        def decorator(func: Callable):
            func_name = name or f"{func.__module__}.{func.__name__}"
            
            @functools.wraps(func)
            async def wrapper(*args, **kwargs):
                start_time = time.time()
                operation_id = f"{func_name}_{id(asyncio.current_task())}"
                
                # ë™ì‹œ ì‹¤í–‰ ì¶”ì 
                relative_time = start_time - self.start_time
                self.concurrent_operations[relative_time].append(operation_id)
                
                try:
                    result = await func(*args, **kwargs)
                    return result
                finally:
                    end_time = time.time()
                    duration = end_time - start_time
                    self.function_times[func_name].append(duration)
                    
                    # ì™„ë£Œ ì‹œì  ê¸°ë¡
                    relative_end_time = end_time - self.start_time
                    if operation_id in self.concurrent_operations[relative_time]:
                        self.concurrent_operations[relative_time].remove(operation_id)
            
            return wrapper
        return decorator
    
    @asynccontextmanager
    async def profile_context(self, operation_name: str):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¡œ ì½”ë“œ ë¸”ë¡ í”„ë¡œíŒŒì¼ë§"""
        start_time = time.time()
        try:
            yield
        finally:
            duration = time.time() - start_time
            self.function_times[operation_name].append(duration)
    
    def get_async_bottlenecks(self) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ë³‘ëª© ë¶„ì„"""
        analysis = {}
        
        for func_name, times in self.function_times.items():
            if not times:
                continue
            
            analysis[func_name] = {
                'call_count': len(times),
                'total_time': sum(times),
                'avg_time': sum(times) / len(times),
                'min_time': min(times),
                'max_time': max(times),
                'std_dev': np.std(times) if len(times) > 1 else 0
            }
        
        # ê°€ì¥ ëŠë¦° í•¨ìˆ˜ë“¤ ì •ë ¬
        sorted_analysis = dict(sorted(analysis.items(), 
                                    key=lambda x: x[1]['total_time'], 
                                    reverse=True))
        
        return sorted_analysis
    
    def detect_blocking_operations(self, threshold: float = 0.1) -> List[Dict]:
        """ë¸”ë¡œí‚¹ ì‘ì—… ê°ì§€ (0.1ì´ˆ ì´ìƒ ê±¸ë¦¬ëŠ” ì‘ì—…)"""
        blocking_ops = []
        
        for func_name, times in self.function_times.items():
            for duration in times:
                if duration > threshold:
                    blocking_ops.append({
                        'function': func_name,
                        'duration': duration,
                        'severity': 'critical' if duration > 1.0 else 'warning'
                    })
        
        return sorted(blocking_ops, key=lambda x: x['duration'], reverse=True)

# ì‚¬ìš© ì˜ˆì‹œ
async_profiler = AsyncProfiler()

@async_profiler.profile_async("api_call")
async def fetch_user_data(user_id: str) -> Dict:
    """ì‚¬ìš©ì ë°ì´í„° API í˜¸ì¶œ (ì™¸ë¶€ API)"""
    async with aiohttp.ClientSession() as session:
        # ì‹¤ì œë¡œëŠ” ì™¸ë¶€ API í˜¸ì¶œ, ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(0.2)  # ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
        return {"user_id": user_id, "name": f"User {user_id}"}

@async_profiler.profile_async("database_query")
async def get_user_preferences(user_id: str) -> Dict:
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚¬ìš©ì ì„ í˜¸ë„ ì¡°íšŒ"""
    # DB ì¿¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    await asyncio.sleep(0.05)
    return {"theme": "dark", "language": "ko"}

@async_profiler.profile_async("recommendation_engine")
async def generate_recommendations(user_data: Dict, preferences: Dict) -> List[Dict]:
    """ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ (CPU ì§‘ì•½ì  ì‘ì—…)"""
    # CPU ì§‘ì•½ì  ì‘ì—… ì‹œë®¬ë ˆì´ì…˜ (ë¸”ë¡œí‚¹ ì‘ì—…ì˜ ì˜ˆ)
    start = time.time()
    while time.time() - start < 0.3:  # 0.3ì´ˆ ë™ì•ˆ CPU ì‘ì—…
        pass
    
    return [{"item_id": i, "score": 0.8} for i in range(10)]

async def process_user_request(user_id: str) -> Dict:
    """ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬ (ì—¬ëŸ¬ ë¹„ë™ê¸° ì‘ì—… ì¡°í•©)"""
    
    # ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—…ë“¤
    async with async_profiler.profile_context("parallel_data_fetch"):
        user_data_task = fetch_user_data(user_id)
        preferences_task = get_user_preferences(user_id)
        
        user_data, preferences = await asyncio.gather(
            user_data_task, 
            preferences_task
        )
    
    # ìˆœì°¨ ì‹¤í–‰ì´ í•„ìš”í•œ ì‘ì—…
    async with async_profiler.profile_context("sequential_processing"):
        recommendations = await generate_recommendations(user_data, preferences)
    
    return {
        "user_data": user_data,
        "preferences": preferences,
        "recommendations": recommendations
    }

async def simulate_concurrent_requests():
    """ë™ì‹œ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜"""
    tasks = []
    for i in range(5):
        tasks.append(process_user_request(f"user_{i}"))
    
    results = await asyncio.gather(*tasks)
    return results

# í”„ë¡œíŒŒì¼ë§ ì‹¤í–‰
async def main():
    print("ë¹„ë™ê¸° í”„ë¡œíŒŒì¼ë§ ì‹œì‘...")
    
    start_time = time.time()
    await simulate_concurrent_requests()
    total_time = time.time() - start_time
    
    print(f"ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.3f}ì´ˆ")
    
    # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    bottlenecks = async_profiler.get_async_bottlenecks()
    blocking_ops = async_profiler.detect_blocking_operations()
    
    print("\n=== ë¹„ë™ê¸° ì„±ëŠ¥ ë¶„ì„ ===")
    for func_name, stats in list(bottlenecks.items())[:5]:
        print(f"{func_name}:")
        print(f"  í˜¸ì¶œ íšŸìˆ˜: {stats['call_count']}")
        print(f"  ì´ ì‹œê°„: {stats['total_time']:.3f}ì´ˆ")
        print(f"  í‰ê·  ì‹œê°„: {stats['avg_time']:.3f}ì´ˆ")
        print(f"  ìµœëŒ€ ì‹œê°„: {stats['max_time']:.3f}ì´ˆ")
        print()
    
    print("=== ë¸”ë¡œí‚¹ ì‘ì—… ê°ì§€ ===")
    for op in blocking_ops:
        print(f"âš ï¸ {op['function']}: {op['duration']:.3f}ì´ˆ ({op['severity']})")

# asyncio.run(main())
```

## ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•œë‹¤.

```python
import threading
import queue
import json
from datetime import datetime, timedelta
from typing import Optional

class RealTimeProfiler:
    def __init__(self, sample_interval: float = 1.0, max_samples: int = 1000):
        self.sample_interval = sample_interval
        self.max_samples = max_samples
        self.samples_queue = queue.Queue(maxsize=max_samples)
        self.is_running = False
        self.sampling_thread: Optional[threading.Thread] = None
        
        # ì„±ëŠ¥ ì§€í‘œ
        self.request_counter = 0
        self.error_counter = 0
        self.total_response_time = 0.0
        self.active_requests = 0
        
        # ì„ê³„ê°’ ì„¤ì •
        self.thresholds = {
            'response_time_p95': 1.0,  # 95%ile ì‘ë‹µì‹œê°„ 1ì´ˆ
            'error_rate': 0.05,        # ì—ëŸ¬ìœ¨ 5%
            'memory_usage': 0.8,       # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  80%
            'cpu_usage': 0.8           # CPU ì‚¬ìš©ë¥  80%
        }
    
    def start_monitoring(self):
        """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.is_running:
            return
        
        self.is_running = True
        self.sampling_thread = threading.Thread(target=self._sampling_loop, daemon=True)
        self.sampling_thread.start()
        print("ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    
    def stop_monitoring(self):
        """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.is_running = False
        if self.sampling_thread:
            self.sampling_thread.join()
        print("ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def _sampling_loop(self):
        """ì£¼ê¸°ì  ìƒ˜í”Œë§ ë£¨í”„"""
        while self.is_running:
            try:
                sample = self._collect_sample()
                
                # íê°€ ê°€ë“ ì°¨ë©´ ì˜¤ë˜ëœ ìƒ˜í”Œ ì œê±°
                if self.samples_queue.full():
                    try:
                        self.samples_queue.get_nowait()
                    except queue.Empty:
                        pass
                
                self.samples_queue.put(sample)
                
                # ì„ê³„ê°’ ì²´í¬ ë° ì•Œë¦¼
                self._check_thresholds(sample)
                
            except Exception as e:
                print(f"ìƒ˜í”Œë§ ì¤‘ ì˜¤ë¥˜: {e}")
            
            time.sleep(self.sample_interval)
    
    def _collect_sample(self) -> Dict:
        """í˜„ì¬ ì„±ëŠ¥ ìƒ˜í”Œ ìˆ˜ì§‘"""
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
        process = psutil.Process()
        memory_info = process.memory_info()
        cpu_percent = process.cpu_percent()
        
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­
        error_rate = (self.error_counter / max(self.request_counter, 1))
        avg_response_time = (self.total_response_time / max(self.request_counter, 1))
        
        # ìµœê·¼ ì‘ë‹µì‹œê°„ ë¶„í¬ ê³„ì‚° (ê°„ë‹¨í•œ ì˜ˆì‹œ)
        response_times = self._get_recent_response_times()
        p95_response_time = np.percentile(response_times, 95) if response_times else 0
        
        sample = {
            'timestamp': datetime.now().isoformat(),
            'memory_usage': memory_info.rss / (1024 ** 3),  # GB
            'cpu_usage': cpu_percent / 100.0,
            'active_requests': self.active_requests,
            'total_requests': self.request_counter,
            'error_rate': error_rate,
            'avg_response_time': avg_response_time,
            'p95_response_time': p95_response_time,
            'requests_per_second': self._calculate_rps()
        }
        
        return sample
    
    def _get_recent_response_times(self) -> List[float]:
        """ìµœê·¼ ì‘ë‹µì‹œê°„ ëª©ë¡ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” sliding window ì‚¬ìš©)"""
        # ê°„ë‹¨í•œ êµ¬í˜„ ì˜ˆì‹œ
        return [0.1, 0.2, 0.15, 0.3, 0.8, 1.2, 0.5]
    
    def _calculate_rps(self) -> float:
        """ì´ˆë‹¹ ìš”ì²­ ìˆ˜ ê³„ì‚°"""
        # ìµœê·¼ 1ë¶„ê°„ì˜ ìš”ì²­ ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹œê°„ ìœˆë„ìš° ê¸°ë°˜ ê³„ì‚° í•„ìš”
        return self.request_counter / 60.0  # ê°„ë‹¨í•œ ì˜ˆì‹œ
    
    def _check_thresholds(self, sample: Dict):
        """ì„ê³„ê°’ ì²´í¬ ë° ì•Œë¦¼"""
        alerts = []
        
        for metric, threshold in self.thresholds.items():
            if metric in sample and sample[metric] > threshold:
                alerts.append({
                    'metric': metric,
                    'current_value': sample[metric],
                    'threshold': threshold,
                    'severity': 'critical' if sample[metric] > threshold * 1.5 else 'warning'
                })
        
        if alerts:
            self._send_alerts(alerts)
    
    def _send_alerts(self, alerts: List[Dict]):
        """ì•Œë¦¼ ì „ì†¡"""
        for alert in alerts:
            print(f"ğŸš¨ ALERT: {alert['metric']} = {alert['current_value']:.3f} "
                  f"(ì„ê³„ê°’: {alert['threshold']:.3f}) - {alert['severity']}")
    
    def get_performance_summary(self) -> Dict:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´"""
        samples = []
        while not self.samples_queue.empty():
            try:
                samples.append(self.samples_queue.get_nowait())
            except queue.Empty:
                break
        
        if not samples:
            return {}
        
        # ìµœê·¼ ìƒ˜í”Œë“¤ì„ ë‹¤ì‹œ íì— ë„£ê¸°
        for sample in samples:
            if not self.samples_queue.full():
                self.samples_queue.put(sample)
        
        # í†µê³„ ê³„ì‚°
        cpu_values = [s['cpu_usage'] for s in samples]
        memory_values = [s['memory_usage'] for s in samples]
        response_times = [s['avg_response_time'] for s in samples]
        
        return {
            'sample_count': len(samples),
            'time_range': f"{samples[0]['timestamp']} ~ {samples[-1]['timestamp']}",
            'avg_cpu': np.mean(cpu_values),
            'peak_cpu': np.max(cpu_values),
            'avg_memory': np.mean(memory_values),
            'peak_memory': np.max(memory_values),
            'avg_response_time': np.mean(response_times),
            'max_response_time': np.max(response_times),
            'current_error_rate': self.error_counter / max(self.request_counter, 1)
        }

# ì„±ëŠ¥ ì¶”ì  ë°ì½”ë ˆì´í„°
def track_performance(profiler: RealTimeProfiler):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            profiler.active_requests += 1
            profiler.request_counter += 1
            start_time = time.time()
            
            try:
                result = func(*args, **kwargs)
                return result
            except Exception as e:
                profiler.error_counter += 1
                raise
            finally:
                duration = time.time() - start_time
                profiler.total_response_time += duration
                profiler.active_requests -= 1
        
        return wrapper
    return decorator

# ì‚¬ìš© ì˜ˆì‹œ
real_time_profiler = RealTimeProfiler()

@track_performance(real_time_profiler)
def api_endpoint(request_id: str):
    """API ì—”ë“œí¬ì¸íŠ¸ ì‹œë®¬ë ˆì´ì…˜"""
    # ëœë¤ ì‘ë‹µ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
    import random
    sleep_time = random.uniform(0.1, 0.8)
    time.sleep(sleep_time)
    
    # ê°€ë” ì—ëŸ¬ ë°œìƒ ì‹œë®¬ë ˆì´ì…˜
    if random.random() < 0.02:  # 2% ì—ëŸ¬ìœ¨
        raise Exception("Simulated error")
    
    return {"request_id": request_id, "response": "success"}

# ëª¨ë‹ˆí„°ë§ ì‹œì‘
real_time_profiler.start_monitoring()

# íŠ¸ë˜í”½ ì‹œë®¬ë ˆì´ì…˜
print("íŠ¸ë˜í”½ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")
for i in range(100):
    try:
        api_endpoint(f"req_{i}")
    except Exception:
        pass  # ì—ëŸ¬ëŠ” ì´ë¯¸ ì¹´ìš´íŠ¸ë¨
    
    time.sleep(0.1)

# ì„±ëŠ¥ ìš”ì•½
summary = real_time_profiler.get_performance_summary()
print("\n=== ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìš”ì•½ ===")
for key, value in summary.items():
    print(f"{key}: {value}")

real_time_profiler.stop_monitoring()
```

## ë ˆìŠ¨ ëŸ°

### 1. ì˜¬ë°”ë¥¸ í”„ë¡œíŒŒì¼ë§ ë„êµ¬ë¥¼ ì„ íƒí•˜ë¼

- **í•¨ìˆ˜ ë‹¨ìœ„**: cProfile
- **ë¼ì¸ ë‹¨ìœ„**: line_profiler  
- **ë©”ëª¨ë¦¬**: tracemalloc, memory_profiler
- **ë¹„ë™ê¸°**: ì»¤ìŠ¤í…€ async profiler

### 2. í”„ë¡œë•ì…˜ì—ì„œ ê°€ë²¼ìš´ í”„ë¡œíŒŒì¼ë§ì„ í•˜ë¼

ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì€ **ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ìµœì†Œí™”**í•´ì•¼ í•œë‹¤. ìƒ˜í”Œë§ ê¸°ë°˜ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì.

### 3. ë©”íŠ¸ë¦­ê³¼ í”„ë¡œíŒŒì¼ë§ì„ ì—°ê²°í•˜ë¼

ë©”íŠ¸ë¦­ìœ¼ë¡œ **ë¬¸ì œë¥¼ ê°ì§€**í•˜ê³ , í”„ë¡œíŒŒì¼ë§ìœ¼ë¡œ **ê·¼ë³¸ ì›ì¸ì„ ì°¾ëŠ”ë‹¤**.

### 4. ë³‘ëª©ì˜ ì§„ì§œ ì›ì¸ì„ ì°¾ì•„ë¼

ê²‰ìœ¼ë¡œ ë³´ê¸°ì—ëŠ” CPU ë¬¸ì œê°™ì•„ë„, ì‹¤ì œë¡œëŠ” **I/O ëŒ€ê¸°**ë‚˜ **ë¹„íš¨ìœ¨ì ì¸ ì•Œê³ ë¦¬ì¦˜**ì´ ì›ì¸ì¼ ìˆ˜ ìˆë‹¤.

---

**ë‹¤ìŒ ì¥ì—ì„œëŠ”** ì‹¤ì „ ë””ë²„ê¹… ê¸°ë²•ì„ í†µí•´ ë³µì¡í•œ ì‹œìŠ¤í…œ ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•œë‹¤. í”„ë¡œíŒŒì¼ë§ìœ¼ë¡œ ë³‘ëª©ì„ ì°¾ì•˜ë‹¤ë©´, ì´ì œ ê·¸ê²ƒì„ ì–´ë–»ê²Œ ìˆ˜ì •í• ì§€ ì•Œì•„ì•¼ í•œë‹¤.
