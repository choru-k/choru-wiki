---
tags:
  - Promise Performance
  - Async/Await Optimization
  - Memory Management
  - Concurrency Control
---

# Promise ì„±ëŠ¥ ìµœì í™”: "ë¹„ë™ê¸° ì½”ë“œê°€ ëŠë ¤ìš”"

## ìƒí™©: ë¹„íš¨ìœ¨ì ì¸ Promise ì²´ì´ë‹

"ì•ˆë…•í•˜ì„¸ìš”, ë¹„ë™ê¸° ì²˜ë¦¬ê°€ ë§ì€ Node.js ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œ ì¤‘ì¸ë° ì„±ëŠ¥ì´ ê¸°ëŒ€ë³´ë‹¤ ëŠë¦½ë‹ˆë‹¤. Promise.allì„ ì¨ë„ ëŠë¦¬ê³ , async/awaitì„ ì¨ë„ ëŠë ¤ìš”. íŠ¹íˆ ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ë„ ê¸‰ì¦í•©ë‹ˆë‹¤. Promiseë¥¼ ì–´ë–»ê²Œ ìµœì í™”í•´ì•¼ í• ê¹Œìš”? ë™ì‹œì„± ì œì–´ëŠ” ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?"

ì´ëŸ° Promise ì„±ëŠ¥ ë¬¸ì œëŠ” ì˜ëª»ëœ ë¹„ë™ê¸° íŒ¨í„´ ì‚¬ìš©ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì²´ê³„ì ì¸ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.

## Promise ì„±ëŠ¥ ìµœì í™” ì „ëµ

```mermaid
graph TD
    A[Promise ì„±ëŠ¥ ë¬¸ì œ] --> B{ì›ì¸ ë¶„ì„}
    
    B --> C[ìˆœì°¨ì  ì‹¤í–‰]
    B --> D[ê³¼ë„í•œ ë™ì‹œì„±]
    B --> E[ë©”ëª¨ë¦¬ ëˆ„ìˆ˜]
    B --> F[ë¹„íš¨ìœ¨ì  ì²´ì´ë‹]
    
    C --> G[ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì „í™˜]
    D --> H[ë™ì‹œì„± ì œì–´]
    E --> I[ë©”ëª¨ë¦¬ ê´€ë¦¬]
    F --> J[ì²´ì¸ ìµœì í™”]
    
    subgraph "ìµœì í™” ê¸°ë²•"
        K[Promise.all í™œìš©]
        L[ë°°ì¹˜ ì²˜ë¦¬]
        M[ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬]
        N[Worker Pool]
        O[ë©”ëª¨ë¦¬ í’€ë§]
    end
    
    subgraph "ë™ì‹œì„± ì œì–´"
        P[ì„¸ë§ˆí¬ì–´]
        Q[í ê´€ë¦¬]
        R[ë°±í”„ë ˆì…”]
        S[Rate Limiting]
    end
    
    subgraph "ëª¨ë‹ˆí„°ë§"
        T[Promise ì¶”ì ]
        U[ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§]
        V[ì„±ëŠ¥ ì¸¡ì •]
        W[ë³‘ëª©ì  ë¶„ì„]
    end
```text

## 1. Promise ì„±ëŠ¥ ë¶„ì„ ë„êµ¬

Promise ì‚¬ìš© íŒ¨í„´ê³¼ ì„±ëŠ¥ì„ ë¶„ì„í•˜ëŠ” C ê¸°ë°˜ ë„êµ¬ì…ë‹ˆë‹¤.

```c
// promise_performance_analyzer.c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <time.h>
#include <sys/time.h>
#include <pthread.h>
#include <errno.h>
#include <math.h>
#include <stdatomic.h>
#include <sys/resource.h>

#define MAX_PROMISES 10000
#define MAX_BATCH_SIZE 100
#define MEMORY_POOL_SIZE 1024

typedef enum {
    PROMISE_PENDING,
    PROMISE_FULFILLED,
    PROMISE_REJECTED
} promise_state_t;

typedef struct promise {
    int id;
    promise_state_t state;
    struct timeval created;
    struct timeval resolved;
    double execution_time_ms;
    size_t memory_usage;
    char error_message[256];
    struct promise *next;
} promise_t;

typedef struct {
    promise_t *head;
    promise_t *tail;
    int count;
    pthread_mutex_t mutex;
} promise_queue_t;

typedef struct {
    atomic_int total_promises;
    atomic_int pending_promises;
    atomic_int fulfilled_promises;
    atomic_int rejected_promises;
    atomic_long total_memory_usage;
    atomic_long total_execution_time_ns;
    
    // ì„±ëŠ¥ ë©”íŠ¸ë¦­
    double avg_execution_time_ms;
    double max_execution_time_ms;
    double min_execution_time_ms;
    double memory_peak_mb;
    int memory_leaks;
    
    // ë™ì‹œì„± í†µê³„
    int max_concurrent_promises;
    int current_concurrent_promises;
    double concurrency_efficiency;
} performance_stats_t;

typedef struct {
    int max_concurrent;
    int batch_size;
    int enable_memory_pool;
    int enable_detailed_logging;
    double timeout_ms;
} config_t;

static performance_stats_t stats = {0};
static promise_queue_t active_promises = {0};
static promise_queue_t completed_promises = {0};
static config_t config = {
    .max_concurrent = 10,
    .batch_size = 50,
    .enable_memory_pool = 1,
    .enable_detailed_logging = 0,
    .timeout_ms = 5000.0
};

// ë©”ëª¨ë¦¬ í’€
static char memory_pool[MEMORY_POOL_SIZE * 1024]; // 1MB í’€
static int memory_pool_index = 0;
static pthread_mutex_t memory_pool_mutex = PTHREAD_MUTEX_INITIALIZER;

// ê³ í•´ìƒë„ íƒ€ì´ë¨¸
static inline uint64_t get_timestamp_ns() {
    struct timespec ts;
    clock_gettime(CLOCK_MONOTONIC, &ts);
    return ts.tv_sec * 1000000000ULL + ts.tv_nsec;
}

// ì‹œê°„ ì°¨ì´ ê³„ì‚° (ë°€ë¦¬ì´ˆ)
double time_diff_ms(struct timeval *start, struct timeval *end) {
    return (end->tv_sec - start->tv_sec) * 1000.0 + 
           (end->tv_usec - start->tv_usec) / 1000.0;
}

// ë©”ëª¨ë¦¬ í’€ì—ì„œ í• ë‹¹
void* pool_alloc(size_t size) {
    if (!config.enable_memory_pool) {
        return malloc(size);
    }
    
    pthread_mutex_lock(&memory_pool_mutex);
    
    if (memory_pool_index + size > sizeof(memory_pool)) {
        pthread_mutex_unlock(&memory_pool_mutex);
        return malloc(size); // í’€ ë¶€ì¡± ì‹œ ì¼ë°˜ í• ë‹¹
    }
    
    void *ptr = memory_pool + memory_pool_index;
    memory_pool_index += size;
    
    pthread_mutex_unlock(&memory_pool_mutex);
    return ptr;
}

// ë©”ëª¨ë¦¬ í’€ í•´ì œ (ì‹¤ì œë¡œëŠ” ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ)
void pool_free(void *ptr) {
    if (!config.enable_memory_pool) {
        free(ptr);
    }
    // í’€ ë©”ëª¨ë¦¬ëŠ” í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ í•´ì œ
}

// í ì´ˆê¸°í™”
void init_queue(promise_queue_t *queue) {
    queue->head = NULL;
    queue->tail = NULL;
    queue->count = 0;
    if (pthread_mutex_init(&queue->mutex, NULL) != 0) {
        perror("í ë®¤í…ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨");
        exit(1);
    }
}

// íì— Promise ì¶”ê°€
void enqueue_promise(promise_queue_t *queue, promise_t *promise) {
    pthread_mutex_lock(&queue->mutex);
    
    if (queue->tail) {
        queue->tail->next = promise;
    } else {
        queue->head = promise;
    }
    
    queue->tail = promise;
    promise->next = NULL;
    queue->count++;
    
    pthread_mutex_unlock(&queue->mutex);
}

// íì—ì„œ Promise ì œê±°
promise_t* dequeue_promise(promise_queue_t *queue) {
    pthread_mutex_lock(&queue->mutex);
    
    if (!queue->head) {
        pthread_mutex_unlock(&queue->mutex);
        return NULL;
    }
    
    promise_t *promise = queue->head;
    queue->head = promise->next;
    
    if (!queue->head) {
        queue->tail = NULL;
    }
    
    queue->count--;
    
    pthread_mutex_unlock(&queue->mutex);
    return promise;
}

// Promise ìƒì„±
promise_t* create_promise() {
    promise_t *promise = (promise_t*)pool_alloc(sizeof(promise_t));
    if (!promise) {
        return NULL;
    }
    
    static int promise_id = 0;
    promise->id = __sync_add_and_fetch(&promise_id, 1);
    promise->state = PROMISE_PENDING;
    gettimeofday(&promise->created, NULL);
    promise->execution_time_ms = 0;
    promise->memory_usage = sizeof(promise_t);
    promise->error_message[0] = '\0';
    promise->next = NULL;
    
    atomic_fetch_add(&stats.total_promises, 1);
    atomic_fetch_add(&stats.pending_promises, 1);
    atomic_fetch_add(&stats.total_memory_usage, promise->memory_usage);
    
    // ë™ì‹œì„± ì¶”ì 
    int current = atomic_fetch_add(&stats.current_concurrent_promises, 1) + 1;
    if (current > stats.max_concurrent_promises) {
        stats.max_concurrent_promises = current;
    }
    
    enqueue_promise(&active_promises, promise);
    
    if (config.enable_detailed_logging) {
        printf("[CREATE] Promise %d ìƒì„±, ", promise->id);
    }
    
    return promise;
}

// Promise í•´ê²°
void resolve_promise(promise_t *promise, const char *result) {
    if (promise->state != PROMISE_PENDING) {
        return;
    }
    
    gettimeofday(&promise->resolved, NULL);
    promise->state = PROMISE_FULFILLED;
    promise->execution_time_ms = time_diff_ms(&promise->created, &promise->resolved);
    
    atomic_fetch_sub(&stats.pending_promises, 1);
    atomic_fetch_add(&stats.fulfilled_promises, 1);
    atomic_fetch_sub(&stats.current_concurrent_promises, 1);
    
    // ì‹¤í–‰ ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸
    if (promise->execution_time_ms > stats.max_execution_time_ms) {
        stats.max_execution_time_ms = promise->execution_time_ms;
    }
    
    if (promise->execution_time_ms < stats.min_execution_time_ms || 
        stats.min_execution_time_ms == 0) {
        stats.min_execution_time_ms = promise->execution_time_ms;
    }
    
    atomic_fetch_add(&stats.total_execution_time_ns, 
                     (long)(promise->execution_time_ms * 1000000));
    
    enqueue_promise(&completed_promises, promise);
    
    if (config.enable_detailed_logging) {
        printf("[RESOLVE] Promise %d í•´ê²° (%.2fms), ", 
               promise->id, promise->execution_time_ms);
    }
}

// Promise ê±°ë¶€
void reject_promise(promise_t *promise, const char *error) {
    if (promise->state != PROMISE_PENDING) {
        return;
    }
    
    gettimeofday(&promise->resolved, NULL);
    promise->state = PROMISE_REJECTED;
    promise->execution_time_ms = time_diff_ms(&promise->created, &promise->resolved);
    strncpy(promise->error_message, error, sizeof(promise->error_message) - 1);
    
    atomic_fetch_sub(&stats.pending_promises, 1);
    atomic_fetch_add(&stats.rejected_promises, 1);
    atomic_fetch_sub(&stats.current_concurrent_promises, 1);
    
    enqueue_promise(&completed_promises, promise);
    
    if (config.enable_detailed_logging) {
        printf("[REJECT] Promise %d ê±°ë¶€: %s, ", promise->id, error);
    }
}

// ë¹„ë™ê¸° ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
void* async_worker(void *arg) {
    promise_t *promise = (promise_t*)arg;
    
    // ì‹¤ì œ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜ (100ms ~ 1ì´ˆ)
    int work_time_ms = 100 + (rand() % 900);
    usleep(work_time_ms * 1000);
    
    // 90% í™•ë¥ ë¡œ ì„±ê³µ
    if (rand() % 100 < 90) {
        resolve_promise(promise, "ì‘ì—… ì™„ë£Œ");
    } else {
        reject_promise(promise, "ì‘ì—… ì‹¤íŒ¨");
    }
    
    return NULL;
}

// ë™ì‹œì„± ì œì–´ëœ Promise ì‹¤í–‰
void execute_promises_with_concurrency_control(int count) {
    printf("ë™ì‹œì„± ì œì–´ Promise ì‹¤í–‰ ì‹œì‘ (%dê°œ, ìµœëŒ€ ë™ì‹œì„±: %d), ", 
           count, config.max_concurrent);
    
    pthread_t threads[config.max_concurrent];
    int active_threads = 0;
    int created_promises = 0;
    
    uint64_t start_time = get_timestamp_ns();
    
    while (created_promises < count || active_threads > 0) {
        // ìƒˆ Promise ìƒì„± (ë™ì‹œì„± í•œë„ ë‚´ì—ì„œ)
        while (created_promises < count && active_threads < config.max_concurrent) {
            promise_t *promise = create_promise();
            if (!promise) {
                printf("Promise ìƒì„± ì‹¤íŒ¨, ");
                break;
            }
            
            if (pthread_create(&threads[active_threads], NULL, 
                              async_worker, promise) == 0) {
                active_threads++;
                created_promises++;
            } else {
                reject_promise(promise, "ìŠ¤ë ˆë“œ ìƒì„± ì‹¤íŒ¨");
            }
        }
        
        // ì™„ë£Œëœ ìŠ¤ë ˆë“œ ì •ë¦¬
        for (int i = 0; i < active_threads; i++) {
            if (pthread_tryjoin_np(threads[i], NULL) == 0) {
                // ì™„ë£Œëœ ìŠ¤ë ˆë“œë¥¼ ë°°ì—´ì—ì„œ ì œê±°
                for (int j = i; j < active_threads - 1; j++) {
                    threads[j] = threads[j + 1];
                }
                active_threads--;
                i--; // ì¸ë±ìŠ¤ ì¡°ì •
            }
        }
        
        usleep(1000); // 1ms ëŒ€ê¸°
    }
    
    uint64_t end_time = get_timestamp_ns();
    double total_time_ms = (end_time - start_time) / 1000000.0;
    
    printf("ì‹¤í–‰ ì™„ë£Œ: %.2fms, ", total_time_ms);
}

// ë°°ì¹˜ ì²˜ë¦¬
void execute_promises_in_batches(int total_count) {
    printf("ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ (ì´ %dê°œ, ë°°ì¹˜ í¬ê¸°: %d), ", 
           total_count, config.batch_size);
    
    int remaining = total_count;
    int batch_number = 1;
    
    uint64_t start_time = get_timestamp_ns();
    
    while (remaining > 0) {
        int batch_size = remaining < config.batch_size ? remaining : config.batch_size;
        
        printf("ë°°ì¹˜ %d ì‹¤í–‰ ì¤‘ (%dê°œ)..., ", batch_number, batch_size);
        
        // ë°°ì¹˜ ë‚´ Promiseë“¤ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
        pthread_t threads[batch_size];
        promise_t *promises[batch_size];
        
        // Promise ìƒì„± ë° ìŠ¤ë ˆë“œ ì‹œì‘
        for (int i = 0; i < batch_size; i++) {
            promises[i] = create_promise();
            if (promises[i]) {
                if (pthread_create(&threads[i], NULL, async_worker, promises[i]) != 0) {
                    reject_promise(promises[i], "ìŠ¤ë ˆë“œ ìƒì„± ì‹¤íŒ¨");
                }
            }
        }
        
        // ë°°ì¹˜ ì™„ë£Œ ëŒ€ê¸°
        for (int i = 0; i < batch_size; i++) {
            if (promises[i]) {
                pthread_join(threads[i], NULL);
            }
        }
        
        remaining -= batch_size;
        batch_number++;
        
        printf("ë°°ì¹˜ %d ì™„ë£Œ, ", batch_number - 1);
    }
    
    uint64_t end_time = get_timestamp_ns();
    double total_time_ms = (end_time - start_time) / 1000000.0;
    
    printf("ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: %.2fms, ", total_time_ms);
}

// ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
void monitor_memory_usage() {
    struct rusage usage;
    if (getrusage(RUSAGE_SELF, &usage) == 0) {
        double memory_mb = usage.ru_maxrss / 1024.0; // KBë¥¼ MBë¡œ ë³€í™˜
        
        if (memory_mb > stats.memory_peak_mb) {
            stats.memory_peak_mb = memory_mb;
        }
        
        printf("í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: %.2f MB (í”¼í¬: %.2f MB), ", 
               memory_mb, stats.memory_peak_mb);
    }
}

// ì„±ëŠ¥ í†µê³„ ê³„ì‚°
void calculate_performance_stats() {
    int total = atomic_load(&stats.total_promises);
    int fulfilled = atomic_load(&stats.fulfilled_promises);
    long total_time_ns = atomic_load(&stats.total_execution_time_ns);
    
    if (fulfilled > 0) {
        stats.avg_execution_time_ms = (double)total_time_ns / (fulfilled * 1000000.0);
    }
    
    if (stats.max_concurrent_promises > 0) {
        stats.concurrency_efficiency = (double)fulfilled / stats.max_concurrent_promises;
    }
    
    // ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
    if (atomic_load(&stats.total_memory_usage) > total * sizeof(promise_t) * 2) {
        stats.memory_leaks = 1;
    }
}

// ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì¶œë ¥
void print_performance_report() {
    calculate_performance_stats();
    
    printf(", =====================================, ");
    printf("Promise ì„±ëŠ¥ ë¶„ì„ ë¦¬í¬íŠ¸, ");
    printf("=====================================, ");
    
    printf("ğŸ“Š ê¸°ë³¸ í†µê³„:, ");
    printf("  ì´ Promise ìˆ˜: %d, ", atomic_load(&stats.total_promises));
    printf("  ì„±ê³µí•œ Promise: %d, ", atomic_load(&stats.fulfilled_promises));
    printf("  ì‹¤íŒ¨í•œ Promise: %d, ", atomic_load(&stats.rejected_promises));
    printf("  ëŒ€ê¸° ì¤‘ì¸ Promise: %d, ", atomic_load(&stats.pending_promises));
    
    if (atomic_load(&stats.fulfilled_promises) > 0) {
        double success_rate = (double)atomic_load(&stats.fulfilled_promises) / 
                             atomic_load(&stats.total_promises) * 100;
        printf("  ì„±ê³µë¥ : %.1f%%, ", success_rate);
    }
    
    printf(", â±ï¸  ì‹¤í–‰ ì‹œê°„ í†µê³„:, ");
    printf("  í‰ê·  ì‹¤í–‰ ì‹œê°„: %.2f ms, ", stats.avg_execution_time_ms);
    printf("  ìµœì†Œ ì‹¤í–‰ ì‹œê°„: %.2f ms, ", stats.min_execution_time_ms);
    printf("  ìµœëŒ€ ì‹¤í–‰ ì‹œê°„: %.2f ms, ", stats.max_execution_time_ms);
    
    printf(", ğŸ”„ ë™ì‹œì„± í†µê³„:, ");
    printf("  ìµœëŒ€ ë™ì‹œ Promise ìˆ˜: %d, ", stats.max_concurrent_promises);
    printf("  ë™ì‹œì„± íš¨ìœ¨ì„±: %.2f, ", stats.concurrency_efficiency);
    printf("  ì„¤ì •ëœ ìµœëŒ€ ë™ì‹œì„±: %d, ", config.max_concurrent);
    
    printf(", ğŸ’¾ ë©”ëª¨ë¦¬ í†µê³„:, ");
    printf("  ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: %ld bytes, ", atomic_load(&stats.total_memory_usage));
    printf("  í”¼í¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: %.2f MB, ", stats.memory_peak_mb);
    printf("  ë©”ëª¨ë¦¬ í’€ ì‚¬ìš©: %s, ", config.enable_memory_pool ? "í™œì„±í™”" : "ë¹„í™œì„±í™”");
    
    if (stats.memory_leaks) {
        printf("  âš ï¸  ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ë¨, ");
    }
    
    printf(", ğŸ¯ ìµœì í™” ê¶Œì¥ì‚¬í•­:, ");
    
    if (stats.avg_execution_time_ms > 1000) {
        printf("  - í‰ê·  ì‹¤í–‰ ì‹œê°„ì´ ë†’ìŠµë‹ˆë‹¤. ì‘ì—…ì„ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì„¸ìš”., ");
    }
    
    if (stats.concurrency_efficiency < 0.5) {
        printf("  - ë™ì‹œì„± íš¨ìœ¨ì„±ì´ ë‚®ìŠµë‹ˆë‹¤. ë™ì‹œì„± ìˆ˜ì¤€ì„ ì¡°ì •í•˜ì„¸ìš”., ");
    }
    
    if (stats.memory_leaks) {
        printf("  - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. Promise ì •ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”., ");
    }
    
    if (atomic_load(&stats.rejected_promises) > atomic_load(&stats.total_promises) * 0.1) {
        printf("  - ì‹¤íŒ¨ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ê°œì„ í•˜ì„¸ìš”., ");
    }
    
    if (stats.max_concurrent_promises < config.max_concurrent) {
        printf("  - ì„¤ì •ëœ ë™ì‹œì„±ì´ ì¶©ë¶„íˆ í™œìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤., ");
    }
    
    printf(", ìµœì í™” ê¸°ë²•:, ");
    printf("  - Promise.all() ì‚¬ìš©ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬, ");
    printf("  - ì ì ˆí•œ ë™ì‹œì„± ì œì–´ (ì„¸ë§ˆí¬ì–´ íŒ¨í„´), ");
    printf("  - ë©”ëª¨ë¦¬ í’€ë§ìœ¼ë¡œ í• ë‹¹ ìµœì í™”, ");
    printf("  - ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„± í–¥ìƒ, ");
}

// Promise ì²´ì¸ ë¶„ì„
void analyze_promise_chains() {
    printf(", ğŸ”— Promise ì²´ì¸ ë¶„ì„:, ");
    
    // ì™„ë£Œëœ Promiseë“¤ì„ ë¶„ì„
    promise_t *current = completed_promises.head;
    int chain_length = 0;
    double total_chain_time = 0;
    
    while (current) {
        chain_length++;
        total_chain_time += current->execution_time_ms;
        current = current->next;
    }
    
    if (chain_length > 0) {
        printf("  í‰ê·  ì²´ì¸ ê¸¸ì´: %d, ", chain_length);
        printf("  ì´ ì²´ì¸ ì‹¤í–‰ ì‹œê°„: %.2f ms, ", total_chain_time);
        printf("  ì²´ì¸ë‹¹ í‰ê·  ì‹œê°„: %.2f ms, ", total_chain_time / chain_length);
    }
}

// ì •ë¦¬ í•¨ìˆ˜
void cleanup() {
    printf(", ì •ë¦¬ ì¤‘..., ");
    
    // í™œì„± Promise ì •ë¦¬
    promise_t *current = active_promises.head;
    while (current) {
        promise_t *next = current->next;
        pool_free(current);
        current = next;
    }
    
    // ì™„ë£Œëœ Promise ì •ë¦¬
    current = completed_promises.head;
    while (current) {
        promise_t *next = current->next;
        pool_free(current);
        current = next;
    }
    
    pthread_mutex_destroy(&active_promises.mutex);
    pthread_mutex_destroy(&completed_promises.mutex);
    pthread_mutex_destroy(&memory_pool_mutex);
}

// ì‚¬ìš©ë²• ì¶œë ¥
void print_usage(const char *program_name) {
    printf("Promise ì„±ëŠ¥ ë¶„ì„ê¸°, ");
    printf("ì‚¬ìš©ë²•: %s [ì˜µì…˜], ", program_name);
    printf("ì˜µì…˜:, ");
    printf("  -n COUNT       Promise ìˆ˜ (ê¸°ë³¸ê°’: 100), ");
    printf("  -c CONCURRENT  ìµœëŒ€ ë™ì‹œì„± (ê¸°ë³¸ê°’: 10), ");
    printf("  -b BATCH       ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 50), ");
    printf("  -m             ë©”ëª¨ë¦¬ í’€ ë¹„í™œì„±í™”, ");
    printf("  -v             ìƒì„¸ ë¡œê¹… í™œì„±í™”, ");
    printf("  -t TEST        í…ŒìŠ¤íŠ¸ ëª¨ë“œ (concurrency|batch|chain), ");
    printf("  --help         ì´ ë„ì›€ë§ ì¶œë ¥, ");
}

int main(int argc, char *argv[]) {
    int promise_count = 100;
    char test_mode[64] = "concurrency";
    
    // ëª…ë ¹í–‰ ì¸ì ì²˜ë¦¬
    for (int i = 1; i < argc; i++) {
        if (strcmp(argv[i], "-n") == 0 && i + 1 < argc) {
            promise_count = atoi(argv[++i]);
        } else if (strcmp(argv[i], "-c") == 0 && i + 1 < argc) {
            config.max_concurrent = atoi(argv[++i]);
        } else if (strcmp(argv[i], "-b") == 0 && i + 1 < argc) {
            config.batch_size = atoi(argv[++i]);
        } else if (strcmp(argv[i], "-m") == 0) {
            config.enable_memory_pool = 0;
        } else if (strcmp(argv[i], "-v") == 0) {
            config.enable_detailed_logging = 1;
        } else if (strcmp(argv[i], "-t") == 0 && i + 1 < argc) {
            strncpy(test_mode, argv[++i], sizeof(test_mode) - 1);
        } else if (strcmp(argv[i], "--help") == 0) {
            print_usage(argv[0]);
            return 0;
        }
    }
    
    // ì´ˆê¸°í™”
    init_queue(&active_promises);
    init_queue(&completed_promises);
    
    printf("Promise ì„±ëŠ¥ ë¶„ì„ ì‹œì‘, ");
    printf("Promise ìˆ˜: %d, ", promise_count);
    printf("í…ŒìŠ¤íŠ¸ ëª¨ë“œ: %s, ", test_mode);
    printf("============================, , ");
    
    // í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if (strcmp(test_mode, "concurrency") == 0) {
        execute_promises_with_concurrency_control(promise_count);
    } else if (strcmp(test_mode, "batch") == 0) {
        execute_promises_in_batches(promise_count);
    } else if (strcmp(test_mode, "chain") == 0) {
        // ì²´ì¸ í…ŒìŠ¤íŠ¸ëŠ” ê°„ë‹¨ ë²„ì „
        for (int i = 0; i < promise_count; i++) {
            promise_t *promise = create_promise();
            if (promise) {
                pthread_t thread;
                if (pthread_create(&thread, NULL, async_worker, promise) == 0) {
                    pthread_join(thread, NULL);
                } else {
                    reject_promise(promise, "ìŠ¤ë ˆë“œ ìƒì„± ì‹¤íŒ¨");
                }
            }
        }
    } else {
        printf("ì•Œ ìˆ˜ ì—†ëŠ” í…ŒìŠ¤íŠ¸ ëª¨ë“œ: %s, ", test_mode);
        return 1;
    }
    
    // ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
    monitor_memory_usage();
    
    // ê²°ê³¼ ë¶„ì„
    print_performance_report();
    analyze_promise_chains();
    
    // ì •ë¦¬
    cleanup();
    
    return 0;
}
```text

## 2. JavaScript Promise ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬

```javascript
// promise_optimizer.js

class PromiseOptimizer {
    constructor(options = {}) {
        this.config = {
            maxConcurrency: options.maxConcurrency || 10,
            batchSize: options.batchSize || 50,
            retryAttempts: options.retryAttempts || 3,
            retryDelay: options.retryDelay || 1000,
            timeout: options.timeout || 30000,
            enableMetrics: options.enableMetrics !== false,
            memoryThreshold: options.memoryThreshold || 100 * 1024 * 1024, // 100MB
            ...options
        };
        
        this.metrics = {
            totalPromises: 0,
            succeededPromises: 0,
            failedPromises: 0,
            retries: 0,
            totalExecutionTime: 0,
            maxExecutionTime: 0,
            minExecutionTime: Infinity,
            memoryUsage: [],
            concurrencyLevels: [],
            errorTypes: new Map()
        };
        
        this.activePromises = new Set();
        this.semaphore = new Semaphore(this.config.maxConcurrency);
        
        if (this.config.enableMetrics) {
            this.startMetricsCollection();
        }
    }
    
    // ì„¸ë§ˆí¬ì–´ êµ¬í˜„
    static Semaphore = class {
        constructor(maxConcurrency) {
            this.maxConcurrency = maxConcurrency;
            this.currentConcurrency = 0;
            this.queue = [];
        }
        
        async acquire() {
            return new Promise(resolve => {
                if (this.currentConcurrency < this.maxConcurrency) {
                    this.currentConcurrency++;
                    resolve();
                } else {
                    this.queue.push(resolve);
                }
            });
        }
        
        release() {
            this.currentConcurrency--;
            if (this.queue.length > 0) {
                const next = this.queue.shift();
                this.currentConcurrency++;
                next();
            }
        }
    };
    
    // ë™ì‹œì„± ì œì–´ëœ Promise ì‹¤í–‰
    async withConcurrencyControl(promiseFactory) {
        await this.semaphore.acquire();
        
        const startTime = Date.now();
        const promiseId = this.generatePromiseId();
        
        try {
            this.metrics.totalPromises++;
            this.activePromises.add(promiseId);
            
            const result = await Promise.race([
                promiseFactory(),
                this.createTimeoutPromise(this.config.timeout)
            ]);
            
            const executionTime = Date.now() - startTime;
            this.updateExecutionTimeMetrics(executionTime);
            this.metrics.succeededPromises++;
            
            return result;
        } catch (error) {
            this.metrics.failedPromises++;
            this.updateErrorMetrics(error);
            throw error;
        } finally {
            this.activePromises.delete(promiseId);
            this.semaphore.release();
        }
    }
    
    // ë°°ì¹˜ ì²˜ë¦¬
    async processBatch(tasks, options = {}) {
        const batchSize = options.batchSize || this.config.batchSize;
        const results = [];
        const errors = [];
        
        console.log(`ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: ${tasks.length}ê°œ ì‘ì—…, ë°°ì¹˜ í¬ê¸°: ${batchSize}`);
        
        for (let i = 0; i < tasks.length; i += batchSize) {
            const batch = tasks.slice(i, i + batchSize);
            console.log(`ë°°ì¹˜ ${Math.floor(i / batchSize) + 1} ì²˜ë¦¬ ì¤‘... (${batch.length}ê°œ ì‘ì—…)`);
            
            try {
                const batchResults = await this.executeBatch(batch, options);
                results.push(...batchResults.successes);
                errors.push(...batchResults.errors);
            } catch (error) {
                console.error(`ë°°ì¹˜ ${Math.floor(i / batchSize) + 1} ì‹¤íŒ¨:`, error);
                errors.push({ batchIndex: Math.floor(i / batchSize) + 1, error });
            }
            
            // ë©”ëª¨ë¦¬ ì••ë°• ì‹œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ íŒíŠ¸
            if (this.isMemoryPressureHigh()) {
                console.warn('ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ, GC íŠ¸ë¦¬ê±° ì‹œë„');
                global.gc && global.gc();
                await this.sleep(100); // GC ì‹œê°„ ì œê³µ
            }
        }
        
        return { results, errors };
    }
    
    // ê°œë³„ ë°°ì¹˜ ì‹¤í–‰
    async executeBatch(batch, options = {}) {
        const promises = batch.map(async (task, index) => {
            try {
                const result = await this.withConcurrencyControl(() => 
                    typeof task === 'function' ? task() : task
                );
                return { success: true, result, index };
            } catch (error) {
                return { success: false, error, index };
            }
        });
        
        const results = await Promise.allSettled(promises);
        
        const successes = [];
        const errors = [];
        
        results.forEach((result, index) => {
            if (result.status === 'fulfilled') {
                if (result.value.success) {
                    successes.push(result.value.result);
                } else {
                    errors.push({
                        index,
                        error: result.value.error,
                        task: batch[index]
                    });
                }
            } else {
                errors.push({
                    index,
                    error: result.reason,
                    task: batch[index]
                });
            }
        });
        
        return { successes, errors };
    }
    
    // ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ Promise ì‹¤í–‰
    async withRetry(promiseFactory, options = {}) {
        const maxAttempts = options.retryAttempts || this.config.retryAttempts;
        const retryDelay = options.retryDelay || this.config.retryDelay;
        
        let lastError;
        
        for (let attempt = 1; attempt <= maxAttempts; attempt++) {
            try {
                return await this.withConcurrencyControl(promiseFactory);
            } catch (error) {
                lastError = error;
                this.metrics.retries++;
                
                if (attempt === maxAttempts) {
                    throw error;
                }
                
                const delay = retryDelay * Math.pow(2, attempt - 1); // ì§€ìˆ˜ ë°±ì˜¤í”„
                console.log(`ì¬ì‹œë„ ${attempt}/${maxAttempts} (${delay}ms í›„)...`);
                await this.sleep(delay);
            }
        }
        
        throw lastError;
    }
    
    // ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ (ëŒ€ìš©ëŸ‰ ë°ì´í„°)
    async processStream(dataSource, processor, options = {}) {
        const chunkSize = options.chunkSize || 1000;
        const highWaterMark = options.highWaterMark || 16;
        
        return new Promise((resolve, reject) => {
            const results = [];
            const errors = [];
            let processed = 0;
            let isProcessing = false;
            let ended = false;
            
            const processingQueue = [];
            
            const processChunk = async () => {
                if (isProcessing || processingQueue.length === 0) return;
                
                isProcessing = true;
                
                while (processingQueue.length > 0 && 
                       this.activePromises.size < this.config.maxConcurrency) {
                    
                    const chunk = processingQueue.shift();
                    
                    try {
                        const result = await this.withConcurrencyControl(() => 
                            processor(chunk)
                        );
                        results.push(result);
                        processed++;
                    } catch (error) {
                        errors.push({ chunk, error });
                    }
                }
                
                isProcessing = false;
                
                if (ended && processingQueue.length === 0 && this.activePromises.size === 0) {
                    resolve({ results, errors, processed });
                }
            };
            
            // ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì²­í¬ ì½ê¸°
            const readChunks = async () => {
                try {
                    for await (const chunk of dataSource) {
                        processingQueue.push(chunk);
                        
                        // ë°±í”„ë ˆì…” ì œì–´
                        if (processingQueue.length >= highWaterMark) {
                            await this.sleep(10);
                        }
                        
                        processChunk();
                    }
                    ended = true;
                    processChunk();
                } catch (error) {
                    reject(error);
                }
            };
            
            readChunks();
        });
    }
    
    // Promise ë˜í•‘ ë° ìµœì í™”
    optimizePromise(promise, options = {}) {
        const startTime = Date.now();
        const promiseId = this.generatePromiseId();
        
        return promise
            .then(result => {
                const executionTime = Date.now() - startTime;
                this.updateExecutionTimeMetrics(executionTime);
                this.metrics.succeededPromises++;
                return result;
            })
            .catch(error => {
                this.metrics.failedPromises++;
                this.updateErrorMetrics(error);
                
                if (options.fallback) {
                    return options.fallback(error);
                }
                
                throw error;
            });
    }
    
    // ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
    startMetricsCollection() {
        setInterval(() => {
            const memUsage = process.memoryUsage();
            this.metrics.memoryUsage.push({
                timestamp: Date.now(),
                heapUsed: memUsage.heapUsed,
                heapTotal: memUsage.heapTotal,
                external: memUsage.external,
                rss: memUsage.rss
            });
            
            this.metrics.concurrencyLevels.push({
                timestamp: Date.now(),
                active: this.activePromises.size,
                max: this.config.maxConcurrency
            });
            
            // ë©”íŠ¸ë¦­ ë°ì´í„° í¬ê¸° ì œí•œ
            if (this.metrics.memoryUsage.length > 1000) {
                this.metrics.memoryUsage = this.metrics.memoryUsage.slice(-500);
            }
            
            if (this.metrics.concurrencyLevels.length > 1000) {
                this.metrics.concurrencyLevels = this.metrics.concurrencyLevels.slice(-500);
            }
        }, 1000);
    }
    
    // ë©”ëª¨ë¦¬ ì••ë°• ê°ì§€
    isMemoryPressureHigh() {
        const memUsage = process.memoryUsage();
        return memUsage.heapUsed > this.config.memoryThreshold;
    }
    
    // ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    generatePromiseId() {
        return `promise_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    }
    
    createTimeoutPromise(timeout) {
        return new Promise((_, reject) => {
            setTimeout(() => reject(new Error(`íƒ€ì„ì•„ì›ƒ: ${timeout}ms`)), timeout);
        });
    }
    
    sleep(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }
    
    updateExecutionTimeMetrics(executionTime) {
        this.metrics.totalExecutionTime += executionTime;
        this.metrics.maxExecutionTime = Math.max(this.metrics.maxExecutionTime, executionTime);
        this.metrics.minExecutionTime = Math.min(this.metrics.minExecutionTime, executionTime);
    }
    
    updateErrorMetrics(error) {
        const errorType = error.constructor.name;
        const count = this.metrics.errorTypes.get(errorType) || 0;
        this.metrics.errorTypes.set(errorType, count + 1);
    }
    
    // ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±
    getPerformanceReport() {
        const avgExecutionTime = this.metrics.totalPromises > 0 ? 
            this.metrics.totalExecutionTime / this.metrics.totalPromises : 0;
        
        const successRate = this.metrics.totalPromises > 0 ? 
            (this.metrics.succeededPromises / this.metrics.totalPromises) * 100 : 0;
        
        const recentMemoryUsage = this.metrics.memoryUsage.slice(-10);
        const avgMemoryUsage = recentMemoryUsage.length > 0 ?
            recentMemoryUsage.reduce((sum, m) => sum + m.heapUsed, 0) / recentMemoryUsage.length : 0;
        
        return {
            summary: {
                totalPromises: this.metrics.totalPromises,
                succeededPromises: this.metrics.succeededPromises,
                failedPromises: this.metrics.failedPromises,
                successRate: successRate.toFixed(1) + '%',
                retries: this.metrics.retries
            },
            
            performance: {
                avgExecutionTime: avgExecutionTime.toFixed(2) + 'ms',
                maxExecutionTime: this.metrics.maxExecutionTime + 'ms',
                minExecutionTime: this.metrics.minExecutionTime === Infinity ? 
                    '0ms' : this.metrics.minExecutionTime + 'ms'
            },
            
            memory: {
                averageHeapUsed: this.formatBytes(avgMemoryUsage),
                currentHeapUsed: this.formatBytes(process.memoryUsage().heapUsed),
                memoryThreshold: this.formatBytes(this.config.memoryThreshold)
            },
            
            concurrency: {
                maxConcurrency: this.config.maxConcurrency,
                currentActive: this.activePromises.size,
                avgConcurrencyLevel: this.calculateAverageConcurrency()
            },
            
            errors: Array.from(this.metrics.errorTypes.entries()).map(([type, count]) => ({
                type,
                count,
                percentage: ((count / this.metrics.failedPromises) * 100).toFixed(1) + '%'
            })),
            
            recommendations: this.generateRecommendations()
        };
    }
    
    calculateAverageConcurrency() {
        if (this.metrics.concurrencyLevels.length === 0) return 0;
        
        const sum = this.metrics.concurrencyLevels.reduce((total, level) => total + level.active, 0);
        return (sum / this.metrics.concurrencyLevels.length).toFixed(2);
    }
    
    formatBytes(bytes) {
        const units = ['B', 'KB', 'MB', 'GB'];
        let size = bytes;
        let unitIndex = 0;
        
        while (size >= 1024 && unitIndex < units.length - 1) {
            size /= 1024;
            unitIndex++;
        }
        
        return size.toFixed(2) + ' ' + units[unitIndex];
    }
    
    generateRecommendations() {
        const recommendations = [];
        const avgExecutionTime = this.metrics.totalPromises > 0 ? 
            this.metrics.totalExecutionTime / this.metrics.totalPromises : 0;
        
        if (avgExecutionTime > 5000) {
            recommendations.push({
                type: 'performance',
                priority: 'high',
                message: 'í‰ê·  ì‹¤í–‰ ì‹œê°„ì´ ë†’ìŠµë‹ˆë‹¤. ì‘ì—…ì„ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ê±°ë‚˜ íƒ€ì„ì•„ì›ƒì„ ì¤„ì´ì„¸ìš”.'
            });
        }
        
        if (this.metrics.failedPromises / this.metrics.totalPromises > 0.1) {
            recommendations.push({
                type: 'reliability',
                priority: 'high',
                message: 'ì‹¤íŒ¨ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. ì—ëŸ¬ ì²˜ë¦¬ì™€ ì¬ì‹œë„ ë¡œì§ì„ ê°œì„ í•˜ì„¸ìš”.'
            });
        }
        
        const avgConcurrency = this.calculateAverageConcurrency();
        if (avgConcurrency < this.config.maxConcurrency * 0.5) {
            recommendations.push({
                type: 'concurrency',
                priority: 'medium',
                message: 'ë™ì‹œì„±ì´ ì¶©ë¶„íˆ í™œìš©ë˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤. ì‘ì—… ë¶„í• ì´ë‚˜ ë™ì‹œì„± ìˆ˜ì¤€ì„ ê²€í† í•˜ì„¸ìš”.'
            });
        }
        
        if (this.isMemoryPressureHigh()) {
            recommendations.push({
                type: 'memory',
                priority: 'high',
                message: 'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.'
            });
        }
        
        return recommendations;
    }
    
    // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    cleanup() {
        this.activePromises.clear();
        this.metrics.memoryUsage = [];
        this.metrics.concurrencyLevels = [];
        this.metrics.errorTypes.clear();
    }
}

// ì‚¬ìš© ì˜ˆì œ
async function example() {
    const optimizer = new PromiseOptimizer({
        maxConcurrency: 5,
        batchSize: 20,
        retryAttempts: 3,
        enableMetrics: true
    });
    
    // 1. ë™ì‹œì„± ì œì–´ëœ ì‹¤í–‰
    const task1 = () => fetch('https://api.example.com/data');
    const result1 = await optimizer.withConcurrencyControl(task1);
    
    // 2. ì¬ì‹œë„ ë¡œì§
    const task2 = () => riskyOperation();
    const result2 = await optimizer.withRetry(task2);
    
    // 3. ë°°ì¹˜ ì²˜ë¦¬
    const tasks = Array.from({ length: 100 }, (_, i) => 
        () => processItem(i)
    );
    const batchResult = await optimizer.processBatch(tasks);
    
    // 4. ì„±ëŠ¥ ë¦¬í¬íŠ¸
    const report = optimizer.getPerformanceReport();
    console.log('ì„±ëŠ¥ ë¦¬í¬íŠ¸:', JSON.stringify(report, null, 2));
    
    // ì •ë¦¬
    optimizer.cleanup();
}

module.exports = PromiseOptimizer;
```text

ì´ ë¬¸ì„œëŠ” Promiseì™€ ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ì˜ ì„±ëŠ¥ ìµœì í™” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ë™ì‹œì„± ì œì–´, ë©”ëª¨ë¦¬ ê´€ë¦¬, ë°°ì¹˜ ì²˜ë¦¬ ë“±ì˜ ê³ ê¸‰ ê¸°ë²•ì„ í†µí•´ ëŒ€ê·œëª¨ ë¹„ë™ê¸° ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
