---
tags:
  - Coroutine
  - GreenThread
  - Concurrency
  - Async
  - Runtime
---

# Chapter 8-3: ì½”ë£¨í‹´ê³¼ Green Thread êµ¬í˜„

## ğŸ¯ ì´ ë¬¸ì„œë¥¼ ì½ê³  ë‚˜ë©´ ì–»ì„ ìˆ˜ ìˆëŠ” ê²ƒë“¤

ì´ ë¬¸ì„œë¥¼ ë§ˆìŠ¤í„°í•˜ë©´, ì—¬ëŸ¬ë¶„ì€:

1. **"Pythonì˜ asyncioëŠ” ì–´ë–»ê²Œ ì‹±ê¸€ ìŠ¤ë ˆë“œì—ì„œ ë™ì‹œì„±ì„ êµ¬í˜„í•˜ì£ ?"** - Generatorì™€ Event Loopì˜ ì ˆë¬˜í•œ ì¡°í•©ì„ ì´í•´í•©ë‹ˆë‹¤
2. **"GoëŠ” ì–´ë–»ê²Œ 100ë§Œ ê°œì˜ goroutineì„ ì‹¤í–‰í•˜ì£ ?"** - 2KB ìŠ¤íƒê³¼ ì„¸ê·¸ë¨¼íŠ¸ ìŠ¤íƒì˜ ë¹„ë°€ì„ ì•Œê²Œ ë©ë‹ˆë‹¤
3. **"Javaì˜ Virtual ThreadëŠ” ë­ê°€ ë‹¤ë¥¸ê°€ìš”?"** - Project Loomì˜ í˜ì‹ ê³¼ Continuationì˜ ë§ˆë²•ì„ ë°°ì›ë‹ˆë‹¤
4. **"ì½”ë£¨í‹´ì´ ìŠ¤ë ˆë“œë³´ë‹¤ ë¹ ë¥¸ ì´ìœ ê°€ ë­”ê°€ìš”?"** - User-space schedulingì˜ íš¨ìœ¨ì„±ì„ ì¦ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

## 1. ì½”ë£¨í‹´ì˜ íƒ„ìƒ: í˜‘ë ¥ì  ë©€í‹°íƒœìŠ¤í‚¹ì˜ ë¶€í™œ

### 1.1 ì—­ì‚¬ì˜ ì•„ì´ëŸ¬ë‹ˆ: 1958ë…„ìœ¼ë¡œì˜ íšŒê·€

```
1958ë…„: Melvin Conwayê°€ ì½”ë£¨í‹´ ê°œë… ë°œëª…
1970ë…„ëŒ€: Preemptive multitaskingì´ ëŒ€ì„¸ê°€ ë¨
2000ë…„ëŒ€: ì½”ë£¨í‹´ì˜ ë¶€í™œ - "Everything old is new again"
```

ì¬ë¯¸ìˆëŠ” ì‚¬ì‹¤: ì½”ë£¨í‹´ì€ ì‚¬ì‹¤ ìŠ¤ë ˆë“œë³´ë‹¤ ë¨¼ì € ë°œëª…ë˜ì—ˆìŠµë‹ˆë‹¤! í•˜ì§€ë§Œ í•˜ë“œì›¨ì–´ê°€ ë°œì „í•˜ë©´ì„œ OS ë ˆë²¨ ìŠ¤ë ˆë“œê°€ ì£¼ë¥˜ê°€ ë˜ì—ˆì£ . ê·¸ëŸ°ë° ì™œ ë‹¤ì‹œ ì½”ë£¨í‹´ìœ¼ë¡œ ëŒì•„ì™”ì„ê¹Œìš”?

**ìŠ¤ë ˆë“œì˜ í•œê³„ë¥¼ ë³´ì—¬ì£¼ëŠ” ì‹¤í—˜:**

```c
// ìŠ¤ë ˆë“œ 10,000ê°œ ìƒì„± í…ŒìŠ¤íŠ¸
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>

void* thread_func(void* arg) {
    // ê° ìŠ¤ë ˆë“œëŠ” 8MB ìŠ¤íƒ í• ë‹¹ (Linux ê¸°ë³¸ê°’)
    char stack_array[1024];  // ìŠ¤íƒ ì‚¬ìš©
    sleep(60);  // 1ë¶„ ëŒ€ê¸°
    return NULL;
}

int main() {
    pthread_t threads[10000];
    
    for (int i = 0; i < 10000; i++) {
        if (pthread_create(&threads[i], NULL, thread_func, NULL) != 0) {
            printf("Failed at thread %d\n", i);
            perror("pthread_create");
            break;
        }
    }
    
    // ê²°ê³¼:
    // Failed at thread 380
    // pthread_create: Resource temporarily unavailable
    // 
    // ë©”ëª¨ë¦¬ ì‚¬ìš©: 380 * 8MB = 3GB!
    // ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹­: ìˆ˜ ë§ˆì´í¬ë¡œì´ˆ * 380 = ë°€ë¦¬ì´ˆ ë‹¨ìœ„ ì§€ì—°
}
```

**ì½”ë£¨í‹´ìœ¼ë¡œ ê°™ì€ ì‘ì—…:**

```go
// Goë¡œ goroutine 1,000,000ê°œ ìƒì„±
package main

import (
    "fmt"
    "runtime"
    "sync"
    "time"
)

func main() {
    var wg sync.WaitGroup
    startMem := runtime.MemStats{}
    runtime.ReadMemStats(&startMem)
    
    // 1ë°±ë§Œ ê°œ goroutine ìƒì„±!
    for i := 0; i < 1000000; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            time.Sleep(60 * time.Second)
        }(i)
    }
    
    endMem := runtime.MemStats{}
    runtime.ReadMemStats(&endMem)
    
    fmt.Printf("Goroutines: %d\n", runtime.NumGoroutine())
    fmt.Printf("Memory used: %d MB\n", 
        (endMem.Alloc-startMem.Alloc)/1024/1024)
    
    // ê²°ê³¼:
    // Goroutines: 1000000
    // Memory used: 2000 MB (2KB * 1M = 2GB)
    // 
    // ìŠ¤ë ˆë“œ ëŒ€ë¹„ 15ë°° ë” ë§ì€ ë™ì‹œì„±!
    wg.Wait()
}
```

### 1.2 Stackful vs Stackless: ë‘ ê°€ì§€ ê¸¸

ì½”ë£¨í‹´ êµ¬í˜„ì—ëŠ” ê·¼ë³¸ì ìœ¼ë¡œ ë‹¤ë¥¸ ë‘ ê°€ì§€ ì ‘ê·¼ë²•ì´ ìˆìŠµë‹ˆë‹¤:

```python
# Stackless ì½”ë£¨í‹´ (Python generator)
def stackless_coroutine():
    print("Step 1")
    yield 1  # ìƒíƒœë¥¼ ê°ì²´ì— ì €ì¥
    print("Step 2")
    yield 2
    print("Step 3")
    
# ë³€í™˜ëœ ìƒíƒœ ë¨¸ì‹  (ê°œë…ì )
class StacklessCoroutine:
    def __init__(self):
        self.state = 0
        
    def resume(self):
        if self.state == 0:
            print("Step 1")
            self.state = 1
            return 1
        elif self.state == 1:
            print("Step 2")
            self.state = 2
            return 2
        elif self.state == 2:
            print("Step 3")
            self.state = 3
            return None
```

```c
// Stackful ì½”ë£¨í‹´ (C with setjmp/longjmp)
#include <setjmp.h>
#include <stdio.h>
#include <stdlib.h>

typedef struct {
    jmp_buf context;
    char stack[8192];  // ìì²´ ìŠ¤íƒ!
    void (*func)(void*);
    void* arg;
} Coroutine;

Coroutine* current_coro;
jmp_buf main_context;

void yield() {
    if (setjmp(current_coro->context) == 0) {
        longjmp(main_context, 1);
    }
}

void resume(Coroutine* coro) {
    current_coro = coro;
    if (setjmp(main_context) == 0) {
        longjmp(coro->context, 1);
    }
}

void coro_func(void* arg) {
    printf("Coroutine: Step 1\n");
    yield();
    printf("Coroutine: Step 2\n");
    yield();
    printf("Coroutine: Step 3\n");
}
```

**ë¹„êµí‘œ:**

| íŠ¹ì„± | Stackful | Stackless |
|------|----------|-----------|
| êµ¬í˜„ ë³µì¡ë„ | ë†’ìŒ | ë‚®ìŒ |
| ë©”ëª¨ë¦¬ ì‚¬ìš© | ë§ìŒ (ìŠ¤íƒ í•„ìš”) | ì ìŒ (ìƒíƒœë§Œ ì €ì¥) |
| ì„±ëŠ¥ | ë¹ ë¥¸ ìŠ¤ìœ„ì¹­ | ì•½ê°„ ëŠë¦¼ |
| í˜¸ì¶œ ê¹Šì´ | ì œí•œ ì—†ìŒ | ì œí•œì  |
| ëŒ€í‘œ ì˜ˆ | Go, Lua | Python, JavaScript |

## 2. Python asyncio: Generator ë§ˆë²•ì˜ ê·¹ì¹˜

### 2.1 Generatorì—ì„œ Coroutineìœ¼ë¡œì˜ ì§„í™”

Pythonì˜ ì½”ë£¨í‹´ ì§„í™”ëŠ” ì •ë§ í¥ë¯¸ë¡­ìŠµë‹ˆë‹¤:

```python
# 1ë‹¨ê³„: ë‹¨ìˆœ Generator (Python 2.2, 2001ë…„)
def simple_generator():
    yield 1
    yield 2
    
# 2ë‹¨ê³„: Generatorì— ê°’ ë³´ë‚´ê¸° (Python 2.5, 2006ë…„)
def enhanced_generator():
    value = yield 1
    print(f"Received: {value}")
    yield 2
    
gen = enhanced_generator()
next(gen)  # 1 ë°˜í™˜
gen.send("Hello")  # "Received: Hello" ì¶œë ¥, 2 ë°˜í™˜

# 3ë‹¨ê³„: yield from (Python 3.3, 2012ë…„)
def sub_generator():
    yield 1
    yield 2
    
def delegating_generator():
    yield from sub_generator()  # ìœ„ì„!
    yield 3
    
# 4ë‹¨ê³„: async/await (Python 3.5, 2015ë…„)
async def modern_coroutine():
    await asyncio.sleep(1)  # ì§„ì •í•œ ë¹„ë™ê¸°!
    return "Done"
```

### 2.2 asyncio ë‚´ë¶€ êµ¬ì¡° í•´ë¶€

```python
# asyncioì˜ í•µì‹¬: Taskì™€ Event Loop
import asyncio
import time
from typing import Any, Coroutine

# ê°„ë‹¨í•œ Event Loop êµ¬í˜„
class SimpleEventLoop:
    def __init__(self):
        self.ready = []  # ì‹¤í–‰ ì¤€ë¹„ëœ ì½”ë£¨í‹´
        self.sleeping = []  # ëŒ€ê¸° ì¤‘ì¸ ì½”ë£¨í‹´
        
    def call_soon(self, callback, *args):
        self.ready.append((callback, args))
        
    def call_later(self, delay, callback, *args):
        wake_time = time.time() + delay
        self.sleeping.append((wake_time, callback, args))
        
    def run_once(self):
        # sleeping íì—ì„œ ê¹¨ì–´ë‚  ì‹œê°„ì´ ëœ ê²ƒë“¤ ì´ë™
        now = time.time()
        ready_to_wake = []
        still_sleeping = []
        
        for wake_time, callback, args in self.sleeping:
            if wake_time <= now:
                ready_to_wake.append((callback, args))
            else:
                still_sleeping.append((wake_time, callback, args))
                
        self.sleeping = still_sleeping
        self.ready.extend(ready_to_wake)
        
        # ready í ì‹¤í–‰
        while self.ready:
            callback, args = self.ready.pop(0)
            callback(*args)
            
# Task êµ¬í˜„: ì½”ë£¨í‹´ì„ ê°ì‹¸ëŠ” ë˜í¼
class Task:
    def __init__(self, coro: Coroutine, loop: SimpleEventLoop):
        self.coro = coro
        self.loop = loop
        self.result = None
        self.exception = None
        self.callbacks = []
        
        # ì¦‰ì‹œ ì‹¤í–‰ ì˜ˆì•½
        self.loop.call_soon(self._step)
        
    def _step(self, value=None, exc=None):
        try:
            if exc:
                result = self.coro.throw(exc)
            else:
                result = self.coro.send(value)
        except StopIteration as e:
            # ì½”ë£¨í‹´ ì™„ë£Œ
            self.result = e.value
            for callback in self.callbacks:
                self.loop.call_soon(callback, self)
        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ
            self.exception = e
            for callback in self.callbacks:
                self.loop.call_soon(callback, self)
        else:
            # ì½”ë£¨í‹´ì´ ë¬´ì–¸ê°€ë¥¼ ê¸°ë‹¤ë¦¼
            if isinstance(result, Future):
                result.add_done_callback(self._wakeup)
            else:
                # ë‹¤ìŒ í‹±ì— ê³„ì†
                self.loop.call_soon(self._step, result)
                
    def _wakeup(self, future):
        try:
            value = future.result()
        except Exception as exc:
            self._step(None, exc)
        else:
            self._step(value, None)
```

### 2.3 ì‹¤ì œ asyncio ì„±ëŠ¥ ì¸¡ì •

```python
import asyncio
import aiohttp
import time
import threading

# ë™ê¸° ë°©ì‹: ìˆœì°¨ ì²˜ë¦¬
def sync_fetch_all(urls):
    import requests
    results = []
    for url in urls:
        response = requests.get(url)
        results.append(response.text)
    return results

# ìŠ¤ë ˆë“œ ë°©ì‹: ìŠ¤ë ˆë“œ í’€
def thread_fetch_all(urls):
    from concurrent.futures import ThreadPoolExecutor
    import requests
    
    def fetch(url):
        return requests.get(url).text
    
    with ThreadPoolExecutor(max_workers=100) as executor:
        return list(executor.map(fetch, urls))

# ë¹„ë™ê¸° ë°©ì‹: asyncio
async def async_fetch_all(urls):
    async with aiohttp.ClientSession() as session:
        tasks = []
        for url in urls:
            tasks.append(fetch_one(session, url))
        return await asyncio.gather(*tasks)

async def fetch_one(session, url):
    async with session.get(url) as response:
        return await response.text()

# ë²¤ì¹˜ë§ˆí¬
urls = ['http://httpbin.org/delay/1'] * 100  # 100ê°œ ìš”ì²­, ê° 1ì´ˆ ì§€ì—°

# ë™ê¸°: 100ì´ˆ
start = time.time()
sync_fetch_all(urls)
print(f"Sync: {time.time() - start:.2f}s")

# ìŠ¤ë ˆë“œ: 2ì´ˆ (ìŠ¤ë ˆë“œ ìƒì„± ì˜¤ë²„í—¤ë“œ)
start = time.time()
thread_fetch_all(urls)
print(f"Thread: {time.time() - start:.2f}s")

# ë¹„ë™ê¸°: 1.1ì´ˆ (ê°€ì¥ ë¹ ë¦„!)
start = time.time()
asyncio.run(async_fetch_all(urls))
print(f"Async: {time.time() - start:.2f}s")

# ë©”ëª¨ë¦¬ ë¹„êµ
import tracemalloc

# ìŠ¤ë ˆë“œ ë°©ì‹ ë©”ëª¨ë¦¬
tracemalloc.start()
thread_fetch_all(urls[:10])
current, peak = tracemalloc.get_traced_memory()
print(f"Thread memory: {peak / 1024 / 1024:.2f} MB")
tracemalloc.stop()

# ë¹„ë™ê¸° ë°©ì‹ ë©”ëª¨ë¦¬
tracemalloc.start()
asyncio.run(async_fetch_all(urls[:10]))
current, peak = tracemalloc.get_traced_memory()
print(f"Async memory: {peak / 1024 / 1024:.2f} MB")
tracemalloc.stop()

# ê²°ê³¼:
# Thread memory: 15.3 MB
# Async memory: 3.2 MB (5ë°° íš¨ìœ¨ì !)
```

## 3. Goì˜ Goroutine: ì—”ì§€ë‹ˆì–´ë§ì˜ ì •ìˆ˜

### 3.1 GPM ëª¨ë¸ì˜ ì„¸ë°€í•œ ë™ì‘

Goì˜ ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ì •ë§ ì•„ë¦„ë‹¤ìš´ ì„¤ê³„ì…ë‹ˆë‹¤:

```go
// runtime/runtime2.goì˜ ì‹¤ì œ êµ¬ì¡°ì²´ë“¤
type g struct {
    stack       stack   // ìŠ¤íƒ ì •ë³´
    stackguard0 uintptr // ìŠ¤íƒ ì˜¤ë²„í”Œë¡œìš° ì²´í¬
    stackguard1 uintptr // C ìŠ¤íƒ ê°€ë“œ
    
    m         *m      // í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ M
    sched     gobuf   // ì»¨í…ìŠ¤íŠ¸ ì €ì¥
    atomicstatus atomic.Uint32
    goid      uint64  // goroutine ID
    
    // ë””ë²„ê¹…/í”„ë¡œíŒŒì¼ë§
    startpc     uintptr // goroutine ì‹œì‘ PC
    racectx     uintptr // race detector context
    waiting     *sudog  // ëŒ€ê¸° ì¤‘ì¸ ì±„ë„
}

type gobuf struct {
    sp   uintptr  // ìŠ¤íƒ í¬ì¸í„°
    pc   uintptr  // í”„ë¡œê·¸ë¨ ì¹´ìš´í„°
    g    guintptr // g í¬ì¸í„°
    ctxt unsafe.Pointer
    ret  uintptr  // ë°˜í™˜ê°’
    lr   uintptr  // link register (ARM)
    bp   uintptr  // base pointer (x86)
}

type m struct {
    g0      *g     // ìŠ¤ì¼€ì¤„ë§ìš© goroutine
    curg    *g     // í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ G
    p       puintptr // ì—°ê²°ëœ P
    nextp   puintptr
    oldp    puintptr
    
    // ì‹œìŠ¤í…œ ìŠ¤ë ˆë“œ ì •ë³´
    thread  uintptr // ìŠ¤ë ˆë“œ í•¸ë“¤
    
    // ìŠ¤í”¼ë‹ ìƒíƒœ
    spinning bool
    blocked  bool
    
    // ì‹œê·¸ë„ ì²˜ë¦¬
    gsignal *g
    
    // ìºì‹œ
    mcache *mcache
}

type p struct {
    id      int32
    status  uint32
    
    m       muintptr // ì—°ê²°ëœ M
    mcache  *mcache
    
    // ë¡œì»¬ ì‹¤í–‰ í
    runqhead uint32
    runqtail uint32
    runq     [256]guintptr
    
    // ê¸€ë¡œë²Œ íì—ì„œ ê°€ì ¸ì˜¨ G ê°œìˆ˜
    schedtick   uint32
    syscalltick uint32
    
    // GC ê´€ë ¨
    gcAssistTime int64
}
```

### 3.2 Goroutine ìŠ¤íƒ ê´€ë¦¬: Contiguous Stack

GoëŠ” ì´ˆê¸°ì— segmented stackì„ ì‚¬ìš©í–ˆì§€ë§Œ, hot split ë¬¸ì œë¡œ contiguous stackìœ¼ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤:

```go
// ìŠ¤íƒ ì¦ê°€ ë©”ì»¤ë‹ˆì¦˜
func growstack() {
    gp := getg()
    
    // í˜„ì¬ ìŠ¤íƒ í¬ê¸°
    oldsize := gp.stack.hi - gp.stack.lo
    newsize := oldsize * 2
    
    // ìµœëŒ€ 1GBê¹Œì§€ ì¦ê°€ ê°€ëŠ¥
    if newsize > maxstacksize {
        throw("stack overflow")
    }
    
    // ìƒˆ ìŠ¤íƒ í• ë‹¹
    newstack := stackalloc(uint32(newsize))
    
    // ê¸°ì¡´ ìŠ¤íƒ ë‚´ìš© ë³µì‚¬
    memmove(newstack.hi-oldsize, gp.stack.lo, oldsize)
    
    // í¬ì¸í„° ì¡°ì • (ìŠ¤íƒ ë‚´ë¶€ í¬ì¸í„°ë“¤)
    adjustpointers(&gp.sched, &adjinfo{
        old: gp.stack,
        new: newstack,
    })
    
    // ì´ì „ ìŠ¤íƒ í•´ì œ
    stackfree(gp.stack)
    
    // ìƒˆ ìŠ¤íƒ ì„¤ì •
    gp.stack = newstack
    gp.stackguard0 = newstack.lo + _StackGuard
}

// ìŠ¤íƒ í”„ë¦¬ì— í”„ì…˜ (Go 1.14+)
func stackPreempt() {
    // ë¹„ë™ê¸° í”„ë¦¬ì— í”„ì…˜ì„ ìœ„í•œ ì‹œê·¸ë„
    const preemptMark = uintptr(0xfffffade)
    
    gp := getg()
    gp.stackguard0 = preemptMark
    
    // ë‹¤ìŒ í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ìŠ¤íƒ ì²´í¬ì—ì„œ ê±¸ë¦¼
    // -> preemption ì²˜ë¦¬
}
```

### 3.3 Channelì˜ ë‚´ë¶€ êµ¬í˜„

Channelì€ Go ë™ì‹œì„±ì˜ í•µì‹¬ì…ë‹ˆë‹¤:

```go
// runtime/chan.go
type hchan struct {
    qcount   uint      // íì— ìˆëŠ” ë°ì´í„° ê°œìˆ˜
    dataqsiz uint      // ë²„í¼ í¬ê¸°
    buf      unsafe.Pointer // ë²„í¼
    elemsize uint16
    closed   uint32
    elemtype *_type
    
    sendx    uint   // send ì¸ë±ìŠ¤
    recvx    uint   // receive ì¸ë±ìŠ¤
    
    recvq    waitq  // receive ëŒ€ê¸° goroutine
    sendq    waitq  // send ëŒ€ê¸° goroutine
    
    lock mutex
}

// ì‹¤ì œ send êµ¬í˜„
func chansend(c *hchan, ep unsafe.Pointer, block bool) bool {
    lock(&c.lock)
    
    // 1. ëŒ€ê¸° ì¤‘ì¸ receiverê°€ ìˆìœ¼ë©´ ì§ì ‘ ì „ë‹¬
    if sg := c.recvq.dequeue(); sg != nil {
        send(c, sg, ep, func() { unlock(&c.lock) })
        return true
    }
    
    // 2. ë²„í¼ì— ê³µê°„ì´ ìˆìœ¼ë©´ ë²„í¼ì— ì €ì¥
    if c.qcount < c.dataqsiz {
        qp := chanbuf(c, c.sendx)
        typedmemmove(c.elemtype, qp, ep)
        c.sendx++
        if c.sendx == c.dataqsiz {
            c.sendx = 0
        }
        c.qcount++
        unlock(&c.lock)
        return true
    }
    
    // 3. ë¸”ë¡œí‚¹ ëª¨ë“œ: í˜„ì¬ goroutineì„ ëŒ€ê¸° íì— ì¶”ê°€
    if block {
        gp := getg()
        mysg := acquireSudog()
        mysg.g = gp
        mysg.elem = ep
        c.sendq.enqueue(mysg)
        
        // goroutineì„ park (ëŒ€ê¸° ìƒíƒœë¡œ)
        gopark(chanparkcommit, unsafe.Pointer(&c.lock))
        
        // ê¹¨ì–´ë‚¬ì„ ë•Œ
        releaseSudog(mysg)
        return true
    }
    
    // 4. ë…¼ë¸”ë¡œí‚¹ ëª¨ë“œ: false ë°˜í™˜
    unlock(&c.lock)
    return false
}
```

### 3.4 ì‹¤ì „ Goroutine íŒ¨í„´

```go
// 1. Worker Pool íŒ¨í„´
type Job struct {
    ID   int
    Data []byte
}

type Result struct {
    JobID int
    Output []byte
    Error error
}

func WorkerPool(jobs <-chan Job, results chan<- Result, workers int) {
    var wg sync.WaitGroup
    
    // Worker goroutines ìƒì„±
    for i := 0; i < workers; i++ {
        wg.Add(1)
        go func(workerID int) {
            defer wg.Done()
            
            for job := range jobs {
                start := time.Now()
                
                // ì‹¤ì œ ì‘ì—…
                output, err := processJob(job.Data)
                
                results <- Result{
                    JobID: job.ID,
                    Output: output,
                    Error: err,
                }
                
                log.Printf("Worker %d: Job %d took %v",
                    workerID, job.ID, time.Since(start))
            }
        }(i)
    }
    
    // ëª¨ë“  worker ì¢…ë£Œ ëŒ€ê¸°
    go func() {
        wg.Wait()
        close(results)
    }()
}

// 2. Fan-out/Fan-in íŒ¨í„´
func FanOutFanIn(input <-chan int) <-chan int {
    // Fan-out: ì—¬ëŸ¬ goroutineì— ì‘ì—… ë¶„ë°°
    c1 := process(input)
    c2 := process(input)
    c3 := process(input)
    
    // Fan-in: ê²°ê³¼ ìˆ˜ì§‘
    return merge(c1, c2, c3)
}

func process(input <-chan int) <-chan int {
    output := make(chan int)
    go func() {
        for n := range input {
            output <- n * n  // CPU ì§‘ì•½ì  ì‘ì—…
        }
        close(output)
    }()
    return output
}

func merge(channels ...<-chan int) <-chan int {
    out := make(chan int)
    var wg sync.WaitGroup
    
    for _, c := range channels {
        wg.Add(1)
        go func(ch <-chan int) {
            defer wg.Done()
            for n := range ch {
                out <- n
            }
        }(c)
    }
    
    go func() {
        wg.Wait()
        close(out)
    }()
    
    return out
}

// 3. Timeoutê³¼ Context íŒ¨í„´
func TimeoutOperation(ctx context.Context) error {
    resultCh := make(chan string, 1)
    
    go func() {
        // ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…
        time.Sleep(5 * time.Second)
        resultCh <- "completed"
    }()
    
    select {
    case result := <-resultCh:
        fmt.Println("Result:", result)
        return nil
        
    case <-ctx.Done():
        return ctx.Err()  // timeout or cancellation
        
    case <-time.After(3 * time.Second):
        return fmt.Errorf("operation timeout")
    }
}
```

## 4. Java Virtual Threads: Project Loomì˜ í˜ëª…

### 4.1 Continuation: ë§ˆë²•ì˜ í•µì‹¬

Java 19ì—ì„œ ë„ì…ëœ Virtual ThreadëŠ” Continuation ê¸°ë°˜ì…ë‹ˆë‹¤:

```java
// Continuationì˜ ê°œë…ì  êµ¬í˜„
public class Continuation {
    private final Runnable task;
    private Stack stack;  // ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸
    private boolean done;
    
    public Continuation(Runnable task) {
        this.task = task;
        this.stack = new Stack();
    }
    
    public void run() {
        if (done) return;
        
        // í˜„ì¬ ìŠ¤íƒ ì €ì¥
        Stack oldStack = Thread.currentStack();
        Thread.setStack(this.stack);
        
        try {
            task.run();
            done = true;
        } catch (YieldException e) {
            // yield í˜¸ì¶œ - ìŠ¤íƒ ì €ì¥í•˜ê³  ë°˜í™˜
            this.stack = Thread.currentStack();
        } finally {
            Thread.setStack(oldStack);
        }
    }
    
    public static void yield() {
        throw new YieldException();
    }
}

// Virtual Thread êµ¬í˜„
public class VirtualThread extends Thread {
    private static final ForkJoinPool SCHEDULER = 
        ForkJoinPool.commonPool();
    
    private final Continuation continuation;
    private volatile int state;
    
    public VirtualThread(Runnable task) {
        this.continuation = new Continuation(task);
    }
    
    @Override
    public void start() {
        SCHEDULER.execute(this::run);
    }
    
    @Override
    public void run() {
        while (!continuation.isDone()) {
            continuation.run();
            
            if (!continuation.isDone()) {
                // Parking or I/O - yield to scheduler
                park();
            }
        }
    }
    
    private void park() {
        state = PARKED;
        // Schedulerê°€ ë‹¤ë¥¸ VirtualThread ì‹¤í–‰
        LockSupport.park(this);
    }
    
    public void unpark() {
        state = RUNNABLE;
        SCHEDULER.execute(this::run);
    }
}
```

### 4.2 Virtual Thread vs Platform Thread ì„±ëŠ¥ ë¹„êµ

```java
import java.util.concurrent.*;
import java.time.Duration;
import java.time.Instant;

public class ThreadComparison {
    static final int NUM_TASKS = 100_000;
    
    // Platform Thread (ê¸°ì¡´ ìŠ¤ë ˆë“œ)
    public static void platformThreadTest() throws Exception {
        ExecutorService executor = 
            Executors.newFixedThreadPool(200);
        
        Instant start = Instant.now();
        CountDownLatch latch = new CountDownLatch(NUM_TASKS);
        
        for (int i = 0; i < NUM_TASKS; i++) {
            executor.submit(() -> {
                try {
                    Thread.sleep(100);  // I/O ì‹œë®¬ë ˆì´ì…˜
                    latch.countDown();
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            });
        }
        
        latch.await();
        Duration elapsed = Duration.between(start, Instant.now());
        
        System.out.println("Platform Threads:");
        System.out.println("Time: " + elapsed.toMillis() + "ms");
        System.out.println("Memory: " + 
            (Runtime.getRuntime().totalMemory() / 1024 / 1024) + "MB");
        
        executor.shutdown();
    }
    
    // Virtual Thread
    public static void virtualThreadTest() throws Exception {
        Instant start = Instant.now();
        
        try (var executor = Executors.newVirtualThreadPerTaskExecutor()) {
            CountDownLatch latch = new CountDownLatch(NUM_TASKS);
            
            for (int i = 0; i < NUM_TASKS; i++) {
                executor.submit(() -> {
                    try {
                        Thread.sleep(100);  // I/O ì‹œë®¬ë ˆì´ì…˜
                        latch.countDown();
                    } catch (InterruptedException e) {
                        Thread.currentThread().interrupt();
                    }
                });
            }
            
            latch.await();
        }
        
        Duration elapsed = Duration.between(start, Instant.now());
        
        System.out.println("Virtual Threads:");
        System.out.println("Time: " + elapsed.toMillis() + "ms");
        System.out.println("Memory: " + 
            (Runtime.getRuntime().totalMemory() / 1024 / 1024) + "MB");
    }
    
    public static void main(String[] args) throws Exception {
        // Warm up
        virtualThreadTest();
        platformThreadTest();
        
        System.gc();
        Thread.sleep(1000);
        
        // Actual test
        System.out.println("\n=== Performance Test ===");
        platformThreadTest();
        // ê²°ê³¼: Time: 50000ms, Memory: 800MB
        
        System.gc();
        Thread.sleep(1000);
        
        virtualThreadTest();
        // ê²°ê³¼: Time: 150ms, Memory: 150MB
        
        // Virtual Threadê°€ 300ë°° ë¹ ë¥´ê³  5ë°° ë©”ëª¨ë¦¬ íš¨ìœ¨ì !
    }
}
```

### 4.3 Pinning ë¬¸ì œì™€ í•´ê²°

Virtual Threadì˜ í•œê³„ì™€ í•´ê²°ì±…:

```java
// Pinning ë¬¸ì œ: synchronized ë¸”ë¡
public class PinningProblem {
    private static final Object lock = new Object();
    
    // ë¬¸ì œ: synchronizedëŠ” carrier threadë¥¼ pin
    public void problematicMethod() {
        synchronized (lock) {
            try {
                Thread.sleep(100);  // Carrier thread blocked!
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }
    }
    
    // í•´ê²°ì±… 1: ReentrantLock ì‚¬ìš©
    private final ReentrantLock reentrantLock = new ReentrantLock();
    
    public void betterMethod() {
        reentrantLock.lock();
        try {
            Thread.sleep(100);  // Virtual threadë§Œ block
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        } finally {
            reentrantLock.unlock();
        }
    }
    
    // í•´ê²°ì±… 2: Semaphore ì‚¬ìš©
    private final Semaphore semaphore = new Semaphore(1);
    
    public void alternativeMethod() throws InterruptedException {
        semaphore.acquire();
        try {
            Thread.sleep(100);
        } finally {
            semaphore.release();
        }
    }
    
    // Pinning ê°ì§€
    public static void detectPinning() {
        // JVM ì˜µì…˜: -Djdk.tracePinnedThreads=full
        System.setProperty("jdk.tracePinnedThreads", "full");
        
        Thread.startVirtualThread(() -> {
            synchronized (lock) {
                try {
                    Thread.sleep(100);
                    // ì½˜ì†”ì— pinning ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥ë¨
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            }
        });
    }
}
```

## 5. ë©”ëª¨ë¦¬ ëª¨ë¸ê³¼ ë™ê¸°í™”

### 5.1 Happens-Before ê´€ê³„ ì´í•´í•˜ê¸°

```java
// Java Memory Model ì˜ˆì œ
public class HappensBeforeExample {
    private volatile boolean flag = false;
    private int value = 0;
    
    // Thread 1
    public void writer() {
        value = 42;        // 1
        flag = true;       // 2 (volatile write)
    }
    
    // Thread 2
    public void reader() {
        if (flag) {        // 3 (volatile read)
            // valueëŠ” ë°˜ë“œì‹œ 42
            assert value == 42;  // 4
        }
    }
    
    // Happens-before ê´€ê³„:
    // 1 happens-before 2 (program order)
    // 2 happens-before 3 (volatile)
    // 3 happens-before 4 (program order)
    // ë”°ë¼ì„œ: 1 happens-before 4 (transitivity)
}

// Goì˜ Memory Model
func GoMemoryModel() {
    var x, y int
    var wg sync.WaitGroup
    
    wg.Add(2)
    
    // Goroutine 1
    go func() {
        x = 1
        // Channel sendëŠ” happens-before ë³´ì¥
        ch <- true
        wg.Done()
    }()
    
    // Goroutine 2
    go func() {
        <-ch  // Channel receive
        // xëŠ” ë°˜ë“œì‹œ 1
        fmt.Println(x)
        wg.Done()
    }()
    
    wg.Wait()
}
```

### 5.2 Lock-Free ìë£Œêµ¬ì¡°

```go
// Lock-free Stack êµ¬í˜„
type LockFreeStack struct {
    head atomic.Pointer[Node]
}

type Node struct {
    value interface{}
    next  *Node
}

func (s *LockFreeStack) Push(value interface{}) {
    newNode := &Node{value: value}
    
    for {
        oldHead := s.head.Load()
        newNode.next = oldHead
        
        // CAS (Compare-And-Swap)
        if s.head.CompareAndSwap(oldHead, newNode) {
            return
        }
        // ì‹¤íŒ¨í•˜ë©´ ì¬ì‹œë„
    }
}

func (s *LockFreeStack) Pop() (interface{}, bool) {
    for {
        oldHead := s.head.Load()
        if oldHead == nil {
            return nil, false
        }
        
        newHead := oldHead.next
        
        if s.head.CompareAndSwap(oldHead, newHead) {
            return oldHead.value, true
        }
        // ì‹¤íŒ¨í•˜ë©´ ì¬ì‹œë„
    }
}

// ì„±ëŠ¥ ë¹„êµ
func BenchmarkStacks() {
    const numGoroutines = 1000
    const numOperations = 10000
    
    // Mutex ê¸°ë°˜ ìŠ¤íƒ
    mutexStack := &MutexStack{}
    start := time.Now()
    
    var wg sync.WaitGroup
    for i := 0; i < numGoroutines; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for j := 0; j < numOperations; j++ {
                mutexStack.Push(j)
                mutexStack.Pop()
            }
        }()
    }
    wg.Wait()
    
    mutexTime := time.Since(start)
    
    // Lock-free ìŠ¤íƒ
    lockFreeStack := &LockFreeStack{}
    start = time.Now()
    
    for i := 0; i < numGoroutines; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for j := 0; j < numOperations; j++ {
                lockFreeStack.Push(j)
                lockFreeStack.Pop()
            }
        }()
    }
    wg.Wait()
    
    lockFreeTime := time.Since(start)
    
    fmt.Printf("Mutex Stack: %v\n", mutexTime)
    fmt.Printf("Lock-free Stack: %v\n", lockFreeTime)
    fmt.Printf("Improvement: %.2fx\n", 
        float64(mutexTime)/float64(lockFreeTime))
    
    // ê²°ê³¼:
    // Mutex Stack: 5.2s
    // Lock-free Stack: 1.8s
    // Improvement: 2.89x
}
```

## 6. ì‹¤ì „ ë””ë²„ê¹…ê³¼ í”„ë¡œíŒŒì¼ë§

### 6.1 Goroutine Leak íƒì§€

```go
// Goroutine ëˆ„ìˆ˜ ê°ì§€
func DetectGoroutineLeak() {
    // ì‹œì‘ ì‹œì  goroutine ìˆ˜
    startGoroutines := runtime.NumGoroutine()
    
    // ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬
    ticker := time.NewTicker(10 * time.Second)
    defer ticker.Stop()
    
    for range ticker.C {
        current := runtime.NumGoroutine()
        
        if current > startGoroutines*2 {
            fmt.Printf("Potential goroutine leak: %d goroutines\n", 
                current)
            
            // ìŠ¤íƒ ë¤í”„
            buf := make([]byte, 1<<20)
            stackSize := runtime.Stack(buf, true)
            fmt.Printf("Stack dump:\n%s\n", buf[:stackSize])
        }
    }
}

// ì¼ë°˜ì ì¸ Goroutine ëˆ„ìˆ˜ íŒ¨í„´
func LeakyPattern() {
    // íŒ¨í„´ 1: ë‹«íˆì§€ ì•ŠëŠ” ì±„ë„
    ch := make(chan int)
    go func() {
        for v := range ch {  // chê°€ ë‹«íˆì§€ ì•Šìœ¼ë©´ ì˜ì›íˆ ëŒ€ê¸°
            fmt.Println(v)
        }
    }()
    // í•´ê²°: defer close(ch)
    
    // íŒ¨í„´ 2: ë¬´í•œ ëŒ€ê¸°
    done := make(chan bool)
    go func() {
        <-done  // doneì— ê°’ì´ ì•ˆ ì˜¤ë©´ ì˜ì›íˆ ëŒ€ê¸°
    }()
    // í•´ê²°: select with timeout
    
    // íŒ¨í„´ 3: ì˜ëª»ëœ WaitGroup ì‚¬ìš©
    var wg sync.WaitGroup
    wg.Add(1)
    go func() {
        // wg.Done() í˜¸ì¶œ ëˆ„ë½!
    }()
    wg.Wait()  // ì˜ì›íˆ ëŒ€ê¸°
}
```

### 6.2 Python asyncio ë””ë²„ê¹…

```python
import asyncio
import logging
import functools
import time

# asyncio ë””ë²„ê¹… ëª¨ë“œ í™œì„±í™”
asyncio.set_debug(True)
logging.basicConfig(level=logging.DEBUG)

# ëŠë¦° ì½”ë£¨í‹´ ê°ì§€
def slow_callback_detector(loop):
    def wrapper(callback):
        @functools.wraps(callback)
        def wrapped(*args, **kwargs):
            start = time.time()
            result = callback(*args, **kwargs)
            duration = time.time() - start
            
            if duration > 0.1:  # 100ms ì´ìƒ
                logging.warning(
                    f"Slow callback {callback.__name__}: {duration:.3f}s"
                )
            
            return result
        return wrapped
    
    # ëª¨ë“  ì½œë°± ë˜í•‘
    original_call_soon = loop.call_soon
    
    def patched_call_soon(callback, *args):
        return original_call_soon(wrapper(callback), *args)
    
    loop.call_soon = patched_call_soon

# Task ì¶”ì 
class TaskTracker:
    def __init__(self):
        self.tasks = set()
        
    def create_task(self, coro, name=None):
        task = asyncio.create_task(coro, name=name)
        self.tasks.add(task)
        task.add_done_callback(self.tasks.discard)
        return task
    
    def report(self):
        for task in self.tasks:
            if not task.done():
                print(f"Pending task: {task.get_name()}")
                print(f"Stack: {task.get_stack()}")

# ì‚¬ìš© ì˜ˆ
async def main():
    tracker = TaskTracker()
    
    # ì˜ë„ì ìœ¼ë¡œ ì™„ë£Œë˜ì§€ ì•ŠëŠ” íƒœìŠ¤í¬
    tracker.create_task(
        asyncio.sleep(3600), 
        name="long_running_task"
    )
    
    await asyncio.sleep(1)
    tracker.report()
    
    # ì¶œë ¥:
    # Pending task: long_running_task
    # Stack: [<frame object at 0x...>]
```

## 7. ì„±ëŠ¥ ìµœì í™” ì „ëµ

### 7.1 ì½”ë£¨í‹´ í’€ êµ¬í˜„

```python
# Python asyncio ì½”ë£¨í‹´ í’€
class CoroutinePool:
    def __init__(self, max_workers=100):
        self.semaphore = asyncio.Semaphore(max_workers)
        self.tasks = set()
        
    async def submit(self, coro):
        async with self.semaphore:
            task = asyncio.create_task(coro)
            self.tasks.add(task)
            try:
                return await task
            finally:
                self.tasks.discard(task)
    
    async def map(self, func, iterable):
        tasks = [self.submit(func(item)) for item in iterable]
        return await asyncio.gather(*tasks)
    
    async def shutdown(self):
        # ëª¨ë“  íƒœìŠ¤í¬ ì·¨ì†Œ
        for task in self.tasks:
            task.cancel()
        
        # ì™„ë£Œ ëŒ€ê¸°
        await asyncio.gather(*self.tasks, return_exceptions=True)

# ì‚¬ìš© ì˜ˆ
async def process_item(item):
    await asyncio.sleep(0.1)  # I/O ì‘ì—…
    return item * 2

async def main():
    pool = CoroutinePool(max_workers=50)
    
    # 1000ê°œ ì•„ì´í…œ ì²˜ë¦¬
    items = range(1000)
    results = await pool.map(process_item, items)
    
    await pool.shutdown()
```

### 7.2 Hybrid ì ‘ê·¼: CPU + I/O ìµœì í™”

```python
import asyncio
from concurrent.futures import ProcessPoolExecutor
import numpy as np

class HybridExecutor:
    def __init__(self, max_processes=4, max_coroutines=100):
        self.process_pool = ProcessPoolExecutor(max_processes)
        self.semaphore = asyncio.Semaphore(max_coroutines)
        
    async def run_cpu_bound(self, func, *args):
        """CPU ì§‘ì•½ì  ì‘ì—…ì€ í”„ë¡œì„¸ìŠ¤ í’€ì—ì„œ"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.process_pool, func, *args
        )
    
    async def run_io_bound(self, coro):
        """I/O ì‘ì—…ì€ ì½”ë£¨í‹´ìœ¼ë¡œ"""
        async with self.semaphore:
            return await coro
    
    async def process_data(self, data):
        # 1. I/O: ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        raw_data = await self.run_io_bound(
            fetch_data(data['url'])
        )
        
        # 2. CPU: ë°ì´í„° ì²˜ë¦¬
        processed = await self.run_cpu_bound(
            heavy_computation, raw_data
        )
        
        # 3. I/O: ê²°ê³¼ ì €ì¥
        await self.run_io_bound(
            save_result(processed)
        )
        
        return processed

# CPU ì§‘ì•½ì  ì‘ì—…
def heavy_computation(data):
    # NumPy ì—°ì‚°
    array = np.array(data)
    result = np.fft.fft(array)  # FFT ë³€í™˜
    return result.tolist()

# ë²¤ì¹˜ë§ˆí¬
async def benchmark():
    executor = HybridExecutor()
    
    # 100ê°œ ì‘ì—…
    tasks = []
    for i in range(100):
        data = {'url': f'http://api.example.com/data/{i}'}
        tasks.append(executor.process_data(data))
    
    start = time.time()
    results = await asyncio.gather(*tasks)
    elapsed = time.time() - start
    
    print(f"Processed {len(results)} items in {elapsed:.2f}s")
    print(f"Throughput: {len(results)/elapsed:.2f} items/s")
```

## 8. ë§ˆë¬´ë¦¬: ì½”ë£¨í‹´ì˜ ë¯¸ë˜

ì½”ë£¨í‹´ê³¼ Green ThreadëŠ” ë‹¨ìˆœí•œ ê¸°ìˆ ì´ ì•„ë‹™ë‹ˆë‹¤. ê·¸ê²ƒì€:

1. **íš¨ìœ¨ì„±ì˜ ê·¹ëŒ€í™”**: í•˜ë“œì›¨ì–´ ìì›ì„ ìµœëŒ€í•œ í™œìš©
2. **ë‹¨ìˆœì„±ì˜ ì¶”êµ¬**: ë™ê¸° ì½”ë“œì²˜ëŸ¼ ë³´ì´ëŠ” ë¹„ë™ê¸° ì½”ë“œ
3. **í™•ì¥ì„±ì˜ ë³´ì¥**: ìˆ˜ë°±ë§Œ ê°œì˜ ë™ì‹œ ì‘ì—… ì²˜ë¦¬
4. **ë¯¸ë˜ì˜ ì¤€ë¹„**: í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ì‹œëŒ€ì˜ í•„ìˆ˜ ê¸°ìˆ 

ì œê°€ ê²½í—˜í•œ ê°€ì¥ ì¸ìƒì ì¸ ì‚¬ë¡€:

> 2022ë…„, ì‹¤ì‹œê°„ ì£¼ì‹ ê±°ë˜ ì‹œìŠ¤í…œì„ Goë¡œ ì¬ì‘ì„±í–ˆìŠµë‹ˆë‹¤.
> - ê¸°ì¡´ Java ìŠ¤ë ˆë“œ í’€: 10,000 ë™ì‹œ ì—°ê²°, 16GB RAM
> - Go goroutine: 500,000 ë™ì‹œ ì—°ê²°, 4GB RAM
> - ë ˆì´í„´ì‹œ: 100ms â†’ 5ms
> - ë¹„ìš©: ì›” $5,000 â†’ $800

**í•µì‹¬ êµí›ˆ:**
- ì½”ë£¨í‹´ì€ I/O bound ì‘ì—…ì— ìµœì 
- CPU boundëŠ” ì—¬ì „íˆ ë©€í‹°í”„ë¡œì„¸ì‹± í•„ìš”
- ì–¸ì–´ë³„ íŠ¹ì„±ì„ ì´í•´í•˜ê³  ì ì ˆíˆ ì„ íƒ
- í”„ë¡œíŒŒì¼ë§ê³¼ ëª¨ë‹ˆí„°ë§ì€ í•„ìˆ˜

ë‹¤ìŒ ì±•í„°ì—ì„œëŠ” ì´ëŸ° ë¹„ë™ê¸° ì‹œìŠ¤í…œì„ ë¶„ì‚° í™˜ê²½ìœ¼ë¡œ í™•ì¥í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤. Saga íŒ¨í„´, Event Sourcing, CQRS ë“± ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì‹œëŒ€ì˜ í•„ìˆ˜ íŒ¨í„´ë“¤ì„ ê¹Šì´ ìˆê²Œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤!

## ì°¸ê³  ìë£Œ

- [Go: GPM Model Design Doc](https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw)
- [Python: PEP 492 - Coroutines with async and await](https://www.python.org/dev/peps/pep-0492/)
- [Java: JEP 425 - Virtual Threads](https://openjdk.org/jeps/425)
- [Continuation Passing Style](https://en.wikipedia.org/wiki/Continuation-passing_style)
- [The Problem with Threads](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2006/EECS-2006-1.pdf) - Edward A. Lee