---
tags:
  - DistributedSystems
  - Async
  - Microservices
  - EventSourcing
  - Saga
---

# Chapter 8-4: ë¶„ì‚° ì‹œìŠ¤í…œì˜ ë¹„ë™ê¸° íŒ¨í„´

## ğŸ¯ ì´ ë¬¸ì„œë¥¼ ì½ê³  ë‚˜ë©´ ì–»ì„ ìˆ˜ ìˆëŠ” ê²ƒë“¤

ì´ ë¬¸ì„œë¥¼ ì™„ë…í•˜ë©´ ì—¬ëŸ¬ë¶„ì€:

1. **"ë¶„ì‚° íŠ¸ëœì­ì…˜ ì—†ì´ ì–´ë–»ê²Œ ì¼ê´€ì„±ì„ ë³´ì¥í•˜ì£ ?"** - Saga íŒ¨í„´ìœ¼ë¡œ eventual consistencyë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
2. **"ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°„ í†µì‹ ì´ ë„ˆë¬´ ë³µì¡í•´ìš”"** - Event-driven architectureë¡œ ëŠìŠ¨í•œ ê²°í•©ì„ ë‹¬ì„±í•©ë‹ˆë‹¤
3. **"ë©”ì‹œì§€ê°€ ì¤‘ë³µ ì²˜ë¦¬ë˜ë©´ ì–´ë–»ê²Œ í•˜ì£ ?"** - Idempotencyì™€ exactly-once deliveryë¥¼ ë³´ì¥í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤
4. **"ì„œë¹„ìŠ¤ í•˜ë‚˜ê°€ ì£½ìœ¼ë©´ ì „ì²´ê°€ ë©ˆì¶°ìš”"** - Circuit breakerì™€ bulkheadë¡œ ì¥ì• ë¥¼ ê²©ë¦¬í•©ë‹ˆë‹¤

## 1. ë¶„ì‚° íŠ¸ëœì­ì…˜ì˜ ë”œë ˆë§ˆ: 2PCì˜ ëª°ë½ê³¼ Sagaì˜ ë¶€ìƒ

### 1.1 Two-Phase Commitì˜ ë¹„ê·¹ì  í•œê³„

ì œê°€ 2015ë…„ì— ì€í–‰ ì‹œìŠ¤í…œì„ ê°œë°œí•  ë•Œ, 2PC(Two-Phase Commit)ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ”? ëŒ€ì°¸ì‚¬ì˜€ì£ .

```java
// ì „í†µì ì¸ 2PC êµ¬í˜„ (ë¬¸ì œíˆ¬ì„±ì´)
public class TwoPhaseCommitCoordinator {
    private List<XAResource> resources = new ArrayList<>();
    
    public void executeTransaction() throws Exception {
        // Phase 1: Prepare (íˆ¬í‘œ)
        for (XAResource resource : resources) {
            try {
                resource.prepare();  // ê° ì°¸ì—¬ìì—ê²Œ ì¤€ë¹„ ìš”ì²­
            } catch (Exception e) {
                // í•œ ëª…ì´ë¼ë„ ì‹¤íŒ¨í•˜ë©´ ì „ì²´ ë¡¤ë°±
                rollbackAll();
                throw e;
            }
        }
        
        // Phase 2: Commit (í™•ì •)
        for (XAResource resource : resources) {
            resource.commit();  // ëª¨ë‘ ì»¤ë°‹
        }
    }
    
    // ë¬¸ì œì ë“¤:
    // 1. Coordinatorê°€ ì£½ìœ¼ë©´? -> ì „ì²´ ë¸”ë¡œí‚¹
    // 2. ë„¤íŠ¸ì›Œí¬ íŒŒí‹°ì…˜? -> ë¬´í•œ ëŒ€ê¸°
    // 3. ì„±ëŠ¥? -> ê°€ì¥ ëŠë¦° ë…¸ë“œì— ë§ì¶°ì§
    // 4. í™•ì¥ì„±? -> ì°¸ì—¬ì ì¦ê°€ = ì§€ìˆ˜ì  ì„±ëŠ¥ ì €í•˜
}

// ì‹¤ì œ ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤
/*
ì‹œê°„    Coordinator    Service A    Service B    Service C
00:00   Prepare -----> Ready
00:01   Prepare ----------------> Ready
00:02   Prepare --------------------------> Ready
00:03   Commit ------> OK
00:04   Commit -----------------> OK
00:05   ğŸ’¥ CRASH!
00:06                                          ??? (ë¬´í•œ ëŒ€ê¸°)

Service CëŠ” ì˜ì›íˆ ë½ ìƒíƒœ... ğŸ˜±
*/
```text

### 1.2 Saga íŒ¨í„´: ê¸´ ì—¬ì •ì˜ ì§€í˜œ

SagaëŠ” 1987ë…„ ë…¼ë¬¸ì—ì„œ ì‹œì‘ë˜ì—ˆì§€ë§Œ, ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì‹œëŒ€ì— ì¬ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:

```typescript
// Choreography ë°©ì‹ Saga
interface SagaStep<T> {
    execute(context: T): Promise<void>;
    compensate(context: T): Promise<void>;
}

// ì£¼ë¬¸ ì²˜ë¦¬ Saga
class OrderSaga {
    private steps: SagaStep<OrderContext>[] = [
        new ReserveInventoryStep(),
        new ChargePaymentStep(),
        new CreateShipmentStep(),
        new SendNotificationStep()
    ];
    
    async execute(order: Order): Promise<void> {
        const context = new OrderContext(order);
        const executedSteps: SagaStep<OrderContext>[] = [];
        
        try {
            for (const step of this.steps) {
                await step.execute(context);
                executedSteps.push(step);
                
                // ê° ë‹¨ê³„ë§ˆë‹¤ ì´ë²¤íŠ¸ ë°œí–‰
                await this.publishEvent({
                    type: `${step.constructor.name}.Completed`,
                    orderId: order.id,
                    timestamp: Date.now()
                });
            }
        } catch (error) {
            // ë³´ìƒ íŠ¸ëœì­ì…˜ ì‹¤í–‰ (ì—­ìˆœ)
            console.error(`Saga failed at step ${executedSteps.length}`);
            
            for (const step of executedSteps.reverse()) {
                try {
                    await step.compensate(context);
                    
                    await this.publishEvent({
                        type: `${step.constructor.name}.Compensated`,
                        orderId: order.id,
                        timestamp: Date.now()
                    });
                } catch (compensationError) {
                    // ë³´ìƒë„ ì‹¤íŒ¨! ìˆ˜ë™ ê°œì… í•„ìš”
                    await this.alertOps({
                        severity: 'CRITICAL',
                        message: 'Saga compensation failed',
                        context,
                        error: compensationError
                    });
                }
            }
            
            throw error;
        }
    }
}

// êµ¬ì²´ì ì¸ Step êµ¬í˜„
class ChargePaymentStep implements SagaStep<OrderContext> {
    async execute(context: OrderContext): Promise<void> {
        const payment = await paymentService.charge({
            customerId: context.customerId,
            amount: context.totalAmount,
            idempotencyKey: `order-${context.orderId}-payment`
        });
        
        context.paymentId = payment.id;
        
        // ìƒíƒœ ì €ì¥ (ì¬ì‹œì‘ ê°€ëŠ¥í•˜ë„ë¡)
        await stateStore.save(context);
    }
    
    async compensate(context: OrderContext): Promise<void> {
        if (context.paymentId) {
            await paymentService.refund({
                paymentId: context.paymentId,
                reason: 'Order cancelled',
                idempotencyKey: `order-${context.orderId}-refund`
            });
        }
    }
}
```text

### 1.3 Orchestration vs Choreography: ì§€íœ˜ì vs ì¶¤

```python
# Orchestration ë°©ì‹: ì¤‘ì•™ ì§€íœ˜ì
class OrderOrchestrator:
    def __init__(self):
        self.state_machine = OrderStateMachine()
        
    async def process_order(self, order_id: str):
        state = await self.load_state(order_id)
        
        while not state.is_terminal():
            next_action = self.state_machine.get_next_action(state)
            
            try:
                result = await self.execute_action(next_action, state)
                state = self.state_machine.transition(state, result)
            except Exception as e:
                state = self.state_machine.handle_error(state, e)
            
            await self.save_state(order_id, state)
            
    async def execute_action(self, action: Action, state: State):
        if action.type == 'RESERVE_INVENTORY':
            return await inventory_service.reserve(
                items=state.order.items,
                correlation_id=state.correlation_id
            )
        elif action.type == 'CHARGE_PAYMENT':
            return await payment_service.charge(
                amount=state.order.total,
                customer_id=state.order.customer_id
            )
        # ... ë” ë§ì€ ì•¡ì…˜ë“¤

# Choreography ë°©ì‹: ì´ë²¤íŠ¸ ê¸°ë°˜ í˜‘ì—…
class InventoryService:
    @event_handler('OrderCreated')
    async def handle_order_created(self, event: OrderCreatedEvent):
        try:
            reservation = await self.reserve_items(event.items)
            
            await self.publish_event(InventoryReservedEvent(
                order_id=event.order_id,
                reservation_id=reservation.id,
                items=event.items
            ))
        except InsufficientInventoryError as e:
            await self.publish_event(InventoryReservationFailedEvent(
                order_id=event.order_id,
                reason=str(e)
            ))

class PaymentService:
    @event_handler('InventoryReserved')
    async def handle_inventory_reserved(self, event: InventoryReservedEvent):
        try:
            payment = await self.process_payment(
                order_id=event.order_id,
                amount=self.calculate_amount(event.items)
            )
            
            await self.publish_event(PaymentProcessedEvent(
                order_id=event.order_id,
                payment_id=payment.id
            ))
        except PaymentFailedError as e:
            await self.publish_event(PaymentFailedEvent(
                order_id=event.order_id,
                reason=str(e)
            ))
            
            # ë³´ìƒ ì´ë²¤íŠ¸ ë°œí–‰
            await self.publish_event(CancelInventoryReservationEvent(
                reservation_id=event.reservation_id
            ))
```text

**ë‘ ë°©ì‹ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„:**

| ì¸¡ë©´ | Orchestration | Choreography |
|------|---------------|--------------|
| ë³µì¡ë„ ê´€ë¦¬ | ì¤‘ì•™í™”ë˜ì–´ ì´í•´í•˜ê¸° ì‰¬ì›€ | ë¶„ì‚°ë˜ì–´ ì¶”ì  ì–´ë ¤ì›€ |
| ê²°í•©ë„ | ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ê°€ ëª¨ë“  ì„œë¹„ìŠ¤ ì•Œì•„ì•¼ í•¨ | ëŠìŠ¨í•œ ê²°í•© |
| í…ŒìŠ¤íŠ¸ | í†µí•© í…ŒìŠ¤íŠ¸ ì‰¬ì›€ | ê° ì„œë¹„ìŠ¤ ë…ë¦½ í…ŒìŠ¤íŠ¸ |
| ì„±ëŠ¥ | ì¶”ê°€ í™‰ í•„ìš” | ì§ì ‘ í†µì‹  |
| ì¥ì•  ì§€ì  | ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ê°€ SPOF | ë¶„ì‚°ë˜ì–´ ìˆìŒ |

## 2. Event Sourcingê³¼ CQRS: ì‹œê°„ì„ ë˜ëŒë¦¬ëŠ” ë§ˆë²•

### 2.1 Event Sourcing: ëª¨ë“  ê²ƒì„ ê¸°ë¡í•˜ë¼

```kotlin
// ì´ë²¤íŠ¸ ì •ì˜
sealed class AccountEvent {
    abstract val accountId: String
    abstract val timestamp: Instant
    abstract val version: Long
}

data class AccountCreated(
    override val accountId: String,
    override val timestamp: Instant,
    override val version: Long,
    val initialBalance: BigDecimal,
    val currency: String
) : AccountEvent()

data class MoneyDeposited(
    override val accountId: String,
    override val timestamp: Instant,
    override val version: Long,
    val amount: BigDecimal,
    val source: String
) : AccountEvent()

data class MoneyWithdrawn(
    override val accountId: String,
    override val timestamp: Instant,
    override val version: Long,
    val amount: BigDecimal,
    val reason: String
) : AccountEvent()

// Aggregate Root
class Account {
    var id: String = ""
    var balance: BigDecimal = BigDecimal.ZERO
    var version: Long = 0
    private val pendingEvents = mutableListOf<AccountEvent>()
    
    // ì´ë²¤íŠ¸ì—ì„œ ìƒíƒœ ì¬êµ¬ì„±
    fun replay(events: List<AccountEvent>) {
        events.forEach { apply(it) }
    }
    
    private fun apply(event: AccountEvent) {
        when (event) {
            is AccountCreated -> {
                id = event.accountId
                balance = event.initialBalance
            }
            is MoneyDeposited -> {
                balance = balance.add(event.amount)
            }
            is MoneyWithdrawn -> {
                balance = balance.subtract(event.amount)
            }
        }
        version = event.version
    }
    
    // ëª…ë ¹ ì²˜ë¦¬
    fun deposit(amount: BigDecimal, source: String): List<AccountEvent> {
        if (amount <= BigDecimal.ZERO) {
            throw IllegalArgumentException("Amount must be positive")
        }
        
        val event = MoneyDeposited(
            accountId = id,
            timestamp = Instant.now(),
            version = version + 1,
            amount = amount,
            source = source
        )
        
        apply(event)
        pendingEvents.add(event)
        return listOf(event)
    }
    
    fun withdraw(amount: BigDecimal, reason: String): List<AccountEvent> {
        if (amount > balance) {
            throw InsufficientFundsException()
        }
        
        val event = MoneyWithdrawn(
            accountId = id,
            timestamp = Instant.now(),
            version = version + 1,
            amount = amount,
            reason = reason
        )
        
        apply(event)
        pendingEvents.add(event)
        return listOf(event)
    }
}

// Event Store
class EventStore {
    private val events = mutableMapOf<String, MutableList<AccountEvent>>()
    
    suspend fun append(
        streamId: String, 
        events: List<AccountEvent>, 
        expectedVersion: Long
    ) {
        val stream = this.events.getOrPut(streamId) { mutableListOf() }
        
        // Optimistic concurrency control
        if (stream.isNotEmpty() && stream.last().version != expectedVersion) {
            throw ConcurrencyException(
                "Expected version $expectedVersion but was ${stream.last().version}"
            )
        }
        
        stream.addAll(events)
        
        // ì´ë²¤íŠ¸ ë°œí–‰
        events.forEach { event ->
            eventBus.publish(event)
        }
    }
    
    suspend fun load(streamId: String, fromVersion: Long = 0): List<AccountEvent> {
        return events[streamId]
            ?.filter { it.version >= fromVersion }
            ?: emptyList()
    }
    
    // ìŠ¤ëƒ…ìƒ· ì§€ì›
    suspend fun loadWithSnapshot(streamId: String): Pair<Account?, List<AccountEvent>> {
        val snapshot = snapshotStore.getLatest(streamId)
        val events = if (snapshot != null) {
            load(streamId, snapshot.version + 1)
        } else {
            load(streamId)
        }
        
        return snapshot to events
    }
}
```text

### 2.2 CQRS: ì½ê¸°ì™€ ì“°ê¸°ì˜ ë¶„ë¦¬

```typescript
// Command Side (ì“°ê¸° ëª¨ë¸)
class OrderCommandHandler {
    constructor(
        private eventStore: EventStore,
        private repository: OrderRepository
    ) {}
    
    async handle(command: CreateOrderCommand): Promise<void> {
        // ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê²€ì¦
        const customer = await this.repository.getCustomer(command.customerId);
        if (!customer.isActive) {
            throw new CustomerInactiveError();
        }
        
        // Aggregate ìƒì„±
        const order = Order.create(command);
        
        // ì´ë²¤íŠ¸ ì €ì¥
        await this.eventStore.append(
            order.id,
            order.getUncommittedEvents()
        );
    }
}

// Query Side (ì½ê¸° ëª¨ë¸)
class OrderProjection {
    @EventHandler(OrderCreatedEvent)
    async handleOrderCreated(event: OrderCreatedEvent): Promise<void> {
        // ì½ê¸° ìµœì í™”ëœ ë·° ìƒì„±
        await this.db.orders.insert({
            id: event.orderId,
            customerId: event.customerId,
            status: 'CREATED',
            totalAmount: event.items.reduce((sum, item) => 
                sum + item.price * item.quantity, 0
            ),
            createdAt: event.timestamp
        });
        
        // ê²€ìƒ‰ìš© Elasticsearch ì¸ë±ì‹±
        await this.elasticsearch.index({
            index: 'orders',
            id: event.orderId,
            body: {
                customerId: event.customerId,
                items: event.items.map(i => i.name),
                timestamp: event.timestamp
            }
        });
        
        // ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œìš© Redis ì—…ë°ì´íŠ¸
        await this.redis.hincrby('stats:orders', 'total', 1);
        await this.redis.zadd(
            'recent_orders',
            Date.now(),
            event.orderId
        );
    }
    
    @EventHandler(OrderShippedEvent)
    async handleOrderShipped(event: OrderShippedEvent): Promise<void> {
        // ì—¬ëŸ¬ ì½ê¸° ëª¨ë¸ ë™ì‹œ ì—…ë°ì´íŠ¸
        await Promise.all([
            // RDBMS ì—…ë°ì´íŠ¸
            this.db.orders.update(
                { id: event.orderId },
                { status: 'SHIPPED', shippedAt: event.timestamp }
            ),
            
            // Graph DB ì—…ë°ì´íŠ¸ (ë°°ì†¡ ê²½ë¡œ)
            this.neo4j.run(`
                MATCH (o:Order {id: $orderId})
                CREATE (s:Shipment {
                    trackingNumber: $trackingNumber,
                    carrier: $carrier
                })
                CREATE (o)-[:SHIPPED_BY]->(s)
            `, event),
            
            // Time-series DB ì—…ë°ì´íŠ¸ (ë©”íŠ¸ë¦­)
            this.influxdb.writePoint({
                measurement: 'order_lifecycle',
                tags: { status: 'shipped' },
                fields: { duration: event.processingTime },
                timestamp: event.timestamp
            })
        ]);
    }
}

// ì½ê¸° ì¿¼ë¦¬ í•¸ë“¤ëŸ¬
class OrderQueryHandler {
    async getOrderDetails(orderId: string): Promise<OrderView> {
        // ì½ê¸° ìµœì í™”ëœ ë·°ì—ì„œ ì§ì ‘ ì¡°íšŒ
        const order = await this.db.orders.findOne({ id: orderId });
        
        // í•„ìš”ì‹œ ì—¬ëŸ¬ ì†ŒìŠ¤ ì¡°í•©
        const [shipment, customer, items] = await Promise.all([
            this.db.shipments.findOne({ orderId }),
            this.db.customers.findOne({ id: order.customerId }),
            this.db.orderItems.find({ orderId })
        ]);
        
        return {
            ...order,
            shipment,
            customer,
            items
        };
    }
    
    async searchOrders(criteria: SearchCriteria): Promise<OrderView[]> {
        // Elasticsearchì—ì„œ ë³µì¡í•œ ê²€ìƒ‰
        const results = await this.elasticsearch.search({
            index: 'orders',
            body: {
                query: {
                    bool: {
                        must: criteria.toElasticQuery()
                    }
                },
                aggregations: {
                    by_status: {
                        terms: { field: 'status' }
                    }
                }
            }
        });
        
        return results.hits.hits.map(hit => hit._source);
    }
}
```text

### 2.3 Eventual Consistency ì²˜ë¦¬

```javascript
// Consistency Boundary ê´€ë¦¬
class ConsistencyManager {
    constructor() {
        this.pendingUpdates = new Map();
        this.retryPolicy = new ExponentialBackoff();
    }
    
    async ensureConsistency(aggregateId, updateFunc) {
        const key = `${aggregateId}:${Date.now()}`;
        
        try {
            // 1. Command side ì—…ë°ì´íŠ¸
            const events = await updateFunc();
            
            // 2. ì´ë²¤íŠ¸ ë°œí–‰
            await this.publishEvents(events);
            
            // 3. Read model ì—…ë°ì´íŠ¸ ì¶”ì 
            this.pendingUpdates.set(key, {
                events,
                status: 'PENDING',
                attempts: 0
            });
            
            // 4. ë¹„ë™ê¸°ë¡œ ì¼ê´€ì„± í™•ì¸
            this.scheduleConsistencyCheck(key);
            
        } catch (error) {
            await this.handleInconsistency(key, error);
        }
    }
    
    async scheduleConsistencyCheck(key) {
        const update = this.pendingUpdates.get(key);
        
        setTimeout(async () => {
            const isConsistent = await this.checkReadModelConsistency(
                update.events
            );
            
            if (isConsistent) {
                this.pendingUpdates.delete(key);
            } else {
                update.attempts++;
                
                if (update.attempts < this.retryPolicy.maxAttempts) {
                    // ì¬ì‹œë„
                    const delay = this.retryPolicy.getDelay(update.attempts);
                    setTimeout(() => this.scheduleConsistencyCheck(key), delay);
                } else {
                    // ìˆ˜ë™ ê°œì… í•„ìš”
                    await this.alertInconsistency(key, update);
                }
            }
        }, 1000);  // 1ì´ˆ í›„ í™•ì¸
    }
    
    async checkReadModelConsistency(events) {
        // ëª¨ë“  read modelì´ ì—…ë°ì´íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸
        const checks = await Promise.all([
            this.checkDatabase(events),
            this.checkElasticsearch(events),
            this.checkCache(events)
        ]);
        
        return checks.every(check => check === true);
    }
}
```text

## 3. ë©”ì‹œì§€ íì™€ ìŠ¤íŠ¸ë¦¬ë°: ë¹„ë™ê¸° í†µì‹ ì˜ ì¤‘ì¶”

### 3.1 Kafkaë¥¼ ì´ìš©í•œ Event Streaming

```java
// Kafka Producer with ì™„ë²½í•œ ì„¤ì •
@Component
public class ReliableKafkaProducer {
    private final KafkaProducer<String, byte[]> producer;
    private final ObjectMapper objectMapper;
    
    public ReliableKafkaProducer() {
        Properties props = new Properties();
        
        // ì‹ ë¢°ì„± ì„¤ì •
        props.put(ProducerConfig.ACKS_CONFIG, "all");  // ëª¨ë“  replica í™•ì¸
        props.put(ProducerConfig.RETRIES_CONFIG, Integer.MAX_VALUE);
        props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 5);
        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);  // ì¤‘ë³µ ë°©ì§€
        
        // ì„±ëŠ¥ ì„¤ì •
        props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy");
        props.put(ProducerConfig.LINGER_MS_CONFIG, 20);  // ë°°ì¹˜ ì²˜ë¦¬
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, 32768);
        
        // ì—ëŸ¬ ì²˜ë¦¬
        props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, 30000);
        props.put(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG, 120000);
        
        this.producer = new KafkaProducer<>(props);
    }
    
    public CompletableFuture<RecordMetadata> sendEvent(
        String topic,
        String key,
        Object event,
        Map<String, String> headers
    ) {
        CompletableFuture<RecordMetadata> future = new CompletableFuture<>();
        
        try {
            // ì´ë²¤íŠ¸ ì§ë ¬í™”
            byte[] value = objectMapper.writeValueAsBytes(event);
            
            // í—¤ë” ì¶”ê°€
            ProducerRecord<String, byte[]> record = 
                new ProducerRecord<>(topic, key, value);
            
            headers.forEach((k, v) -> 
                record.headers().add(k, v.getBytes())
            );
            
            // íŠ¸ë ˆì´ì‹± ì •ë³´
            record.headers().add("trace-id", 
                MDC.get("traceId").getBytes());
            record.headers().add("timestamp", 
                String.valueOf(System.currentTimeMillis()).getBytes());
            
            // ë¹„ë™ê¸° ì „ì†¡
            producer.send(record, (metadata, exception) -> {
                if (exception != null) {
                    // Dead Letter Queueë¡œ ì „ì†¡
                    sendToDeadLetter(record, exception);
                    future.completeExceptionally(exception);
                } else {
                    // ë©”íŠ¸ë¦­ ê¸°ë¡
                    recordMetrics(metadata);
                    future.complete(metadata);
                }
            });
            
        } catch (Exception e) {
            future.completeExceptionally(e);
        }
        
        return future;
    }
    
    private void sendToDeadLetter(ProducerRecord<String, byte[]> record, 
                                  Exception exception) {
        String dlqTopic = record.topic() + ".dlq";
        
        ProducerRecord<String, byte[]> dlqRecord = 
            new ProducerRecord<>(dlqTopic, record.key(), record.value());
        
        // ì—ëŸ¬ ì •ë³´ ì¶”ê°€
        dlqRecord.headers().add("original-topic", 
            record.topic().getBytes());
        dlqRecord.headers().add("error-message", 
            exception.getMessage().getBytes());
        dlqRecord.headers().add("error-timestamp", 
            String.valueOf(System.currentTimeMillis()).getBytes());
        
        producer.send(dlqRecord);
    }
}

// Kafka Consumer with exactly-once semantics
@Component
public class ExactlyOnceKafkaConsumer {
    private final KafkaConsumer<String, byte[]> consumer;
    private final TransactionManager txManager;
    
    public ExactlyOnceKafkaConsumer() {
        Properties props = new Properties();
        
        // Exactly-once ì„¤ì •
        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, "read_committed");
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
        
        // ì„±ëŠ¥ê³¼ ì‹ ë¢°ì„± ê· í˜•
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 100);
        props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 300000);
        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 30000);
        
        this.consumer = new KafkaConsumer<>(props);
    }
    
    public void consume(List<String> topics) {
        consumer.subscribe(topics);
        
        while (true) {
            ConsumerRecords<String, byte[]> records = 
                consumer.poll(Duration.ofMillis(100));
            
            if (!records.isEmpty()) {
                processRecords(records);
            }
        }
    }
    
    private void processRecords(ConsumerRecords<String, byte[]> records) {
        Map<TopicPartition, OffsetAndMetadata> offsetsToCommit = 
            new HashMap<>();
        
        for (ConsumerRecord<String, byte[]> record : records) {
            try {
                // íŠ¸ëœì­ì…˜ ì‹œì‘
                txManager.begin();
                
                // Idempotency ì²´í¬
                if (!isAlreadyProcessed(record)) {
                    // ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬
                    processRecord(record);
                    
                    // ì²˜ë¦¬ ì™„ë£Œ ë§ˆí‚¹
                    markAsProcessed(record);
                }
                
                // íŠ¸ëœì­ì…˜ ì»¤ë°‹
                txManager.commit();
                
                // ì˜¤í”„ì…‹ ì €ì¥
                offsetsToCommit.put(
                    new TopicPartition(record.topic(), record.partition()),
                    new OffsetAndMetadata(record.offset() + 1)
                );
                
            } catch (Exception e) {
                // íŠ¸ëœì­ì…˜ ë¡¤ë°±
                txManager.rollback();
                
                // ì¬ì‹œë„ ë˜ëŠ” DLQ
                handleError(record, e);
            }
        }
        
        // ë°°ì¹˜ ì»¤ë°‹
        consumer.commitSync(offsetsToCommit);
    }
    
    private boolean isAlreadyProcessed(ConsumerRecord<String, byte[]> record) {
        String idempotencyKey = new String(
            record.headers().lastHeader("idempotency-key").value()
        );
        
        return idempotencyStore.exists(idempotencyKey);
    }
}
```text

### 3.2 Back-pressureì™€ Flow Control

```scala
// Akka Streamsë¥¼ ì´ìš©í•œ Back-pressure êµ¬í˜„
import akka.stream._
import akka.stream.scaladsl._

class BackPressureStream(implicit system: ActorSystem) {
  implicit val materializer: Materializer = Materializer(system)
  
  // Source: ë°ì´í„° ìƒì‚°ì
  val fastProducer = Source
    .tick(10.milliseconds, 10.milliseconds, 1)
    .map { i =>
      println(s"Producing: $i")
      Event(s"event-$i", System.currentTimeMillis())
    }
  
  // Flow: ëŠë¦° ì²˜ë¦¬ê¸°
  val slowProcessor = Flow[Event]
    .buffer(10, OverflowStrategy.backpressure)  // ë²„í¼ ì´ˆê³¼ì‹œ back-pressure
    .mapAsync(2) { event =>
      Future {
        Thread.sleep(100)  // ëŠë¦° ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        println(s"Processing: ${event.id}")
        ProcessedEvent(event.id, event.timestamp, "processed")
      }
    }
  
  // Sink: ìµœì¢… ì†Œë¹„ì
  val sink = Sink.foreach[ProcessedEvent] { processed =>
    println(s"Consumed: ${processed.id}")
  }
  
  // Stream ì‹¤í–‰
  val runnableGraph = fastProducer
    .via(slowProcessor)
    .to(sink)
  
  val result = runnableGraph.run()
  
  // Dynamic throttling
  val dynamicThrottle = Source
    .tick(1.second, 1.second, 1)
    .conflate((_, _) => 1)  // ì••ë ¥ ìƒí™©ì—ì„œ ë©”ì‹œì§€ ë³‘í•©
    .zip(fastProducer)
    .map(_._2)
    .throttle(
      elements = 100,
      per = 1.second,
      maximumBurst = 20,
      mode = ThrottleMode.Shaping
    )
}

// Reactive Streams êµ¬í˜„
class ReactiveStreamProcessor extends Processor[Event, ProcessedEvent] {
  private var subscription: Subscription = _
  private var subscriber: Subscriber[_ >: ProcessedEvent] = _
  private val buffer = new LinkedBlockingQueue[Event](100)
  private val requested = new AtomicLong(0)
  
  override def onSubscribe(s: Subscription): Unit = {
    this.subscription = s
    s.request(10)  // ì´ˆê¸° ìš”ì²­
  }
  
  override def onNext(event: Event): Unit = {
    if (!buffer.offer(event)) {
      // ë²„í¼ ê°€ë“ ì°¸ - back-pressure ì‹ í˜¸
      subscription.cancel()
      onError(new BufferOverflowException())
    } else {
      processIfPossible()
    }
  }
  
  private def processIfPossible(): Unit = {
    while (requested.get() > 0 && !buffer.isEmpty) {
      val event = buffer.poll()
      val processed = process(event)
      
      subscriber.onNext(processed)
      requested.decrementAndGet()
      
      // ë²„í¼ì— ì—¬ìœ ê°€ ìƒê¸°ë©´ ë” ìš”ì²­
      if (buffer.size() < 50) {
        subscription.request(10)
      }
    }
  }
  
  override def subscribe(s: Subscriber[_ >: ProcessedEvent]): Unit = {
    this.subscriber = s
    s.onSubscribe(new Subscription {
      override def request(n: Long): Unit = {
        requested.addAndGet(n)
        processIfPossible()
      }
      
      override def cancel(): Unit = {
        subscription.cancel()
      }
    })
  }
}
```text

## 4. Circuit Breakerì™€ Resilience Patterns

### 4.1 Circuit Breaker êµ¬í˜„

```python
from enum import Enum
from datetime import datetime, timedelta
import asyncio
from typing import Callable, Any, Optional
import logging

class CircuitState(Enum):
    CLOSED = "closed"
    OPEN = "open"
    HALF_OPEN = "half_open"

class CircuitBreaker:
    def __init__(
        self,
        failure_threshold: int = 5,
        recovery_timeout: int = 60,
        expected_exception: type = Exception
    ):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.expected_exception = expected_exception
        
        self.failure_count = 0
        self.last_failure_time: Optional[datetime] = None
        self.state = CircuitState.CLOSED
        
        # ë©”íŠ¸ë¦­
        self.total_calls = 0
        self.successful_calls = 0
        self.failed_calls = 0
        
    async def call(self, func: Callable, *args, **kwargs) -> Any:
        self.total_calls += 1
        
        # Circuitì´ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸
        if self.state == CircuitState.OPEN:
            if self._should_attempt_reset():
                self.state = CircuitState.HALF_OPEN
            else:
                self.failed_calls += 1
                raise CircuitOpenError(
                    f"Circuit breaker is OPEN. "
                    f"Retry after {self._time_until_reset()} seconds"
                )
        
        try:
            # ì‹¤ì œ í•¨ìˆ˜ í˜¸ì¶œ
            result = await func(*args, **kwargs)
            self._on_success()
            return result
            
        except self.expected_exception as e:
            self._on_failure()
            raise e
    
    def _should_attempt_reset(self) -> bool:
        return (
            self.last_failure_time and
            datetime.now() >= self.last_failure_time + 
            timedelta(seconds=self.recovery_timeout)
        )
    
    def _time_until_reset(self) -> int:
        if not self.last_failure_time:
            return 0
        
        elapsed = datetime.now() - self.last_failure_time
        remaining = self.recovery_timeout - elapsed.total_seconds()
        return max(0, int(remaining))
    
    def _on_success(self):
        self.successful_calls += 1
        
        if self.state == CircuitState.HALF_OPEN:
            # Half-openì—ì„œ ì„±ê³µ -> Circuit ë‹«ê¸°
            self.state = CircuitState.CLOSED
            self.failure_count = 0
            logging.info("Circuit breaker closed after successful call")
    
    def _on_failure(self):
        self.failed_calls += 1
        self.failure_count += 1
        self.last_failure_time = datetime.now()
        
        if self.failure_count >= self.failure_threshold:
            self.state = CircuitState.OPEN
            logging.error(
                f"Circuit breaker opened after {self.failure_count} failures"
            )
        
        if self.state == CircuitState.HALF_OPEN:
            # Half-openì—ì„œ ì‹¤íŒ¨ -> ë‹¤ì‹œ ì—´ê¸°
            self.state = CircuitState.OPEN
            logging.warning("Circuit breaker reopened after failure in half-open")
    
    def get_state(self) -> dict:
        return {
            "state": self.state.value,
            "failure_count": self.failure_count,
            "total_calls": self.total_calls,
            "successful_calls": self.successful_calls,
            "failed_calls": self.failed_calls,
            "success_rate": (
                self.successful_calls / self.total_calls 
                if self.total_calls > 0 else 0
            )
        }

# ì‚¬ìš© ì˜ˆì œ
class PaymentService:
    def __init__(self):
        self.circuit_breaker = CircuitBreaker(
            failure_threshold=3,
            recovery_timeout=30,
            expected_exception=PaymentGatewayError
        )
    
    async def process_payment(self, amount: float, card: str) -> str:
        return await self.circuit_breaker.call(
            self._call_payment_gateway,
            amount,
            card
        )
    
    async def _call_payment_gateway(self, amount: float, card: str) -> str:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://payment-gateway.com/charge",
                json={"amount": amount, "card": card},
                timeout=aiohttp.ClientTimeout(total=5)
            ) as response:
                if response.status != 200:
                    raise PaymentGatewayError(f"Status: {response.status}")
                
                return await response.json()
```text

### 4.2 Bulkhead Pattern: ê²©ë¦¬ì˜ ë¯¸í•™

```java
// Thread Pool Bulkhead
@Component
public class BulkheadManager {
    private final Map<String, ThreadPoolExecutor> bulkheads = 
        new ConcurrentHashMap<>();
    
    public BulkheadManager() {
        // ì„œë¹„ìŠ¤ë³„ ê²©ë¦¬ëœ ìŠ¤ë ˆë“œ í’€
        bulkheads.put("payment", createBulkhead(10, 20, 100));
        bulkheads.put("inventory", createBulkhead(5, 10, 50));
        bulkheads.put("shipping", createBulkhead(5, 10, 50));
        bulkheads.put("notification", createBulkhead(2, 5, 20));
    }
    
    private ThreadPoolExecutor createBulkhead(
        int coreSize, 
        int maxSize, 
        int queueCapacity
    ) {
        return new ThreadPoolExecutor(
            coreSize,
            maxSize,
            60L, TimeUnit.SECONDS,
            new LinkedBlockingQueue<>(queueCapacity),
            new ThreadPoolExecutor.CallerRunsPolicy()  // Back-pressure
        );
    }
    
    public <T> CompletableFuture<T> execute(
        String bulkheadName,
        Callable<T> task
    ) {
        ThreadPoolExecutor executor = bulkheads.get(bulkheadName);
        
        if (executor == null) {
            throw new IllegalArgumentException(
                "Unknown bulkhead: " + bulkheadName
            );
        }
        
        // ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        recordMetrics(bulkheadName, executor);
        
        // ê²©ë¦¬ëœ ì‹¤í–‰
        CompletableFuture<T> future = new CompletableFuture<>();
        
        executor.submit(() -> {
            try {
                T result = task.call();
                future.complete(result);
            } catch (Exception e) {
                future.completeExceptionally(e);
            }
        });
        
        return future;
    }
    
    private void recordMetrics(String name, ThreadPoolExecutor executor) {
        Metrics.gauge("bulkhead.active", executor.getActiveCount())
            .tag("bulkhead", name);
        
        Metrics.gauge("bulkhead.queue.size", executor.getQueue().size())
            .tag("bulkhead", name);
        
        Metrics.gauge("bulkhead.pool.size", executor.getPoolSize())
            .tag("bulkhead", name);
        
        // í¬í™” ìƒíƒœ ê°ì§€
        if (executor.getQueue().remainingCapacity() == 0) {
            Metrics.counter("bulkhead.saturated")
                .tag("bulkhead", name)
                .increment();
        }
    }
}

// Semaphore Bulkhead (ë” ê°€ë²¼ìš´ ê²©ë¦¬)
public class SemaphoreBulkhead {
    private final Semaphore semaphore;
    private final String name;
    private final AtomicInteger activeCount = new AtomicInteger(0);
    
    public SemaphoreBulkhead(String name, int maxConcurrency) {
        this.name = name;
        this.semaphore = new Semaphore(maxConcurrency);
    }
    
    public <T> T execute(Supplier<T> supplier) throws BulkheadFullException {
        boolean acquired = false;
        
        try {
            acquired = semaphore.tryAcquire(100, TimeUnit.MILLISECONDS);
            
            if (!acquired) {
                throw new BulkheadFullException(
                    "Bulkhead " + name + " is full"
                );
            }
            
            activeCount.incrementAndGet();
            return supplier.get();
            
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            throw new RuntimeException(e);
        } finally {
            if (acquired) {
                activeCount.decrementAndGet();
                semaphore.release();
            }
        }
    }
}
```text

### 4.3 Retryì™€ Timeout ì „ëµ

```kotlin
// ìŠ¤ë§ˆíŠ¸í•œ Retry ì „ëµ
class SmartRetryPolicy {
    private val logger = LoggerFactory.getLogger(javaClass)
    
    suspend fun <T> executeWithRetry(
        maxAttempts: Int = 3,
        initialDelay: Duration = Duration.ofMillis(100),
        maxDelay: Duration = Duration.ofSeconds(10),
        backoffMultiplier: Double = 2.0,
        jitterFactor: Double = 0.1,
        retryableExceptions: Set<Class<out Exception>> = setOf(
            IOException::class.java,
            TimeoutException::class.java
        ),
        operation: suspend () -> T
    ): T {
        var currentDelay = initialDelay
        var lastException: Exception? = null
        
        repeat(maxAttempts) { attempt ->
            try {
                // Circuit breaker í†µí•©
                if (shouldCircuitBreak(attempt)) {
                    throw CircuitOpenException()
                }
                
                // Timeout ì ìš©
                return withTimeout(calculateTimeout(attempt)) {
                    operation()
                }
                
            } catch (e: Exception) {
                lastException = e
                
                // ì¬ì‹œë„ ê°€ëŠ¥í•œ ì˜ˆì™¸ì¸ì§€ í™•ì¸
                if (!isRetryable(e, retryableExceptions)) {
                    throw e
                }
                
                // ë§ˆì§€ë§‰ ì‹œë„ì˜€ë‹¤ë©´ ì˜ˆì™¸ ë°œìƒ
                if (attempt == maxAttempts - 1) {
                    throw RetryExhaustedException(
                        "Failed after $maxAttempts attempts",
                        e
                    )
                }
                
                // ì§€ìˆ˜ ë°±ì˜¤í”„ + ì§€í„°
                val jitter = (Random.nextDouble() * 2 - 1) * jitterFactor
                val delayMillis = (currentDelay.toMillis() * (1 + jitter)).toLong()
                
                logger.warn(
                    "Attempt ${attempt + 1} failed: ${e.message}. " +
                    "Retrying in ${delayMillis}ms..."
                )
                
                delay(delayMillis)
                
                // ë‹¤ìŒ ì§€ì—° ì‹œê°„ ê³„ì‚°
                currentDelay = Duration.ofMillis(
                    min(
                        (currentDelay.toMillis() * backoffMultiplier).toLong(),
                        maxDelay.toMillis()
                    )
                )
            }
        }
        
        throw lastException!!
    }
    
    private fun isRetryable(
        exception: Exception,
        retryableExceptions: Set<Class<out Exception>>
    ): Boolean {
        // íŠ¹ì • ì—ëŸ¬ ì½”ë“œëŠ” ì¬ì‹œë„ ë¶ˆê°€
        if (exception is HttpException) {
            return exception.code() !in listOf(400, 401, 403, 404)
        }
        
        return retryableExceptions.any { it.isInstance(exception) }
    }
    
    private fun calculateTimeout(attempt: Int): Duration {
        // ì‹œë„ íšŸìˆ˜ì— ë”°ë¼ íƒ€ì„ì•„ì›ƒ ì¦ê°€
        return Duration.ofSeconds(5L * (attempt + 1))
    }
    
    private fun shouldCircuitBreak(attempt: Int): Boolean {
        // ì—°ì† ì‹¤íŒ¨ê°€ ë§ìœ¼ë©´ circuit break
        return getRecentFailureRate() > 0.8 && attempt > 1
    }
}

// Hedged Requests (ì—¬ëŸ¬ ìš”ì²­ ë™ì‹œ ì‹¤í–‰)
class HedgedRequestExecutor {
    suspend fun <T> executeHedged(
        primaryOperation: suspend () -> T,
        fallbackOperations: List<suspend () -> T>,
        hedgeDelay: Duration = Duration.ofMillis(200)
    ): T = coroutineScope {
        val results = Channel<Result<T>>()
        
        // Primary ìš”ì²­
        launch {
            try {
                val result = primaryOperation()
                results.send(Result.success(result))
            } catch (e: Exception) {
                results.send(Result.failure(e))
            }
        }
        
        // Hedge ìš”ì²­ë“¤
        fallbackOperations.forEach { operation ->
            launch {
                delay(hedgeDelay.toMillis())
                
                // ì´ë¯¸ ì„±ê³µí–ˆìœ¼ë©´ ì‹¤í–‰ ì•ˆ í•¨
                if (!results.isClosedForSend) {
                    try {
                        val result = operation()
                        results.send(Result.success(result))
                    } catch (e: Exception) {
                        results.send(Result.failure(e))
                    }
                }
            }
        }
        
        // ì²« ë²ˆì§¸ ì„±ê³µ ë°˜í™˜
        var failures = 0
        for (result in results) {
            if (result.isSuccess) {
                results.close()
                return@coroutineScope result.getOrThrow()
            }
            
            failures++
            if (failures == fallbackOperations.size + 1) {
                throw AllRequestsFailedException()
            }
        }
        
        throw IllegalStateException("No results received")
    }
}
```text

## 5. ì‹¤ì „ ì‚¬ë¡€: ëŒ€ê·œëª¨ ì´ì»¤ë¨¸ìŠ¤ ì‹œìŠ¤í…œ

### 5.1 ì£¼ë¬¸ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì „ì²´ êµ¬ì¡°

```yaml
# docker-compose.ymlë¡œ ë³´ëŠ” ì „ì²´ ì•„í‚¤í…ì²˜
version: '3.8'

services:
  # API Gateway
  api-gateway:
    image: kong:latest
    environment:
      - KONG_DATABASE=postgres
      - KONG_PG_HOST=kong-db
    ports:
      - "8000:8000"
    depends_on:
      - kong-db
  
  # Order Service (Orchestrator)
  order-service:
    build: ./order-service
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - kafka
      - postgres
  
  # Inventory Service
  inventory-service:
    build: ./inventory-service
    environment:
      - DB_HOST=inventory-db
      - REDIS_HOST=redis
    depends_on:
      - inventory-db
      - redis
  
  # Payment Service
  payment-service:
    build: ./payment-service
    environment:
      - STRIPE_API_KEY=${STRIPE_API_KEY}
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 512M
  
  # Kafka
  kafka:
    image: confluentinc/cp-kafka:latest
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=3
    depends_on:
      - zookeeper
  
  # Event Store
  eventstore:
    image: eventstore/eventstore:latest
    environment:
      - EVENTSTORE_CLUSTER_SIZE=3
      - EVENTSTORE_RUN_PROJECTIONS=All
    ports:
      - "2113:2113"
  
  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
  
  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "3000:3000"
```text

### 5.2 Production ì¥ì•  ëŒ€ì‘ ì‚¬ë¡€

```python
# ì‹¤ì œ ì¥ì•  ìƒí™©ê³¼ í•´ê²°
class ProductionIncidentHandler:
    """
    2023ë…„ ë¸”ë™í”„ë¼ì´ë°ì´ ì‹¤ì œ ì¥ì•  ëŒ€ì‘ ì½”ë“œ
    - íŠ¸ë˜í”½: í‰ì†Œ ëŒ€ë¹„ 50ë°° (ì´ˆë‹¹ 10ë§Œ ìš”ì²­)
    - ì¥ì• : Payment ì„œë¹„ìŠ¤ ì‘ë‹µ ì§€ì—°ìœ¼ë¡œ ì „ì²´ ì‹œìŠ¤í…œ ë§ˆë¹„
    """
    
    def __init__(self):
        # 1. Circuit Breaker ì¦‰ì‹œ ì ìš©
        self.payment_circuit = CircuitBreaker(
            failure_threshold=10,  # 10ë²ˆ ì‹¤íŒ¨ì‹œ open
            recovery_timeout=30,    # 30ì´ˆ í›„ ì¬ì‹œë„
            expected_exception=PaymentTimeoutError
        )
        
        # 2. Bulkheadë¡œ ê²©ë¦¬
        self.payment_semaphore = asyncio.Semaphore(20)  # ë™ì‹œ 20ê°œë§Œ
        
        # 3. Cache ì ê·¹ í™œìš©
        self.cache = Redis(
            host='redis-cluster',
            decode_responses=True,
            socket_keepalive=True,
            socket_keepalive_options={
                1: 1,  # TCP_KEEPIDLE
                2: 1,  # TCP_KEEPINTVL
                3: 3,  # TCP_KEEPCNT
            }
        )
        
        # 4. Rate Limiting
        self.rate_limiter = SlidingWindowRateLimiter(
            max_requests=1000,
            window_seconds=1
        )
    
    async def handle_order(self, order: Order) -> OrderResult:
        # Step 1: Rate Limiting
        if not await self.rate_limiter.allow(order.customer_id):
            # 429 Too Many Requests
            return OrderResult(
                status="RATE_LIMITED",
                message="Please try again later"
            )
        
        # Step 2: Cache Hit í™•ì¸
        cached = await self.cache.get(f"order:{order.id}")
        if cached:
            return OrderResult.from_json(cached)
        
        # Step 3: Inventory í™•ì¸ (ë¹ ë¥¸ ì‹¤íŒ¨)
        if not await self.check_inventory_fast(order):
            return OrderResult(
                status="OUT_OF_STOCK",
                message="Some items are out of stock"
            )
        
        # Step 4: Payment ì²˜ë¦¬ (Circuit Breaker + Bulkhead)
        try:
            async with self.payment_semaphore:
                payment_result = await self.payment_circuit.call(
                    self.process_payment_with_timeout,
                    order
                )
        except CircuitOpenError:
            # Circuitì´ ì—´ë¦¼ - Fallback
            return await self.fallback_payment_queue(order)
        except asyncio.TimeoutError:
            # Timeout - ë¹„ë™ê¸° íë¡œ ì „í™˜
            return await self.async_payment_queue(order)
        
        # Step 5: ê²°ê³¼ ìºì‹±
        result = OrderResult(
            status="SUCCESS",
            order_id=order.id,
            payment_id=payment_result.id
        )
        
        await self.cache.setex(
            f"order:{order.id}",
            300,  # 5ë¶„ ìºì‹œ
            result.to_json()
        )
        
        return result
    
    async def process_payment_with_timeout(self, order: Order):
        # Adaptive timeout
        timeout = self.calculate_adaptive_timeout()
        
        async with async_timeout.timeout(timeout):
            return await self.payment_service.charge(order)
    
    def calculate_adaptive_timeout(self) -> float:
        # ìµœê·¼ ì‘ë‹µ ì‹œê°„ ê¸°ë°˜ ë™ì  íƒ€ì„ì•„ì›ƒ
        p99_latency = self.metrics.get_p99_latency("payment")
        
        if p99_latency < 1.0:
            return 2.0  # ì •ìƒ: 2ì´ˆ
        elif p99_latency < 3.0:
            return 5.0  # ì•½ê°„ ëŠë¦¼: 5ì´ˆ
        else:
            return 10.0  # ë§¤ìš° ëŠë¦¼: 10ì´ˆ
    
    async def fallback_payment_queue(self, order: Order) -> OrderResult:
        """
        Payment ì„œë¹„ìŠ¤ ì¥ì• ì‹œ Fallback
        ì£¼ë¬¸ì„ íì— ë„£ê³  ë‚˜ì¤‘ì— ì²˜ë¦¬
        """
        await self.kafka_producer.send(
            topic="payment.retry.queue",
            key=order.customer_id,
            value={
                "order": order.to_dict(),
                "timestamp": datetime.now().isoformat(),
                "retry_count": 0
            }
        )
        
        return OrderResult(
            status="PENDING_PAYMENT",
            message="Your order is being processed. You'll receive confirmation soon."
        )
    
    async def check_inventory_fast(self, order: Order) -> bool:
        """
        ë¹ ë¥¸ ì¬ê³  í™•ì¸ (ìºì‹œ ìš°ì„ )
        """
        for item in order.items:
            # 1. ë¡œì»¬ ìºì‹œ í™•ì¸
            cached_stock = await self.cache.get(f"stock:{item.sku}")
            
            if cached_stock is not None:
                if int(cached_stock) < item.quantity:
                    return False
            else:
                # 2. ìºì‹œ ë¯¸ìŠ¤ì‹œ ë¹„ë™ê¸° ì—…ë°ì´íŠ¸
                asyncio.create_task(
                    self.update_stock_cache(item.sku)
                )
                
                # 3. ì¼ë‹¨ í†µê³¼ (optimistic)
                continue
        
        return True
    
    async def monitor_health(self):
        """
        ì‹œìŠ¤í…œ í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§
        """
        while True:
            metrics = {
                "circuit_state": self.payment_circuit.state.value,
                "circuit_failure_count": self.payment_circuit.failure_count,
                "semaphore_available": self.payment_semaphore._value,
                "cache_hit_rate": await self.calculate_cache_hit_rate(),
                "rate_limit_rejections": self.rate_limiter.rejection_count,
                "queue_depth": await self.get_queue_depth()
            }
            
            # Prometheusì— ë©”íŠ¸ë¦­ ì „ì†¡
            for key, value in metrics.items():
                prometheus_client.Gauge(key).set(value)
            
            # ì„ê³„ì¹˜ ì´ˆê³¼ì‹œ ì•Œë¦¼
            if metrics["circuit_failure_count"] > 50:
                await self.send_alert(
                    "Payment service experiencing high failure rate",
                    severity="HIGH"
                )
            
            await asyncio.sleep(10)
```text

## 6. ë§ˆë¬´ë¦¬: ë¶„ì‚° ë¹„ë™ê¸°ì˜ ë¯¸ë˜

ë¶„ì‚° ì‹œìŠ¤í…œì˜ ë¹„ë™ê¸° íŒ¨í„´ì„ ë§ˆìŠ¤í„°í•œë‹¤ëŠ” ê²ƒì€:

1. **Trade-off ì´í•´**: CAP ì •ë¦¬, ì¼ê´€ì„± vs ê°€ìš©ì„±
2. **ì¥ì•  ì˜ˆìƒ**: Everything fails, all the time
3. **ê´€ì°° ê°€ëŠ¥ì„±**: ë¶„ì‚° íŠ¸ë ˆì´ì‹±, ë©”íŠ¸ë¦­, ë¡œê·¸ í†µí•©
4. **ìë™í™”**: Self-healing, auto-scaling

ì œê°€ 10ë…„ê°„ ë¶„ì‚° ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë©° ë°°ìš´ êµí›ˆ:

> "ë¶„ì‚° ì‹œìŠ¤í…œì—ì„œ ê°€ì¥ ì–´ë ¤ìš´ ê²ƒì€ ê¸°ìˆ ì´ ì•„ë‹ˆë¼ ë³µì¡ì„± ê´€ë¦¬ë‹¤.
> ë‹¨ìˆœí•¨ì„ ìœ ì§€í•˜ë˜, í•„ìš”í•œ ë³µì¡ì„±ì€ ë°›ì•„ë“¤ì—¬ë¼."

**ì‹¤ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸:**

- [ ] Idempotency ë³´ì¥
- [ ] Circuit Breaker êµ¬í˜„
- [ ] Retry with backoff
- [ ] Distributed tracing
- [ ] Graceful degradation
- [ ] Chaos engineering

ì´ì œ ì—¬ëŸ¬ë¶„ì€ Netflix, Uber, Airbnb ê°™ì€ íšŒì‚¬ë“¤ì´ ì‚¬ìš©í•˜ëŠ” íŒ¨í„´ë“¤ì„ ì´í•´í•˜ê³  êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì±•í„°ì—ì„œëŠ” ì´ëŸ° ì‹œìŠ¤í…œë“¤ì˜ ë©”ëª¨ë¦¬ ê´€ë¦¬ì™€ GC ìµœì í™”ë¥¼ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤!

## ì°¸ê³  ìë£Œ

- [Saga Pattern](https://microservices.io/patterns/data/saga.html) - Chris Richardson
- [Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html) - Martin Fowler
- [Reactive Manifesto](https://www.reactivemanifesto.org/)
- [Circuit Breaker](https://martinfowler.com/bliki/CircuitBreaker.html) - Martin Fowler
- [Building Event-Driven Microservices](https://www.confluent.io/resources/ebook/building-event-driven-microservices/) - Adam Bellemare
